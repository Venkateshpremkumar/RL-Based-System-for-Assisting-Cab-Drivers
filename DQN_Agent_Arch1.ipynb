{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon = 1\n",
    "        # the below epsilon decay rate has been calculated from the graph as shown at the end of the file\n",
    "        self.epsilon_decay = 0.9991\n",
    "        #self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state,env):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment\n",
    "        #print(\"Get Action state is \",state)\n",
    "        possible_actions_index,actions = env.requests(state) # Find possible action indexes and append 0\n",
    "        possible_actions_index.append(0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # Give a random action only amongst possible action\n",
    "            return random.sample(possible_actions_index,1)[0]\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = state.reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            # Give action with max q_value only amongst possible action\n",
    "            return np.where(q_value[0] == np.max(np.array([q_value[0][i] for i in possible_actions_index])))[0][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state,done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state,done))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self,env):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                \n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                done.append(done_boolean)\n",
    "                update_output[i] = next_state\n",
    "                \n",
    "                # Write your code from here\n",
    "                \n",
    "            # 1. Predict the target from earlier model           \n",
    "            target = self.model.predict(update_input)\n",
    "            \n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                # Find possible actions from next state\n",
    "                next_possible_actions_index,_ = env.requests(update_output[i])\n",
    "                next_possible_actions_index.append(0)\n",
    "                if not done[i]:\n",
    "                    # Only take the max q_value from valid actions from next state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(np.array([target_qval[i][j] for j in next_possible_actions_index]))\n",
    "                else:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            #print(\"Training Model\")\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            #print(\"Model Training Model\")\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State is  [1, 4, 6]\n",
      "episode 0, reward -312.0, memory_length 123, epsilon 0.9991, time 734.0, rides 122\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1, reward -30.0, memory_length 259, epsilon 0.9982008099999999, time 730.0, rides 135\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2, reward -300.0, memory_length 398, epsilon 0.9973024292709999, time 722.0, rides 138\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3, reward -210.0, memory_length 526, epsilon 0.996404857084656, time 730.0, rides 127\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4, reward -471.0, memory_length 646, epsilon 0.9955080927132798, time 742.0, rides 119\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5, reward -356.0, memory_length 776, epsilon 0.9946121354298378, time 725.0, rides 129\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 6, reward 127.0, memory_length 905, epsilon 0.993716984507951, time 728.0, rides 128\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 7, reward -214.0, memory_length 1039, epsilon 0.9928226392218938, time 732.0, rides 133\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 8, reward -254.0, memory_length 1171, epsilon 0.9919290988465941, time 721.0, rides 131\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 9, reward -32.0, memory_length 1305, epsilon 0.9910363626576322, time 727.0, rides 133\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 10, reward -367.0, memory_length 1425, epsilon 0.9901444299312403, time 724.0, rides 119\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 11, reward -252.0, memory_length 1545, epsilon 0.9892532999443022, time 725.0, rides 119\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 12, reward -340.0, memory_length 1681, epsilon 0.9883629719743523, time 728.0, rides 135\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 13, reward -410.0, memory_length 1815, epsilon 0.9874734452995754, time 733.0, rides 133\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 14, reward -359.0, memory_length 1946, epsilon 0.9865847191988057, time 722.0, rides 130\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 15, reward -61.0, memory_length 2000, epsilon 0.9856967929515268, time 727.0, rides 132\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 16, reward -237.0, memory_length 2000, epsilon 0.9848096658378704, time 723.0, rides 123\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 17, reward -187.0, memory_length 2000, epsilon 0.9839233371386163, time 721.0, rides 132\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 18, reward -339.0, memory_length 2000, epsilon 0.9830378061351915, time 730.0, rides 128\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 19, reward -164.0, memory_length 2000, epsilon 0.9821530721096698, time 725.0, rides 137\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 20, reward -308.0, memory_length 2000, epsilon 0.9812691343447711, time 726.0, rides 117\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 21, reward -202.0, memory_length 2000, epsilon 0.9803859921238608, time 733.0, rides 142\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 22, reward -202.0, memory_length 2000, epsilon 0.9795036447309493, time 735.0, rides 131\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 23, reward -445.0, memory_length 2000, epsilon 0.9786220914506915, time 727.0, rides 128\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 24, reward -293.0, memory_length 2000, epsilon 0.9777413315683858, time 721.0, rides 122\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 25, reward -106.0, memory_length 2000, epsilon 0.9768613643699743, time 735.0, rides 123\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 26, reward -223.0, memory_length 2000, epsilon 0.9759821891420413, time 724.0, rides 128\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 27, reward -465.0, memory_length 2000, epsilon 0.9751038051718134, time 724.0, rides 122\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 28, reward -167.0, memory_length 2000, epsilon 0.9742262117471587, time 732.0, rides 125\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 29, reward -201.0, memory_length 2000, epsilon 0.9733494081565863, time 727.0, rides 128\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 30, reward -231.0, memory_length 2000, epsilon 0.9724733936892453, time 729.0, rides 125\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 31, reward -130.0, memory_length 2000, epsilon 0.971598167634925, time 727.0, rides 125\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 32, reward -431.0, memory_length 2000, epsilon 0.9707237292840536, time 732.0, rides 139\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 33, reward -111.0, memory_length 2000, epsilon 0.969850077927698, time 729.0, rides 138\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 34, reward -439.0, memory_length 2000, epsilon 0.968977212857563, time 727.0, rides 136\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 35, reward -395.0, memory_length 2000, epsilon 0.9681051333659911, time 739.0, rides 119\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 36, reward -400.0, memory_length 2000, epsilon 0.9672338387459617, time 732.0, rides 132\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 37, reward -444.0, memory_length 2000, epsilon 0.9663633282910903, time 728.0, rides 130\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 38, reward -334.0, memory_length 2000, epsilon 0.9654936012956283, time 730.0, rides 121\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 39, reward -212.0, memory_length 2000, epsilon 0.9646246570544622, time 727.0, rides 128\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 40, reward -345.0, memory_length 2000, epsilon 0.9637564948631132, time 728.0, rides 131\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 41, reward -225.0, memory_length 2000, epsilon 0.9628891140177364, time 732.0, rides 140\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 42, reward -247.0, memory_length 2000, epsilon 0.9620225138151204, time 734.0, rides 124\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 43, reward -418.0, memory_length 2000, epsilon 0.9611566935526867, time 723.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 44, reward -185.0, memory_length 2000, epsilon 0.9602916525284894, time 723.0, rides 126\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 45, reward -229.0, memory_length 2000, epsilon 0.9594273900412137, time 728.0, rides 129\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 46, reward 19.0, memory_length 2000, epsilon 0.9585639053901766, time 735.0, rides 125\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 47, reward -277.0, memory_length 2000, epsilon 0.9577011978753254, time 728.0, rides 132\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 48, reward -374.0, memory_length 2000, epsilon 0.9568392667972375, time 734.0, rides 124\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 49, reward -338.0, memory_length 2000, epsilon 0.95597811145712, time 724.0, rides 137\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 50, reward -319.0, memory_length 2000, epsilon 0.9551177311568085, time 724.0, rides 134\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 51, reward -175.0, memory_length 2000, epsilon 0.9542581251987674, time 726.0, rides 132\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 52, reward -38.0, memory_length 2000, epsilon 0.9533992928860885, time 728.0, rides 128\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 53, reward -265.0, memory_length 2000, epsilon 0.952541233522491, time 732.0, rides 129\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 54, reward -281.0, memory_length 2000, epsilon 0.9516839464123207, time 725.0, rides 118\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 55, reward -337.0, memory_length 2000, epsilon 0.9508274308605495, time 737.0, rides 128\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 56, reward -357.0, memory_length 2000, epsilon 0.949971686172775, time 731.0, rides 116\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 57, reward -375.0, memory_length 2000, epsilon 0.9491167116552195, time 734.0, rides 143\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 58, reward -138.0, memory_length 2000, epsilon 0.9482625066147298, time 725.0, rides 116\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 59, reward -523.0, memory_length 2000, epsilon 0.9474090703587765, time 728.0, rides 137\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 60, reward -151.0, memory_length 2000, epsilon 0.9465564021954537, time 734.0, rides 126\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 61, reward -258.0, memory_length 2000, epsilon 0.9457045014334777, time 735.0, rides 122\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 62, reward -58.0, memory_length 2000, epsilon 0.9448533673821876, time 726.0, rides 122\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 63, reward -297.0, memory_length 2000, epsilon 0.9440029993515436, time 727.0, rides 141\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 64, reward -223.0, memory_length 2000, epsilon 0.9431533966521273, time 731.0, rides 124\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 65, reward -199.0, memory_length 2000, epsilon 0.9423045585951404, time 746.0, rides 124\n",
      "Initial State is  [2, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 66, reward -435.0, memory_length 2000, epsilon 0.9414564844924047, time 735.0, rides 125\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 67, reward 69.0, memory_length 2000, epsilon 0.9406091736563615, time 728.0, rides 115\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 68, reward -242.0, memory_length 2000, epsilon 0.9397626254000708, time 724.0, rides 132\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 69, reward -381.0, memory_length 2000, epsilon 0.9389168390372108, time 723.0, rides 126\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 70, reward -511.0, memory_length 2000, epsilon 0.9380718138820773, time 727.0, rides 142\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 71, reward -337.0, memory_length 2000, epsilon 0.9372275492495834, time 727.0, rides 134\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 72, reward -410.0, memory_length 2000, epsilon 0.9363840444552588, time 728.0, rides 131\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 73, reward -420.0, memory_length 2000, epsilon 0.9355412988152491, time 731.0, rides 136\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 74, reward -515.0, memory_length 2000, epsilon 0.9346993116463154, time 731.0, rides 132\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 75, reward -185.0, memory_length 2000, epsilon 0.9338580822658337, time 726.0, rides 131\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 76, reward -215.0, memory_length 2000, epsilon 0.9330176099917944, time 737.0, rides 143\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 77, reward -141.0, memory_length 2000, epsilon 0.9321778941428017, time 728.0, rides 122\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 78, reward -249.0, memory_length 2000, epsilon 0.9313389340380732, time 728.0, rides 125\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 79, reward -54.0, memory_length 2000, epsilon 0.930500728997439, time 732.0, rides 121\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 80, reward -486.0, memory_length 2000, epsilon 0.9296632783413412, time 731.0, rides 135\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 81, reward -159.0, memory_length 2000, epsilon 0.928826581390834, time 730.0, rides 121\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 82, reward -93.0, memory_length 2000, epsilon 0.9279906374675821, time 729.0, rides 123\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 83, reward -426.0, memory_length 2000, epsilon 0.9271554458938613, time 731.0, rides 126\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 84, reward -333.0, memory_length 2000, epsilon 0.9263210059925568, time 727.0, rides 121\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 85, reward -249.0, memory_length 2000, epsilon 0.9254873170871636, time 725.0, rides 131\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 86, reward -180.0, memory_length 2000, epsilon 0.9246543785017851, time 737.0, rides 130\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 87, reward -381.0, memory_length 2000, epsilon 0.9238221895611335, time 733.0, rides 123\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 88, reward 25.0, memory_length 2000, epsilon 0.9229907495905284, time 742.0, rides 110\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 89, reward -270.0, memory_length 2000, epsilon 0.922160057915897, time 727.0, rides 127\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 90, reward -308.0, memory_length 2000, epsilon 0.9213301138637726, time 734.0, rides 131\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 91, reward -317.0, memory_length 2000, epsilon 0.9205009167612952, time 724.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 92, reward -277.0, memory_length 2000, epsilon 0.91967246593621, time 728.0, rides 131\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 93, reward 12.0, memory_length 2000, epsilon 0.9188447607168674, time 728.0, rides 115\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 94, reward -334.0, memory_length 2000, epsilon 0.9180178004322221, time 727.0, rides 122\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 95, reward -419.0, memory_length 2000, epsilon 0.9171915844118331, time 738.0, rides 128\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 96, reward -425.0, memory_length 2000, epsilon 0.9163661119858625, time 731.0, rides 119\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 97, reward -385.0, memory_length 2000, epsilon 0.9155413824850752, time 731.0, rides 138\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 98, reward -216.0, memory_length 2000, epsilon 0.9147173952408386, time 724.0, rides 124\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 99, reward -98.0, memory_length 2000, epsilon 0.9138941495851218, time 725.0, rides 129\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 100, reward -451.0, memory_length 2000, epsilon 0.9130716448504952, time 739.0, rides 126\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 101, reward -282.0, memory_length 2000, epsilon 0.9122498803701298, time 741.0, rides 122\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 102, reward -177.0, memory_length 2000, epsilon 0.9114288554777966, time 730.0, rides 132\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 103, reward -230.0, memory_length 2000, epsilon 0.9106085695078666, time 729.0, rides 123\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 104, reward 38.0, memory_length 2000, epsilon 0.9097890217953095, time 729.0, rides 118\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 105, reward -198.0, memory_length 2000, epsilon 0.9089702116756937, time 731.0, rides 132\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 106, reward -211.0, memory_length 2000, epsilon 0.9081521384851856, time 725.0, rides 142\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 107, reward -19.0, memory_length 2000, epsilon 0.9073348015605489, time 728.0, rides 139\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 108, reward -407.0, memory_length 2000, epsilon 0.9065182002391444, time 739.0, rides 117\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 109, reward -220.0, memory_length 2000, epsilon 0.9057023338589292, time 732.0, rides 122\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 110, reward -208.0, memory_length 2000, epsilon 0.9048872017584562, time 738.0, rides 120\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 111, reward -16.0, memory_length 2000, epsilon 0.9040728032768736, time 725.0, rides 122\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 112, reward -94.0, memory_length 2000, epsilon 0.9032591377539244, time 729.0, rides 123\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 113, reward -324.0, memory_length 2000, epsilon 0.9024462045299458, time 731.0, rides 123\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 114, reward -109.0, memory_length 2000, epsilon 0.9016340029458689, time 727.0, rides 128\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 115, reward -40.0, memory_length 2000, epsilon 0.9008225323432176, time 733.0, rides 118\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 116, reward -112.0, memory_length 2000, epsilon 0.9000117920641088, time 731.0, rides 128\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 117, reward -166.0, memory_length 2000, epsilon 0.8992017814512511, time 726.0, rides 125\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 118, reward -336.0, memory_length 2000, epsilon 0.8983924998479449, time 728.0, rides 126\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 119, reward -357.0, memory_length 2000, epsilon 0.8975839465980817, time 727.0, rides 121\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 120, reward -236.0, memory_length 2000, epsilon 0.8967761210461435, time 730.0, rides 129\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 121, reward -230.0, memory_length 2000, epsilon 0.8959690225372019, time 727.0, rides 128\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 122, reward -129.0, memory_length 2000, epsilon 0.8951626504169184, time 730.0, rides 139\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 123, reward -500.0, memory_length 2000, epsilon 0.8943570040315432, time 728.0, rides 118\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 124, reward -320.0, memory_length 2000, epsilon 0.8935520827279148, time 733.0, rides 125\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 125, reward -40.0, memory_length 2000, epsilon 0.8927478858534597, time 734.0, rides 125\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 126, reward -307.0, memory_length 2000, epsilon 0.8919444127561915, time 725.0, rides 122\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 127, reward -361.0, memory_length 2000, epsilon 0.891141662784711, time 734.0, rides 130\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 128, reward -72.0, memory_length 2000, epsilon 0.8903396352882047, time 739.0, rides 111\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 129, reward -358.0, memory_length 2000, epsilon 0.8895383296164453, time 725.0, rides 118\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 130, reward -265.0, memory_length 2000, epsilon 0.8887377451197905, time 730.0, rides 122\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 131, reward -7.0, memory_length 2000, epsilon 0.8879378811491827, time 735.0, rides 147\n",
      "Initial State is  [0, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 132, reward -308.0, memory_length 2000, epsilon 0.8871387370561484, time 725.0, rides 131\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 133, reward -91.0, memory_length 2000, epsilon 0.8863403121927979, time 723.0, rides 118\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 134, reward -92.0, memory_length 2000, epsilon 0.8855426059118243, time 729.0, rides 117\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 135, reward -191.0, memory_length 2000, epsilon 0.8847456175665037, time 735.0, rides 128\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 136, reward -19.0, memory_length 2000, epsilon 0.8839493465106939, time 732.0, rides 114\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 137, reward -423.0, memory_length 2000, epsilon 0.8831537920988343, time 724.0, rides 130\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 138, reward -158.0, memory_length 2000, epsilon 0.8823589536859453, time 730.0, rides 126\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 139, reward -292.0, memory_length 2000, epsilon 0.8815648306276279, time 731.0, rides 121\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 140, reward -23.0, memory_length 2000, epsilon 0.880771422280063, time 733.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 141, reward -269.0, memory_length 2000, epsilon 0.879978728000011, time 724.0, rides 119\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 142, reward -298.0, memory_length 2000, epsilon 0.8791867471448109, time 732.0, rides 128\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 143, reward -308.0, memory_length 2000, epsilon 0.8783954790723806, time 728.0, rides 146\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 144, reward -363.0, memory_length 2000, epsilon 0.8776049231412154, time 729.0, rides 126\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 145, reward -88.0, memory_length 2000, epsilon 0.8768150787103883, time 727.0, rides 138\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 146, reward -157.0, memory_length 2000, epsilon 0.876025945139549, time 729.0, rides 146\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 147, reward -391.0, memory_length 2000, epsilon 0.8752375217889234, time 735.0, rides 121\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 148, reward -321.0, memory_length 2000, epsilon 0.8744498080193134, time 746.0, rides 128\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 149, reward 68.0, memory_length 2000, epsilon 0.873662803192096, time 726.0, rides 136\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 150, reward -347.0, memory_length 2000, epsilon 0.8728765066692231, time 723.0, rides 132\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 151, reward -344.0, memory_length 2000, epsilon 0.8720909178132208, time 730.0, rides 141\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 152, reward -225.0, memory_length 2000, epsilon 0.8713060359871889, time 737.0, rides 123\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 153, reward -249.0, memory_length 2000, epsilon 0.8705218605548004, time 738.0, rides 119\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 154, reward -293.0, memory_length 2000, epsilon 0.869738390880301, time 723.0, rides 125\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 155, reward -118.0, memory_length 2000, epsilon 0.8689556263285088, time 728.0, rides 139\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 156, reward -160.0, memory_length 2000, epsilon 0.8681735662648131, time 731.0, rides 123\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 157, reward -520.0, memory_length 2000, epsilon 0.8673922100551748, time 725.0, rides 103\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 158, reward -104.0, memory_length 2000, epsilon 0.8666115570661251, time 725.0, rides 133\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 159, reward -518.0, memory_length 2000, epsilon 0.8658316066647657, time 734.0, rides 136\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 160, reward -173.0, memory_length 2000, epsilon 0.8650523582187674, time 730.0, rides 126\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 161, reward -359.0, memory_length 2000, epsilon 0.8642738110963705, time 734.0, rides 117\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 162, reward 76.0, memory_length 2000, epsilon 0.8634959646663837, time 731.0, rides 114\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 163, reward -204.0, memory_length 2000, epsilon 0.8627188182981839, time 726.0, rides 120\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 164, reward -586.0, memory_length 2000, epsilon 0.8619423713617155, time 741.0, rides 124\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 165, reward -263.0, memory_length 2000, epsilon 0.8611666232274899, time 730.0, rides 104\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 166, reward -247.0, memory_length 2000, epsilon 0.8603915732665852, time 735.0, rides 145\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 167, reward -262.0, memory_length 2000, epsilon 0.8596172208506453, time 729.0, rides 115\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 168, reward -165.0, memory_length 2000, epsilon 0.8588435653518797, time 734.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 169, reward 31.0, memory_length 2000, epsilon 0.858070606143063, time 742.0, rides 125\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 170, reward -19.0, memory_length 2000, epsilon 0.8572983425975342, time 731.0, rides 123\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 171, reward -451.0, memory_length 2000, epsilon 0.8565267740891964, time 737.0, rides 128\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 172, reward -452.0, memory_length 2000, epsilon 0.8557558999925161, time 728.0, rides 131\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 173, reward -169.0, memory_length 2000, epsilon 0.8549857196825228, time 733.0, rides 125\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 174, reward -38.0, memory_length 2000, epsilon 0.8542162325348085, time 734.0, rides 127\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 175, reward -130.0, memory_length 2000, epsilon 0.8534474379255271, time 727.0, rides 119\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 176, reward -408.0, memory_length 2000, epsilon 0.8526793352313942, time 732.0, rides 140\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 177, reward -284.0, memory_length 2000, epsilon 0.851911923829686, time 729.0, rides 163\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 178, reward -149.0, memory_length 2000, epsilon 0.8511452030982393, time 728.0, rides 130\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 179, reward -192.0, memory_length 2000, epsilon 0.8503791724154508, time 728.0, rides 126\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 180, reward -310.0, memory_length 2000, epsilon 0.8496138311602769, time 736.0, rides 136\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 181, reward -382.0, memory_length 2000, epsilon 0.8488491787122326, time 723.0, rides 122\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 182, reward -205.0, memory_length 2000, epsilon 0.8480852144513916, time 730.0, rides 135\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 183, reward -507.0, memory_length 2000, epsilon 0.8473219377583854, time 723.0, rides 127\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 184, reward -79.0, memory_length 2000, epsilon 0.8465593480144028, time 728.0, rides 134\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 185, reward -387.0, memory_length 2000, epsilon 0.8457974446011898, time 728.0, rides 126\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 186, reward -140.0, memory_length 2000, epsilon 0.8450362269010487, time 727.0, rides 126\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 187, reward -220.0, memory_length 2000, epsilon 0.8442756942968378, time 735.0, rides 134\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 188, reward -502.0, memory_length 2000, epsilon 0.8435158461719706, time 733.0, rides 116\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 189, reward -172.0, memory_length 2000, epsilon 0.8427566819104159, time 720.0, rides 123\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 190, reward -229.0, memory_length 2000, epsilon 0.8419982008966965, time 734.0, rides 116\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 191, reward -504.0, memory_length 2000, epsilon 0.8412404025158895, time 729.0, rides 122\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 192, reward -404.0, memory_length 2000, epsilon 0.8404832861536252, time 735.0, rides 129\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 193, reward -255.0, memory_length 2000, epsilon 0.8397268511960869, time 727.0, rides 125\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 194, reward -257.0, memory_length 2000, epsilon 0.8389710970300104, time 739.0, rides 126\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 195, reward -205.0, memory_length 2000, epsilon 0.8382160230426834, time 733.0, rides 128\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 196, reward -256.0, memory_length 2000, epsilon 0.837461628621945, time 733.0, rides 129\n",
      "Initial State is  [0, 17, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 197, reward 92.0, memory_length 2000, epsilon 0.8367079131561852, time 726.0, rides 118\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 198, reward -195.0, memory_length 2000, epsilon 0.8359548760343446, time 727.0, rides 126\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 199, reward 140.0, memory_length 2000, epsilon 0.8352025166459137, time 736.0, rides 134\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 200, reward -310.0, memory_length 2000, epsilon 0.8344508343809324, time 728.0, rides 135\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 201, reward -358.0, memory_length 2000, epsilon 0.8336998286299895, time 725.0, rides 121\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 202, reward -95.0, memory_length 2000, epsilon 0.8329494987842225, time 732.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 203, reward -175.0, memory_length 2000, epsilon 0.8321998442353167, time 726.0, rides 127\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 204, reward -242.0, memory_length 2000, epsilon 0.8314508643755049, time 727.0, rides 118\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 205, reward -348.0, memory_length 2000, epsilon 0.8307025585975669, time 730.0, rides 123\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 206, reward -289.0, memory_length 2000, epsilon 0.8299549262948291, time 728.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 207, reward -285.0, memory_length 2000, epsilon 0.8292079668611638, time 736.0, rides 126\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 208, reward -325.0, memory_length 2000, epsilon 0.8284616796909887, time 730.0, rides 112\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 209, reward -308.0, memory_length 2000, epsilon 0.8277160641792668, time 730.0, rides 140\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 210, reward -17.0, memory_length 2000, epsilon 0.8269711197215055, time 736.0, rides 131\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 211, reward 186.0, memory_length 2000, epsilon 0.8262268457137562, time 732.0, rides 116\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 212, reward -395.0, memory_length 2000, epsilon 0.8254832415526138, time 726.0, rides 130\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 213, reward -203.0, memory_length 2000, epsilon 0.8247403066352164, time 732.0, rides 117\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 214, reward -135.0, memory_length 2000, epsilon 0.8239980403592446, time 727.0, rides 117\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 215, reward 68.0, memory_length 2000, epsilon 0.8232564421229213, time 735.0, rides 130\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 216, reward -215.0, memory_length 2000, epsilon 0.8225155113250107, time 731.0, rides 136\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 217, reward -344.0, memory_length 2000, epsilon 0.8217752473648181, time 727.0, rides 116\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 218, reward -146.0, memory_length 2000, epsilon 0.8210356496421898, time 728.0, rides 133\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 219, reward -97.0, memory_length 2000, epsilon 0.8202967175575118, time 726.0, rides 136\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 220, reward -164.0, memory_length 2000, epsilon 0.81955845051171, time 731.0, rides 116\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 221, reward -137.0, memory_length 2000, epsilon 0.8188208479062494, time 726.0, rides 129\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 222, reward -544.0, memory_length 2000, epsilon 0.8180839091431338, time 722.0, rides 135\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 223, reward -208.0, memory_length 2000, epsilon 0.8173476336249049, time 729.0, rides 110\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 224, reward -555.0, memory_length 2000, epsilon 0.8166120207546425, time 727.0, rides 127\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 225, reward -346.0, memory_length 2000, epsilon 0.8158770699359633, time 726.0, rides 115\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 226, reward -174.0, memory_length 2000, epsilon 0.8151427805730209, time 727.0, rides 125\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 227, reward -67.0, memory_length 2000, epsilon 0.8144091520705052, time 727.0, rides 130\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 228, reward -275.0, memory_length 2000, epsilon 0.8136761838336418, time 736.0, rides 125\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 229, reward -286.0, memory_length 2000, epsilon 0.8129438752681916, time 726.0, rides 120\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 230, reward -145.0, memory_length 2000, epsilon 0.8122122257804502, time 729.0, rides 134\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 231, reward 0.0, memory_length 2000, epsilon 0.8114812347772478, time 729.0, rides 128\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 232, reward -327.0, memory_length 2000, epsilon 0.8107509016659482, time 732.0, rides 137\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 233, reward 14.0, memory_length 2000, epsilon 0.8100212258544488, time 723.0, rides 128\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 234, reward 164.0, memory_length 2000, epsilon 0.8092922067511797, time 740.0, rides 119\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 235, reward 86.0, memory_length 2000, epsilon 0.8085638437651037, time 731.0, rides 122\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 236, reward -142.0, memory_length 2000, epsilon 0.8078361363057152, time 734.0, rides 134\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 237, reward -216.0, memory_length 2000, epsilon 0.80710908378304, time 735.0, rides 127\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 238, reward -303.0, memory_length 2000, epsilon 0.8063826856076353, time 725.0, rides 134\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 239, reward 155.0, memory_length 2000, epsilon 0.8056569411905884, time 729.0, rides 133\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 240, reward -31.0, memory_length 2000, epsilon 0.8049318499435169, time 729.0, rides 133\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 241, reward -216.0, memory_length 2000, epsilon 0.8042074112785677, time 733.0, rides 132\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 242, reward 206.0, memory_length 2000, epsilon 0.8034836246084169, time 732.0, rides 120\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 243, reward -62.0, memory_length 2000, epsilon 0.8027604893462693, time 725.0, rides 117\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 244, reward -41.0, memory_length 2000, epsilon 0.8020380049058576, time 723.0, rides 132\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 245, reward -139.0, memory_length 2000, epsilon 0.8013161707014423, time 727.0, rides 120\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 246, reward -111.0, memory_length 2000, epsilon 0.800594986147811, time 732.0, rides 148\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 247, reward -421.0, memory_length 2000, epsilon 0.799874450660278, time 732.0, rides 134\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 248, reward -68.0, memory_length 2000, epsilon 0.7991545636546837, time 725.0, rides 125\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 249, reward -20.0, memory_length 2000, epsilon 0.7984353245473945, time 727.0, rides 129\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 250, reward -226.0, memory_length 2000, epsilon 0.7977167327553019, time 730.0, rides 126\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 251, reward -116.0, memory_length 2000, epsilon 0.7969987876958221, time 732.0, rides 128\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 252, reward -480.0, memory_length 2000, epsilon 0.7962814887868959, time 725.0, rides 132\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 253, reward 19.0, memory_length 2000, epsilon 0.7955648354469876, time 735.0, rides 133\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 254, reward -173.0, memory_length 2000, epsilon 0.7948488270950853, time 725.0, rides 120\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 255, reward -87.0, memory_length 2000, epsilon 0.7941334631506998, time 727.0, rides 132\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 256, reward -147.0, memory_length 2000, epsilon 0.7934187430338642, time 734.0, rides 132\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 257, reward -166.0, memory_length 2000, epsilon 0.7927046661651337, time 742.0, rides 115\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 258, reward 152.0, memory_length 2000, epsilon 0.7919912319655851, time 734.0, rides 138\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 259, reward -9.0, memory_length 2000, epsilon 0.791278439856816, time 722.0, rides 118\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 260, reward -421.0, memory_length 2000, epsilon 0.7905662892609449, time 723.0, rides 125\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 261, reward -172.0, memory_length 2000, epsilon 0.78985477960061, time 733.0, rides 142\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 262, reward -290.0, memory_length 2000, epsilon 0.7891439102989695, time 723.0, rides 128\n",
      "Initial State is  [1, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 263, reward -189.0, memory_length 2000, epsilon 0.7884336807797003, time 730.0, rides 124\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 264, reward -174.0, memory_length 2000, epsilon 0.7877240904669985, time 734.0, rides 128\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 265, reward -234.0, memory_length 2000, epsilon 0.7870151387855783, time 732.0, rides 124\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 266, reward -193.0, memory_length 2000, epsilon 0.7863068251606713, time 734.0, rides 128\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 267, reward -171.0, memory_length 2000, epsilon 0.7855991490180266, time 727.0, rides 119\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 268, reward 61.0, memory_length 2000, epsilon 0.7848921097839104, time 733.0, rides 128\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 269, reward -384.0, memory_length 2000, epsilon 0.7841857068851049, time 730.0, rides 118\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 270, reward 45.0, memory_length 2000, epsilon 0.7834799397489083, time 726.0, rides 130\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 271, reward -253.0, memory_length 2000, epsilon 0.7827748078031342, time 733.0, rides 118\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 272, reward -66.0, memory_length 2000, epsilon 0.7820703104761114, time 733.0, rides 115\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 273, reward -123.0, memory_length 2000, epsilon 0.7813664471966829, time 721.0, rides 132\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 274, reward 70.0, memory_length 2000, epsilon 0.7806632173942059, time 732.0, rides 125\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 275, reward -95.0, memory_length 2000, epsilon 0.7799606204985511, time 736.0, rides 110\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 276, reward 50.0, memory_length 2000, epsilon 0.7792586559401024, time 730.0, rides 122\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 277, reward -99.0, memory_length 2000, epsilon 0.7785573231497562, time 731.0, rides 129\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 278, reward -20.0, memory_length 2000, epsilon 0.7778566215589214, time 735.0, rides 132\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 279, reward -253.0, memory_length 2000, epsilon 0.7771565505995184, time 722.0, rides 125\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 280, reward 42.0, memory_length 2000, epsilon 0.7764571097039789, time 728.0, rides 123\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 281, reward -219.0, memory_length 2000, epsilon 0.7757582983052452, time 725.0, rides 127\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 282, reward 5.0, memory_length 2000, epsilon 0.7750601158367705, time 731.0, rides 135\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 283, reward 105.0, memory_length 2000, epsilon 0.7743625617325174, time 731.0, rides 127\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 284, reward 30.0, memory_length 2000, epsilon 0.7736656354269581, time 727.0, rides 120\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 285, reward -11.0, memory_length 2000, epsilon 0.7729693363550738, time 729.0, rides 112\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 286, reward -177.0, memory_length 2000, epsilon 0.7722736639523542, time 726.0, rides 131\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 287, reward -163.0, memory_length 2000, epsilon 0.7715786176547971, time 743.0, rides 121\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 288, reward -139.0, memory_length 2000, epsilon 0.7708841968989077, time 730.0, rides 120\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 289, reward -44.0, memory_length 2000, epsilon 0.7701904011216987, time 738.0, rides 136\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 290, reward -137.0, memory_length 2000, epsilon 0.7694972297606891, time 726.0, rides 122\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 291, reward -111.0, memory_length 2000, epsilon 0.7688046822539045, time 726.0, rides 139\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 292, reward -65.0, memory_length 2000, epsilon 0.768112758039876, time 729.0, rides 128\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 293, reward -129.0, memory_length 2000, epsilon 0.76742145655764, time 725.0, rides 131\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 294, reward -49.0, memory_length 2000, epsilon 0.7667307772467382, time 725.0, rides 130\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 295, reward -158.0, memory_length 2000, epsilon 0.7660407195472161, time 723.0, rides 113\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 296, reward -181.0, memory_length 2000, epsilon 0.7653512828996236, time 729.0, rides 124\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 297, reward -86.0, memory_length 2000, epsilon 0.7646624667450139, time 730.0, rides 130\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 298, reward -135.0, memory_length 2000, epsilon 0.7639742705249434, time 731.0, rides 131\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 299, reward 20.0, memory_length 2000, epsilon 0.763286693681471, time 731.0, rides 111\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 300, reward -190.0, memory_length 2000, epsilon 0.7625997356571577, time 734.0, rides 140\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 301, reward -117.0, memory_length 2000, epsilon 0.7619133958950662, time 723.0, rides 134\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 302, reward -76.0, memory_length 2000, epsilon 0.7612276738387607, time 735.0, rides 127\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 303, reward -76.0, memory_length 2000, epsilon 0.7605425689323058, time 729.0, rides 125\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 304, reward -107.0, memory_length 2000, epsilon 0.7598580806202667, time 725.0, rides 120\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 305, reward -235.0, memory_length 2000, epsilon 0.7591742083477084, time 726.0, rides 133\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 306, reward -147.0, memory_length 2000, epsilon 0.7584909515601955, time 735.0, rides 127\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 307, reward -384.0, memory_length 2000, epsilon 0.7578083097037913, time 732.0, rides 121\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 308, reward -151.0, memory_length 2000, epsilon 0.7571262822250578, time 728.0, rides 117\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 309, reward -191.0, memory_length 2000, epsilon 0.7564448685710553, time 732.0, rides 117\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 310, reward 47.0, memory_length 2000, epsilon 0.7557640681893414, time 723.0, rides 131\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 311, reward -82.0, memory_length 2000, epsilon 0.7550838805279709, time 729.0, rides 122\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 312, reward -70.0, memory_length 2000, epsilon 0.7544043050354957, time 727.0, rides 125\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 313, reward 46.0, memory_length 2000, epsilon 0.7537253411609638, time 727.0, rides 126\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 314, reward -83.0, memory_length 2000, epsilon 0.7530469883539189, time 728.0, rides 119\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 315, reward -111.0, memory_length 2000, epsilon 0.7523692460644004, time 729.0, rides 131\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 316, reward -2.0, memory_length 2000, epsilon 0.7516921137429424, time 737.0, rides 108\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 317, reward 170.0, memory_length 2000, epsilon 0.7510155908405738, time 733.0, rides 123\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 318, reward -106.0, memory_length 2000, epsilon 0.7503396768088173, time 735.0, rides 120\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 319, reward -199.0, memory_length 2000, epsilon 0.7496643710996893, time 733.0, rides 140\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 320, reward -333.0, memory_length 2000, epsilon 0.7489896731656995, time 736.0, rides 124\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 321, reward -92.0, memory_length 2000, epsilon 0.7483155824598504, time 734.0, rides 129\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 322, reward -298.0, memory_length 2000, epsilon 0.7476420984356366, time 725.0, rides 131\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 323, reward 37.0, memory_length 2000, epsilon 0.7469692205470445, time 724.0, rides 128\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 324, reward -280.0, memory_length 2000, epsilon 0.7462969482485522, time 726.0, rides 124\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 325, reward 70.0, memory_length 2000, epsilon 0.7456252809951285, time 724.0, rides 141\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 326, reward -325.0, memory_length 2000, epsilon 0.7449542182422328, time 728.0, rides 127\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 327, reward -153.0, memory_length 2000, epsilon 0.7442837594458148, time 724.0, rides 132\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 328, reward 252.0, memory_length 2000, epsilon 0.7436139040623135, time 731.0, rides 119\n",
      "Initial State is  [2, 9, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 329, reward -123.0, memory_length 2000, epsilon 0.7429446515486574, time 738.0, rides 127\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 330, reward -245.0, memory_length 2000, epsilon 0.7422760013622636, time 737.0, rides 117\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 331, reward 103.0, memory_length 2000, epsilon 0.7416079529610375, time 723.0, rides 131\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 332, reward -222.0, memory_length 2000, epsilon 0.7409405058033726, time 728.0, rides 119\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 333, reward -43.0, memory_length 2000, epsilon 0.7402736593481495, time 732.0, rides 127\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 334, reward -132.0, memory_length 2000, epsilon 0.7396074130547361, time 741.0, rides 135\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 335, reward -220.0, memory_length 2000, epsilon 0.7389417663829868, time 729.0, rides 124\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 336, reward -39.0, memory_length 2000, epsilon 0.7382767187932421, time 736.0, rides 130\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 337, reward -63.0, memory_length 2000, epsilon 0.7376122697463282, time 727.0, rides 120\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 338, reward -69.0, memory_length 2000, epsilon 0.7369484187035565, time 731.0, rides 132\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 339, reward -277.0, memory_length 2000, epsilon 0.7362851651267234, time 727.0, rides 126\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 340, reward 97.0, memory_length 2000, epsilon 0.7356225084781093, time 735.0, rides 132\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 341, reward -23.0, memory_length 2000, epsilon 0.734960448220479, time 728.0, rides 131\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 342, reward -176.0, memory_length 2000, epsilon 0.7342989838170806, time 728.0, rides 127\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 343, reward 71.0, memory_length 2000, epsilon 0.7336381147316452, time 728.0, rides 117\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 344, reward 126.0, memory_length 2000, epsilon 0.7329778404283868, time 737.0, rides 128\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 345, reward -132.0, memory_length 2000, epsilon 0.7323181603720013, time 735.0, rides 132\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 346, reward -94.0, memory_length 2000, epsilon 0.7316590740276665, time 729.0, rides 132\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 347, reward -54.0, memory_length 2000, epsilon 0.7310005808610416, time 730.0, rides 115\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 348, reward 129.0, memory_length 2000, epsilon 0.7303426803382667, time 736.0, rides 130\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 349, reward -65.0, memory_length 2000, epsilon 0.7296853719259622, time 724.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 350, reward -178.0, memory_length 2000, epsilon 0.7290286550912288, time 737.0, rides 122\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 351, reward 94.0, memory_length 2000, epsilon 0.7283725293016468, time 730.0, rides 134\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 352, reward -115.0, memory_length 2000, epsilon 0.7277169940252752, time 729.0, rides 147\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 353, reward 59.0, memory_length 2000, epsilon 0.7270620487306525, time 727.0, rides 123\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 354, reward -25.0, memory_length 2000, epsilon 0.7264076928867949, time 734.0, rides 125\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 355, reward -29.0, memory_length 2000, epsilon 0.7257539259631968, time 725.0, rides 143\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 356, reward -238.0, memory_length 2000, epsilon 0.7251007474298299, time 735.0, rides 108\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 357, reward -61.0, memory_length 2000, epsilon 0.724448156757143, time 728.0, rides 121\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 358, reward -395.0, memory_length 2000, epsilon 0.7237961534160616, time 733.0, rides 148\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 359, reward -79.0, memory_length 2000, epsilon 0.7231447368779872, time 734.0, rides 138\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 360, reward 117.0, memory_length 2000, epsilon 0.722493906614797, time 731.0, rides 126\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 361, reward -37.0, memory_length 2000, epsilon 0.7218436620988437, time 729.0, rides 131\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 362, reward -125.0, memory_length 2000, epsilon 0.7211940028029546, time 730.0, rides 124\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 363, reward -202.0, memory_length 2000, epsilon 0.720544928200432, time 723.0, rides 124\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 364, reward 117.0, memory_length 2000, epsilon 0.7198964377650516, time 734.0, rides 135\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 365, reward -158.0, memory_length 2000, epsilon 0.7192485309710631, time 734.0, rides 133\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 366, reward -18.0, memory_length 2000, epsilon 0.7186012072931891, time 732.0, rides 126\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 367, reward -187.0, memory_length 2000, epsilon 0.7179544662066252, time 726.0, rides 131\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 368, reward -251.0, memory_length 2000, epsilon 0.7173083071870392, time 728.0, rides 132\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 369, reward 85.0, memory_length 2000, epsilon 0.7166627297105709, time 740.0, rides 143\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 370, reward -288.0, memory_length 2000, epsilon 0.7160177332538313, time 721.0, rides 133\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 371, reward 81.0, memory_length 2000, epsilon 0.7153733172939029, time 728.0, rides 114\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 372, reward -233.0, memory_length 2000, epsilon 0.7147294813083384, time 728.0, rides 119\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 373, reward -174.0, memory_length 2000, epsilon 0.7140862247751608, time 724.0, rides 129\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 374, reward -303.0, memory_length 2000, epsilon 0.7134435471728632, time 740.0, rides 131\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 375, reward -93.0, memory_length 2000, epsilon 0.7128014479804076, time 731.0, rides 110\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 376, reward -5.0, memory_length 2000, epsilon 0.7121599266772252, time 736.0, rides 128\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 377, reward -1.0, memory_length 2000, epsilon 0.7115189827432157, time 728.0, rides 140\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 378, reward 56.0, memory_length 2000, epsilon 0.7108786156587468, time 723.0, rides 117\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 379, reward -370.0, memory_length 2000, epsilon 0.7102388249046538, time 730.0, rides 115\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 380, reward 50.0, memory_length 2000, epsilon 0.7095996099622397, time 721.0, rides 127\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 381, reward 107.0, memory_length 2000, epsilon 0.7089609703132737, time 739.0, rides 127\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 382, reward -235.0, memory_length 2000, epsilon 0.7083229054399917, time 725.0, rides 129\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 383, reward 79.0, memory_length 2000, epsilon 0.7076854148250956, time 736.0, rides 124\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 384, reward 116.0, memory_length 2000, epsilon 0.7070484979517531, time 733.0, rides 128\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 385, reward -170.0, memory_length 2000, epsilon 0.7064121543035965, time 735.0, rides 132\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 386, reward 139.0, memory_length 2000, epsilon 0.7057763833647233, time 734.0, rides 116\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 387, reward 166.0, memory_length 2000, epsilon 0.705141184619695, time 729.0, rides 125\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 388, reward -125.0, memory_length 2000, epsilon 0.7045065575535373, time 737.0, rides 149\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 389, reward -251.0, memory_length 2000, epsilon 0.7038725016517391, time 731.0, rides 138\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 390, reward 46.0, memory_length 2000, epsilon 0.7032390164002525, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 391, reward 51.0, memory_length 2000, epsilon 0.7026061012854923, time 730.0, rides 134\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 392, reward -119.0, memory_length 2000, epsilon 0.7019737557943353, time 731.0, rides 133\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 393, reward -221.0, memory_length 2000, epsilon 0.7013419794141204, time 734.0, rides 131\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 394, reward -145.0, memory_length 2000, epsilon 0.7007107716326476, time 735.0, rides 134\n",
      "Initial State is  [4, 8, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 395, reward 111.0, memory_length 2000, epsilon 0.7000801319381782, time 736.0, rides 118\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 396, reward -86.0, memory_length 2000, epsilon 0.6994500598194339, time 724.0, rides 120\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 397, reward -130.0, memory_length 2000, epsilon 0.6988205547655963, time 731.0, rides 132\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 398, reward -41.0, memory_length 2000, epsilon 0.6981916162663073, time 728.0, rides 135\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 399, reward -88.0, memory_length 2000, epsilon 0.6975632438116677, time 730.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 400, reward 149.0, memory_length 2000, epsilon 0.6969354368922371, time 730.0, rides 124\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 401, reward -95.0, memory_length 2000, epsilon 0.6963081949990341, time 724.0, rides 148\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 402, reward -26.0, memory_length 2000, epsilon 0.6956815176235349, time 723.0, rides 127\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 403, reward 52.0, memory_length 2000, epsilon 0.6950554042576738, time 727.0, rides 120\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 404, reward 94.0, memory_length 2000, epsilon 0.6944298543938419, time 728.0, rides 140\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 405, reward -168.0, memory_length 2000, epsilon 0.6938048675248873, time 729.0, rides 118\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 406, reward 162.0, memory_length 2000, epsilon 0.693180443144115, time 726.0, rides 128\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 407, reward 34.0, memory_length 2000, epsilon 0.6925565807452853, time 736.0, rides 127\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 408, reward 427.0, memory_length 2000, epsilon 0.6919332798226145, time 736.0, rides 121\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 409, reward 14.0, memory_length 2000, epsilon 0.6913105398707742, time 729.0, rides 119\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 410, reward 302.0, memory_length 2000, epsilon 0.6906883603848905, time 732.0, rides 113\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 411, reward -391.0, memory_length 2000, epsilon 0.6900667408605441, time 724.0, rides 116\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 412, reward 139.0, memory_length 2000, epsilon 0.6894456807937696, time 729.0, rides 137\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 413, reward 506.0, memory_length 2000, epsilon 0.6888251796810552, time 724.0, rides 116\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 414, reward 78.0, memory_length 2000, epsilon 0.6882052370193422, time 720.0, rides 134\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 415, reward 87.0, memory_length 2000, epsilon 0.6875858523060248, time 726.0, rides 129\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 416, reward 26.0, memory_length 2000, epsilon 0.6869670250389494, time 727.0, rides 129\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 417, reward 52.0, memory_length 2000, epsilon 0.6863487547164143, time 735.0, rides 123\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 418, reward -115.0, memory_length 2000, epsilon 0.6857310408371695, time 726.0, rides 132\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 419, reward -57.0, memory_length 2000, epsilon 0.6851138829004161, time 731.0, rides 132\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 420, reward 173.0, memory_length 2000, epsilon 0.6844972804058057, time 731.0, rides 122\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 421, reward 16.0, memory_length 2000, epsilon 0.6838812328534405, time 724.0, rides 134\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 422, reward 359.0, memory_length 2000, epsilon 0.6832657397438724, time 724.0, rides 119\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 423, reward -142.0, memory_length 2000, epsilon 0.6826508005781029, time 737.0, rides 137\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 424, reward 81.0, memory_length 2000, epsilon 0.6820364148575826, time 730.0, rides 130\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 425, reward 74.0, memory_length 2000, epsilon 0.6814225820842108, time 729.0, rides 131\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 426, reward -30.0, memory_length 2000, epsilon 0.680809301760335, time 725.0, rides 136\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 427, reward -233.0, memory_length 2000, epsilon 0.6801965733887507, time 733.0, rides 113\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 428, reward -111.0, memory_length 2000, epsilon 0.6795843964727009, time 737.0, rides 124\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 429, reward 54.0, memory_length 2000, epsilon 0.6789727705158755, time 730.0, rides 134\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 430, reward 30.0, memory_length 2000, epsilon 0.6783616950224112, time 723.0, rides 125\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 431, reward -90.0, memory_length 2000, epsilon 0.677751169496891, time 738.0, rides 114\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 432, reward -137.0, memory_length 2000, epsilon 0.6771411934443438, time 724.0, rides 133\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 433, reward 11.0, memory_length 2000, epsilon 0.6765317663702438, time 726.0, rides 118\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 434, reward -292.0, memory_length 2000, epsilon 0.6759228877805106, time 724.0, rides 108\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 435, reward -75.0, memory_length 2000, epsilon 0.6753145571815081, time 729.0, rides 121\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 436, reward 245.0, memory_length 2000, epsilon 0.6747067740800448, time 736.0, rides 145\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 437, reward -188.0, memory_length 2000, epsilon 0.6740995379833727, time 726.0, rides 122\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 438, reward -111.0, memory_length 2000, epsilon 0.6734928483991877, time 727.0, rides 124\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 439, reward -128.0, memory_length 2000, epsilon 0.6728867048356284, time 731.0, rides 119\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 440, reward 47.0, memory_length 2000, epsilon 0.6722811068012763, time 733.0, rides 118\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 441, reward 173.0, memory_length 2000, epsilon 0.6716760538051552, time 734.0, rides 126\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 442, reward -22.0, memory_length 2000, epsilon 0.6710715453567305, time 723.0, rides 126\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 443, reward 55.0, memory_length 2000, epsilon 0.6704675809659094, time 723.0, rides 127\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 444, reward -173.0, memory_length 2000, epsilon 0.6698641601430401, time 724.0, rides 138\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 445, reward -58.0, memory_length 2000, epsilon 0.6692612823989114, time 723.0, rides 133\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 446, reward 136.0, memory_length 2000, epsilon 0.6686589472447524, time 723.0, rides 132\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 447, reward -166.0, memory_length 2000, epsilon 0.6680571541922321, time 731.0, rides 130\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 448, reward 156.0, memory_length 2000, epsilon 0.6674559027534591, time 725.0, rides 130\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 449, reward 20.0, memory_length 2000, epsilon 0.666855192440981, time 728.0, rides 126\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 450, reward 188.0, memory_length 2000, epsilon 0.6662550227677841, time 726.0, rides 126\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 451, reward 159.0, memory_length 2000, epsilon 0.6656553932472932, time 722.0, rides 131\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 452, reward -104.0, memory_length 2000, epsilon 0.6650563033933706, time 727.0, rides 109\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 453, reward -25.0, memory_length 2000, epsilon 0.6644577527203166, time 730.0, rides 129\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 454, reward 18.0, memory_length 2000, epsilon 0.6638597407428684, time 735.0, rides 134\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 455, reward -207.0, memory_length 2000, epsilon 0.6632622669761997, time 725.0, rides 126\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 456, reward -123.0, memory_length 2000, epsilon 0.6626653309359212, time 723.0, rides 121\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 457, reward 51.0, memory_length 2000, epsilon 0.6620689321380788, time 735.0, rides 136\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 458, reward 164.0, memory_length 2000, epsilon 0.6614730700991546, time 731.0, rides 125\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 459, reward 67.0, memory_length 2000, epsilon 0.6608777443360653, time 733.0, rides 129\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 460, reward -105.0, memory_length 2000, epsilon 0.6602829543661628, time 731.0, rides 110\n",
      "Initial State is  [0, 0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 461, reward -133.0, memory_length 2000, epsilon 0.6596886997072332, time 728.0, rides 117\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 462, reward -223.0, memory_length 2000, epsilon 0.6590949798774967, time 738.0, rides 132\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 463, reward -7.0, memory_length 2000, epsilon 0.6585017943956069, time 724.0, rides 129\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 464, reward 420.0, memory_length 2000, epsilon 0.6579091427806508, time 730.0, rides 124\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 465, reward 304.0, memory_length 2000, epsilon 0.6573170245521482, time 735.0, rides 127\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 466, reward -118.0, memory_length 2000, epsilon 0.6567254392300513, time 733.0, rides 132\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 467, reward -183.0, memory_length 2000, epsilon 0.6561343863347443, time 732.0, rides 138\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 468, reward 94.0, memory_length 2000, epsilon 0.655543865387043, time 730.0, rides 115\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 469, reward 25.0, memory_length 2000, epsilon 0.6549538759081946, time 739.0, rides 131\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 470, reward -148.0, memory_length 2000, epsilon 0.6543644174198773, time 728.0, rides 128\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 471, reward 153.0, memory_length 2000, epsilon 0.6537754894441994, time 727.0, rides 134\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 472, reward 71.0, memory_length 2000, epsilon 0.6531870915036996, time 729.0, rides 132\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 473, reward 164.0, memory_length 2000, epsilon 0.6525992231213462, time 734.0, rides 145\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 474, reward 100.0, memory_length 2000, epsilon 0.652011883820537, time 735.0, rides 134\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 475, reward 286.0, memory_length 2000, epsilon 0.6514250731250985, time 726.0, rides 129\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 476, reward 61.0, memory_length 2000, epsilon 0.6508387905592858, time 722.0, rides 136\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 477, reward -148.0, memory_length 2000, epsilon 0.6502530356477825, time 728.0, rides 141\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 478, reward 69.0, memory_length 2000, epsilon 0.6496678079156994, time 729.0, rides 126\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 479, reward -113.0, memory_length 2000, epsilon 0.6490831068885753, time 721.0, rides 126\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 480, reward 220.0, memory_length 2000, epsilon 0.6484989320923755, time 729.0, rides 138\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 481, reward -297.0, memory_length 2000, epsilon 0.6479152830534923, time 733.0, rides 129\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 482, reward 99.0, memory_length 2000, epsilon 0.6473321592987442, time 726.0, rides 147\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 483, reward 28.0, memory_length 2000, epsilon 0.6467495603553753, time 734.0, rides 128\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 484, reward 33.0, memory_length 2000, epsilon 0.6461674857510555, time 731.0, rides 125\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 485, reward 234.0, memory_length 2000, epsilon 0.6455859350138796, time 725.0, rides 123\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 486, reward 39.0, memory_length 2000, epsilon 0.6450049076723671, time 722.0, rides 136\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 487, reward -136.0, memory_length 2000, epsilon 0.6444244032554619, time 729.0, rides 140\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 488, reward -119.0, memory_length 2000, epsilon 0.6438444212925319, time 728.0, rides 132\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 489, reward -38.0, memory_length 2000, epsilon 0.6432649613133686, time 735.0, rides 128\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 490, reward 289.0, memory_length 2000, epsilon 0.6426860228481865, time 729.0, rides 142\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 491, reward -132.0, memory_length 2000, epsilon 0.6421076054276231, time 727.0, rides 133\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 492, reward 235.0, memory_length 2000, epsilon 0.6415297085827383, time 734.0, rides 117\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 493, reward -49.0, memory_length 2000, epsilon 0.6409523318450138, time 728.0, rides 125\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 494, reward 66.0, memory_length 2000, epsilon 0.6403754747463533, time 729.0, rides 116\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 495, reward 112.0, memory_length 2000, epsilon 0.6397991368190815, time 724.0, rides 126\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 496, reward 280.0, memory_length 2000, epsilon 0.6392233175959443, time 730.0, rides 118\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 497, reward 85.0, memory_length 2000, epsilon 0.638648016610108, time 730.0, rides 142\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 498, reward 284.0, memory_length 2000, epsilon 0.6380732333951589, time 726.0, rides 133\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 499, reward 168.0, memory_length 2000, epsilon 0.6374989674851033, time 731.0, rides 127\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 500, reward 84.0, memory_length 2000, epsilon 0.6369252184143667, time 732.0, rides 129\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 501, reward 155.0, memory_length 2000, epsilon 0.6363519857177937, time 729.0, rides 137\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 502, reward -35.0, memory_length 2000, epsilon 0.6357792689306477, time 727.0, rides 125\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 503, reward 27.0, memory_length 2000, epsilon 0.6352070675886101, time 725.0, rides 133\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 504, reward 59.0, memory_length 2000, epsilon 0.6346353812277804, time 721.0, rides 134\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 505, reward -47.0, memory_length 2000, epsilon 0.6340642093846754, time 728.0, rides 129\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 506, reward 87.0, memory_length 2000, epsilon 0.6334935515962292, time 725.0, rides 120\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 507, reward 222.0, memory_length 2000, epsilon 0.6329234073997926, time 732.0, rides 138\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 508, reward 120.0, memory_length 2000, epsilon 0.6323537763331327, time 727.0, rides 136\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 509, reward 203.0, memory_length 2000, epsilon 0.631784657934433, time 724.0, rides 136\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 510, reward 84.0, memory_length 2000, epsilon 0.6312160517422919, time 735.0, rides 123\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 511, reward 311.0, memory_length 2000, epsilon 0.6306479572957239, time 729.0, rides 121\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 512, reward -60.0, memory_length 2000, epsilon 0.6300803741341577, time 728.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 513, reward -233.0, memory_length 2000, epsilon 0.629513301797437, time 727.0, rides 136\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 514, reward 38.0, memory_length 2000, epsilon 0.6289467398258193, time 722.0, rides 131\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 515, reward 70.0, memory_length 2000, epsilon 0.628380687759976, time 734.0, rides 125\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 516, reward 336.0, memory_length 2000, epsilon 0.627815145140992, time 732.0, rides 121\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 517, reward -189.0, memory_length 2000, epsilon 0.6272501115103651, time 726.0, rides 133\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 518, reward 435.0, memory_length 2000, epsilon 0.6266855864100058, time 723.0, rides 129\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 519, reward -13.0, memory_length 2000, epsilon 0.6261215693822368, time 730.0, rides 133\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 520, reward 80.0, memory_length 2000, epsilon 0.6255580599697929, time 721.0, rides 113\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 521, reward -50.0, memory_length 2000, epsilon 0.6249950577158201, time 729.0, rides 155\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 522, reward 109.0, memory_length 2000, epsilon 0.6244325621638759, time 729.0, rides 122\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 523, reward 22.0, memory_length 2000, epsilon 0.6238705728579284, time 731.0, rides 141\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 524, reward 14.0, memory_length 2000, epsilon 0.6233090893423562, time 730.0, rides 113\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 525, reward 214.0, memory_length 2000, epsilon 0.6227481111619481, time 731.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 526, reward -35.0, memory_length 2000, epsilon 0.6221876378619023, time 737.0, rides 130\n",
      "Initial State is  [1, 6, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 527, reward -55.0, memory_length 2000, epsilon 0.6216276689878266, time 732.0, rides 116\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 528, reward 14.0, memory_length 2000, epsilon 0.6210682040857376, time 732.0, rides 133\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 529, reward -16.0, memory_length 2000, epsilon 0.6205092427020604, time 726.0, rides 129\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 530, reward -234.0, memory_length 2000, epsilon 0.6199507843836286, time 740.0, rides 137\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 531, reward 149.0, memory_length 2000, epsilon 0.6193928286776833, time 723.0, rides 130\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 532, reward -195.0, memory_length 2000, epsilon 0.6188353751318734, time 733.0, rides 132\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 533, reward -136.0, memory_length 2000, epsilon 0.6182784232942546, time 730.0, rides 120\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 534, reward -145.0, memory_length 2000, epsilon 0.6177219727132898, time 727.0, rides 121\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 535, reward -8.0, memory_length 2000, epsilon 0.6171660229378478, time 731.0, rides 110\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 536, reward 39.0, memory_length 2000, epsilon 0.6166105735172037, time 724.0, rides 132\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 537, reward 66.0, memory_length 2000, epsilon 0.6160556240010382, time 731.0, rides 128\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 538, reward 313.0, memory_length 2000, epsilon 0.6155011739394373, time 737.0, rides 130\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 539, reward 278.0, memory_length 2000, epsilon 0.6149472228828917, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 540, reward 236.0, memory_length 2000, epsilon 0.6143937703822971, time 726.0, rides 125\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 541, reward -53.0, memory_length 2000, epsilon 0.613840815988953, time 736.0, rides 135\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 542, reward -21.0, memory_length 2000, epsilon 0.6132883592545629, time 734.0, rides 121\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 543, reward -74.0, memory_length 2000, epsilon 0.6127363997312338, time 725.0, rides 126\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 544, reward -63.0, memory_length 2000, epsilon 0.6121849369714757, time 733.0, rides 116\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 545, reward 208.0, memory_length 2000, epsilon 0.6116339705282013, time 742.0, rides 121\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 546, reward -160.0, memory_length 2000, epsilon 0.611083499954726, time 732.0, rides 145\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 547, reward 256.0, memory_length 2000, epsilon 0.6105335248047667, time 722.0, rides 114\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 548, reward 230.0, memory_length 2000, epsilon 0.6099840446324425, time 735.0, rides 133\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 549, reward -268.0, memory_length 2000, epsilon 0.6094350589922732, time 734.0, rides 141\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 550, reward 305.0, memory_length 2000, epsilon 0.6088865674391802, time 734.0, rides 133\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 551, reward 110.0, memory_length 2000, epsilon 0.608338569528485, time 729.0, rides 127\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 552, reward 111.0, memory_length 2000, epsilon 0.6077910648159093, time 733.0, rides 117\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 553, reward 108.0, memory_length 2000, epsilon 0.607244052857575, time 730.0, rides 126\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 554, reward -53.0, memory_length 2000, epsilon 0.6066975332100032, time 733.0, rides 139\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 555, reward -77.0, memory_length 2000, epsilon 0.6061515054301142, time 730.0, rides 125\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 556, reward 314.0, memory_length 2000, epsilon 0.6056059690752271, time 725.0, rides 126\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 557, reward -128.0, memory_length 2000, epsilon 0.6050609237030594, time 726.0, rides 132\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 558, reward 289.0, memory_length 2000, epsilon 0.6045163688717267, time 730.0, rides 125\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 559, reward 354.0, memory_length 2000, epsilon 0.6039723041397421, time 726.0, rides 135\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 560, reward 195.0, memory_length 2000, epsilon 0.6034287290660163, time 732.0, rides 137\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 561, reward 106.0, memory_length 2000, epsilon 0.6028856432098568, time 725.0, rides 127\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 562, reward -130.0, memory_length 2000, epsilon 0.6023430461309679, time 727.0, rides 120\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 563, reward 445.0, memory_length 2000, epsilon 0.6018009373894501, time 730.0, rides 132\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 564, reward -66.0, memory_length 2000, epsilon 0.6012593165457996, time 723.0, rides 120\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 565, reward 481.0, memory_length 2000, epsilon 0.6007181831609083, time 727.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 566, reward -101.0, memory_length 2000, epsilon 0.6001775367960634, time 727.0, rides 117\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 567, reward 13.0, memory_length 2000, epsilon 0.599637377012947, time 730.0, rides 120\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 568, reward 209.0, memory_length 2000, epsilon 0.5990977033736353, time 730.0, rides 140\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 569, reward 204.0, memory_length 2000, epsilon 0.598558515440599, time 731.0, rides 136\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 570, reward 156.0, memory_length 2000, epsilon 0.5980198127767025, time 740.0, rides 120\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 571, reward 147.0, memory_length 2000, epsilon 0.5974815949452035, time 727.0, rides 112\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 572, reward -155.0, memory_length 2000, epsilon 0.5969438615097528, time 721.0, rides 121\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 573, reward -91.0, memory_length 2000, epsilon 0.5964066120343939, time 723.0, rides 140\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 574, reward 9.0, memory_length 2000, epsilon 0.595869846083563, time 731.0, rides 137\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 575, reward -40.0, memory_length 2000, epsilon 0.5953335632220877, time 726.0, rides 125\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 576, reward -91.0, memory_length 2000, epsilon 0.5947977630151878, time 730.0, rides 119\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 577, reward 110.0, memory_length 2000, epsilon 0.5942624450284741, time 731.0, rides 140\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 578, reward -79.0, memory_length 2000, epsilon 0.5937276088279485, time 726.0, rides 133\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 579, reward 189.0, memory_length 2000, epsilon 0.5931932539800033, time 729.0, rides 130\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 580, reward 55.0, memory_length 2000, epsilon 0.5926593800514213, time 741.0, rides 130\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 581, reward 151.0, memory_length 2000, epsilon 0.592125986609375, time 734.0, rides 127\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 582, reward -100.0, memory_length 2000, epsilon 0.5915930732214265, time 735.0, rides 141\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 583, reward 199.0, memory_length 2000, epsilon 0.5910606394555272, time 733.0, rides 139\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 584, reward 174.0, memory_length 2000, epsilon 0.5905286848800172, time 732.0, rides 121\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 585, reward 111.0, memory_length 2000, epsilon 0.5899972090636252, time 729.0, rides 132\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 586, reward 382.0, memory_length 2000, epsilon 0.589466211575468, time 736.0, rides 127\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 587, reward 532.0, memory_length 2000, epsilon 0.58893569198505, time 724.0, rides 141\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 588, reward 92.0, memory_length 2000, epsilon 0.5884056498622635, time 730.0, rides 128\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 589, reward 54.0, memory_length 2000, epsilon 0.5878760847773875, time 723.0, rides 120\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 590, reward 272.0, memory_length 2000, epsilon 0.5873469963010879, time 727.0, rides 140\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 591, reward 67.0, memory_length 2000, epsilon 0.5868183840044169, time 734.0, rides 138\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 592, reward 223.0, memory_length 2000, epsilon 0.5862902474588129, time 737.0, rides 126\n",
      "Initial State is  [1, 10, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 593, reward 44.0, memory_length 2000, epsilon 0.5857625862360999, time 732.0, rides 118\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 594, reward -229.0, memory_length 2000, epsilon 0.5852353999084874, time 722.0, rides 130\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 595, reward -60.0, memory_length 2000, epsilon 0.5847086880485698, time 729.0, rides 116\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 596, reward -84.0, memory_length 2000, epsilon 0.584182450229326, time 729.0, rides 120\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 597, reward 255.0, memory_length 2000, epsilon 0.5836566860241196, time 721.0, rides 123\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 598, reward 118.0, memory_length 2000, epsilon 0.5831313950066979, time 737.0, rides 119\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 599, reward 260.0, memory_length 2000, epsilon 0.5826065767511919, time 738.0, rides 120\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 600, reward 281.0, memory_length 2000, epsilon 0.5820822308321157, time 727.0, rides 114\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 601, reward 460.0, memory_length 2000, epsilon 0.5815583568243669, time 732.0, rides 139\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 602, reward 71.0, memory_length 2000, epsilon 0.5810349543032249, time 730.0, rides 120\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 603, reward 400.0, memory_length 2000, epsilon 0.580512022844352, time 733.0, rides 142\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 604, reward 58.0, memory_length 2000, epsilon 0.579989562023792, time 731.0, rides 125\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 605, reward 65.0, memory_length 2000, epsilon 0.5794675714179707, time 735.0, rides 134\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 606, reward 158.0, memory_length 2000, epsilon 0.5789460506036945, time 734.0, rides 124\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 607, reward 281.0, memory_length 2000, epsilon 0.5784249991581512, time 727.0, rides 128\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 608, reward 248.0, memory_length 2000, epsilon 0.5779044166589088, time 732.0, rides 128\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 609, reward -39.0, memory_length 2000, epsilon 0.5773843026839157, time 738.0, rides 127\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 610, reward 251.0, memory_length 2000, epsilon 0.5768646568115002, time 732.0, rides 130\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 611, reward 227.0, memory_length 2000, epsilon 0.5763454786203699, time 730.0, rides 124\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 612, reward 332.0, memory_length 2000, epsilon 0.5758267676896115, time 728.0, rides 146\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 613, reward 229.0, memory_length 2000, epsilon 0.5753085235986909, time 728.0, rides 122\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 614, reward 313.0, memory_length 2000, epsilon 0.574790745927452, time 725.0, rides 114\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 615, reward 591.0, memory_length 2000, epsilon 0.5742734342561173, time 726.0, rides 133\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 616, reward 320.0, memory_length 2000, epsilon 0.5737565881652869, time 732.0, rides 137\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 617, reward 23.0, memory_length 2000, epsilon 0.573240207235938, time 721.0, rides 124\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 618, reward 180.0, memory_length 2000, epsilon 0.5727242910494257, time 728.0, rides 126\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 619, reward 97.0, memory_length 2000, epsilon 0.5722088391874812, time 728.0, rides 122\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 620, reward 234.0, memory_length 2000, epsilon 0.5716938512322125, time 729.0, rides 118\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 621, reward 406.0, memory_length 2000, epsilon 0.5711793267661035, time 729.0, rides 118\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 622, reward 329.0, memory_length 2000, epsilon 0.570665265372014, time 725.0, rides 113\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 623, reward 47.0, memory_length 2000, epsilon 0.5701516666331792, time 728.0, rides 145\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 624, reward -71.0, memory_length 2000, epsilon 0.5696385301332093, time 727.0, rides 119\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 625, reward 48.0, memory_length 2000, epsilon 0.5691258554560894, time 734.0, rides 127\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 626, reward 64.0, memory_length 2000, epsilon 0.5686136421861789, time 729.0, rides 112\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 627, reward 255.0, memory_length 2000, epsilon 0.5681018899082114, time 725.0, rides 128\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 628, reward 397.0, memory_length 2000, epsilon 0.5675905982072941, time 737.0, rides 137\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 629, reward 346.0, memory_length 2000, epsilon 0.5670797666689075, time 724.0, rides 126\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 630, reward 293.0, memory_length 2000, epsilon 0.5665693948789055, time 728.0, rides 125\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 631, reward 96.0, memory_length 2000, epsilon 0.5660594824235144, time 723.0, rides 114\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 632, reward 291.0, memory_length 2000, epsilon 0.5655500288893333, time 727.0, rides 129\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 633, reward 283.0, memory_length 2000, epsilon 0.5650410338633328, time 731.0, rides 137\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 634, reward 227.0, memory_length 2000, epsilon 0.5645324969328558, time 731.0, rides 131\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 635, reward 157.0, memory_length 2000, epsilon 0.5640244176856162, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 636, reward 251.0, memory_length 2000, epsilon 0.5635167957096991, time 724.0, rides 136\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 637, reward 159.0, memory_length 2000, epsilon 0.5630096305935605, time 729.0, rides 120\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 638, reward 352.0, memory_length 2000, epsilon 0.5625029219260262, time 735.0, rides 125\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 639, reward 118.0, memory_length 2000, epsilon 0.5619966692962928, time 745.0, rides 121\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 640, reward 161.0, memory_length 2000, epsilon 0.5614908722939261, time 724.0, rides 126\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 641, reward 274.0, memory_length 2000, epsilon 0.5609855305088616, time 724.0, rides 130\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 642, reward 336.0, memory_length 2000, epsilon 0.5604806435314036, time 733.0, rides 126\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 643, reward -31.0, memory_length 2000, epsilon 0.5599762109522253, time 723.0, rides 123\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 644, reward -42.0, memory_length 2000, epsilon 0.5594722323623683, time 730.0, rides 125\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 645, reward 190.0, memory_length 2000, epsilon 0.5589687073532422, time 729.0, rides 129\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 646, reward 368.0, memory_length 2000, epsilon 0.5584656355166243, time 730.0, rides 123\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 647, reward 27.0, memory_length 2000, epsilon 0.5579630164446594, time 740.0, rides 120\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 648, reward 45.0, memory_length 2000, epsilon 0.5574608497298592, time 737.0, rides 124\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 649, reward 338.0, memory_length 2000, epsilon 0.5569591349651023, time 732.0, rides 113\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 650, reward 390.0, memory_length 2000, epsilon 0.5564578717436337, time 729.0, rides 125\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 651, reward 285.0, memory_length 2000, epsilon 0.5559570596590644, time 729.0, rides 116\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 652, reward 133.0, memory_length 2000, epsilon 0.5554566983053713, time 722.0, rides 151\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 653, reward 221.0, memory_length 2000, epsilon 0.5549567872768965, time 725.0, rides 120\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 654, reward 120.0, memory_length 2000, epsilon 0.5544573261683472, time 730.0, rides 120\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 655, reward 182.0, memory_length 2000, epsilon 0.5539583145747957, time 729.0, rides 122\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 656, reward 236.0, memory_length 2000, epsilon 0.5534597520916784, time 727.0, rides 124\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 657, reward 1.0, memory_length 2000, epsilon 0.552961638314796, time 722.0, rides 125\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 658, reward 326.0, memory_length 2000, epsilon 0.5524639728403126, time 731.0, rides 124\n",
      "Initial State is  [4, 10, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 659, reward 45.0, memory_length 2000, epsilon 0.5519667552647562, time 738.0, rides 136\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 660, reward 127.0, memory_length 2000, epsilon 0.551469985185018, time 729.0, rides 116\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 661, reward 6.0, memory_length 2000, epsilon 0.5509736621983514, time 735.0, rides 138\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 662, reward 118.0, memory_length 2000, epsilon 0.550477785902373, time 722.0, rides 135\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 663, reward 95.0, memory_length 2000, epsilon 0.5499823558950608, time 731.0, rides 118\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 664, reward 152.0, memory_length 2000, epsilon 0.5494873717747553, time 722.0, rides 136\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 665, reward 390.0, memory_length 2000, epsilon 0.548992833140158, time 724.0, rides 124\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 666, reward 425.0, memory_length 2000, epsilon 0.5484987395903319, time 727.0, rides 145\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 667, reward 203.0, memory_length 2000, epsilon 0.5480050907247006, time 727.0, rides 131\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 668, reward 353.0, memory_length 2000, epsilon 0.5475118861430484, time 734.0, rides 134\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 669, reward 102.0, memory_length 2000, epsilon 0.5470191254455196, time 731.0, rides 128\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 670, reward 297.0, memory_length 2000, epsilon 0.5465268082326186, time 727.0, rides 123\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 671, reward 338.0, memory_length 2000, epsilon 0.5460349341052092, time 733.0, rides 133\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 672, reward 267.0, memory_length 2000, epsilon 0.5455435026645145, time 727.0, rides 128\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 673, reward 353.0, memory_length 2000, epsilon 0.5450525135121164, time 729.0, rides 122\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 674, reward 305.0, memory_length 2000, epsilon 0.5445619662499555, time 728.0, rides 124\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 675, reward 98.0, memory_length 2000, epsilon 0.5440718604803305, time 736.0, rides 137\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 676, reward 125.0, memory_length 2000, epsilon 0.5435821958058982, time 722.0, rides 141\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 677, reward 548.0, memory_length 2000, epsilon 0.5430929718296729, time 730.0, rides 138\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 678, reward 212.0, memory_length 2000, epsilon 0.5426041881550262, time 722.0, rides 120\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 679, reward 110.0, memory_length 2000, epsilon 0.5421158443856867, time 731.0, rides 121\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 680, reward 41.0, memory_length 2000, epsilon 0.5416279401257396, time 728.0, rides 136\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 681, reward 151.0, memory_length 2000, epsilon 0.5411404749796264, time 724.0, rides 137\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 682, reward 58.0, memory_length 2000, epsilon 0.5406534485521447, time 723.0, rides 108\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 683, reward 208.0, memory_length 2000, epsilon 0.5401668604484477, time 736.0, rides 132\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 684, reward 47.0, memory_length 2000, epsilon 0.5396807102740442, time 726.0, rides 120\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 685, reward 188.0, memory_length 2000, epsilon 0.5391949976347975, time 725.0, rides 119\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 686, reward 300.0, memory_length 2000, epsilon 0.5387097221369261, time 723.0, rides 120\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 687, reward 158.0, memory_length 2000, epsilon 0.5382248833870029, time 722.0, rides 134\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 688, reward 142.0, memory_length 2000, epsilon 0.5377404809919546, time 726.0, rides 125\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 689, reward 292.0, memory_length 2000, epsilon 0.5372565145590619, time 728.0, rides 130\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 690, reward 253.0, memory_length 2000, epsilon 0.5367729836959587, time 729.0, rides 131\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 691, reward 91.0, memory_length 2000, epsilon 0.5362898880106324, time 737.0, rides 129\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 692, reward 206.0, memory_length 2000, epsilon 0.5358072271114228, time 727.0, rides 111\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 693, reward 210.0, memory_length 2000, epsilon 0.5353250006070225, time 742.0, rides 126\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 694, reward 79.0, memory_length 2000, epsilon 0.5348432081064761, time 739.0, rides 126\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 695, reward 336.0, memory_length 2000, epsilon 0.5343618492191803, time 739.0, rides 126\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 696, reward 255.0, memory_length 2000, epsilon 0.533880923554883, time 727.0, rides 126\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 697, reward 219.0, memory_length 2000, epsilon 0.5334004307236836, time 731.0, rides 114\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 698, reward 176.0, memory_length 2000, epsilon 0.5329203703360322, time 738.0, rides 128\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 699, reward 550.0, memory_length 2000, epsilon 0.5324407420027298, time 736.0, rides 133\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 700, reward -61.0, memory_length 2000, epsilon 0.5319615453349273, time 722.0, rides 125\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 701, reward 56.0, memory_length 2000, epsilon 0.5314827799441258, time 725.0, rides 127\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 702, reward 78.0, memory_length 2000, epsilon 0.5310044454421762, time 734.0, rides 122\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 703, reward 516.0, memory_length 2000, epsilon 0.5305265414412782, time 723.0, rides 131\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 704, reward 193.0, memory_length 2000, epsilon 0.5300490675539811, time 722.0, rides 122\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 705, reward 226.0, memory_length 2000, epsilon 0.5295720233931824, time 730.0, rides 130\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 706, reward 250.0, memory_length 2000, epsilon 0.5290954085721286, time 732.0, rides 112\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 707, reward 28.0, memory_length 2000, epsilon 0.5286192227044136, time 740.0, rides 107\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 708, reward 271.0, memory_length 2000, epsilon 0.5281434654039796, time 723.0, rides 136\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 709, reward 374.0, memory_length 2000, epsilon 0.527668136285116, time 728.0, rides 124\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 710, reward 208.0, memory_length 2000, epsilon 0.5271932349624594, time 725.0, rides 122\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 711, reward 183.0, memory_length 2000, epsilon 0.5267187610509931, time 733.0, rides 131\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 712, reward 243.0, memory_length 2000, epsilon 0.5262447141660472, time 723.0, rides 125\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 713, reward 64.0, memory_length 2000, epsilon 0.5257710939232978, time 732.0, rides 119\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 714, reward 243.0, memory_length 2000, epsilon 0.5252978999387669, time 731.0, rides 139\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 715, reward 110.0, memory_length 2000, epsilon 0.524825131828822, time 730.0, rides 117\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 716, reward 116.0, memory_length 2000, epsilon 0.524352789210176, time 735.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 717, reward 234.0, memory_length 2000, epsilon 0.5238808716998868, time 731.0, rides 133\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 718, reward 90.0, memory_length 2000, epsilon 0.5234093789153569, time 734.0, rides 129\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 719, reward 271.0, memory_length 2000, epsilon 0.522938310474333, time 726.0, rides 124\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 720, reward 60.0, memory_length 2000, epsilon 0.5224676659949061, time 732.0, rides 119\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 721, reward 27.0, memory_length 2000, epsilon 0.5219974450955107, time 738.0, rides 120\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 722, reward 162.0, memory_length 2000, epsilon 0.5215276473949247, time 736.0, rides 136\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 723, reward 144.0, memory_length 2000, epsilon 0.5210582725122693, time 729.0, rides 119\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 724, reward 81.0, memory_length 2000, epsilon 0.5205893200670083, time 732.0, rides 132\n",
      "Initial State is  [1, 0, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 725, reward -1.0, memory_length 2000, epsilon 0.520120789678948, time 729.0, rides 140\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 726, reward 325.0, memory_length 2000, epsilon 0.519652680968237, time 745.0, rides 124\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 727, reward 290.0, memory_length 2000, epsilon 0.5191849935553656, time 734.0, rides 136\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 728, reward 116.0, memory_length 2000, epsilon 0.5187177270611658, time 727.0, rides 124\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 729, reward 233.0, memory_length 2000, epsilon 0.5182508811068107, time 723.0, rides 118\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 730, reward 199.0, memory_length 2000, epsilon 0.5177844553138146, time 731.0, rides 122\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 731, reward 146.0, memory_length 2000, epsilon 0.5173184493040321, time 732.0, rides 129\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 732, reward 242.0, memory_length 2000, epsilon 0.5168528626996585, time 726.0, rides 126\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 733, reward -135.0, memory_length 2000, epsilon 0.5163876951232288, time 726.0, rides 126\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 734, reward 139.0, memory_length 2000, epsilon 0.5159229461976179, time 731.0, rides 115\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 735, reward 259.0, memory_length 2000, epsilon 0.51545861554604, time 732.0, rides 142\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 736, reward 74.0, memory_length 2000, epsilon 0.5149947027920485, time 729.0, rides 126\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 737, reward 364.0, memory_length 2000, epsilon 0.5145312075595356, time 722.0, rides 128\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 738, reward 205.0, memory_length 2000, epsilon 0.5140681294727321, time 730.0, rides 134\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 739, reward 352.0, memory_length 2000, epsilon 0.5136054681562066, time 731.0, rides 135\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 740, reward 27.0, memory_length 2000, epsilon 0.5131432232348659, time 732.0, rides 124\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 741, reward 470.0, memory_length 2000, epsilon 0.5126813943339545, time 725.0, rides 127\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 742, reward 368.0, memory_length 2000, epsilon 0.512219981079054, time 732.0, rides 134\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 743, reward 306.0, memory_length 2000, epsilon 0.5117589830960828, time 738.0, rides 121\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 744, reward 310.0, memory_length 2000, epsilon 0.5112984000112963, time 739.0, rides 123\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 745, reward 194.0, memory_length 2000, epsilon 0.5108382314512862, time 724.0, rides 127\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 746, reward 383.0, memory_length 2000, epsilon 0.51037847704298, time 733.0, rides 116\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 747, reward 185.0, memory_length 2000, epsilon 0.5099191364136413, time 728.0, rides 129\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 748, reward 158.0, memory_length 2000, epsilon 0.509460209190869, time 726.0, rides 130\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 749, reward 64.0, memory_length 2000, epsilon 0.5090016950025972, time 724.0, rides 134\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 750, reward 451.0, memory_length 2000, epsilon 0.5085435934770949, time 733.0, rides 117\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 751, reward 289.0, memory_length 2000, epsilon 0.5080859042429655, time 721.0, rides 116\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 752, reward 154.0, memory_length 2000, epsilon 0.5076286269291468, time 727.0, rides 130\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 753, reward 424.0, memory_length 2000, epsilon 0.5071717611649106, time 732.0, rides 117\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 754, reward -142.0, memory_length 2000, epsilon 0.5067153065798622, time 734.0, rides 127\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 755, reward 274.0, memory_length 2000, epsilon 0.5062592628039403, time 738.0, rides 141\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 756, reward 141.0, memory_length 2000, epsilon 0.5058036294674167, time 727.0, rides 135\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 757, reward 258.0, memory_length 2000, epsilon 0.505348406200896, time 730.0, rides 125\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 758, reward 76.0, memory_length 2000, epsilon 0.5048935926353152, time 733.0, rides 126\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 759, reward 205.0, memory_length 2000, epsilon 0.5044391884019434, time 730.0, rides 130\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 760, reward 494.0, memory_length 2000, epsilon 0.5039851931323815, time 724.0, rides 132\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 761, reward 95.0, memory_length 2000, epsilon 0.5035316064585624, time 724.0, rides 131\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 762, reward 200.0, memory_length 2000, epsilon 0.5030784280127497, time 732.0, rides 133\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 763, reward 16.0, memory_length 2000, epsilon 0.5026256574275383, time 734.0, rides 136\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 764, reward 152.0, memory_length 2000, epsilon 0.5021732943358534, time 733.0, rides 124\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 765, reward 559.0, memory_length 2000, epsilon 0.5017213383709511, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 766, reward 180.0, memory_length 2000, epsilon 0.5012697891664173, time 734.0, rides 123\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 767, reward 389.0, memory_length 2000, epsilon 0.5008186463561675, time 726.0, rides 118\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 768, reward 71.0, memory_length 2000, epsilon 0.5003679095744469, time 730.0, rides 126\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 769, reward 160.0, memory_length 2000, epsilon 0.49991757845582985, time 730.0, rides 134\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 770, reward -52.0, memory_length 2000, epsilon 0.4994676526352196, time 726.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 771, reward 360.0, memory_length 2000, epsilon 0.49901813174784787, time 724.0, rides 117\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 772, reward 472.0, memory_length 2000, epsilon 0.4985690154292748, time 727.0, rides 122\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 773, reward 233.0, memory_length 2000, epsilon 0.4981203033153884, time 728.0, rides 134\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 774, reward 263.0, memory_length 2000, epsilon 0.49767199504240456, time 724.0, rides 124\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 775, reward 343.0, memory_length 2000, epsilon 0.49722409024686637, time 728.0, rides 125\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 776, reward 393.0, memory_length 2000, epsilon 0.49677658856564416, time 730.0, rides 135\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 777, reward 253.0, memory_length 2000, epsilon 0.4963294896359351, time 728.0, rides 111\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 778, reward 169.0, memory_length 2000, epsilon 0.49588279309526273, time 733.0, rides 132\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 779, reward 329.0, memory_length 2000, epsilon 0.495436498581477, time 726.0, rides 124\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 780, reward 91.0, memory_length 2000, epsilon 0.49499060573275366, time 729.0, rides 119\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 781, reward 63.0, memory_length 2000, epsilon 0.49454511418759417, time 743.0, rides 127\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 782, reward 407.0, memory_length 2000, epsilon 0.49410002358482535, time 729.0, rides 130\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 783, reward 15.0, memory_length 2000, epsilon 0.49365533356359903, time 732.0, rides 130\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 784, reward 545.0, memory_length 2000, epsilon 0.4932110437633918, time 727.0, rides 126\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 785, reward 253.0, memory_length 2000, epsilon 0.49276715382400477, time 724.0, rides 114\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 786, reward 384.0, memory_length 2000, epsilon 0.49232366338556316, time 731.0, rides 135\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 787, reward 336.0, memory_length 2000, epsilon 0.49188057208851615, time 732.0, rides 126\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 788, reward 121.0, memory_length 2000, epsilon 0.4914378795736365, time 729.0, rides 114\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 789, reward 349.0, memory_length 2000, epsilon 0.4909955854820202, time 731.0, rides 126\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 790, reward 29.0, memory_length 2000, epsilon 0.4905536894550864, time 734.0, rides 131\n",
      "Initial State is  [4, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 791, reward 46.0, memory_length 2000, epsilon 0.49011219113457677, time 730.0, rides 129\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 792, reward -43.0, memory_length 2000, epsilon 0.48967109016255567, time 722.0, rides 136\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 793, reward 232.0, memory_length 2000, epsilon 0.48923038618140935, time 725.0, rides 117\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 794, reward 294.0, memory_length 2000, epsilon 0.48879007883384606, time 734.0, rides 127\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 795, reward 426.0, memory_length 2000, epsilon 0.4883501677628956, time 727.0, rides 135\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 796, reward 169.0, memory_length 2000, epsilon 0.48791065261190897, time 727.0, rides 147\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 797, reward 170.0, memory_length 2000, epsilon 0.48747153302455826, time 728.0, rides 124\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 798, reward 82.0, memory_length 2000, epsilon 0.48703280864483617, time 729.0, rides 130\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 799, reward 116.0, memory_length 2000, epsilon 0.48659447911705583, time 725.0, rides 134\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 800, reward 209.0, memory_length 2000, epsilon 0.48615654408585046, time 734.0, rides 129\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 801, reward 294.0, memory_length 2000, epsilon 0.48571900319617317, time 731.0, rides 139\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 802, reward 60.0, memory_length 2000, epsilon 0.4852818560932966, time 729.0, rides 138\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 803, reward 346.0, memory_length 2000, epsilon 0.48484510242281265, time 732.0, rides 144\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 804, reward 170.0, memory_length 2000, epsilon 0.4844087418306321, time 730.0, rides 134\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 805, reward 363.0, memory_length 2000, epsilon 0.4839727739629845, time 734.0, rides 128\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 806, reward 328.0, memory_length 2000, epsilon 0.4835371984664178, time 728.0, rides 128\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 807, reward 255.0, memory_length 2000, epsilon 0.48310201498779803, time 734.0, rides 130\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 808, reward -95.0, memory_length 2000, epsilon 0.482667223174309, time 732.0, rides 121\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 809, reward 210.0, memory_length 2000, epsilon 0.48223282267345213, time 726.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 810, reward 165.0, memory_length 2000, epsilon 0.481798813133046, time 729.0, rides 136\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 811, reward 395.0, memory_length 2000, epsilon 0.48136519420122625, time 737.0, rides 138\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 812, reward 157.0, memory_length 2000, epsilon 0.4809319655264451, time 722.0, rides 121\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 813, reward 332.0, memory_length 2000, epsilon 0.4804991267574713, time 728.0, rides 131\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 814, reward 173.0, memory_length 2000, epsilon 0.48006667754338955, time 740.0, rides 137\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 815, reward 449.0, memory_length 2000, epsilon 0.4796346175336005, time 736.0, rides 110\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 816, reward 98.0, memory_length 2000, epsilon 0.47920294637782024, time 729.0, rides 125\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 817, reward -25.0, memory_length 2000, epsilon 0.4787716637260802, time 726.0, rides 137\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 818, reward 279.0, memory_length 2000, epsilon 0.47834076922872676, time 733.0, rides 125\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 819, reward 368.0, memory_length 2000, epsilon 0.4779102625364209, time 729.0, rides 130\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 820, reward 329.0, memory_length 2000, epsilon 0.4774801433001381, time 723.0, rides 126\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 821, reward 127.0, memory_length 2000, epsilon 0.477050411171168, time 732.0, rides 139\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 822, reward 415.0, memory_length 2000, epsilon 0.4766210658011139, time 730.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 823, reward 632.0, memory_length 2000, epsilon 0.4761921068418929, time 731.0, rides 124\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 824, reward 570.0, memory_length 2000, epsilon 0.4757635339457352, time 728.0, rides 136\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 825, reward 84.0, memory_length 2000, epsilon 0.475335346765184, time 735.0, rides 125\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 826, reward 269.0, memory_length 2000, epsilon 0.47490754495309534, time 728.0, rides 124\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 827, reward 236.0, memory_length 2000, epsilon 0.47448012816263757, time 723.0, rides 140\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 828, reward -11.0, memory_length 2000, epsilon 0.4740530960472912, time 727.0, rides 130\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 829, reward 230.0, memory_length 2000, epsilon 0.4736264482608486, time 733.0, rides 143\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 830, reward 629.0, memory_length 2000, epsilon 0.47320018445741385, time 724.0, rides 143\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 831, reward 419.0, memory_length 2000, epsilon 0.47277430429140216, time 731.0, rides 147\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 832, reward 422.0, memory_length 2000, epsilon 0.4723488074175399, time 739.0, rides 112\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 833, reward 125.0, memory_length 2000, epsilon 0.4719236934908641, time 734.0, rides 135\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 834, reward 409.0, memory_length 2000, epsilon 0.4714989621667223, time 724.0, rides 136\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 835, reward 354.0, memory_length 2000, epsilon 0.47107461310077225, time 732.0, rides 144\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 836, reward 200.0, memory_length 2000, epsilon 0.47065064594898154, time 723.0, rides 121\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 837, reward 232.0, memory_length 2000, epsilon 0.47022706036762746, time 732.0, rides 129\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 838, reward 311.0, memory_length 2000, epsilon 0.4698038560132966, time 727.0, rides 121\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 839, reward 467.0, memory_length 2000, epsilon 0.46938103254288466, time 732.0, rides 127\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 840, reward 253.0, memory_length 2000, epsilon 0.46895858961359604, time 731.0, rides 131\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 841, reward 475.0, memory_length 2000, epsilon 0.4685365268829438, time 731.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 842, reward 275.0, memory_length 2000, epsilon 0.46811484400874914, time 735.0, rides 133\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 843, reward 266.0, memory_length 2000, epsilon 0.46769354064914126, time 728.0, rides 130\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 844, reward 57.0, memory_length 2000, epsilon 0.467272616462557, time 724.0, rides 114\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 845, reward 221.0, memory_length 2000, epsilon 0.46685207110774074, time 731.0, rides 131\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 846, reward -42.0, memory_length 2000, epsilon 0.46643190424374376, time 737.0, rides 130\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 847, reward 557.0, memory_length 2000, epsilon 0.4660121155299244, time 733.0, rides 124\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 848, reward 409.0, memory_length 2000, epsilon 0.46559270462594743, time 727.0, rides 140\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 849, reward 178.0, memory_length 2000, epsilon 0.46517367119178404, time 729.0, rides 123\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 850, reward 384.0, memory_length 2000, epsilon 0.4647550148877114, time 728.0, rides 143\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 851, reward 414.0, memory_length 2000, epsilon 0.46433673537431247, time 737.0, rides 137\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 852, reward 245.0, memory_length 2000, epsilon 0.4639188323124756, time 729.0, rides 132\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 853, reward 378.0, memory_length 2000, epsilon 0.46350130536339434, time 729.0, rides 120\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 854, reward 320.0, memory_length 2000, epsilon 0.4630841541885673, time 729.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 855, reward 200.0, memory_length 2000, epsilon 0.4626673784497976, time 728.0, rides 123\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 856, reward 406.0, memory_length 2000, epsilon 0.4622509778091928, time 734.0, rides 119\n",
      "Initial State is  [2, 19, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 857, reward 280.0, memory_length 2000, epsilon 0.4618349519291645, time 734.0, rides 111\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 858, reward 306.0, memory_length 2000, epsilon 0.46141930047242824, time 730.0, rides 132\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 859, reward 407.0, memory_length 2000, epsilon 0.46100402310200306, time 722.0, rides 127\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 860, reward 92.0, memory_length 2000, epsilon 0.46058911948121123, time 732.0, rides 105\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 861, reward 219.0, memory_length 2000, epsilon 0.46017458927367816, time 726.0, rides 131\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 862, reward 357.0, memory_length 2000, epsilon 0.45976043214333184, time 731.0, rides 118\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 863, reward 249.0, memory_length 2000, epsilon 0.4593466477544028, time 732.0, rides 137\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 864, reward 229.0, memory_length 2000, epsilon 0.45893323577142386, time 729.0, rides 119\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 865, reward 659.0, memory_length 2000, epsilon 0.4585201958592296, time 721.0, rides 120\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 866, reward 52.0, memory_length 2000, epsilon 0.45810752768295626, time 732.0, rides 140\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 867, reward 135.0, memory_length 2000, epsilon 0.4576952309080416, time 725.0, rides 138\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 868, reward 296.0, memory_length 2000, epsilon 0.45728330520022437, time 730.0, rides 134\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 869, reward 170.0, memory_length 2000, epsilon 0.45687175022554416, time 727.0, rides 129\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 870, reward 163.0, memory_length 2000, epsilon 0.45646056565034115, time 727.0, rides 123\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 871, reward 117.0, memory_length 2000, epsilon 0.45604975114125584, time 732.0, rides 141\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 872, reward 657.0, memory_length 2000, epsilon 0.4556393063652287, time 730.0, rides 131\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 873, reward 479.0, memory_length 2000, epsilon 0.45522923098949997, time 728.0, rides 142\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 874, reward -33.0, memory_length 2000, epsilon 0.4548195246816094, time 740.0, rides 130\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 875, reward 192.0, memory_length 2000, epsilon 0.45441018710939596, time 725.0, rides 130\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 876, reward 536.0, memory_length 2000, epsilon 0.4540012179409975, time 726.0, rides 123\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 877, reward 523.0, memory_length 2000, epsilon 0.45359261684485064, time 729.0, rides 141\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 878, reward 349.0, memory_length 2000, epsilon 0.45318438348969026, time 730.0, rides 117\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 879, reward 263.0, memory_length 2000, epsilon 0.4527765175445495, time 725.0, rides 126\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 880, reward 22.0, memory_length 2000, epsilon 0.4523690186787594, time 726.0, rides 139\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 881, reward 452.0, memory_length 2000, epsilon 0.4519618865619485, time 725.0, rides 128\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 882, reward 374.0, memory_length 2000, epsilon 0.45155512086404276, time 732.0, rides 127\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 883, reward 50.0, memory_length 2000, epsilon 0.4511487212552651, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 884, reward 489.0, memory_length 2000, epsilon 0.4507426874061354, time 723.0, rides 126\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 885, reward 242.0, memory_length 2000, epsilon 0.45033701898746986, time 734.0, rides 123\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 886, reward 371.0, memory_length 2000, epsilon 0.44993171567038115, time 729.0, rides 131\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 887, reward 374.0, memory_length 2000, epsilon 0.4495267771262778, time 723.0, rides 133\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 888, reward 159.0, memory_length 2000, epsilon 0.4491222030268642, time 724.0, rides 130\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 889, reward 453.0, memory_length 2000, epsilon 0.44871799304414, time 734.0, rides 122\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 890, reward 460.0, memory_length 2000, epsilon 0.4483141468504003, time 733.0, rides 131\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 891, reward 469.0, memory_length 2000, epsilon 0.44791066411823494, time 722.0, rides 133\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 892, reward 93.0, memory_length 2000, epsilon 0.44750754452052854, time 722.0, rides 120\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 893, reward 389.0, memory_length 2000, epsilon 0.4471047877304601, time 725.0, rides 117\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 894, reward 201.0, memory_length 2000, epsilon 0.44670239342150264, time 730.0, rides 145\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 895, reward 125.0, memory_length 2000, epsilon 0.4463003612674233, time 732.0, rides 113\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 896, reward 293.0, memory_length 2000, epsilon 0.44589869094228257, time 722.0, rides 132\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 897, reward 478.0, memory_length 2000, epsilon 0.4454973821204345, time 730.0, rides 130\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 898, reward 388.0, memory_length 2000, epsilon 0.4450964344765261, time 728.0, rides 131\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 899, reward 399.0, memory_length 2000, epsilon 0.4446958476854972, time 731.0, rides 124\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 900, reward 404.0, memory_length 2000, epsilon 0.4442956214225802, time 733.0, rides 133\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 901, reward 452.0, memory_length 2000, epsilon 0.4438957553632999, time 735.0, rides 129\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 902, reward 170.0, memory_length 2000, epsilon 0.4434962491834729, time 727.0, rides 128\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 903, reward 235.0, memory_length 2000, epsilon 0.44309710255920776, time 731.0, rides 134\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 904, reward 470.0, memory_length 2000, epsilon 0.44269831516690444, time 725.0, rides 118\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 905, reward 497.0, memory_length 2000, epsilon 0.4422998866832542, time 727.0, rides 131\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 906, reward 202.0, memory_length 2000, epsilon 0.44190181678523927, time 732.0, rides 127\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 907, reward 240.0, memory_length 2000, epsilon 0.44150410515013255, time 722.0, rides 128\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 908, reward 152.0, memory_length 2000, epsilon 0.44110675145549744, time 737.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 909, reward 342.0, memory_length 2000, epsilon 0.4407097553791875, time 728.0, rides 135\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 910, reward 404.0, memory_length 2000, epsilon 0.44031311659934624, time 731.0, rides 130\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 911, reward 366.0, memory_length 2000, epsilon 0.43991683479440685, time 736.0, rides 139\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 912, reward 158.0, memory_length 2000, epsilon 0.4395209096430919, time 731.0, rides 137\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 913, reward 703.0, memory_length 2000, epsilon 0.43912534082441307, time 727.0, rides 133\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 914, reward 319.0, memory_length 2000, epsilon 0.4387301280176711, time 728.0, rides 129\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 915, reward 657.0, memory_length 2000, epsilon 0.43833527090245517, time 724.0, rides 140\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 916, reward 382.0, memory_length 2000, epsilon 0.43794076915864294, time 733.0, rides 118\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 917, reward 518.0, memory_length 2000, epsilon 0.43754662246640014, time 722.0, rides 139\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 918, reward 35.0, memory_length 2000, epsilon 0.43715283050618037, time 728.0, rides 133\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 919, reward 293.0, memory_length 2000, epsilon 0.4367593929587248, time 731.0, rides 121\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 920, reward 375.0, memory_length 2000, epsilon 0.43636630950506194, time 730.0, rides 114\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 921, reward 375.0, memory_length 2000, epsilon 0.43597357982650736, time 727.0, rides 117\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 922, reward 316.0, memory_length 2000, epsilon 0.4355812036046635, time 728.0, rides 129\n",
      "Initial State is  [2, 15, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 923, reward 119.0, memory_length 2000, epsilon 0.4351891805214193, time 726.0, rides 131\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 924, reward 505.0, memory_length 2000, epsilon 0.43479751025895, time 735.0, rides 115\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 925, reward 120.0, memory_length 2000, epsilon 0.43440619249971696, time 736.0, rides 133\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 926, reward -127.0, memory_length 2000, epsilon 0.4340152269264672, time 729.0, rides 124\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 927, reward 290.0, memory_length 2000, epsilon 0.4336246132222334, time 731.0, rides 130\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 928, reward 135.0, memory_length 2000, epsilon 0.43323435107033337, time 726.0, rides 136\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 929, reward 140.0, memory_length 2000, epsilon 0.43284444015437007, time 732.0, rides 118\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 930, reward 132.0, memory_length 2000, epsilon 0.43245488015823114, time 731.0, rides 130\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 931, reward 311.0, memory_length 2000, epsilon 0.4320656707660887, time 731.0, rides 122\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 932, reward 250.0, memory_length 2000, epsilon 0.43167681166239924, time 723.0, rides 129\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 933, reward 241.0, memory_length 2000, epsilon 0.4312883025319031, time 732.0, rides 134\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 934, reward 460.0, memory_length 2000, epsilon 0.4309001430596244, time 732.0, rides 142\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 935, reward 245.0, memory_length 2000, epsilon 0.4305123329308707, time 728.0, rides 137\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 936, reward 406.0, memory_length 2000, epsilon 0.43012487183123294, time 732.0, rides 139\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 937, reward 641.0, memory_length 2000, epsilon 0.4297377594465848, time 729.0, rides 129\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 938, reward 147.0, memory_length 2000, epsilon 0.42935099546308286, time 723.0, rides 122\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 939, reward 509.0, memory_length 2000, epsilon 0.4289645795671661, time 725.0, rides 115\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 940, reward 126.0, memory_length 2000, epsilon 0.42857851144555564, time 722.0, rides 121\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 941, reward 173.0, memory_length 2000, epsilon 0.42819279078525463, time 729.0, rides 128\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 942, reward 404.0, memory_length 2000, epsilon 0.4278074172735479, time 726.0, rides 142\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 943, reward 35.0, memory_length 2000, epsilon 0.4274223905980017, time 725.0, rides 129\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 944, reward 215.0, memory_length 2000, epsilon 0.4270377104464635, time 724.0, rides 119\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 945, reward 100.0, memory_length 2000, epsilon 0.42665337650706164, time 725.0, rides 118\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 946, reward 271.0, memory_length 2000, epsilon 0.4262693884682053, time 727.0, rides 123\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 947, reward 300.0, memory_length 2000, epsilon 0.42588574601858387, time 724.0, rides 114\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 948, reward 178.0, memory_length 2000, epsilon 0.42550244884716715, time 732.0, rides 113\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 949, reward 550.0, memory_length 2000, epsilon 0.4251194966432047, time 729.0, rides 129\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 950, reward 386.0, memory_length 2000, epsilon 0.4247368890962258, time 722.0, rides 121\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 951, reward 301.0, memory_length 2000, epsilon 0.42435462589603923, time 728.0, rides 127\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 952, reward 535.0, memory_length 2000, epsilon 0.4239727067327328, time 729.0, rides 133\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 953, reward 198.0, memory_length 2000, epsilon 0.4235911312966733, time 726.0, rides 125\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 954, reward 400.0, memory_length 2000, epsilon 0.4232098992785063, time 727.0, rides 122\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 955, reward 309.0, memory_length 2000, epsilon 0.4228290103691556, time 727.0, rides 131\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 956, reward 184.0, memory_length 2000, epsilon 0.42244846425982335, time 730.0, rides 130\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 957, reward 236.0, memory_length 2000, epsilon 0.4220682606419895, time 736.0, rides 134\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 958, reward 377.0, memory_length 2000, epsilon 0.4216883992074117, time 730.0, rides 120\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 959, reward 418.0, memory_length 2000, epsilon 0.421308879648125, time 727.0, rides 129\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 960, reward 252.0, memory_length 2000, epsilon 0.4209297016564417, time 737.0, rides 117\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 961, reward 459.0, memory_length 2000, epsilon 0.4205508649249509, time 728.0, rides 130\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 962, reward 373.0, memory_length 2000, epsilon 0.42017236914651845, time 733.0, rides 130\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 963, reward 423.0, memory_length 2000, epsilon 0.41979421401428657, time 725.0, rides 130\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 964, reward 277.0, memory_length 2000, epsilon 0.41941639922167373, time 731.0, rides 118\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 965, reward 410.0, memory_length 2000, epsilon 0.41903892446237423, time 723.0, rides 130\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 966, reward 317.0, memory_length 2000, epsilon 0.4186617894303581, time 732.0, rides 122\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 967, reward 614.0, memory_length 2000, epsilon 0.4182849938198708, time 728.0, rides 123\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 968, reward 270.0, memory_length 2000, epsilon 0.41790853732543287, time 735.0, rides 127\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 969, reward 501.0, memory_length 2000, epsilon 0.41753241964183996, time 723.0, rides 131\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 970, reward 46.0, memory_length 2000, epsilon 0.4171566404641623, time 723.0, rides 141\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 971, reward 491.0, memory_length 2000, epsilon 0.41678119948774456, time 729.0, rides 124\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 972, reward 304.0, memory_length 2000, epsilon 0.4164060964082056, time 728.0, rides 128\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 973, reward 757.0, memory_length 2000, epsilon 0.4160313309214382, time 732.0, rides 123\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 974, reward 428.0, memory_length 2000, epsilon 0.4156569027236089, time 729.0, rides 115\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 975, reward 99.0, memory_length 2000, epsilon 0.41528281151115765, time 731.0, rides 124\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 976, reward 291.0, memory_length 2000, epsilon 0.4149090569807976, time 728.0, rides 132\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 977, reward 332.0, memory_length 2000, epsilon 0.4145356388295149, time 733.0, rides 103\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 978, reward 458.0, memory_length 2000, epsilon 0.4141625567545683, time 730.0, rides 124\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 979, reward 310.0, memory_length 2000, epsilon 0.41378981045348917, time 734.0, rides 121\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 980, reward 413.0, memory_length 2000, epsilon 0.41341739962408103, time 725.0, rides 122\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 981, reward 417.0, memory_length 2000, epsilon 0.41304532396441934, time 729.0, rides 136\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 982, reward 315.0, memory_length 2000, epsilon 0.41267358317285135, time 728.0, rides 143\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 983, reward 178.0, memory_length 2000, epsilon 0.41230217694799576, time 734.0, rides 125\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 984, reward 305.0, memory_length 2000, epsilon 0.4119311049887426, time 722.0, rides 117\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 985, reward 244.0, memory_length 2000, epsilon 0.4115603669942527, time 728.0, rides 120\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 986, reward 149.0, memory_length 2000, epsilon 0.41118996266395785, time 727.0, rides 122\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 987, reward 737.0, memory_length 2000, epsilon 0.4108198916975603, time 728.0, rides 129\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 988, reward 410.0, memory_length 2000, epsilon 0.41045015379503247, time 723.0, rides 137\n",
      "Initial State is  [4, 1, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 989, reward 159.0, memory_length 2000, epsilon 0.4100807486566169, time 732.0, rides 125\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 990, reward 538.0, memory_length 2000, epsilon 0.409711675982826, time 727.0, rides 126\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 991, reward 328.0, memory_length 2000, epsilon 0.40934293547444145, time 724.0, rides 138\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 992, reward 525.0, memory_length 2000, epsilon 0.40897452683251445, time 727.0, rides 133\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 993, reward 441.0, memory_length 2000, epsilon 0.4086064497583652, time 725.0, rides 130\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 994, reward 401.0, memory_length 2000, epsilon 0.40823870395358264, time 728.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 995, reward 201.0, memory_length 2000, epsilon 0.4078712891200244, time 729.0, rides 124\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 996, reward 133.0, memory_length 2000, epsilon 0.4075042049598164, time 730.0, rides 111\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 997, reward 327.0, memory_length 2000, epsilon 0.40713745117535255, time 726.0, rides 116\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 998, reward 367.0, memory_length 2000, epsilon 0.4067710274692947, time 728.0, rides 123\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 999, reward 285.0, memory_length 2000, epsilon 0.40640493354457236, time 724.0, rides 136\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 1000, reward 187.0, memory_length 2000, epsilon 0.40603916910438226, time 730.0, rides 136\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 1001, reward 510.0, memory_length 2000, epsilon 0.4056737338521883, time 722.0, rides 129\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1002, reward 634.0, memory_length 2000, epsilon 0.4053086274917213, time 730.0, rides 144\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 1003, reward 432.0, memory_length 2000, epsilon 0.4049438497269788, time 734.0, rides 129\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1004, reward 160.0, memory_length 2000, epsilon 0.4045794002622245, time 733.0, rides 137\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 1005, reward 486.0, memory_length 2000, epsilon 0.4042152788019885, time 729.0, rides 126\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 1006, reward 429.0, memory_length 2000, epsilon 0.4038514850510667, time 736.0, rides 125\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 1007, reward 390.0, memory_length 2000, epsilon 0.4034880187145207, time 727.0, rides 129\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 1008, reward 439.0, memory_length 2000, epsilon 0.40312487949767767, time 724.0, rides 130\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1009, reward 181.0, memory_length 2000, epsilon 0.4027620671061298, time 737.0, rides 119\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 1010, reward 354.0, memory_length 2000, epsilon 0.4023995812457343, time 729.0, rides 136\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 1011, reward 273.0, memory_length 2000, epsilon 0.40203742162261313, time 723.0, rides 126\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 1012, reward 538.0, memory_length 2000, epsilon 0.4016755879431528, time 729.0, rides 110\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 1013, reward 288.0, memory_length 2000, epsilon 0.4013140799140039, time 734.0, rides 124\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 1014, reward 463.0, memory_length 2000, epsilon 0.40095289724208133, time 722.0, rides 136\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1015, reward 340.0, memory_length 2000, epsilon 0.40059203963456347, time 723.0, rides 120\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1016, reward 328.0, memory_length 2000, epsilon 0.40023150679889236, time 728.0, rides 138\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1017, reward 190.0, memory_length 2000, epsilon 0.39987129844277336, time 725.0, rides 121\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 1018, reward 379.0, memory_length 2000, epsilon 0.39951141427417486, time 742.0, rides 132\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1019, reward 287.0, memory_length 2000, epsilon 0.3991518540013281, time 726.0, rides 134\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1020, reward 378.0, memory_length 2000, epsilon 0.39879261733272686, time 727.0, rides 140\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 1021, reward 394.0, memory_length 2000, epsilon 0.3984337039771274, time 725.0, rides 131\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 1022, reward 399.0, memory_length 2000, epsilon 0.398075113643548, time 727.0, rides 118\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 1023, reward 402.0, memory_length 2000, epsilon 0.3977168460412688, time 734.0, rides 131\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 1024, reward 343.0, memory_length 2000, epsilon 0.3973589008798316, time 738.0, rides 122\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 1025, reward 652.0, memory_length 2000, epsilon 0.39700127786903977, time 726.0, rides 136\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 1026, reward 222.0, memory_length 2000, epsilon 0.3966439767189576, time 724.0, rides 138\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 1027, reward 316.0, memory_length 2000, epsilon 0.39628699713991056, time 726.0, rides 130\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1028, reward 537.0, memory_length 2000, epsilon 0.39593033884248463, time 733.0, rides 145\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 1029, reward 678.0, memory_length 2000, epsilon 0.39557400153752637, time 725.0, rides 142\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 1030, reward 119.0, memory_length 2000, epsilon 0.3952179849361426, time 737.0, rides 139\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 1031, reward 384.0, memory_length 2000, epsilon 0.39486228874970003, time 731.0, rides 129\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1032, reward 283.0, memory_length 2000, epsilon 0.3945069126898253, time 724.0, rides 113\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 1033, reward 590.0, memory_length 2000, epsilon 0.39415185646840445, time 726.0, rides 125\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 1034, reward 797.0, memory_length 2000, epsilon 0.39379711979758286, time 725.0, rides 124\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 1035, reward 314.0, memory_length 2000, epsilon 0.39344270238976503, time 729.0, rides 120\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1036, reward 268.0, memory_length 2000, epsilon 0.39308860395761425, time 723.0, rides 149\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 1037, reward 112.0, memory_length 2000, epsilon 0.39273482421405237, time 733.0, rides 116\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1038, reward 400.0, memory_length 2000, epsilon 0.3923813628722597, time 733.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1039, reward 590.0, memory_length 2000, epsilon 0.3920282196456747, time 732.0, rides 136\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 1040, reward 428.0, memory_length 2000, epsilon 0.3916753942479936, time 728.0, rides 111\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 1041, reward 173.0, memory_length 2000, epsilon 0.39132288639317037, time 728.0, rides 119\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1042, reward 586.0, memory_length 2000, epsilon 0.3909706957954165, time 727.0, rides 119\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1043, reward 349.0, memory_length 2000, epsilon 0.39061882216920063, time 732.0, rides 132\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 1044, reward 255.0, memory_length 2000, epsilon 0.3902672652292484, time 731.0, rides 116\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 1045, reward 203.0, memory_length 2000, epsilon 0.38991602469054204, time 728.0, rides 119\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1046, reward 415.0, memory_length 2000, epsilon 0.38956510026832053, time 723.0, rides 134\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 1047, reward 500.0, memory_length 2000, epsilon 0.38921449167807903, time 724.0, rides 130\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 1048, reward 326.0, memory_length 2000, epsilon 0.38886419863556876, time 731.0, rides 118\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 1049, reward 316.0, memory_length 2000, epsilon 0.38851422085679677, time 727.0, rides 124\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 1050, reward 493.0, memory_length 2000, epsilon 0.38816455805802563, time 736.0, rides 124\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 1051, reward 436.0, memory_length 2000, epsilon 0.3878152099557734, time 724.0, rides 127\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 1052, reward 250.0, memory_length 2000, epsilon 0.3874661762668132, time 726.0, rides 119\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 1053, reward 267.0, memory_length 2000, epsilon 0.38711745670817305, time 725.0, rides 138\n",
      "Initial State is  [3, 22, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1054, reward 544.0, memory_length 2000, epsilon 0.3867690509971357, time 724.0, rides 126\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1055, reward 178.0, memory_length 2000, epsilon 0.3864209588512383, time 728.0, rides 137\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 1056, reward 650.0, memory_length 2000, epsilon 0.3860731799882722, time 730.0, rides 128\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 1057, reward 554.0, memory_length 2000, epsilon 0.3857257141262827, time 722.0, rides 124\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1058, reward 281.0, memory_length 2000, epsilon 0.38537856098356904, time 745.0, rides 126\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 1059, reward 501.0, memory_length 2000, epsilon 0.3850317202786838, time 739.0, rides 140\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 1060, reward 294.0, memory_length 2000, epsilon 0.384685191730433, time 725.0, rides 124\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 1061, reward 203.0, memory_length 2000, epsilon 0.38433897505787556, time 724.0, rides 118\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 1062, reward 544.0, memory_length 2000, epsilon 0.38399306998032345, time 726.0, rides 128\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 1063, reward 514.0, memory_length 2000, epsilon 0.38364747621734113, time 723.0, rides 126\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 1064, reward 598.0, memory_length 2000, epsilon 0.3833021934887455, time 727.0, rides 128\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1065, reward 19.0, memory_length 2000, epsilon 0.38295722151460565, time 725.0, rides 127\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 1066, reward 603.0, memory_length 2000, epsilon 0.3826125600152425, time 723.0, rides 123\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 1067, reward 128.0, memory_length 2000, epsilon 0.3822682087112288, time 727.0, rides 126\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1068, reward 519.0, memory_length 2000, epsilon 0.3819241673233887, time 726.0, rides 137\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1069, reward 61.0, memory_length 2000, epsilon 0.38158043557279764, time 722.0, rides 124\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 1070, reward 611.0, memory_length 2000, epsilon 0.3812370131807821, time 733.0, rides 124\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 1071, reward 235.0, memory_length 2000, epsilon 0.3808938998689194, time 720.0, rides 123\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 1072, reward 563.0, memory_length 2000, epsilon 0.38055109535903736, time 728.0, rides 135\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1073, reward 167.0, memory_length 2000, epsilon 0.3802085993732142, time 725.0, rides 125\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 1074, reward 266.0, memory_length 2000, epsilon 0.3798664116337783, time 731.0, rides 126\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1075, reward 396.0, memory_length 2000, epsilon 0.3795245318633079, time 722.0, rides 119\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 1076, reward 512.0, memory_length 2000, epsilon 0.37918295978463096, time 739.0, rides 125\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 1077, reward 888.0, memory_length 2000, epsilon 0.3788416951208248, time 723.0, rides 123\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 1078, reward 212.0, memory_length 2000, epsilon 0.378500737595216, time 729.0, rides 109\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 1079, reward 381.0, memory_length 2000, epsilon 0.3781600869313803, time 733.0, rides 121\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 1080, reward 76.0, memory_length 2000, epsilon 0.37781974285314207, time 729.0, rides 138\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 1081, reward 250.0, memory_length 2000, epsilon 0.37747970508457424, time 730.0, rides 128\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 1082, reward 282.0, memory_length 2000, epsilon 0.3771399733499981, time 735.0, rides 118\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1083, reward 155.0, memory_length 2000, epsilon 0.3768005473739831, time 722.0, rides 118\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 1084, reward 214.0, memory_length 2000, epsilon 0.37646142688134654, time 728.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 1085, reward 216.0, memory_length 2000, epsilon 0.3761226115971533, time 729.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 1086, reward 275.0, memory_length 2000, epsilon 0.3757841012467159, time 731.0, rides 123\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 1087, reward 313.0, memory_length 2000, epsilon 0.3754458955555939, time 732.0, rides 143\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 1088, reward 558.0, memory_length 2000, epsilon 0.37510799424959385, time 729.0, rides 131\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 1089, reward 255.0, memory_length 2000, epsilon 0.3747703970547692, time 729.0, rides 121\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 1090, reward 367.0, memory_length 2000, epsilon 0.37443310369741994, time 729.0, rides 123\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 1091, reward 251.0, memory_length 2000, epsilon 0.37409611390409225, time 723.0, rides 127\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 1092, reward 786.0, memory_length 2000, epsilon 0.3737594274015786, time 726.0, rides 127\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 1093, reward 555.0, memory_length 2000, epsilon 0.37342304391691716, time 731.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 1094, reward 455.0, memory_length 2000, epsilon 0.37308696317739193, time 730.0, rides 137\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1095, reward 265.0, memory_length 2000, epsilon 0.3727511849105323, time 731.0, rides 134\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 1096, reward 127.0, memory_length 2000, epsilon 0.3724157088441128, time 721.0, rides 133\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1097, reward -50.0, memory_length 2000, epsilon 0.3720805347061531, time 729.0, rides 121\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 1098, reward 565.0, memory_length 2000, epsilon 0.37174566222491756, time 726.0, rides 147\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 1099, reward 309.0, memory_length 2000, epsilon 0.3714110911289151, time 731.0, rides 139\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 1100, reward 405.0, memory_length 2000, epsilon 0.3710768211468991, time 728.0, rides 122\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 1101, reward 608.0, memory_length 2000, epsilon 0.3707428520078669, time 725.0, rides 144\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 1102, reward 259.0, memory_length 2000, epsilon 0.3704091834410598, time 722.0, rides 127\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 1103, reward 235.0, memory_length 2000, epsilon 0.37007581517596283, time 730.0, rides 135\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 1104, reward 388.0, memory_length 2000, epsilon 0.36974274694230447, time 725.0, rides 120\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 1105, reward 305.0, memory_length 2000, epsilon 0.3694099784700564, time 725.0, rides 129\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 1106, reward 262.0, memory_length 2000, epsilon 0.36907750948943335, time 725.0, rides 121\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1107, reward 120.0, memory_length 2000, epsilon 0.36874533973089285, time 726.0, rides 140\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 1108, reward 568.0, memory_length 2000, epsilon 0.36841346892513505, time 728.0, rides 139\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 1109, reward 143.0, memory_length 2000, epsilon 0.36808189680310244, time 727.0, rides 120\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 1110, reward 449.0, memory_length 2000, epsilon 0.36775062309597967, time 731.0, rides 135\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1111, reward 456.0, memory_length 2000, epsilon 0.3674196475351933, time 726.0, rides 130\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 1112, reward 206.0, memory_length 2000, epsilon 0.36708896985241163, time 725.0, rides 147\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 1113, reward 496.0, memory_length 2000, epsilon 0.36675858977954445, time 731.0, rides 124\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1114, reward 370.0, memory_length 2000, epsilon 0.36642850704874286, time 727.0, rides 135\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 1115, reward 379.0, memory_length 2000, epsilon 0.36609872139239896, time 729.0, rides 138\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 1116, reward 499.0, memory_length 2000, epsilon 0.3657692325431458, time 725.0, rides 119\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 1117, reward 438.0, memory_length 2000, epsilon 0.36544004023385696, time 729.0, rides 134\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 1118, reward 692.0, memory_length 2000, epsilon 0.36511114419764645, time 731.0, rides 128\n",
      "Initial State is  [3, 16, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1119, reward 214.0, memory_length 2000, epsilon 0.3647825441678686, time 739.0, rides 125\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 1120, reward 267.0, memory_length 2000, epsilon 0.3644542398781175, time 724.0, rides 131\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 1121, reward 509.0, memory_length 2000, epsilon 0.3641262310622272, time 742.0, rides 125\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 1122, reward 483.0, memory_length 2000, epsilon 0.36379851745427116, time 738.0, rides 126\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 1123, reward 155.0, memory_length 2000, epsilon 0.3634710987885623, time 729.0, rides 130\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1124, reward 425.0, memory_length 2000, epsilon 0.3631439747996526, time 731.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1125, reward 514.0, memory_length 2000, epsilon 0.36281714522233294, time 730.0, rides 132\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 1126, reward 668.0, memory_length 2000, epsilon 0.36249060979163283, time 729.0, rides 119\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 1127, reward 649.0, memory_length 2000, epsilon 0.36216436824282033, time 724.0, rides 138\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1128, reward 271.0, memory_length 2000, epsilon 0.3618384203114018, time 737.0, rides 133\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1129, reward 380.0, memory_length 2000, epsilon 0.3615127657331215, time 744.0, rides 125\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 1130, reward 93.0, memory_length 2000, epsilon 0.36118740424396173, time 726.0, rides 129\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1131, reward 431.0, memory_length 2000, epsilon 0.36086233558014214, time 728.0, rides 134\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1132, reward 287.0, memory_length 2000, epsilon 0.36053755947812, time 724.0, rides 137\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 1133, reward 437.0, memory_length 2000, epsilon 0.36021307567458966, time 723.0, rides 130\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1134, reward 362.0, memory_length 2000, epsilon 0.3598888839064825, time 734.0, rides 129\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 1135, reward 497.0, memory_length 2000, epsilon 0.35956498391096664, time 734.0, rides 131\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 1136, reward 552.0, memory_length 2000, epsilon 0.35924137542544676, time 729.0, rides 135\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 1137, reward 155.0, memory_length 2000, epsilon 0.35891805818756384, time 722.0, rides 142\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 1138, reward 574.0, memory_length 2000, epsilon 0.35859503193519504, time 723.0, rides 118\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 1139, reward 263.0, memory_length 2000, epsilon 0.35827229640645336, time 722.0, rides 124\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 1140, reward 153.0, memory_length 2000, epsilon 0.35794985133968754, time 742.0, rides 126\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1141, reward 457.0, memory_length 2000, epsilon 0.3576276964734818, time 728.0, rides 136\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 1142, reward 631.0, memory_length 2000, epsilon 0.3573058315466557, time 732.0, rides 132\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 1143, reward 487.0, memory_length 2000, epsilon 0.3569842562982637, time 737.0, rides 130\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 1144, reward 396.0, memory_length 2000, epsilon 0.35666297046759526, time 724.0, rides 123\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1145, reward 389.0, memory_length 2000, epsilon 0.3563419737941744, time 725.0, rides 125\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1146, reward 519.0, memory_length 2000, epsilon 0.3560212660177597, time 724.0, rides 127\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 1147, reward 133.0, memory_length 2000, epsilon 0.3557008468783437, time 728.0, rides 134\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 1148, reward 392.0, memory_length 2000, epsilon 0.3553807161161532, time 747.0, rides 131\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 1149, reward 131.0, memory_length 2000, epsilon 0.35506087347164866, time 729.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1150, reward 240.0, memory_length 2000, epsilon 0.35474131868552417, time 729.0, rides 139\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1151, reward 428.0, memory_length 2000, epsilon 0.3544220514987072, time 739.0, rides 145\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 1152, reward 359.0, memory_length 2000, epsilon 0.3541030716523584, time 729.0, rides 136\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 1153, reward 321.0, memory_length 2000, epsilon 0.35378437888787123, time 733.0, rides 128\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 1154, reward 363.0, memory_length 2000, epsilon 0.35346597294687215, time 735.0, rides 126\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 1155, reward 346.0, memory_length 2000, epsilon 0.35314785357121997, time 727.0, rides 133\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1156, reward 645.0, memory_length 2000, epsilon 0.3528300205030059, time 727.0, rides 134\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 1157, reward 257.0, memory_length 2000, epsilon 0.35251247348455317, time 722.0, rides 133\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 1158, reward 440.0, memory_length 2000, epsilon 0.35219521225841705, time 732.0, rides 124\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 1159, reward 286.0, memory_length 2000, epsilon 0.3518782365673845, time 729.0, rides 121\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 1160, reward 485.0, memory_length 2000, epsilon 0.3515615461544738, time 729.0, rides 133\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 1161, reward 352.0, memory_length 2000, epsilon 0.3512451407629348, time 726.0, rides 122\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 1162, reward 238.0, memory_length 2000, epsilon 0.35092902013624816, time 730.0, rides 131\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1163, reward 416.0, memory_length 2000, epsilon 0.3506131840181255, time 734.0, rides 119\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1164, reward 262.0, memory_length 2000, epsilon 0.3502976321525092, time 722.0, rides 120\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 1165, reward 464.0, memory_length 2000, epsilon 0.34998236428357193, time 730.0, rides 123\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 1166, reward 721.0, memory_length 2000, epsilon 0.3496673801557167, time 726.0, rides 127\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1167, reward 615.0, memory_length 2000, epsilon 0.3493526795135765, time 727.0, rides 128\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 1168, reward 438.0, memory_length 2000, epsilon 0.3490382621020143, time 735.0, rides 140\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 1169, reward 462.0, memory_length 2000, epsilon 0.34872412766612243, time 736.0, rides 127\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 1170, reward 474.0, memory_length 2000, epsilon 0.3484102759512229, time 727.0, rides 113\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 1171, reward 453.0, memory_length 2000, epsilon 0.3480967067028668, time 729.0, rides 114\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1172, reward 254.0, memory_length 2000, epsilon 0.34778341966683424, time 726.0, rides 140\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 1173, reward 349.0, memory_length 2000, epsilon 0.3474704145891341, time 722.0, rides 114\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1174, reward 304.0, memory_length 2000, epsilon 0.34715769121600387, time 728.0, rides 135\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 1175, reward 276.0, memory_length 2000, epsilon 0.3468452492939095, time 725.0, rides 141\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 1176, reward 201.0, memory_length 2000, epsilon 0.34653308856954496, time 725.0, rides 133\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 1177, reward 499.0, memory_length 2000, epsilon 0.34622120878983237, time 724.0, rides 131\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 1178, reward 643.0, memory_length 2000, epsilon 0.3459096097019215, time 726.0, rides 124\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 1179, reward 627.0, memory_length 2000, epsilon 0.3455982910531898, time 721.0, rides 125\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 1180, reward 562.0, memory_length 2000, epsilon 0.34528725259124193, time 727.0, rides 121\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 1181, reward 710.0, memory_length 2000, epsilon 0.3449764940639098, time 728.0, rides 132\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 1182, reward 346.0, memory_length 2000, epsilon 0.3446660152192523, time 728.0, rides 119\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 1183, reward 375.0, memory_length 2000, epsilon 0.34435581580555497, time 731.0, rides 121\n",
      "Initial State is  [3, 16, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1184, reward 581.0, memory_length 2000, epsilon 0.34404589557133, time 738.0, rides 113\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1185, reward 542.0, memory_length 2000, epsilon 0.3437362542653158, time 731.0, rides 133\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1186, reward 502.0, memory_length 2000, epsilon 0.343426891636477, time 723.0, rides 126\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1187, reward 436.0, memory_length 2000, epsilon 0.34311780743400416, time 734.0, rides 128\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 1188, reward 237.0, memory_length 2000, epsilon 0.3428090014073136, time 732.0, rides 123\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 1189, reward 19.0, memory_length 2000, epsilon 0.342500473306047, time 731.0, rides 134\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 1190, reward 703.0, memory_length 2000, epsilon 0.34219222288007156, time 728.0, rides 137\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 1191, reward 328.0, memory_length 2000, epsilon 0.3418842498794795, time 734.0, rides 123\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 1192, reward 95.0, memory_length 2000, epsilon 0.341576554054588, time 732.0, rides 124\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1193, reward 615.0, memory_length 2000, epsilon 0.3412691351559388, time 724.0, rides 133\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 1194, reward 467.0, memory_length 2000, epsilon 0.34096199293429846, time 728.0, rides 129\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 1195, reward 514.0, memory_length 2000, epsilon 0.3406551271406576, time 729.0, rides 126\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 1196, reward 481.0, memory_length 2000, epsilon 0.340348537526231, time 726.0, rides 113\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 1197, reward 296.0, memory_length 2000, epsilon 0.3400422238424574, time 727.0, rides 124\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1198, reward 478.0, memory_length 2000, epsilon 0.3397361858409992, time 728.0, rides 118\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1199, reward 128.0, memory_length 2000, epsilon 0.3394304232737423, time 729.0, rides 122\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1200, reward 529.0, memory_length 2000, epsilon 0.3391249358927959, time 726.0, rides 140\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 1201, reward 601.0, memory_length 2000, epsilon 0.3388197234504924, time 726.0, rides 132\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 1202, reward 525.0, memory_length 2000, epsilon 0.3385147856993869, time 734.0, rides 140\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 1203, reward 4.0, memory_length 2000, epsilon 0.33821012239225745, time 731.0, rides 123\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 1204, reward 623.0, memory_length 2000, epsilon 0.33790573328210444, time 738.0, rides 120\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1205, reward 196.0, memory_length 2000, epsilon 0.33760161812215056, time 723.0, rides 136\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 1206, reward 487.0, memory_length 2000, epsilon 0.3372977766658406, time 721.0, rides 135\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 1207, reward 380.0, memory_length 2000, epsilon 0.3369942086668413, time 725.0, rides 127\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 1208, reward 608.0, memory_length 2000, epsilon 0.33669091387904115, time 727.0, rides 124\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 1209, reward 656.0, memory_length 2000, epsilon 0.33638789205655, time 731.0, rides 125\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 1210, reward 488.0, memory_length 2000, epsilon 0.3360851429536991, time 726.0, rides 117\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1211, reward 253.0, memory_length 2000, epsilon 0.3357826663250408, time 725.0, rides 132\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1212, reward 371.0, memory_length 2000, epsilon 0.33548046192534825, time 724.0, rides 120\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 1213, reward 384.0, memory_length 2000, epsilon 0.3351785295096154, time 732.0, rides 128\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 1214, reward 307.0, memory_length 2000, epsilon 0.33487686883305673, time 741.0, rides 133\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 1215, reward 419.0, memory_length 2000, epsilon 0.33457547965110696, time 734.0, rides 128\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 1216, reward 539.0, memory_length 2000, epsilon 0.33427436171942093, time 727.0, rides 124\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 1217, reward 500.0, memory_length 2000, epsilon 0.33397351479387344, time 728.0, rides 127\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 1218, reward 592.0, memory_length 2000, epsilon 0.33367293863055897, time 733.0, rides 128\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 1219, reward 559.0, memory_length 2000, epsilon 0.33337263298579145, time 729.0, rides 115\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 1220, reward 662.0, memory_length 2000, epsilon 0.33307259761610425, time 727.0, rides 134\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 1221, reward 404.0, memory_length 2000, epsilon 0.3327728322782498, time 729.0, rides 119\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 1222, reward 122.0, memory_length 2000, epsilon 0.3324733367291993, time 725.0, rides 113\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 1223, reward 455.0, memory_length 2000, epsilon 0.33217411072614306, time 737.0, rides 127\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 1224, reward 449.0, memory_length 2000, epsilon 0.33187515402648954, time 739.0, rides 126\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 1225, reward 474.0, memory_length 2000, epsilon 0.3315764663878657, time 732.0, rides 129\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 1226, reward 550.0, memory_length 2000, epsilon 0.33127804756811663, time 728.0, rides 131\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 1227, reward 426.0, memory_length 2000, epsilon 0.3309798973253053, time 730.0, rides 115\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 1228, reward 304.0, memory_length 2000, epsilon 0.3306820154177125, time 737.0, rides 113\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 1229, reward 354.0, memory_length 2000, epsilon 0.3303844016038366, time 730.0, rides 124\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 1230, reward 244.0, memory_length 2000, epsilon 0.33008705564239316, time 723.0, rides 117\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 1231, reward 519.0, memory_length 2000, epsilon 0.329789977292315, time 728.0, rides 125\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1232, reward 388.0, memory_length 2000, epsilon 0.32949316631275194, time 725.0, rides 119\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 1233, reward 419.0, memory_length 2000, epsilon 0.32919662246307047, time 734.0, rides 120\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 1234, reward 754.0, memory_length 2000, epsilon 0.3289003455028537, time 726.0, rides 132\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1235, reward 481.0, memory_length 2000, epsilon 0.32860433519190113, time 733.0, rides 118\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 1236, reward 316.0, memory_length 2000, epsilon 0.32830859129022844, time 729.0, rides 129\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 1237, reward 760.0, memory_length 2000, epsilon 0.3280131135580672, time 721.0, rides 132\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1238, reward 331.0, memory_length 2000, epsilon 0.32771790175586496, time 737.0, rides 136\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 1239, reward 396.0, memory_length 2000, epsilon 0.3274229556442847, time 734.0, rides 127\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 1240, reward 430.0, memory_length 2000, epsilon 0.3271282749842048, time 727.0, rides 125\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1241, reward 499.0, memory_length 2000, epsilon 0.32683385953671906, time 729.0, rides 128\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1242, reward 507.0, memory_length 2000, epsilon 0.326539709063136, time 724.0, rides 148\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 1243, reward 363.0, memory_length 2000, epsilon 0.3262458233249792, time 734.0, rides 131\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 1244, reward 301.0, memory_length 2000, epsilon 0.32595220208398673, time 736.0, rides 142\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 1245, reward 619.0, memory_length 2000, epsilon 0.3256588451021111, time 726.0, rides 126\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 1246, reward 640.0, memory_length 2000, epsilon 0.32536575214151925, time 731.0, rides 126\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 1247, reward 520.0, memory_length 2000, epsilon 0.3250729229645919, time 740.0, rides 130\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 1248, reward 275.0, memory_length 2000, epsilon 0.32478035733392374, time 725.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1249, reward 451.0, memory_length 2000, epsilon 0.3244880550123232, time 731.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 1250, reward 286.0, memory_length 2000, epsilon 0.3241960157628121, time 731.0, rides 132\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1251, reward 511.0, memory_length 2000, epsilon 0.32390423934862556, time 747.0, rides 120\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1252, reward 706.0, memory_length 2000, epsilon 0.3236127255332118, time 733.0, rides 132\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1253, reward 340.0, memory_length 2000, epsilon 0.32332147408023193, time 730.0, rides 121\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 1254, reward 389.0, memory_length 2000, epsilon 0.3230304847535597, time 734.0, rides 124\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 1255, reward 357.0, memory_length 2000, epsilon 0.3227397573172815, time 722.0, rides 129\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1256, reward 291.0, memory_length 2000, epsilon 0.32244929153569596, time 727.0, rides 121\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1257, reward 367.0, memory_length 2000, epsilon 0.3221590871733138, time 735.0, rides 140\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 1258, reward 209.0, memory_length 2000, epsilon 0.32186914399485783, time 731.0, rides 121\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1259, reward 169.0, memory_length 2000, epsilon 0.3215794617652625, time 732.0, rides 124\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1260, reward 405.0, memory_length 2000, epsilon 0.3212900402496737, time 741.0, rides 128\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 1261, reward 594.0, memory_length 2000, epsilon 0.321000879213449, time 731.0, rides 126\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1262, reward 406.0, memory_length 2000, epsilon 0.3207119784221569, time 731.0, rides 133\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1263, reward 695.0, memory_length 2000, epsilon 0.32042333764157693, time 726.0, rides 128\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 1264, reward 478.0, memory_length 2000, epsilon 0.32013495663769953, time 722.0, rides 149\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1265, reward 391.0, memory_length 2000, epsilon 0.3198468351767256, time 736.0, rides 124\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 1266, reward 465.0, memory_length 2000, epsilon 0.31955897302506653, time 722.0, rides 130\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 1267, reward 376.0, memory_length 2000, epsilon 0.31927136994934396, time 731.0, rides 137\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 1268, reward 543.0, memory_length 2000, epsilon 0.31898402571638956, time 721.0, rides 128\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 1269, reward 524.0, memory_length 2000, epsilon 0.3186969400932448, time 727.0, rides 121\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 1270, reward 347.0, memory_length 2000, epsilon 0.31841011284716086, time 728.0, rides 121\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1271, reward 418.0, memory_length 2000, epsilon 0.3181235437455984, time 724.0, rides 118\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1272, reward 780.0, memory_length 2000, epsilon 0.31783723255622737, time 730.0, rides 129\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 1273, reward 431.0, memory_length 2000, epsilon 0.31755117904692676, time 729.0, rides 135\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 1274, reward 559.0, memory_length 2000, epsilon 0.3172653829857845, time 726.0, rides 130\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 1275, reward 397.0, memory_length 2000, epsilon 0.3169798441410973, time 724.0, rides 120\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 1276, reward 605.0, memory_length 2000, epsilon 0.31669456228137033, time 730.0, rides 131\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1277, reward 751.0, memory_length 2000, epsilon 0.3164095371753171, time 723.0, rides 127\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 1278, reward 473.0, memory_length 2000, epsilon 0.31612476859185934, time 730.0, rides 122\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 1279, reward 572.0, memory_length 2000, epsilon 0.3158402563001267, time 729.0, rides 139\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1280, reward 548.0, memory_length 2000, epsilon 0.31555600006945655, time 729.0, rides 122\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 1281, reward 470.0, memory_length 2000, epsilon 0.31527199966939407, time 735.0, rides 132\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 1282, reward 697.0, memory_length 2000, epsilon 0.3149882548696916, time 730.0, rides 132\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 1283, reward 482.0, memory_length 2000, epsilon 0.3147047654403089, time 730.0, rides 123\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 1284, reward 593.0, memory_length 2000, epsilon 0.31442153115141264, time 727.0, rides 123\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 1285, reward 416.0, memory_length 2000, epsilon 0.31413855177337635, time 731.0, rides 139\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1286, reward 232.0, memory_length 2000, epsilon 0.31385582707678034, time 731.0, rides 124\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1287, reward 634.0, memory_length 2000, epsilon 0.3135733568324112, time 725.0, rides 132\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 1288, reward 725.0, memory_length 2000, epsilon 0.313291140811262, time 736.0, rides 140\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 1289, reward 781.0, memory_length 2000, epsilon 0.3130091787845319, time 735.0, rides 127\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 1290, reward 510.0, memory_length 2000, epsilon 0.3127274705236258, time 729.0, rides 117\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 1291, reward 348.0, memory_length 2000, epsilon 0.3124460158001546, time 732.0, rides 126\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1292, reward 514.0, memory_length 2000, epsilon 0.3121648143859344, time 738.0, rides 128\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 1293, reward 550.0, memory_length 2000, epsilon 0.31188386605298707, time 724.0, rides 124\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 1294, reward 747.0, memory_length 2000, epsilon 0.31160317057353937, time 729.0, rides 130\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1295, reward 695.0, memory_length 2000, epsilon 0.3113227277200232, time 728.0, rides 121\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 1296, reward 482.0, memory_length 2000, epsilon 0.31104253726507514, time 724.0, rides 133\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 1297, reward 471.0, memory_length 2000, epsilon 0.3107625989815366, time 730.0, rides 122\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 1298, reward 299.0, memory_length 2000, epsilon 0.3104829126424532, time 725.0, rides 147\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1299, reward 344.0, memory_length 2000, epsilon 0.310203478021075, time 728.0, rides 113\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 1300, reward 592.0, memory_length 2000, epsilon 0.30992429489085604, time 728.0, rides 131\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 1301, reward 495.0, memory_length 2000, epsilon 0.30964536302545426, time 725.0, rides 132\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 1302, reward 88.0, memory_length 2000, epsilon 0.30936668219873137, time 730.0, rides 125\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 1303, reward 508.0, memory_length 2000, epsilon 0.3090882521847525, time 728.0, rides 123\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 1304, reward 450.0, memory_length 2000, epsilon 0.3088100727577862, time 735.0, rides 130\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 1305, reward 634.0, memory_length 2000, epsilon 0.3085321436923042, time 730.0, rides 125\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 1306, reward 693.0, memory_length 2000, epsilon 0.30825446476298113, time 729.0, rides 135\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 1307, reward 753.0, memory_length 2000, epsilon 0.3079770357446944, time 732.0, rides 131\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1308, reward 860.0, memory_length 2000, epsilon 0.3076998564125242, time 727.0, rides 136\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 1309, reward 625.0, memory_length 2000, epsilon 0.3074229265417529, time 726.0, rides 140\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 1310, reward 691.0, memory_length 2000, epsilon 0.3071462459078653, time 723.0, rides 142\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 1311, reward 655.0, memory_length 2000, epsilon 0.30686981428654825, time 734.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 1312, reward 475.0, memory_length 2000, epsilon 0.30659363145369034, time 728.0, rides 137\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 1313, reward 543.0, memory_length 2000, epsilon 0.30631769718538204, time 734.0, rides 131\n",
      "Initial State is  [2, 10, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1314, reward 475.0, memory_length 2000, epsilon 0.3060420112579152, time 733.0, rides 136\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 1315, reward 126.0, memory_length 2000, epsilon 0.3057665734477831, time 735.0, rides 141\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1316, reward 241.0, memory_length 2000, epsilon 0.30549138353168004, time 732.0, rides 122\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 1317, reward 182.0, memory_length 2000, epsilon 0.30521644128650155, time 730.0, rides 149\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 1318, reward 383.0, memory_length 2000, epsilon 0.3049417464893437, time 728.0, rides 125\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 1319, reward 426.0, memory_length 2000, epsilon 0.30466729891750327, time 729.0, rides 138\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 1320, reward 219.0, memory_length 2000, epsilon 0.3043930983484775, time 729.0, rides 122\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 1321, reward 449.0, memory_length 2000, epsilon 0.30411914455996386, time 727.0, rides 129\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 1322, reward 267.0, memory_length 2000, epsilon 0.3038454373298599, time 739.0, rides 130\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1323, reward 714.0, memory_length 2000, epsilon 0.30357197643626305, time 734.0, rides 131\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 1324, reward 546.0, memory_length 2000, epsilon 0.3032987616574704, time 734.0, rides 136\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 1325, reward 653.0, memory_length 2000, epsilon 0.30302579277197866, time 725.0, rides 139\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1326, reward 496.0, memory_length 2000, epsilon 0.30275306955848386, time 735.0, rides 123\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 1327, reward 418.0, memory_length 2000, epsilon 0.3024805917958812, time 723.0, rides 131\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 1328, reward 456.0, memory_length 2000, epsilon 0.3022083592632649, time 732.0, rides 127\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 1329, reward 482.0, memory_length 2000, epsilon 0.30193637173992793, time 737.0, rides 133\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 1330, reward 400.0, memory_length 2000, epsilon 0.301664629005362, time 724.0, rides 121\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 1331, reward 533.0, memory_length 2000, epsilon 0.3013931308392572, time 721.0, rides 137\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 1332, reward 842.0, memory_length 2000, epsilon 0.30112187702150184, time 729.0, rides 126\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 1333, reward 778.0, memory_length 2000, epsilon 0.30085086733218247, time 738.0, rides 134\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 1334, reward 659.0, memory_length 2000, epsilon 0.3005801015515835, time 733.0, rides 127\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 1335, reward 458.0, memory_length 2000, epsilon 0.30030957946018705, time 721.0, rides 135\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 1336, reward 442.0, memory_length 2000, epsilon 0.30003930083867286, time 727.0, rides 128\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1337, reward 276.0, memory_length 2000, epsilon 0.29976926546791804, time 727.0, rides 131\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1338, reward 351.0, memory_length 2000, epsilon 0.29949947312899694, time 726.0, rides 124\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 1339, reward 529.0, memory_length 2000, epsilon 0.29922992360318085, time 730.0, rides 119\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1340, reward 619.0, memory_length 2000, epsilon 0.29896061667193796, time 722.0, rides 131\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 1341, reward 454.0, memory_length 2000, epsilon 0.2986915521169332, time 724.0, rides 129\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 1342, reward 722.0, memory_length 2000, epsilon 0.298422729720028, time 722.0, rides 119\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 1343, reward 431.0, memory_length 2000, epsilon 0.29815414926327993, time 729.0, rides 130\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1344, reward 413.0, memory_length 2000, epsilon 0.297885810528943, time 730.0, rides 120\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1345, reward 588.0, memory_length 2000, epsilon 0.2976177132994669, time 725.0, rides 139\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 1346, reward 507.0, memory_length 2000, epsilon 0.29734985735749736, time 731.0, rides 127\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 1347, reward 370.0, memory_length 2000, epsilon 0.2970822424858756, time 722.0, rides 115\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1348, reward 674.0, memory_length 2000, epsilon 0.2968148684676383, time 727.0, rides 134\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1349, reward 617.0, memory_length 2000, epsilon 0.29654773508601745, time 731.0, rides 135\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 1350, reward 339.0, memory_length 2000, epsilon 0.29628084212444006, time 726.0, rides 124\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 1351, reward 433.0, memory_length 2000, epsilon 0.29601418936652807, time 737.0, rides 127\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1352, reward 626.0, memory_length 2000, epsilon 0.2957477765960982, time 728.0, rides 117\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 1353, reward 327.0, memory_length 2000, epsilon 0.2954816035971617, time 733.0, rides 125\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1354, reward 650.0, memory_length 2000, epsilon 0.29521567015392425, time 722.0, rides 129\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 1355, reward 587.0, memory_length 2000, epsilon 0.2949499760507857, time 730.0, rides 135\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1356, reward 555.0, memory_length 2000, epsilon 0.29468452107234, time 726.0, rides 129\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 1357, reward 508.0, memory_length 2000, epsilon 0.2944193050033749, time 726.0, rides 133\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1358, reward 346.0, memory_length 2000, epsilon 0.29415432762887184, time 725.0, rides 123\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 1359, reward 854.0, memory_length 2000, epsilon 0.29388958873400584, time 730.0, rides 131\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 1360, reward 409.0, memory_length 2000, epsilon 0.2936250881041452, time 734.0, rides 136\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 1361, reward 532.0, memory_length 2000, epsilon 0.2933608255248515, time 733.0, rides 119\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 1362, reward 503.0, memory_length 2000, epsilon 0.2930968007818791, time 732.0, rides 124\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1363, reward 716.0, memory_length 2000, epsilon 0.2928330136611754, time 729.0, rides 129\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 1364, reward 545.0, memory_length 2000, epsilon 0.29256946394888034, time 726.0, rides 139\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 1365, reward 774.0, memory_length 2000, epsilon 0.2923061514313263, time 729.0, rides 139\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 1366, reward 108.0, memory_length 2000, epsilon 0.29204307589503814, time 727.0, rides 137\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 1367, reward 542.0, memory_length 2000, epsilon 0.2917802371267326, time 730.0, rides 127\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1368, reward 401.0, memory_length 2000, epsilon 0.29151763491331856, time 729.0, rides 133\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 1369, reward 345.0, memory_length 2000, epsilon 0.2912552690418966, time 727.0, rides 148\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 1370, reward 507.0, memory_length 2000, epsilon 0.2909931392997589, time 730.0, rides 127\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1371, reward 665.0, memory_length 2000, epsilon 0.2907312454743891, time 729.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1372, reward 636.0, memory_length 2000, epsilon 0.2904695873534622, time 731.0, rides 130\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 1373, reward 617.0, memory_length 2000, epsilon 0.29020816472484406, time 726.0, rides 126\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1374, reward 283.0, memory_length 2000, epsilon 0.2899469773765917, time 722.0, rides 130\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 1375, reward 761.0, memory_length 2000, epsilon 0.28968602509695274, time 729.0, rides 135\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 1376, reward 681.0, memory_length 2000, epsilon 0.2894253076743655, time 731.0, rides 129\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 1377, reward 171.0, memory_length 2000, epsilon 0.28916482489745854, time 724.0, rides 147\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1378, reward 382.0, memory_length 2000, epsilon 0.2889045765550508, time 742.0, rides 131\n",
      "Initial State is  [1, 11, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1379, reward 254.0, memory_length 2000, epsilon 0.2886445624361513, time 734.0, rides 125\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 1380, reward 679.0, memory_length 2000, epsilon 0.28838478232995873, time 735.0, rides 135\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 1381, reward 605.0, memory_length 2000, epsilon 0.28812523602586176, time 722.0, rides 138\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 1382, reward 614.0, memory_length 2000, epsilon 0.28786592331343847, time 726.0, rides 132\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 1383, reward 523.0, memory_length 2000, epsilon 0.2876068439824564, time 736.0, rides 138\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 1384, reward 470.0, memory_length 2000, epsilon 0.2873479978228722, time 740.0, rides 127\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 1385, reward 288.0, memory_length 2000, epsilon 0.2870893846248316, time 726.0, rides 117\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 1386, reward 552.0, memory_length 2000, epsilon 0.28683100417866925, time 741.0, rides 124\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 1387, reward 476.0, memory_length 2000, epsilon 0.2865728562749084, time 732.0, rides 129\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 1388, reward 620.0, memory_length 2000, epsilon 0.286314940704261, time 732.0, rides 119\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 1389, reward 547.0, memory_length 2000, epsilon 0.28605725725762715, time 728.0, rides 131\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 1390, reward 592.0, memory_length 2000, epsilon 0.28579980572609526, time 736.0, rides 128\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1391, reward 466.0, memory_length 2000, epsilon 0.2855425859009418, time 727.0, rides 124\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 1392, reward 492.0, memory_length 2000, epsilon 0.2852855975736309, time 733.0, rides 122\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 1393, reward 668.0, memory_length 2000, epsilon 0.2850288405358147, time 728.0, rides 129\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 1394, reward 586.0, memory_length 2000, epsilon 0.28477231457933244, time 734.0, rides 131\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1395, reward 525.0, memory_length 2000, epsilon 0.284516019496211, time 723.0, rides 122\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 1396, reward 406.0, memory_length 2000, epsilon 0.2842599550786644, time 725.0, rides 134\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 1397, reward 350.0, memory_length 2000, epsilon 0.2840041211190936, time 730.0, rides 129\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 1398, reward 602.0, memory_length 2000, epsilon 0.28374851741008644, time 729.0, rides 132\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1399, reward 536.0, memory_length 2000, epsilon 0.28349314374441736, time 725.0, rides 130\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 1400, reward 412.0, memory_length 2000, epsilon 0.2832379999150474, time 732.0, rides 118\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 1401, reward 498.0, memory_length 2000, epsilon 0.2829830857151238, time 733.0, rides 130\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1402, reward 611.0, memory_length 2000, epsilon 0.2827284009379802, time 725.0, rides 132\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1403, reward 453.0, memory_length 2000, epsilon 0.282473945377136, time 725.0, rides 135\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 1404, reward 585.0, memory_length 2000, epsilon 0.2822197188262966, time 724.0, rides 131\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 1405, reward 551.0, memory_length 2000, epsilon 0.2819657210793529, time 722.0, rides 121\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 1406, reward 377.0, memory_length 2000, epsilon 0.2817119519303815, time 732.0, rides 117\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 1407, reward 889.0, memory_length 2000, epsilon 0.2814584111736442, time 729.0, rides 138\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 1408, reward 384.0, memory_length 2000, epsilon 0.2812050986035879, time 727.0, rides 124\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 1409, reward 386.0, memory_length 2000, epsilon 0.28095201401484465, time 741.0, rides 139\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1410, reward 428.0, memory_length 2000, epsilon 0.28069915720223126, time 730.0, rides 126\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 1411, reward 621.0, memory_length 2000, epsilon 0.28044652796074926, time 732.0, rides 125\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 1412, reward 513.0, memory_length 2000, epsilon 0.2801941260855846, time 740.0, rides 140\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1413, reward 534.0, memory_length 2000, epsilon 0.27994195137210753, time 727.0, rides 132\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 1414, reward 193.0, memory_length 2000, epsilon 0.27969000361587265, time 729.0, rides 114\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 1415, reward 391.0, memory_length 2000, epsilon 0.2794382826126184, time 734.0, rides 124\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1416, reward 724.0, memory_length 2000, epsilon 0.27918678815826703, time 730.0, rides 135\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1417, reward 653.0, memory_length 2000, epsilon 0.2789355200489246, time 736.0, rides 128\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 1418, reward 805.0, memory_length 2000, epsilon 0.27868447808088054, time 726.0, rides 125\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1419, reward 332.0, memory_length 2000, epsilon 0.27843366205060777, time 739.0, rides 115\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 1420, reward 445.0, memory_length 2000, epsilon 0.2781830717547622, time 732.0, rides 131\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 1421, reward 290.0, memory_length 2000, epsilon 0.2779327069901829, time 727.0, rides 135\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 1422, reward 376.0, memory_length 2000, epsilon 0.27768256755389176, time 720.0, rides 135\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 1423, reward 332.0, memory_length 2000, epsilon 0.27743265324309324, time 729.0, rides 123\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 1424, reward 296.0, memory_length 2000, epsilon 0.27718296385517444, time 728.0, rides 117\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 1425, reward 467.0, memory_length 2000, epsilon 0.27693349918770477, time 724.0, rides 134\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1426, reward 711.0, memory_length 2000, epsilon 0.27668425903843585, time 727.0, rides 132\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 1427, reward 509.0, memory_length 2000, epsilon 0.2764352432053013, time 732.0, rides 132\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1428, reward 514.0, memory_length 2000, epsilon 0.2761864514864165, time 722.0, rides 134\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 1429, reward 802.0, memory_length 2000, epsilon 0.27593788368007877, time 739.0, rides 121\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1430, reward 674.0, memory_length 2000, epsilon 0.2756895395847667, time 724.0, rides 122\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 1431, reward 625.0, memory_length 2000, epsilon 0.27544141899914043, time 723.0, rides 132\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 1432, reward 661.0, memory_length 2000, epsilon 0.2751935217220412, time 727.0, rides 133\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1433, reward 466.0, memory_length 2000, epsilon 0.27494584755249135, time 726.0, rides 131\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1434, reward 428.0, memory_length 2000, epsilon 0.2746983962896941, time 732.0, rides 137\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 1435, reward 396.0, memory_length 2000, epsilon 0.2744511677330334, time 732.0, rides 124\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 1436, reward 663.0, memory_length 2000, epsilon 0.2742041616820737, time 737.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 1437, reward 635.0, memory_length 2000, epsilon 0.27395737793655983, time 726.0, rides 127\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1438, reward 915.0, memory_length 2000, epsilon 0.2737108162964169, time 725.0, rides 135\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 1439, reward 456.0, memory_length 2000, epsilon 0.27346447656175016, time 731.0, rides 120\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1440, reward 411.0, memory_length 2000, epsilon 0.2732183585328446, time 730.0, rides 129\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 1441, reward 536.0, memory_length 2000, epsilon 0.272972462010165, time 726.0, rides 114\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 1442, reward 270.0, memory_length 2000, epsilon 0.27272678679435586, time 729.0, rides 128\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 1443, reward 484.0, memory_length 2000, epsilon 0.2724813326862409, time 727.0, rides 124\n",
      "Initial State is  [1, 11, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1444, reward 532.0, memory_length 2000, epsilon 0.2722360994868233, time 728.0, rides 113\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 1445, reward 666.0, memory_length 2000, epsilon 0.2719910869972852, time 737.0, rides 137\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 1446, reward 558.0, memory_length 2000, epsilon 0.2717462950189876, time 730.0, rides 128\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 1447, reward 720.0, memory_length 2000, epsilon 0.2715017233534705, time 733.0, rides 123\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 1448, reward 504.0, memory_length 2000, epsilon 0.27125737180245235, time 727.0, rides 131\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 1449, reward 487.0, memory_length 2000, epsilon 0.2710132401678301, time 728.0, rides 127\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 1450, reward 579.0, memory_length 2000, epsilon 0.2707693282516791, time 728.0, rides 128\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 1451, reward 573.0, memory_length 2000, epsilon 0.2705256358562526, time 724.0, rides 131\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 1452, reward 301.0, memory_length 2000, epsilon 0.270282162783982, time 728.0, rides 129\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 1453, reward 626.0, memory_length 2000, epsilon 0.2700389088374764, time 722.0, rides 127\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1454, reward 377.0, memory_length 2000, epsilon 0.26979587381952264, time 738.0, rides 132\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1455, reward 763.0, memory_length 2000, epsilon 0.26955305753308506, time 731.0, rides 134\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 1456, reward 344.0, memory_length 2000, epsilon 0.2693104597813053, time 739.0, rides 118\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 1457, reward 795.0, memory_length 2000, epsilon 0.2690680803675021, time 731.0, rides 121\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 1458, reward 451.0, memory_length 2000, epsilon 0.2688259190951714, time 723.0, rides 131\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 1459, reward 524.0, memory_length 2000, epsilon 0.26858397576798576, time 722.0, rides 130\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1460, reward 470.0, memory_length 2000, epsilon 0.2683422501897946, time 725.0, rides 131\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1461, reward 482.0, memory_length 2000, epsilon 0.26810074216462376, time 731.0, rides 122\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1462, reward 557.0, memory_length 2000, epsilon 0.2678594514966756, time 735.0, rides 122\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1463, reward 562.0, memory_length 2000, epsilon 0.2676183779903286, time 735.0, rides 134\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 1464, reward 504.0, memory_length 2000, epsilon 0.2673775214501373, time 735.0, rides 127\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1465, reward 442.0, memory_length 2000, epsilon 0.2671368816808322, time 729.0, rides 126\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 1466, reward 339.0, memory_length 2000, epsilon 0.26689645848731947, time 727.0, rides 128\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 1467, reward 450.0, memory_length 2000, epsilon 0.2666562516746809, time 736.0, rides 127\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 1468, reward 704.0, memory_length 2000, epsilon 0.2664162610481737, time 731.0, rides 136\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 1469, reward 403.0, memory_length 2000, epsilon 0.26617648641323033, time 721.0, rides 118\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 1470, reward 523.0, memory_length 2000, epsilon 0.2659369275754584, time 729.0, rides 131\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 1471, reward 745.0, memory_length 2000, epsilon 0.2656975843406405, time 733.0, rides 122\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 1472, reward 253.0, memory_length 2000, epsilon 0.26545845651473393, time 729.0, rides 123\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1473, reward 528.0, memory_length 2000, epsilon 0.26521954390387065, time 732.0, rides 132\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 1474, reward 584.0, memory_length 2000, epsilon 0.26498084631435714, time 723.0, rides 117\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1475, reward 480.0, memory_length 2000, epsilon 0.2647423635526742, time 722.0, rides 123\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1476, reward 467.0, memory_length 2000, epsilon 0.2645040954254768, time 735.0, rides 136\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 1477, reward 539.0, memory_length 2000, epsilon 0.2642660417395939, time 729.0, rides 129\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 1478, reward 413.0, memory_length 2000, epsilon 0.2640282023020283, time 732.0, rides 124\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 1479, reward 632.0, memory_length 2000, epsilon 0.26379057691995644, time 732.0, rides 137\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 1480, reward 412.0, memory_length 2000, epsilon 0.2635531654007285, time 728.0, rides 125\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 1481, reward 614.0, memory_length 2000, epsilon 0.2633159675518678, time 739.0, rides 133\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 1482, reward 619.0, memory_length 2000, epsilon 0.26307898318107115, time 724.0, rides 124\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1483, reward 621.0, memory_length 2000, epsilon 0.26284221209620817, time 742.0, rides 134\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1484, reward 467.0, memory_length 2000, epsilon 0.2626056541053216, time 736.0, rides 140\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 1485, reward 573.0, memory_length 2000, epsilon 0.2623693090166268, time 730.0, rides 133\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 1486, reward 712.0, memory_length 2000, epsilon 0.2621331766385118, time 735.0, rides 122\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1487, reward 421.0, memory_length 2000, epsilon 0.2618972567795372, time 727.0, rides 133\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 1488, reward 425.0, memory_length 2000, epsilon 0.2616615492484356, time 738.0, rides 145\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 1489, reward 800.0, memory_length 2000, epsilon 0.261426053854112, time 728.0, rides 143\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 1490, reward 570.0, memory_length 2000, epsilon 0.2611907704056433, time 728.0, rides 126\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1491, reward 579.0, memory_length 2000, epsilon 0.26095569871227825, time 727.0, rides 137\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1492, reward 754.0, memory_length 2000, epsilon 0.2607208385834372, time 723.0, rides 134\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1493, reward 396.0, memory_length 2000, epsilon 0.2604861898287121, time 729.0, rides 116\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 1494, reward 147.0, memory_length 2000, epsilon 0.26025175225786623, time 730.0, rides 121\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 1495, reward 657.0, memory_length 2000, epsilon 0.26001752568083414, time 732.0, rides 127\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1496, reward 456.0, memory_length 2000, epsilon 0.25978350990772137, time 722.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 1497, reward 333.0, memory_length 2000, epsilon 0.2595497047488044, time 734.0, rides 114\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 1498, reward 651.0, memory_length 2000, epsilon 0.2593161100145305, time 731.0, rides 127\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 1499, reward 491.0, memory_length 2000, epsilon 0.2590827255155174, time 724.0, rides 130\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 1500, reward 414.0, memory_length 2000, epsilon 0.2588495510625535, time 725.0, rides 131\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1501, reward 329.0, memory_length 2000, epsilon 0.2586165864665972, time 736.0, rides 132\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1502, reward 419.0, memory_length 2000, epsilon 0.25838383153877725, time 729.0, rides 115\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 1503, reward 576.0, memory_length 2000, epsilon 0.25815128609039234, time 724.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 1504, reward 666.0, memory_length 2000, epsilon 0.257918949932911, time 729.0, rides 136\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1505, reward 494.0, memory_length 2000, epsilon 0.25768682287797134, time 723.0, rides 128\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1506, reward 328.0, memory_length 2000, epsilon 0.25745490473738114, time 735.0, rides 121\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 1507, reward 660.0, memory_length 2000, epsilon 0.2572231953231175, time 733.0, rides 133\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1508, reward 467.0, memory_length 2000, epsilon 0.25699169444732667, time 726.0, rides 107\n",
      "Initial State is  [3, 21, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1509, reward 373.0, memory_length 2000, epsilon 0.2567604019223241, time 720.0, rides 129\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1510, reward 591.0, memory_length 2000, epsilon 0.256529317560594, time 725.0, rides 137\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1511, reward 693.0, memory_length 2000, epsilon 0.25629844117478945, time 727.0, rides 138\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 1512, reward 393.0, memory_length 2000, epsilon 0.2560677725777321, time 722.0, rides 133\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 1513, reward 321.0, memory_length 2000, epsilon 0.25583731158241213, time 729.0, rides 119\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1514, reward 588.0, memory_length 2000, epsilon 0.25560705800198796, time 721.0, rides 127\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1515, reward 881.0, memory_length 2000, epsilon 0.25537701164978616, time 727.0, rides 131\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1516, reward 378.0, memory_length 2000, epsilon 0.25514717233930134, time 723.0, rides 122\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 1517, reward 637.0, memory_length 2000, epsilon 0.25491753988419596, time 727.0, rides 119\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 1518, reward 558.0, memory_length 2000, epsilon 0.25468811409830017, time 729.0, rides 125\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 1519, reward 464.0, memory_length 2000, epsilon 0.2544588947956117, time 733.0, rides 141\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 1520, reward 654.0, memory_length 2000, epsilon 0.2542298817902956, time 723.0, rides 126\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 1521, reward 674.0, memory_length 2000, epsilon 0.25400107489668433, time 734.0, rides 133\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1522, reward 490.0, memory_length 2000, epsilon 0.2537724739292773, time 728.0, rides 119\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 1523, reward 596.0, memory_length 2000, epsilon 0.253544078702741, time 728.0, rides 128\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1524, reward 414.0, memory_length 2000, epsilon 0.2533158890319085, time 733.0, rides 129\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 1525, reward 621.0, memory_length 2000, epsilon 0.2530879047317798, time 729.0, rides 127\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1526, reward 656.0, memory_length 2000, epsilon 0.2528601256175212, time 729.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 1527, reward 791.0, memory_length 2000, epsilon 0.2526325515044654, time 726.0, rides 125\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1528, reward 526.0, memory_length 2000, epsilon 0.25240518220811137, time 731.0, rides 117\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 1529, reward 751.0, memory_length 2000, epsilon 0.25217801754412406, time 729.0, rides 135\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 1530, reward 634.0, memory_length 2000, epsilon 0.25195105732833434, time 721.0, rides 126\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 1531, reward 820.0, memory_length 2000, epsilon 0.25172430137673885, time 730.0, rides 125\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 1532, reward 876.0, memory_length 2000, epsilon 0.2514977495054998, time 725.0, rides 133\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 1533, reward 434.0, memory_length 2000, epsilon 0.25127140153094485, time 726.0, rides 116\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1534, reward 455.0, memory_length 2000, epsilon 0.251045257269567, time 725.0, rides 119\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1535, reward 579.0, memory_length 2000, epsilon 0.25081931653802436, time 724.0, rides 120\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 1536, reward 584.0, memory_length 2000, epsilon 0.2505935791531401, time 729.0, rides 119\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 1537, reward 598.0, memory_length 2000, epsilon 0.2503680449319023, time 726.0, rides 119\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 1538, reward 505.0, memory_length 2000, epsilon 0.25014271369146357, time 728.0, rides 122\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 1539, reward 271.0, memory_length 2000, epsilon 0.24991758524914126, time 730.0, rides 125\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 1540, reward 608.0, memory_length 2000, epsilon 0.24969265942241703, time 734.0, rides 133\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 1541, reward 212.0, memory_length 2000, epsilon 0.24946793602893685, time 723.0, rides 115\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1542, reward 543.0, memory_length 2000, epsilon 0.2492434148865108, time 729.0, rides 132\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 1543, reward 526.0, memory_length 2000, epsilon 0.24901909581311293, time 735.0, rides 116\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1544, reward 677.0, memory_length 2000, epsilon 0.24879497862688113, time 730.0, rides 126\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1545, reward 441.0, memory_length 2000, epsilon 0.24857106314611693, time 723.0, rides 130\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1546, reward 424.0, memory_length 2000, epsilon 0.24834734918928542, time 725.0, rides 118\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 1547, reward 570.0, memory_length 2000, epsilon 0.24812383657501505, time 733.0, rides 121\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 1548, reward 362.0, memory_length 2000, epsilon 0.24790052512209754, time 729.0, rides 118\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1549, reward 524.0, memory_length 2000, epsilon 0.24767741464948764, time 730.0, rides 131\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 1550, reward 422.0, memory_length 2000, epsilon 0.2474545049763031, time 724.0, rides 121\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 1551, reward 698.0, memory_length 2000, epsilon 0.24723179592182443, time 731.0, rides 116\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 1552, reward 628.0, memory_length 2000, epsilon 0.2470092873054948, time 729.0, rides 132\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 1553, reward 398.0, memory_length 2000, epsilon 0.24678697894691984, time 726.0, rides 127\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 1554, reward 529.0, memory_length 2000, epsilon 0.2465648706658676, time 732.0, rides 142\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 1555, reward 561.0, memory_length 2000, epsilon 0.24634296228226832, time 736.0, rides 131\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 1556, reward 540.0, memory_length 2000, epsilon 0.24612125361621429, time 721.0, rides 118\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1557, reward 785.0, memory_length 2000, epsilon 0.2458997444879597, time 728.0, rides 121\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 1558, reward 554.0, memory_length 2000, epsilon 0.24567843471792053, time 723.0, rides 129\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 1559, reward 347.0, memory_length 2000, epsilon 0.2454573241266744, time 730.0, rides 132\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1560, reward 582.0, memory_length 2000, epsilon 0.2452364125349604, time 727.0, rides 129\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 1561, reward 631.0, memory_length 2000, epsilon 0.24501569976367893, time 732.0, rides 129\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 1562, reward 780.0, memory_length 2000, epsilon 0.2447951856338916, time 720.0, rides 133\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1563, reward 571.0, memory_length 2000, epsilon 0.2445748699668211, time 729.0, rides 123\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1564, reward 499.0, memory_length 2000, epsilon 0.24435475258385095, time 725.0, rides 117\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 1565, reward 508.0, memory_length 2000, epsilon 0.24413483330652547, time 725.0, rides 132\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1566, reward 621.0, memory_length 2000, epsilon 0.24391511195654958, time 739.0, rides 133\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 1567, reward 588.0, memory_length 2000, epsilon 0.2436955883557887, time 725.0, rides 142\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 1568, reward 406.0, memory_length 2000, epsilon 0.24347626232626848, time 736.0, rides 125\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1569, reward 380.0, memory_length 2000, epsilon 0.24325713369017485, time 728.0, rides 125\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 1570, reward 904.0, memory_length 2000, epsilon 0.24303820226985368, time 731.0, rides 128\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 1571, reward 466.0, memory_length 2000, epsilon 0.2428194678878108, time 721.0, rides 129\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 1572, reward 531.0, memory_length 2000, epsilon 0.24260093036671176, time 738.0, rides 127\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1573, reward 766.0, memory_length 2000, epsilon 0.24238258952938171, time 728.0, rides 136\n",
      "Initial State is  [2, 18, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1574, reward 520.0, memory_length 2000, epsilon 0.24216444519880526, time 732.0, rides 128\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 1575, reward 432.0, memory_length 2000, epsilon 0.24194649719812633, time 722.0, rides 115\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 1576, reward 733.0, memory_length 2000, epsilon 0.241728745350648, time 731.0, rides 131\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 1577, reward 643.0, memory_length 2000, epsilon 0.2415111894798324, time 721.0, rides 125\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1578, reward 545.0, memory_length 2000, epsilon 0.24129382940930055, time 731.0, rides 122\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 1579, reward 560.0, memory_length 2000, epsilon 0.24107666496283217, time 727.0, rides 122\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 1580, reward 583.0, memory_length 2000, epsilon 0.24085969596436563, time 727.0, rides 116\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1581, reward 711.0, memory_length 2000, epsilon 0.2406429222379977, time 735.0, rides 124\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1582, reward 620.0, memory_length 2000, epsilon 0.24042634360798348, time 728.0, rides 131\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 1583, reward 473.0, memory_length 2000, epsilon 0.2402099598987363, time 737.0, rides 124\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 1584, reward 487.0, memory_length 2000, epsilon 0.23999377093482743, time 731.0, rides 129\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 1585, reward 717.0, memory_length 2000, epsilon 0.2397777765409861, time 731.0, rides 123\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 1586, reward 751.0, memory_length 2000, epsilon 0.2395619765420992, time 732.0, rides 134\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 1587, reward 544.0, memory_length 2000, epsilon 0.23934637076321133, time 733.0, rides 136\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 1588, reward 541.0, memory_length 2000, epsilon 0.23913095902952444, time 726.0, rides 121\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 1589, reward 555.0, memory_length 2000, epsilon 0.23891574116639785, time 733.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 1590, reward 772.0, memory_length 2000, epsilon 0.23870071699934808, time 735.0, rides 129\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 1591, reward 556.0, memory_length 2000, epsilon 0.23848588635404866, time 725.0, rides 132\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 1592, reward 312.0, memory_length 2000, epsilon 0.23827124905633001, time 742.0, rides 136\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1593, reward 588.0, memory_length 2000, epsilon 0.23805680493217932, time 731.0, rides 121\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 1594, reward 908.0, memory_length 2000, epsilon 0.23784255380774036, time 721.0, rides 136\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1595, reward 404.0, memory_length 2000, epsilon 0.2376284955093134, time 725.0, rides 123\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 1596, reward 585.0, memory_length 2000, epsilon 0.23741462986335501, time 735.0, rides 127\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 1597, reward 957.0, memory_length 2000, epsilon 0.237200956696478, time 733.0, rides 130\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 1598, reward 627.0, memory_length 2000, epsilon 0.23698747583545118, time 727.0, rides 140\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 1599, reward 868.0, memory_length 2000, epsilon 0.23677418710719927, time 723.0, rides 131\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 1600, reward 488.0, memory_length 2000, epsilon 0.2365610903388028, time 729.0, rides 128\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1601, reward 289.0, memory_length 2000, epsilon 0.23634818535749788, time 726.0, rides 131\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 1602, reward 560.0, memory_length 2000, epsilon 0.23613547199067614, time 731.0, rides 131\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1603, reward 373.0, memory_length 2000, epsilon 0.23592295006588454, time 737.0, rides 129\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 1604, reward 487.0, memory_length 2000, epsilon 0.23571061941082525, time 732.0, rides 134\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 1605, reward 607.0, memory_length 2000, epsilon 0.2354984798533555, time 724.0, rides 128\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 1606, reward 518.0, memory_length 2000, epsilon 0.2352865312214875, time 728.0, rides 128\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1607, reward 520.0, memory_length 2000, epsilon 0.23507477334338814, time 726.0, rides 132\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 1608, reward 749.0, memory_length 2000, epsilon 0.2348632060473791, time 731.0, rides 131\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 1609, reward 463.0, memory_length 2000, epsilon 0.23465182916193644, time 724.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 1610, reward 707.0, memory_length 2000, epsilon 0.2344406425156907, time 731.0, rides 129\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 1611, reward 742.0, memory_length 2000, epsilon 0.23422964593742657, time 732.0, rides 126\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 1612, reward 680.0, memory_length 2000, epsilon 0.23401883925608288, time 733.0, rides 144\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1613, reward 782.0, memory_length 2000, epsilon 0.2338082223007524, time 724.0, rides 124\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 1614, reward 778.0, memory_length 2000, epsilon 0.23359779490068172, time 728.0, rides 145\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 1615, reward 525.0, memory_length 2000, epsilon 0.2333875568852711, time 730.0, rides 126\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 1616, reward 523.0, memory_length 2000, epsilon 0.23317750808407436, time 722.0, rides 132\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 1617, reward 503.0, memory_length 2000, epsilon 0.2329676483267987, time 736.0, rides 136\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 1618, reward 567.0, memory_length 2000, epsilon 0.23275797744330456, time 734.0, rides 136\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 1619, reward 669.0, memory_length 2000, epsilon 0.23254849526360558, time 726.0, rides 140\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1620, reward 595.0, memory_length 2000, epsilon 0.23233920161786834, time 728.0, rides 122\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 1621, reward 388.0, memory_length 2000, epsilon 0.23213009633641224, time 726.0, rides 134\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 1622, reward 827.0, memory_length 2000, epsilon 0.23192117924970945, time 728.0, rides 121\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1623, reward 562.0, memory_length 2000, epsilon 0.2317124501883847, time 730.0, rides 121\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 1624, reward 427.0, memory_length 2000, epsilon 0.23150390898321516, time 733.0, rides 121\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1625, reward 779.0, memory_length 2000, epsilon 0.23129555546513025, time 724.0, rides 128\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 1626, reward 484.0, memory_length 2000, epsilon 0.23108738946521162, time 729.0, rides 126\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 1627, reward 829.0, memory_length 2000, epsilon 0.23087941081469293, time 731.0, rides 117\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 1628, reward 827.0, memory_length 2000, epsilon 0.2306716193449597, time 730.0, rides 122\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 1629, reward 410.0, memory_length 2000, epsilon 0.23046401488754922, time 731.0, rides 136\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 1630, reward 923.0, memory_length 2000, epsilon 0.23025659727415043, time 726.0, rides 138\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 1631, reward 700.0, memory_length 2000, epsilon 0.2300493663366037, time 724.0, rides 137\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1632, reward 720.0, memory_length 2000, epsilon 0.22984232190690074, time 729.0, rides 125\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 1633, reward 557.0, memory_length 2000, epsilon 0.22963546381718453, time 730.0, rides 125\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 1634, reward 231.0, memory_length 2000, epsilon 0.22942879189974905, time 728.0, rides 116\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 1635, reward 809.0, memory_length 2000, epsilon 0.22922230598703927, time 726.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 1636, reward 122.0, memory_length 2000, epsilon 0.22901600591165094, time 725.0, rides 128\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1637, reward 563.0, memory_length 2000, epsilon 0.22880989150633047, time 733.0, rides 130\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 1638, reward 677.0, memory_length 2000, epsilon 0.22860396260397475, time 731.0, rides 135\n",
      "Initial State is  [0, 10, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1639, reward 841.0, memory_length 2000, epsilon 0.22839821903763116, time 730.0, rides 138\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 1640, reward 406.0, memory_length 2000, epsilon 0.22819266064049729, time 731.0, rides 119\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 1641, reward 706.0, memory_length 2000, epsilon 0.22798728724592082, time 730.0, rides 123\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1642, reward 405.0, memory_length 2000, epsilon 0.2277820986873995, time 725.0, rides 128\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 1643, reward 535.0, memory_length 2000, epsilon 0.22757709479858082, time 728.0, rides 128\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1644, reward 678.0, memory_length 2000, epsilon 0.2273722754132621, time 727.0, rides 132\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1645, reward 495.0, memory_length 2000, epsilon 0.22716764036539017, time 736.0, rides 130\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 1646, reward 770.0, memory_length 2000, epsilon 0.2269631894890613, time 730.0, rides 127\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1647, reward 766.0, memory_length 2000, epsilon 0.22675892261852115, time 727.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 1648, reward 827.0, memory_length 2000, epsilon 0.22655483958816447, time 732.0, rides 137\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 1649, reward 473.0, memory_length 2000, epsilon 0.22635094023253513, time 734.0, rides 124\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 1650, reward 627.0, memory_length 2000, epsilon 0.22614722438632584, time 724.0, rides 138\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1651, reward 648.0, memory_length 2000, epsilon 0.22594369188437816, time 724.0, rides 122\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 1652, reward 976.0, memory_length 2000, epsilon 0.2257403425616822, time 730.0, rides 142\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1653, reward 700.0, memory_length 2000, epsilon 0.2255371762533767, time 729.0, rides 126\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 1654, reward 550.0, memory_length 2000, epsilon 0.22533419279474864, time 733.0, rides 137\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1655, reward 905.0, memory_length 2000, epsilon 0.22513139202123336, time 723.0, rides 139\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1656, reward 778.0, memory_length 2000, epsilon 0.22492877376841425, time 727.0, rides 142\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1657, reward 1083.0, memory_length 2000, epsilon 0.22472633787202267, time 730.0, rides 137\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1658, reward 945.0, memory_length 2000, epsilon 0.22452408416793784, time 733.0, rides 136\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 1659, reward 731.0, memory_length 2000, epsilon 0.2243220124921867, time 724.0, rides 119\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1660, reward 775.0, memory_length 2000, epsilon 0.22412012268094372, time 723.0, rides 136\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 1661, reward 664.0, memory_length 2000, epsilon 0.22391841457053088, time 725.0, rides 117\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 1662, reward 670.0, memory_length 2000, epsilon 0.2237168879974174, time 727.0, rides 129\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 1663, reward 429.0, memory_length 2000, epsilon 0.22351554279821972, time 721.0, rides 128\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 1664, reward 649.0, memory_length 2000, epsilon 0.2233143788097013, time 726.0, rides 139\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 1665, reward 695.0, memory_length 2000, epsilon 0.22311339586877257, time 728.0, rides 129\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 1666, reward 572.0, memory_length 2000, epsilon 0.22291259381249068, time 730.0, rides 125\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 1667, reward 848.0, memory_length 2000, epsilon 0.22271197247805943, time 725.0, rides 128\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1668, reward 377.0, memory_length 2000, epsilon 0.22251153170282917, time 726.0, rides 135\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 1669, reward 672.0, memory_length 2000, epsilon 0.22231127132429662, time 726.0, rides 128\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1670, reward 673.0, memory_length 2000, epsilon 0.22211119118010475, time 727.0, rides 131\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 1671, reward 336.0, memory_length 2000, epsilon 0.22191129110804264, time 734.0, rides 133\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 1672, reward 221.0, memory_length 2000, epsilon 0.2217115709460454, time 732.0, rides 129\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 1673, reward 604.0, memory_length 2000, epsilon 0.22151203053219395, time 732.0, rides 132\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1674, reward 336.0, memory_length 2000, epsilon 0.22131266970471497, time 727.0, rides 134\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 1675, reward 462.0, memory_length 2000, epsilon 0.22111348830198072, time 733.0, rides 123\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 1676, reward 875.0, memory_length 2000, epsilon 0.22091448616250892, time 723.0, rides 121\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1677, reward 718.0, memory_length 2000, epsilon 0.22071566312496266, time 738.0, rides 122\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 1678, reward 804.0, memory_length 2000, epsilon 0.22051701902815019, time 729.0, rides 130\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 1679, reward 483.0, memory_length 2000, epsilon 0.22031855371102485, time 725.0, rides 130\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 1680, reward 536.0, memory_length 2000, epsilon 0.22012026701268492, time 734.0, rides 142\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 1681, reward 295.0, memory_length 2000, epsilon 0.2199221587723735, time 731.0, rides 131\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 1682, reward 830.0, memory_length 2000, epsilon 0.21972422882947837, time 726.0, rides 132\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1683, reward 581.0, memory_length 2000, epsilon 0.21952647702353184, time 727.0, rides 135\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1684, reward 645.0, memory_length 2000, epsilon 0.21932890319421067, time 729.0, rides 128\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 1685, reward 570.0, memory_length 2000, epsilon 0.21913150718133587, time 730.0, rides 136\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 1686, reward 521.0, memory_length 2000, epsilon 0.21893428882487267, time 737.0, rides 127\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1687, reward 954.0, memory_length 2000, epsilon 0.2187372479649303, time 725.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1688, reward 516.0, memory_length 2000, epsilon 0.21854038444176185, time 726.0, rides 114\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 1689, reward 599.0, memory_length 2000, epsilon 0.21834369809576426, time 725.0, rides 130\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 1690, reward 700.0, memory_length 2000, epsilon 0.21814718876747807, time 739.0, rides 132\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1691, reward 551.0, memory_length 2000, epsilon 0.21795085629758734, time 727.0, rides 129\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 1692, reward 158.0, memory_length 2000, epsilon 0.2177547005269195, time 728.0, rides 122\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 1693, reward 820.0, memory_length 2000, epsilon 0.21755872129644527, time 725.0, rides 120\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 1694, reward 902.0, memory_length 2000, epsilon 0.21736291844727845, time 730.0, rides 146\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1695, reward 392.0, memory_length 2000, epsilon 0.2171672918206759, time 730.0, rides 128\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1696, reward 957.0, memory_length 2000, epsilon 0.21697184125803728, time 734.0, rides 118\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 1697, reward 704.0, memory_length 2000, epsilon 0.21677656660090505, time 732.0, rides 128\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 1698, reward 455.0, memory_length 2000, epsilon 0.21658146769096423, time 729.0, rides 127\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 1699, reward 501.0, memory_length 2000, epsilon 0.21638654437004237, time 730.0, rides 120\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 1700, reward 699.0, memory_length 2000, epsilon 0.21619179648010933, time 728.0, rides 115\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 1701, reward 919.0, memory_length 2000, epsilon 0.21599722386327724, time 725.0, rides 130\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1702, reward 639.0, memory_length 2000, epsilon 0.2158028263618003, time 724.0, rides 130\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1703, reward 570.0, memory_length 2000, epsilon 0.21560860381807467, time 726.0, rides 129\n",
      "Initial State is  [2, 1, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1704, reward 553.0, memory_length 2000, epsilon 0.2154145560746384, time 731.0, rides 130\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 1705, reward 661.0, memory_length 2000, epsilon 0.21522068297417124, time 726.0, rides 128\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1706, reward 537.0, memory_length 2000, epsilon 0.2150269843594945, time 733.0, rides 122\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 1707, reward 586.0, memory_length 2000, epsilon 0.21483346007357096, time 727.0, rides 143\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1708, reward 779.0, memory_length 2000, epsilon 0.21464010995950475, time 726.0, rides 125\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 1709, reward 481.0, memory_length 2000, epsilon 0.2144469338605412, time 730.0, rides 129\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 1710, reward 567.0, memory_length 2000, epsilon 0.2142539316200667, time 725.0, rides 121\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 1711, reward 882.0, memory_length 2000, epsilon 0.21406110308160864, time 728.0, rides 129\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 1712, reward 727.0, memory_length 2000, epsilon 0.21386844808883518, time 723.0, rides 132\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 1713, reward 921.0, memory_length 2000, epsilon 0.21367596648555523, time 725.0, rides 120\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 1714, reward 791.0, memory_length 2000, epsilon 0.21348365811571823, time 722.0, rides 129\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 1715, reward 455.0, memory_length 2000, epsilon 0.2132915228234141, time 734.0, rides 137\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 1716, reward 669.0, memory_length 2000, epsilon 0.213099560452873, time 724.0, rides 116\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 1717, reward 515.0, memory_length 2000, epsilon 0.21290777084846543, time 726.0, rides 139\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 1718, reward 614.0, memory_length 2000, epsilon 0.2127161538547018, time 727.0, rides 134\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 1719, reward 783.0, memory_length 2000, epsilon 0.21252470931623257, time 721.0, rides 126\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 1720, reward 443.0, memory_length 2000, epsilon 0.21233343707784796, time 738.0, rides 119\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1721, reward 582.0, memory_length 2000, epsilon 0.2121423369844779, time 729.0, rides 136\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1722, reward 604.0, memory_length 2000, epsilon 0.21195140888119188, time 733.0, rides 121\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 1723, reward 730.0, memory_length 2000, epsilon 0.2117606526131988, time 728.0, rides 142\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 1724, reward 629.0, memory_length 2000, epsilon 0.2115700680258469, time 725.0, rides 130\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 1725, reward 665.0, memory_length 2000, epsilon 0.21137965496462363, time 728.0, rides 113\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1726, reward 597.0, memory_length 2000, epsilon 0.21118941327515547, time 730.0, rides 132\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 1727, reward 592.0, memory_length 2000, epsilon 0.21099934280320784, time 723.0, rides 141\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 1728, reward 638.0, memory_length 2000, epsilon 0.21080944339468494, time 722.0, rides 129\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 1729, reward 639.0, memory_length 2000, epsilon 0.21061971489562972, time 731.0, rides 114\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 1730, reward 345.0, memory_length 2000, epsilon 0.21043015715222366, time 733.0, rides 133\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 1731, reward 871.0, memory_length 2000, epsilon 0.21024077001078664, time 730.0, rides 125\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 1732, reward 676.0, memory_length 2000, epsilon 0.21005155331777695, time 732.0, rides 139\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1733, reward 636.0, memory_length 2000, epsilon 0.20986250691979094, time 727.0, rides 117\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 1734, reward 275.0, memory_length 2000, epsilon 0.20967363066356312, time 733.0, rides 123\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 1735, reward 636.0, memory_length 2000, epsilon 0.20948492439596592, time 723.0, rides 125\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 1736, reward 299.0, memory_length 2000, epsilon 0.20929638796400954, time 736.0, rides 127\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1737, reward 479.0, memory_length 2000, epsilon 0.20910802121484193, time 738.0, rides 133\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 1738, reward 597.0, memory_length 2000, epsilon 0.20891982399574857, time 727.0, rides 136\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 1739, reward 650.0, memory_length 2000, epsilon 0.20873179615415238, time 734.0, rides 134\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 1740, reward 805.0, memory_length 2000, epsilon 0.20854393753761363, time 732.0, rides 128\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 1741, reward 576.0, memory_length 2000, epsilon 0.2083562479938298, time 734.0, rides 122\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 1742, reward 652.0, memory_length 2000, epsilon 0.20816872737063535, time 734.0, rides 125\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 1743, reward 635.0, memory_length 2000, epsilon 0.2079813755160018, time 726.0, rides 127\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 1744, reward 382.0, memory_length 2000, epsilon 0.2077941922780374, time 733.0, rides 138\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 1745, reward 588.0, memory_length 2000, epsilon 0.20760717750498714, time 724.0, rides 121\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 1746, reward 658.0, memory_length 2000, epsilon 0.20742033104523264, time 730.0, rides 126\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 1747, reward 724.0, memory_length 2000, epsilon 0.2072336527472919, time 727.0, rides 139\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1748, reward 838.0, memory_length 2000, epsilon 0.20704714245981934, time 730.0, rides 138\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1749, reward 709.0, memory_length 2000, epsilon 0.2068608000316055, time 731.0, rides 130\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 1750, reward 724.0, memory_length 2000, epsilon 0.20667462531157707, time 721.0, rides 135\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1751, reward 780.0, memory_length 2000, epsilon 0.20648861814879665, time 727.0, rides 129\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1752, reward 759.0, memory_length 2000, epsilon 0.20630277839246272, time 727.0, rides 133\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 1753, reward 735.0, memory_length 2000, epsilon 0.2061171058919095, time 726.0, rides 127\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1754, reward 737.0, memory_length 2000, epsilon 0.2059316004966068, time 734.0, rides 147\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1755, reward 628.0, memory_length 2000, epsilon 0.20574626205615987, time 725.0, rides 135\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 1756, reward 738.0, memory_length 2000, epsilon 0.20556109042030932, time 730.0, rides 129\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 1757, reward 965.0, memory_length 2000, epsilon 0.20537608543893104, time 721.0, rides 133\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 1758, reward 663.0, memory_length 2000, epsilon 0.205191246962036, time 730.0, rides 131\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 1759, reward 677.0, memory_length 2000, epsilon 0.20500657483977017, time 728.0, rides 144\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 1760, reward 902.0, memory_length 2000, epsilon 0.20482206892241436, time 725.0, rides 140\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 1761, reward 600.0, memory_length 2000, epsilon 0.2046377290603842, time 731.0, rides 138\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1762, reward 401.0, memory_length 2000, epsilon 0.20445355510422983, time 730.0, rides 123\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 1763, reward 570.0, memory_length 2000, epsilon 0.20426954690463603, time 733.0, rides 124\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 1764, reward 939.0, memory_length 2000, epsilon 0.20408570431242185, time 732.0, rides 147\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 1765, reward 773.0, memory_length 2000, epsilon 0.20390202717854067, time 729.0, rides 134\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 1766, reward 670.0, memory_length 2000, epsilon 0.20371851535407998, time 726.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 1767, reward 556.0, memory_length 2000, epsilon 0.2035351686902613, time 728.0, rides 123\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 1768, reward 775.0, memory_length 2000, epsilon 0.20335198703844007, time 731.0, rides 130\n",
      "Initial State is  [4, 18, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1769, reward 640.0, memory_length 2000, epsilon 0.20316897025010547, time 730.0, rides 144\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 1770, reward 748.0, memory_length 2000, epsilon 0.20298611817688036, time 742.0, rides 135\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1771, reward 605.0, memory_length 2000, epsilon 0.20280343067052117, time 725.0, rides 126\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 1772, reward 618.0, memory_length 2000, epsilon 0.2026209075829177, time 728.0, rides 129\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 1773, reward 607.0, memory_length 2000, epsilon 0.20243854876609307, time 722.0, rides 134\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 1774, reward 433.0, memory_length 2000, epsilon 0.20225635407220358, time 724.0, rides 137\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 1775, reward 964.0, memory_length 2000, epsilon 0.2020743233535386, time 726.0, rides 132\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 1776, reward 550.0, memory_length 2000, epsilon 0.2018924564625204, time 733.0, rides 123\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 1777, reward 751.0, memory_length 2000, epsilon 0.20171075325170415, time 727.0, rides 140\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 1778, reward 509.0, memory_length 2000, epsilon 0.20152921357377762, time 724.0, rides 142\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 1779, reward 508.0, memory_length 2000, epsilon 0.20134783728156122, time 736.0, rides 137\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1780, reward 477.0, memory_length 2000, epsilon 0.20116662422800782, time 727.0, rides 136\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 1781, reward 766.0, memory_length 2000, epsilon 0.20098557426620262, time 739.0, rides 134\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 1782, reward 916.0, memory_length 2000, epsilon 0.20080468724936304, time 741.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 1783, reward 516.0, memory_length 2000, epsilon 0.2006239630308386, time 733.0, rides 146\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 1784, reward 689.0, memory_length 2000, epsilon 0.20044340146411085, time 729.0, rides 126\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1785, reward 806.0, memory_length 2000, epsilon 0.20026300240279316, time 727.0, rides 126\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 1786, reward 614.0, memory_length 2000, epsilon 0.20008276570063063, time 736.0, rides 127\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 1787, reward 618.0, memory_length 2000, epsilon 0.19990269121150006, time 731.0, rides 120\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 1788, reward 783.0, memory_length 2000, epsilon 0.19972277878940972, time 729.0, rides 124\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 1789, reward 621.0, memory_length 2000, epsilon 0.19954302828849926, time 726.0, rides 135\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 1790, reward 598.0, memory_length 2000, epsilon 0.19936343956303962, time 721.0, rides 129\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 1791, reward 716.0, memory_length 2000, epsilon 0.1991840124674329, time 726.0, rides 125\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 1792, reward 899.0, memory_length 2000, epsilon 0.1990047468562122, time 736.0, rides 131\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 1793, reward 907.0, memory_length 2000, epsilon 0.1988256425840416, time 721.0, rides 124\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 1794, reward 749.0, memory_length 2000, epsilon 0.19864669950571595, time 736.0, rides 134\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1795, reward 736.0, memory_length 2000, epsilon 0.1984679174761608, time 723.0, rides 125\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1796, reward 411.0, memory_length 2000, epsilon 0.19828929635043224, time 724.0, rides 130\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 1797, reward 678.0, memory_length 2000, epsilon 0.19811083598371684, time 727.0, rides 119\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 1798, reward 922.0, memory_length 2000, epsilon 0.1979325362313315, time 726.0, rides 123\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 1799, reward 329.0, memory_length 2000, epsilon 0.1977543969487233, time 731.0, rides 124\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 1800, reward 654.0, memory_length 2000, epsilon 0.19757641799146944, time 731.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1801, reward 869.0, memory_length 2000, epsilon 0.1973985992152771, time 725.0, rides 134\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 1802, reward 806.0, memory_length 2000, epsilon 0.19722094047598335, time 728.0, rides 130\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1803, reward 895.0, memory_length 2000, epsilon 0.19704344162955495, time 737.0, rides 124\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 1804, reward 645.0, memory_length 2000, epsilon 0.19686610253208836, time 731.0, rides 119\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 1805, reward 972.0, memory_length 2000, epsilon 0.19668892303980948, time 731.0, rides 122\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 1806, reward 490.0, memory_length 2000, epsilon 0.19651190300907365, time 726.0, rides 123\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1807, reward 639.0, memory_length 2000, epsilon 0.19633504229636548, time 736.0, rides 124\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 1808, reward 435.0, memory_length 2000, epsilon 0.19615834075829874, time 734.0, rides 125\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1809, reward 303.0, memory_length 2000, epsilon 0.19598179825161627, time 741.0, rides 124\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 1810, reward 537.0, memory_length 2000, epsilon 0.19580541463318982, time 729.0, rides 126\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 1811, reward 553.0, memory_length 2000, epsilon 0.19562918976001994, time 723.0, rides 143\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1812, reward 517.0, memory_length 2000, epsilon 0.19545312348923594, time 726.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 1813, reward 598.0, memory_length 2000, epsilon 0.1952772156780956, time 725.0, rides 147\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 1814, reward 796.0, memory_length 2000, epsilon 0.19510146618398533, time 732.0, rides 129\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 1815, reward 547.0, memory_length 2000, epsilon 0.19492587486441973, time 740.0, rides 127\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1816, reward 556.0, memory_length 2000, epsilon 0.19475044157704174, time 729.0, rides 144\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1817, reward 814.0, memory_length 2000, epsilon 0.1945751661796224, time 734.0, rides 124\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1818, reward 482.0, memory_length 2000, epsilon 0.19440004853006074, time 722.0, rides 134\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1819, reward 591.0, memory_length 2000, epsilon 0.19422508848638367, time 729.0, rides 137\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 1820, reward 668.0, memory_length 2000, epsilon 0.19405028590674592, time 728.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 1821, reward 716.0, memory_length 2000, epsilon 0.19387564064942983, time 735.0, rides 125\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1822, reward 523.0, memory_length 2000, epsilon 0.19370115257284534, time 729.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1823, reward 854.0, memory_length 2000, epsilon 0.19352682153552977, time 725.0, rides 136\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 1824, reward 593.0, memory_length 2000, epsilon 0.1933526473961478, time 732.0, rides 135\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1825, reward 929.0, memory_length 2000, epsilon 0.19317863001349125, time 727.0, rides 143\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 1826, reward 908.0, memory_length 2000, epsilon 0.1930047692464791, time 735.0, rides 129\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 1827, reward 1016.0, memory_length 2000, epsilon 0.19283106495415728, time 741.0, rides 136\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 1828, reward 560.0, memory_length 2000, epsilon 0.19265751699569852, time 723.0, rides 142\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 1829, reward 761.0, memory_length 2000, epsilon 0.1924841252304024, time 735.0, rides 137\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 1830, reward 844.0, memory_length 2000, epsilon 0.19231088951769504, time 727.0, rides 137\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 1831, reward 628.0, memory_length 2000, epsilon 0.1921378097171291, time 723.0, rides 119\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 1832, reward 812.0, memory_length 2000, epsilon 0.19196488568838369, time 726.0, rides 146\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 1833, reward 774.0, memory_length 2000, epsilon 0.19179211729126414, time 725.0, rides 150\n",
      "Initial State is  [1, 16, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1834, reward 625.0, memory_length 2000, epsilon 0.191619504385702, time 733.0, rides 134\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 1835, reward 608.0, memory_length 2000, epsilon 0.19144704683175487, time 725.0, rides 133\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1836, reward 637.0, memory_length 2000, epsilon 0.1912747444896063, time 725.0, rides 135\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1837, reward 701.0, memory_length 2000, epsilon 0.19110259721956566, time 728.0, rides 140\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1838, reward 432.0, memory_length 2000, epsilon 0.19093060488206803, time 730.0, rides 132\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 1839, reward 379.0, memory_length 2000, epsilon 0.19075876733767416, time 726.0, rides 134\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1840, reward 392.0, memory_length 2000, epsilon 0.19058708444707026, time 723.0, rides 120\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 1841, reward 480.0, memory_length 2000, epsilon 0.1904155560710679, time 731.0, rides 134\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 1842, reward 394.0, memory_length 2000, epsilon 0.19024418207060392, time 729.0, rides 114\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 1843, reward 753.0, memory_length 2000, epsilon 0.19007296230674037, time 729.0, rides 125\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 1844, reward 659.0, memory_length 2000, epsilon 0.18990189664066429, time 722.0, rides 140\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 1845, reward 457.0, memory_length 2000, epsilon 0.18973098493368767, time 726.0, rides 135\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1846, reward 933.0, memory_length 2000, epsilon 0.18956022704724734, time 731.0, rides 123\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 1847, reward 645.0, memory_length 2000, epsilon 0.1893896228429048, time 723.0, rides 128\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 1848, reward 530.0, memory_length 2000, epsilon 0.18921917218234618, time 728.0, rides 138\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 1849, reward 430.0, memory_length 2000, epsilon 0.18904887492738207, time 723.0, rides 131\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 1850, reward 815.0, memory_length 2000, epsilon 0.18887873093994742, time 730.0, rides 127\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 1851, reward 281.0, memory_length 2000, epsilon 0.18870874008210148, time 732.0, rides 125\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 1852, reward 424.0, memory_length 2000, epsilon 0.1885389022160276, time 730.0, rides 134\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1853, reward 336.0, memory_length 2000, epsilon 0.18836921720403316, time 738.0, rides 137\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 1854, reward 817.0, memory_length 2000, epsilon 0.18819968490854952, time 731.0, rides 127\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1855, reward 752.0, memory_length 2000, epsilon 0.18803030519213182, time 727.0, rides 131\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 1856, reward 392.0, memory_length 2000, epsilon 0.1878610779174589, time 729.0, rides 128\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 1857, reward 791.0, memory_length 2000, epsilon 0.18769200294733318, time 727.0, rides 128\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 1858, reward 665.0, memory_length 2000, epsilon 0.18752308014468058, time 731.0, rides 120\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 1859, reward 623.0, memory_length 2000, epsilon 0.18735430937255038, time 725.0, rides 124\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1860, reward 591.0, memory_length 2000, epsilon 0.18718569049411507, time 724.0, rides 153\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1861, reward 627.0, memory_length 2000, epsilon 0.18701722337267038, time 725.0, rides 130\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 1862, reward 570.0, memory_length 2000, epsilon 0.18684890787163497, time 723.0, rides 134\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1863, reward 500.0, memory_length 2000, epsilon 0.1866807438545505, time 727.0, rides 119\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 1864, reward 744.0, memory_length 2000, epsilon 0.1865127311850814, time 721.0, rides 129\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 1865, reward 709.0, memory_length 2000, epsilon 0.18634486972701483, time 723.0, rides 139\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1866, reward 775.0, memory_length 2000, epsilon 0.18617715934426052, time 737.0, rides 139\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 1867, reward 497.0, memory_length 2000, epsilon 0.18600959990085067, time 730.0, rides 137\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 1868, reward 739.0, memory_length 2000, epsilon 0.1858421912609399, time 728.0, rides 126\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 1869, reward 698.0, memory_length 2000, epsilon 0.18567493328880505, time 725.0, rides 150\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 1870, reward 647.0, memory_length 2000, epsilon 0.18550782584884512, time 723.0, rides 126\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 1871, reward 725.0, memory_length 2000, epsilon 0.18534086880558115, time 731.0, rides 132\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 1872, reward 652.0, memory_length 2000, epsilon 0.18517406202365613, time 728.0, rides 122\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1873, reward 671.0, memory_length 2000, epsilon 0.18500740536783483, time 728.0, rides 132\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 1874, reward 915.0, memory_length 2000, epsilon 0.18484089870300377, time 730.0, rides 135\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 1875, reward 429.0, memory_length 2000, epsilon 0.18467454189417107, time 730.0, rides 118\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 1876, reward 736.0, memory_length 2000, epsilon 0.1845083348064663, time 728.0, rides 144\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 1877, reward 624.0, memory_length 2000, epsilon 0.1843422773051405, time 734.0, rides 133\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 1878, reward 585.0, memory_length 2000, epsilon 0.18417636925556585, time 732.0, rides 138\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 1879, reward 676.0, memory_length 2000, epsilon 0.18401061052323583, time 724.0, rides 147\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1880, reward 638.0, memory_length 2000, epsilon 0.1838450009737649, time 729.0, rides 134\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 1881, reward 223.0, memory_length 2000, epsilon 0.1836795404728885, time 733.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 1882, reward 729.0, memory_length 2000, epsilon 0.1835142288864629, time 734.0, rides 127\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1883, reward 544.0, memory_length 2000, epsilon 0.18334906608046508, time 720.0, rides 117\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1884, reward 526.0, memory_length 2000, epsilon 0.18318405192099266, time 732.0, rides 137\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 1885, reward 542.0, memory_length 2000, epsilon 0.18301918627426375, time 730.0, rides 124\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 1886, reward 670.0, memory_length 2000, epsilon 0.18285446900661692, time 725.0, rides 127\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 1887, reward 683.0, memory_length 2000, epsilon 0.18268989998451096, time 724.0, rides 133\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 1888, reward 734.0, memory_length 2000, epsilon 0.1825254790745249, time 728.0, rides 132\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 1889, reward 581.0, memory_length 2000, epsilon 0.18236120614335782, time 721.0, rides 124\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1890, reward 646.0, memory_length 2000, epsilon 0.1821970810578288, time 734.0, rides 136\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 1891, reward 654.0, memory_length 2000, epsilon 0.18203310368487677, time 729.0, rides 146\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 1892, reward 698.0, memory_length 2000, epsilon 0.18186927389156038, time 729.0, rides 137\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 1893, reward 923.0, memory_length 2000, epsilon 0.18170559154505797, time 724.0, rides 123\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 1894, reward 568.0, memory_length 2000, epsilon 0.18154205651266742, time 720.0, rides 116\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 1895, reward 910.0, memory_length 2000, epsilon 0.18137866866180602, time 728.0, rides 139\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 1896, reward 403.0, memory_length 2000, epsilon 0.18121542786001038, time 730.0, rides 123\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1897, reward 487.0, memory_length 2000, epsilon 0.18105233397493636, time 731.0, rides 141\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 1898, reward 753.0, memory_length 2000, epsilon 0.18088938687435893, time 731.0, rides 128\n",
      "Initial State is  [1, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1899, reward 648.0, memory_length 2000, epsilon 0.180726586426172, time 728.0, rides 137\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 1900, reward 764.0, memory_length 2000, epsilon 0.18056393249838845, time 736.0, rides 133\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 1901, reward 539.0, memory_length 2000, epsilon 0.1804014249591399, time 728.0, rides 131\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 1902, reward 605.0, memory_length 2000, epsilon 0.1802390636766767, time 726.0, rides 132\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 1903, reward 391.0, memory_length 2000, epsilon 0.18007684851936767, time 730.0, rides 130\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1904, reward 715.0, memory_length 2000, epsilon 0.17991477935570024, time 724.0, rides 137\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1905, reward 566.0, memory_length 2000, epsilon 0.17975285605428012, time 735.0, rides 134\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 1906, reward 543.0, memory_length 2000, epsilon 0.17959107848383127, time 726.0, rides 127\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 1907, reward 777.0, memory_length 2000, epsilon 0.1794294465131958, time 725.0, rides 143\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 1908, reward 782.0, memory_length 2000, epsilon 0.17926796001133394, time 733.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 1909, reward 564.0, memory_length 2000, epsilon 0.17910661884732373, time 722.0, rides 121\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1910, reward 719.0, memory_length 2000, epsilon 0.17894542289036114, time 731.0, rides 127\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1911, reward 687.0, memory_length 2000, epsilon 0.1787843720097598, time 726.0, rides 132\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 1912, reward 664.0, memory_length 2000, epsilon 0.17862346607495103, time 725.0, rides 141\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 1913, reward 663.0, memory_length 2000, epsilon 0.17846270495548358, time 723.0, rides 141\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1914, reward 593.0, memory_length 2000, epsilon 0.17830208852102364, time 729.0, rides 133\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1915, reward 741.0, memory_length 2000, epsilon 0.17814161664135472, time 727.0, rides 121\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 1916, reward 707.0, memory_length 2000, epsilon 0.1779812891863775, time 725.0, rides 119\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 1917, reward 810.0, memory_length 2000, epsilon 0.17782110602610976, time 727.0, rides 134\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 1918, reward 927.0, memory_length 2000, epsilon 0.17766106703068626, time 730.0, rides 126\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 1919, reward 1113.0, memory_length 2000, epsilon 0.17750117207035865, time 731.0, rides 128\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1920, reward 786.0, memory_length 2000, epsilon 0.17734142101549533, time 723.0, rides 130\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 1921, reward 395.0, memory_length 2000, epsilon 0.17718181373658137, time 728.0, rides 123\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1922, reward 628.0, memory_length 2000, epsilon 0.17702235010421843, time 723.0, rides 113\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 1923, reward 992.0, memory_length 2000, epsilon 0.17686302998912465, time 725.0, rides 130\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1924, reward 904.0, memory_length 2000, epsilon 0.17670385326213445, time 727.0, rides 120\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 1925, reward 629.0, memory_length 2000, epsilon 0.17654481979419853, time 731.0, rides 120\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 1926, reward 621.0, memory_length 2000, epsilon 0.17638592945638376, time 730.0, rides 138\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 1927, reward 553.0, memory_length 2000, epsilon 0.176227182119873, time 738.0, rides 129\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 1928, reward 479.0, memory_length 2000, epsilon 0.17606857765596512, time 728.0, rides 122\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 1929, reward 707.0, memory_length 2000, epsilon 0.17591011593607475, time 734.0, rides 131\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 1930, reward 831.0, memory_length 2000, epsilon 0.17575179683173228, time 730.0, rides 135\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 1931, reward 528.0, memory_length 2000, epsilon 0.17559362021458372, time 728.0, rides 120\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 1932, reward 672.0, memory_length 2000, epsilon 0.17543558595639058, time 727.0, rides 136\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 1933, reward 599.0, memory_length 2000, epsilon 0.17527769392902984, time 736.0, rides 129\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 1934, reward 591.0, memory_length 2000, epsilon 0.1751199440044937, time 733.0, rides 133\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 1935, reward 686.0, memory_length 2000, epsilon 0.17496233605488967, time 728.0, rides 133\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1936, reward 763.0, memory_length 2000, epsilon 0.17480486995244027, time 731.0, rides 133\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 1937, reward 666.0, memory_length 2000, epsilon 0.17464754556948306, time 730.0, rides 129\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1938, reward 769.0, memory_length 2000, epsilon 0.17449036277847052, time 727.0, rides 137\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1939, reward 563.0, memory_length 2000, epsilon 0.1743333214519699, time 730.0, rides 142\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 1940, reward 804.0, memory_length 2000, epsilon 0.17417642146266313, time 721.0, rides 126\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 1941, reward 696.0, memory_length 2000, epsilon 0.17401966268334673, time 725.0, rides 134\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 1942, reward 898.0, memory_length 2000, epsilon 0.17386304498693173, time 734.0, rides 125\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 1943, reward 747.0, memory_length 2000, epsilon 0.17370656824644348, time 728.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 1944, reward 466.0, memory_length 2000, epsilon 0.17355023233502168, time 723.0, rides 132\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 1945, reward 515.0, memory_length 2000, epsilon 0.17339403712592016, time 735.0, rides 119\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 1946, reward 773.0, memory_length 2000, epsilon 0.17323798249250683, time 740.0, rides 131\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 1947, reward 511.0, memory_length 2000, epsilon 0.17308206830826356, time 731.0, rides 131\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 1948, reward 631.0, memory_length 2000, epsilon 0.17292629444678612, time 733.0, rides 128\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1949, reward 615.0, memory_length 2000, epsilon 0.17277066078178402, time 727.0, rides 122\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 1950, reward 535.0, memory_length 2000, epsilon 0.17261516718708042, time 721.0, rides 126\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 1951, reward 966.0, memory_length 2000, epsilon 0.17245981353661205, time 726.0, rides 136\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 1952, reward 680.0, memory_length 2000, epsilon 0.1723045997044291, time 723.0, rides 127\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 1953, reward 532.0, memory_length 2000, epsilon 0.17214952556469512, time 732.0, rides 124\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 1954, reward 607.0, memory_length 2000, epsilon 0.1719945909916869, time 725.0, rides 133\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 1955, reward 820.0, memory_length 2000, epsilon 0.1718397958597944, time 731.0, rides 133\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 1956, reward 486.0, memory_length 2000, epsilon 0.17168514004352056, time 730.0, rides 140\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 1957, reward 863.0, memory_length 2000, epsilon 0.1715306234174814, time 730.0, rides 120\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 1958, reward 587.0, memory_length 2000, epsilon 0.17137624585640568, time 729.0, rides 133\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 1959, reward 583.0, memory_length 2000, epsilon 0.17122200723513492, time 721.0, rides 129\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 1960, reward 968.0, memory_length 2000, epsilon 0.1710679074286233, time 729.0, rides 131\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 1961, reward 763.0, memory_length 2000, epsilon 0.17091394631193754, time 731.0, rides 132\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 1962, reward 564.0, memory_length 2000, epsilon 0.1707601237602568, time 732.0, rides 126\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 1963, reward 806.0, memory_length 2000, epsilon 0.17060643964887257, time 729.0, rides 139\n",
      "Initial State is  [2, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1964, reward 841.0, memory_length 2000, epsilon 0.17045289385318857, time 727.0, rides 145\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1965, reward 557.0, memory_length 2000, epsilon 0.1702994862487207, time 722.0, rides 135\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 1966, reward 853.0, memory_length 2000, epsilon 0.17014621671109686, time 729.0, rides 147\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 1967, reward 657.0, memory_length 2000, epsilon 0.16999308511605687, time 740.0, rides 141\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 1968, reward 901.0, memory_length 2000, epsilon 0.1698400913394524, time 729.0, rides 135\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 1969, reward 933.0, memory_length 2000, epsilon 0.1696872352572469, time 738.0, rides 132\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 1970, reward 950.0, memory_length 2000, epsilon 0.1695345167455154, time 724.0, rides 128\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 1971, reward 406.0, memory_length 2000, epsilon 0.16938193568044443, time 723.0, rides 126\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 1972, reward 486.0, memory_length 2000, epsilon 0.16922949193833203, time 731.0, rides 130\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 1973, reward 744.0, memory_length 2000, epsilon 0.16907718539558753, time 723.0, rides 128\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 1974, reward 539.0, memory_length 2000, epsilon 0.1689250159287315, time 726.0, rides 129\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 1975, reward 810.0, memory_length 2000, epsilon 0.16877298341439564, time 727.0, rides 137\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 1976, reward 751.0, memory_length 2000, epsilon 0.1686210877293227, time 733.0, rides 126\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 1977, reward 497.0, memory_length 2000, epsilon 0.1684693287503663, time 730.0, rides 115\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 1978, reward 727.0, memory_length 2000, epsilon 0.16831770635449098, time 725.0, rides 142\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 1979, reward 1068.0, memory_length 2000, epsilon 0.16816622041877194, time 731.0, rides 138\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1980, reward 717.0, memory_length 2000, epsilon 0.16801487082039504, time 724.0, rides 129\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 1981, reward 793.0, memory_length 2000, epsilon 0.16786365743665668, time 725.0, rides 134\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1982, reward 917.0, memory_length 2000, epsilon 0.16771258014496368, time 728.0, rides 145\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 1983, reward 736.0, memory_length 2000, epsilon 0.1675616388228332, time 725.0, rides 140\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1984, reward 632.0, memory_length 2000, epsilon 0.16741083334789264, time 728.0, rides 124\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1985, reward 666.0, memory_length 2000, epsilon 0.16726016359787954, time 729.0, rides 131\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 1986, reward 586.0, memory_length 2000, epsilon 0.16710962945064145, time 728.0, rides 118\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1987, reward 711.0, memory_length 2000, epsilon 0.16695923078413588, time 725.0, rides 130\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 1988, reward 818.0, memory_length 2000, epsilon 0.16680896747643015, time 725.0, rides 135\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 1989, reward 585.0, memory_length 2000, epsilon 0.16665883940570136, time 728.0, rides 116\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 1990, reward 721.0, memory_length 2000, epsilon 0.16650884645023623, time 729.0, rides 141\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 1991, reward 759.0, memory_length 2000, epsilon 0.166358988488431, time 728.0, rides 123\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 1992, reward 618.0, memory_length 2000, epsilon 0.1662092653987914, time 727.0, rides 129\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1993, reward 843.0, memory_length 2000, epsilon 0.1660596770599325, time 732.0, rides 133\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 1994, reward 622.0, memory_length 2000, epsilon 0.16591022335057856, time 731.0, rides 125\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1995, reward 372.0, memory_length 2000, epsilon 0.16576090414956304, time 739.0, rides 127\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 1996, reward 759.0, memory_length 2000, epsilon 0.16561171933582844, time 729.0, rides 138\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 1997, reward 674.0, memory_length 2000, epsilon 0.1654626687884262, time 726.0, rides 133\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1998, reward 588.0, memory_length 2000, epsilon 0.1653137523865166, time 728.0, rides 124\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 1999, reward 741.0, memory_length 2000, epsilon 0.16516497000936875, time 727.0, rides 138\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2000, reward 790.0, memory_length 2000, epsilon 0.1650163215363603, time 725.0, rides 125\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2001, reward 697.0, memory_length 2000, epsilon 0.16486780684697758, time 732.0, rides 127\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 2002, reward 662.0, memory_length 2000, epsilon 0.1647194258208153, time 729.0, rides 132\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 2003, reward 876.0, memory_length 2000, epsilon 0.16457117833757656, time 720.0, rides 137\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 2004, reward 927.0, memory_length 2000, epsilon 0.16442306427707273, time 729.0, rides 133\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2005, reward 567.0, memory_length 2000, epsilon 0.16427508351922337, time 734.0, rides 124\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2006, reward 755.0, memory_length 2000, epsilon 0.16412723594405607, time 730.0, rides 143\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2007, reward 576.0, memory_length 2000, epsilon 0.1639795214317064, time 725.0, rides 153\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 2008, reward 729.0, memory_length 2000, epsilon 0.16383193986241787, time 731.0, rides 126\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 2009, reward 749.0, memory_length 2000, epsilon 0.16368449111654168, time 737.0, rides 126\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 2010, reward 715.0, memory_length 2000, epsilon 0.1635371750745368, time 727.0, rides 129\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 2011, reward 597.0, memory_length 2000, epsilon 0.1633899916169697, time 727.0, rides 122\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 2012, reward 679.0, memory_length 2000, epsilon 0.16324294062451444, time 726.0, rides 133\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2013, reward 958.0, memory_length 2000, epsilon 0.16309602197795237, time 726.0, rides 130\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2014, reward 305.0, memory_length 2000, epsilon 0.1629492355581722, time 723.0, rides 126\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 2015, reward 833.0, memory_length 2000, epsilon 0.16280258124616984, time 725.0, rides 128\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2016, reward 552.0, memory_length 2000, epsilon 0.16265605892304827, time 725.0, rides 138\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 2017, reward 344.0, memory_length 2000, epsilon 0.16250966847001752, time 721.0, rides 118\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 2018, reward 386.0, memory_length 2000, epsilon 0.1623634097683945, time 730.0, rides 122\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2019, reward 640.0, memory_length 2000, epsilon 0.16221728269960295, time 724.0, rides 134\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 2020, reward 721.0, memory_length 2000, epsilon 0.1620712871451733, time 735.0, rides 136\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 2021, reward 596.0, memory_length 2000, epsilon 0.16192542298674265, time 727.0, rides 132\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2022, reward 823.0, memory_length 2000, epsilon 0.16177969010605459, time 735.0, rides 128\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 2023, reward 826.0, memory_length 2000, epsilon 0.16163408838495913, time 731.0, rides 124\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2024, reward 563.0, memory_length 2000, epsilon 0.16148861770541267, time 734.0, rides 129\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 2025, reward 691.0, memory_length 2000, epsilon 0.1613432779494778, time 737.0, rides 133\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2026, reward 588.0, memory_length 2000, epsilon 0.1611980689993233, time 731.0, rides 125\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2027, reward 618.0, memory_length 2000, epsilon 0.1610529907372239, time 724.0, rides 136\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 2028, reward 911.0, memory_length 2000, epsilon 0.1609080430455604, time 727.0, rides 129\n",
      "Initial State is  [1, 3, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2029, reward 533.0, memory_length 2000, epsilon 0.16076322580681937, time 722.0, rides 121\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2030, reward 567.0, memory_length 2000, epsilon 0.16061853890359323, time 724.0, rides 143\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2031, reward 769.0, memory_length 2000, epsilon 0.16047398221858, time 722.0, rides 122\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 2032, reward 822.0, memory_length 2000, epsilon 0.1603295556345833, time 728.0, rides 126\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 2033, reward 885.0, memory_length 2000, epsilon 0.16018525903451217, time 740.0, rides 124\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 2034, reward 917.0, memory_length 2000, epsilon 0.1600410923013811, time 726.0, rides 127\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2035, reward 698.0, memory_length 2000, epsilon 0.15989705531830986, time 728.0, rides 127\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 2036, reward 924.0, memory_length 2000, epsilon 0.15975314796852338, time 723.0, rides 129\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 2037, reward 579.0, memory_length 2000, epsilon 0.1596093701353517, time 721.0, rides 144\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2038, reward 780.0, memory_length 2000, epsilon 0.1594657217022299, time 730.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 2039, reward 810.0, memory_length 2000, epsilon 0.15932220255269788, time 733.0, rides 143\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2040, reward 801.0, memory_length 2000, epsilon 0.15917881257040045, time 723.0, rides 134\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 2041, reward 549.0, memory_length 2000, epsilon 0.15903555163908709, time 731.0, rides 122\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 2042, reward 668.0, memory_length 2000, epsilon 0.15889241964261192, time 731.0, rides 136\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 2043, reward 745.0, memory_length 2000, epsilon 0.15874941646493357, time 729.0, rides 123\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 2044, reward 527.0, memory_length 2000, epsilon 0.15860654199011512, time 731.0, rides 129\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 2045, reward 532.0, memory_length 2000, epsilon 0.158463796102324, time 733.0, rides 132\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 2046, reward 807.0, memory_length 2000, epsilon 0.1583211786858319, time 731.0, rides 120\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2047, reward 562.0, memory_length 2000, epsilon 0.15817868962501463, time 728.0, rides 134\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 2048, reward 745.0, memory_length 2000, epsilon 0.15803632880435212, time 724.0, rides 134\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 2049, reward 684.0, memory_length 2000, epsilon 0.1578940961084282, time 733.0, rides 130\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 2050, reward 813.0, memory_length 2000, epsilon 0.1577519914219306, time 727.0, rides 143\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 2051, reward 695.0, memory_length 2000, epsilon 0.15761001462965088, time 736.0, rides 114\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 2052, reward 788.0, memory_length 2000, epsilon 0.1574681656164842, time 726.0, rides 135\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 2053, reward 826.0, memory_length 2000, epsilon 0.15732644426742937, time 730.0, rides 122\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 2054, reward 661.0, memory_length 2000, epsilon 0.15718485046758868, time 725.0, rides 133\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 2055, reward 627.0, memory_length 2000, epsilon 0.15704338410216784, time 728.0, rides 132\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 2056, reward 789.0, memory_length 2000, epsilon 0.1569020450564759, time 728.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 2057, reward 858.0, memory_length 2000, epsilon 0.15676083321592507, time 729.0, rides 129\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2058, reward 694.0, memory_length 2000, epsilon 0.15661974846603074, time 734.0, rides 127\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2059, reward 835.0, memory_length 2000, epsilon 0.1564787906924113, time 733.0, rides 139\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2060, reward 797.0, memory_length 2000, epsilon 0.15633795978078813, time 728.0, rides 136\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 2061, reward 583.0, memory_length 2000, epsilon 0.15619725561698541, time 731.0, rides 137\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 2062, reward 715.0, memory_length 2000, epsilon 0.15605667808693013, time 729.0, rides 129\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 2063, reward 884.0, memory_length 2000, epsilon 0.1559162270766519, time 727.0, rides 118\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 2064, reward 599.0, memory_length 2000, epsilon 0.1557759024722829, time 732.0, rides 128\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 2065, reward 811.0, memory_length 2000, epsilon 0.15563570416005784, time 723.0, rides 136\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2066, reward 978.0, memory_length 2000, epsilon 0.15549563202631378, time 731.0, rides 138\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 2067, reward 844.0, memory_length 2000, epsilon 0.1553556859574901, time 730.0, rides 129\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 2068, reward 770.0, memory_length 2000, epsilon 0.15521586584012836, time 723.0, rides 129\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 2069, reward 775.0, memory_length 2000, epsilon 0.15507617156087225, time 728.0, rides 141\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2070, reward 524.0, memory_length 2000, epsilon 0.15493660300646747, time 729.0, rides 132\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 2071, reward 918.0, memory_length 2000, epsilon 0.15479716006376165, time 728.0, rides 133\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2072, reward 680.0, memory_length 2000, epsilon 0.15465784261970428, time 723.0, rides 112\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 2073, reward 851.0, memory_length 2000, epsilon 0.15451865056134653, time 726.0, rides 135\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 2074, reward 719.0, memory_length 2000, epsilon 0.15437958377584132, time 735.0, rides 126\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 2075, reward 674.0, memory_length 2000, epsilon 0.15424064215044306, time 724.0, rides 126\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 2076, reward 566.0, memory_length 2000, epsilon 0.15410182557250765, time 731.0, rides 128\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2077, reward 743.0, memory_length 2000, epsilon 0.1539631339294924, time 730.0, rides 126\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2078, reward 508.0, memory_length 2000, epsilon 0.15382456710895587, time 729.0, rides 122\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 2079, reward 1054.0, memory_length 2000, epsilon 0.1536861249985578, time 725.0, rides 133\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2080, reward 582.0, memory_length 2000, epsilon 0.1535478074860591, time 728.0, rides 136\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 2081, reward 778.0, memory_length 2000, epsilon 0.15340961445932164, time 732.0, rides 134\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2082, reward 758.0, memory_length 2000, epsilon 0.15327154580630825, time 728.0, rides 136\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 2083, reward 682.0, memory_length 2000, epsilon 0.15313360141508256, time 724.0, rides 136\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 2084, reward 915.0, memory_length 2000, epsilon 0.152995781173809, time 733.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2085, reward 796.0, memory_length 2000, epsilon 0.15285808497075257, time 726.0, rides 134\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 2086, reward 624.0, memory_length 2000, epsilon 0.1527205126942789, time 727.0, rides 130\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 2087, reward 577.0, memory_length 2000, epsilon 0.15258306423285403, time 725.0, rides 117\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 2088, reward 734.0, memory_length 2000, epsilon 0.15244573947504447, time 733.0, rides 136\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 2089, reward 814.0, memory_length 2000, epsilon 0.15230853830951693, time 727.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2090, reward 318.0, memory_length 2000, epsilon 0.15217146062503836, time 727.0, rides 127\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 2091, reward 801.0, memory_length 2000, epsilon 0.15203450631047583, time 724.0, rides 117\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 2092, reward 560.0, memory_length 2000, epsilon 0.1518976752547964, time 727.0, rides 125\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2093, reward 739.0, memory_length 2000, epsilon 0.15176096734706707, time 738.0, rides 122\n",
      "Initial State is  [1, 6, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2094, reward 826.0, memory_length 2000, epsilon 0.1516243824764547, time 730.0, rides 127\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 2095, reward 702.0, memory_length 2000, epsilon 0.1514879205322259, time 721.0, rides 145\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 2096, reward 894.0, memory_length 2000, epsilon 0.15135158140374688, time 728.0, rides 121\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 2097, reward 479.0, memory_length 2000, epsilon 0.15121536498048352, time 731.0, rides 137\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 2098, reward 681.0, memory_length 2000, epsilon 0.1510792711520011, time 732.0, rides 121\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 2099, reward 619.0, memory_length 2000, epsilon 0.15094329980796428, time 726.0, rides 125\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2100, reward 573.0, memory_length 2000, epsilon 0.15080745083813712, time 727.0, rides 121\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 2101, reward 401.0, memory_length 2000, epsilon 0.1506717241323828, time 732.0, rides 124\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2102, reward 850.0, memory_length 2000, epsilon 0.15053611958066365, time 725.0, rides 132\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2103, reward 784.0, memory_length 2000, epsilon 0.15040063707304105, time 727.0, rides 131\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 2104, reward 1026.0, memory_length 2000, epsilon 0.1502652764996753, time 723.0, rides 119\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 2105, reward 707.0, memory_length 2000, epsilon 0.1501300377508256, time 728.0, rides 131\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 2106, reward 811.0, memory_length 2000, epsilon 0.14999492071684983, time 728.0, rides 136\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 2107, reward 697.0, memory_length 2000, epsilon 0.14985992528820466, time 722.0, rides 133\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2108, reward 921.0, memory_length 2000, epsilon 0.14972505135544528, time 728.0, rides 139\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2109, reward 585.0, memory_length 2000, epsilon 0.1495902988092254, time 727.0, rides 117\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 2110, reward 706.0, memory_length 2000, epsilon 0.1494556675402971, time 733.0, rides 140\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2111, reward 517.0, memory_length 2000, epsilon 0.14932115743951083, time 729.0, rides 123\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 2112, reward 514.0, memory_length 2000, epsilon 0.14918676839781528, time 734.0, rides 125\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 2113, reward 886.0, memory_length 2000, epsilon 0.14905250030625725, time 726.0, rides 133\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 2114, reward 652.0, memory_length 2000, epsilon 0.1489183530559816, time 728.0, rides 122\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 2115, reward 727.0, memory_length 2000, epsilon 0.14878432653823123, time 734.0, rides 128\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2116, reward 1051.0, memory_length 2000, epsilon 0.14865042064434683, time 728.0, rides 129\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 2117, reward 534.0, memory_length 2000, epsilon 0.14851663526576692, time 737.0, rides 138\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 2118, reward 799.0, memory_length 2000, epsilon 0.14838297029402772, time 730.0, rides 128\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2119, reward 568.0, memory_length 2000, epsilon 0.1482494256207631, time 724.0, rides 131\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 2120, reward 912.0, memory_length 2000, epsilon 0.1481160011377044, time 724.0, rides 128\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 2121, reward 846.0, memory_length 2000, epsilon 0.14798269673668046, time 732.0, rides 129\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2122, reward 482.0, memory_length 2000, epsilon 0.14784951230961746, time 729.0, rides 133\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2123, reward 590.0, memory_length 2000, epsilon 0.14771644774853881, time 724.0, rides 113\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 2124, reward 555.0, memory_length 2000, epsilon 0.14758350294556513, time 731.0, rides 130\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 2125, reward 756.0, memory_length 2000, epsilon 0.14745067779291413, time 727.0, rides 145\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 2126, reward 537.0, memory_length 2000, epsilon 0.1473179721829005, time 728.0, rides 132\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 2127, reward 869.0, memory_length 2000, epsilon 0.14718538600793588, time 724.0, rides 136\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 2128, reward 524.0, memory_length 2000, epsilon 0.14705291916052873, time 725.0, rides 125\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 2129, reward 652.0, memory_length 2000, epsilon 0.14692057153328425, time 727.0, rides 121\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2130, reward 499.0, memory_length 2000, epsilon 0.14678834301890428, time 725.0, rides 116\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 2131, reward 618.0, memory_length 2000, epsilon 0.14665623351018728, time 737.0, rides 128\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2132, reward 333.0, memory_length 2000, epsilon 0.1465242429000281, time 727.0, rides 117\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 2133, reward 739.0, memory_length 2000, epsilon 0.1463923710814181, time 730.0, rides 130\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 2134, reward 378.0, memory_length 2000, epsilon 0.1462606179474448, time 726.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 2135, reward 869.0, memory_length 2000, epsilon 0.1461289833912921, time 732.0, rides 136\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 2136, reward 535.0, memory_length 2000, epsilon 0.14599746730623994, time 730.0, rides 122\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 2137, reward 519.0, memory_length 2000, epsilon 0.14586606958566434, time 728.0, rides 128\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2138, reward 591.0, memory_length 2000, epsilon 0.14573479012303725, time 733.0, rides 138\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2139, reward 657.0, memory_length 2000, epsilon 0.1456036288119265, time 725.0, rides 149\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 2140, reward 1024.0, memory_length 2000, epsilon 0.14547258554599576, time 727.0, rides 132\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2141, reward 1005.0, memory_length 2000, epsilon 0.14534166021900435, time 730.0, rides 139\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2142, reward 847.0, memory_length 2000, epsilon 0.14521085272480724, time 726.0, rides 152\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2143, reward 353.0, memory_length 2000, epsilon 0.1450801629573549, time 729.0, rides 133\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 2144, reward 587.0, memory_length 2000, epsilon 0.14494959081069328, time 725.0, rides 132\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2145, reward 804.0, memory_length 2000, epsilon 0.14481913617896366, time 737.0, rides 126\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2146, reward 820.0, memory_length 2000, epsilon 0.1446887989564026, time 727.0, rides 116\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 2147, reward 551.0, memory_length 2000, epsilon 0.14455857903734184, time 725.0, rides 125\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 2148, reward 689.0, memory_length 2000, epsilon 0.14442847631620823, time 729.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2149, reward 938.0, memory_length 2000, epsilon 0.14429849068752365, time 734.0, rides 123\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 2150, reward 707.0, memory_length 2000, epsilon 0.1441686220459049, time 729.0, rides 121\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 2151, reward 839.0, memory_length 2000, epsilon 0.14403887028606358, time 732.0, rides 121\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 2152, reward 868.0, memory_length 2000, epsilon 0.1439092353028061, time 728.0, rides 119\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 2153, reward 579.0, memory_length 2000, epsilon 0.1437797169910336, time 733.0, rides 129\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 2154, reward 706.0, memory_length 2000, epsilon 0.14365031524574165, time 734.0, rides 132\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2155, reward 663.0, memory_length 2000, epsilon 0.14352102996202049, time 730.0, rides 124\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 2156, reward 673.0, memory_length 2000, epsilon 0.14339186103505466, time 732.0, rides 143\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 2157, reward 641.0, memory_length 2000, epsilon 0.14326280836012312, time 724.0, rides 130\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 2158, reward 843.0, memory_length 2000, epsilon 0.143133871832599, time 728.0, rides 142\n",
      "Initial State is  [3, 10, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2159, reward 618.0, memory_length 2000, epsilon 0.14300505134794966, time 729.0, rides 128\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 2160, reward 797.0, memory_length 2000, epsilon 0.1428763468017365, time 730.0, rides 146\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2161, reward 1062.0, memory_length 2000, epsilon 0.14274775808961493, time 724.0, rides 129\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 2162, reward 919.0, memory_length 2000, epsilon 0.14261928510733426, time 729.0, rides 143\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 2163, reward 730.0, memory_length 2000, epsilon 0.14249092775073766, time 729.0, rides 118\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 2164, reward 602.0, memory_length 2000, epsilon 0.14236268591576198, time 730.0, rides 138\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 2165, reward 679.0, memory_length 2000, epsilon 0.1422345594984378, time 725.0, rides 141\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 2166, reward 662.0, memory_length 2000, epsilon 0.1421065483948892, time 725.0, rides 126\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2167, reward 522.0, memory_length 2000, epsilon 0.1419786525013338, time 724.0, rides 145\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2168, reward 987.0, memory_length 2000, epsilon 0.1418508717140826, time 737.0, rides 133\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 2169, reward 803.0, memory_length 2000, epsilon 0.1417232059295399, time 729.0, rides 133\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2170, reward 793.0, memory_length 2000, epsilon 0.14159565504420332, time 734.0, rides 135\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 2171, reward 1079.0, memory_length 2000, epsilon 0.14146821895466355, time 722.0, rides 140\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2172, reward 627.0, memory_length 2000, epsilon 0.14134089755760434, time 725.0, rides 133\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 2173, reward 533.0, memory_length 2000, epsilon 0.1412136907498025, time 729.0, rides 125\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 2174, reward 688.0, memory_length 2000, epsilon 0.14108659842812768, time 731.0, rides 124\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 2175, reward 654.0, memory_length 2000, epsilon 0.14095962048954236, time 732.0, rides 135\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2176, reward 916.0, memory_length 2000, epsilon 0.14083275683110177, time 726.0, rides 117\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 2177, reward 663.0, memory_length 2000, epsilon 0.14070600734995378, time 732.0, rides 132\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 2178, reward 684.0, memory_length 2000, epsilon 0.14057937194333883, time 729.0, rides 124\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 2179, reward 777.0, memory_length 2000, epsilon 0.14045285050858983, time 728.0, rides 132\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2180, reward 763.0, memory_length 2000, epsilon 0.1403264429431321, time 730.0, rides 134\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 2181, reward 1121.0, memory_length 2000, epsilon 0.14020014914448328, time 733.0, rides 132\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 2182, reward 557.0, memory_length 2000, epsilon 0.14007396901025324, time 728.0, rides 126\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2183, reward 817.0, memory_length 2000, epsilon 0.139947902438144, time 727.0, rides 126\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2184, reward 649.0, memory_length 2000, epsilon 0.13982194932594968, time 730.0, rides 132\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2185, reward 715.0, memory_length 2000, epsilon 0.13969610957155632, time 728.0, rides 138\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 2186, reward 987.0, memory_length 2000, epsilon 0.13957038307294192, time 728.0, rides 117\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 2187, reward 879.0, memory_length 2000, epsilon 0.13944476972817627, time 738.0, rides 130\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 2188, reward 965.0, memory_length 2000, epsilon 0.13931926943542092, time 731.0, rides 134\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2189, reward 543.0, memory_length 2000, epsilon 0.13919388209292904, time 724.0, rides 121\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 2190, reward 690.0, memory_length 2000, epsilon 0.1390686075990454, time 732.0, rides 149\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 2191, reward 636.0, memory_length 2000, epsilon 0.13894344585220628, time 723.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 2192, reward 599.0, memory_length 2000, epsilon 0.1388183967509393, time 723.0, rides 129\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2193, reward 1023.0, memory_length 2000, epsilon 0.13869346019386344, time 723.0, rides 132\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2194, reward 721.0, memory_length 2000, epsilon 0.13856863607968897, time 726.0, rides 133\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2195, reward 679.0, memory_length 2000, epsilon 0.13844392430721725, time 738.0, rides 132\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 2196, reward 874.0, memory_length 2000, epsilon 0.13831932477534076, time 728.0, rides 136\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 2197, reward 1005.0, memory_length 2000, epsilon 0.13819483738304295, time 726.0, rides 131\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 2198, reward 784.0, memory_length 2000, epsilon 0.1380704620293982, time 726.0, rides 127\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 2199, reward 950.0, memory_length 2000, epsilon 0.13794619861357174, time 729.0, rides 113\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2200, reward 870.0, memory_length 2000, epsilon 0.1378220470348195, time 727.0, rides 131\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 2201, reward 635.0, memory_length 2000, epsilon 0.13769800719248818, time 724.0, rides 120\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 2202, reward 659.0, memory_length 2000, epsilon 0.13757407898601492, time 726.0, rides 134\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 2203, reward 789.0, memory_length 2000, epsilon 0.13745026231492752, time 724.0, rides 126\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 2204, reward 670.0, memory_length 2000, epsilon 0.13732655707884409, time 727.0, rides 130\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 2205, reward 580.0, memory_length 2000, epsilon 0.13720296317747313, time 731.0, rides 135\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 2206, reward 695.0, memory_length 2000, epsilon 0.13707948051061342, time 724.0, rides 133\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2207, reward 859.0, memory_length 2000, epsilon 0.13695610897815386, time 740.0, rides 130\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 2208, reward 799.0, memory_length 2000, epsilon 0.13683284848007352, time 732.0, rides 125\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2209, reward 1227.0, memory_length 2000, epsilon 0.13670969891644144, time 728.0, rides 138\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 2210, reward 821.0, memory_length 2000, epsilon 0.13658666018741664, time 727.0, rides 136\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 2211, reward 553.0, memory_length 2000, epsilon 0.13646373219324795, time 728.0, rides 126\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 2212, reward 893.0, memory_length 2000, epsilon 0.13634091483427402, time 726.0, rides 154\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 2213, reward 585.0, memory_length 2000, epsilon 0.13621820801092316, time 730.0, rides 141\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 2214, reward 742.0, memory_length 2000, epsilon 0.13609561162371334, time 725.0, rides 136\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2215, reward 657.0, memory_length 2000, epsilon 0.135973125573252, time 723.0, rides 127\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 2216, reward 781.0, memory_length 2000, epsilon 0.13585074976023606, time 728.0, rides 130\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2217, reward 784.0, memory_length 2000, epsilon 0.13572848408545185, time 735.0, rides 142\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 2218, reward 915.0, memory_length 2000, epsilon 0.13560632844977494, time 723.0, rides 130\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 2219, reward 707.0, memory_length 2000, epsilon 0.13548428275417013, time 726.0, rides 137\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 2220, reward 759.0, memory_length 2000, epsilon 0.13536234689969137, time 731.0, rides 130\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 2221, reward 842.0, memory_length 2000, epsilon 0.13524052078748164, time 731.0, rides 125\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2222, reward 783.0, memory_length 2000, epsilon 0.1351188043187729, time 724.0, rides 131\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 2223, reward 631.0, memory_length 2000, epsilon 0.134997197394886, time 733.0, rides 137\n",
      "Initial State is  [4, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2224, reward 634.0, memory_length 2000, epsilon 0.1348756999172306, time 738.0, rides 141\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 2225, reward 687.0, memory_length 2000, epsilon 0.1347543117873051, time 726.0, rides 134\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 2226, reward 590.0, memory_length 2000, epsilon 0.1346330329066965, time 727.0, rides 135\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2227, reward 863.0, memory_length 2000, epsilon 0.13451186317708047, time 731.0, rides 131\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 2228, reward 576.0, memory_length 2000, epsilon 0.1343908025002211, time 729.0, rides 132\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 2229, reward 943.0, memory_length 2000, epsilon 0.13426985077797088, time 727.0, rides 134\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 2230, reward 842.0, memory_length 2000, epsilon 0.1341490079122707, time 726.0, rides 134\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 2231, reward 830.0, memory_length 2000, epsilon 0.13402827380514964, time 729.0, rides 152\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 2232, reward 566.0, memory_length 2000, epsilon 0.133907648358725, time 732.0, rides 141\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 2233, reward 934.0, memory_length 2000, epsilon 0.13378713147520216, time 727.0, rides 131\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 2234, reward 846.0, memory_length 2000, epsilon 0.13366672305687446, time 726.0, rides 130\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 2235, reward 784.0, memory_length 2000, epsilon 0.13354642300612327, time 727.0, rides 134\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 2236, reward 964.0, memory_length 2000, epsilon 0.13342623122541775, time 736.0, rides 138\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2237, reward 1066.0, memory_length 2000, epsilon 0.13330614761731488, time 727.0, rides 133\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 2238, reward 754.0, memory_length 2000, epsilon 0.1331861720844593, time 729.0, rides 130\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 2239, reward 775.0, memory_length 2000, epsilon 0.1330663045295833, time 726.0, rides 135\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 2240, reward 188.0, memory_length 2000, epsilon 0.13294654485550667, time 737.0, rides 124\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2241, reward 980.0, memory_length 2000, epsilon 0.1328268929651367, time 729.0, rides 144\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 2242, reward 708.0, memory_length 2000, epsilon 0.13270734876146806, time 729.0, rides 132\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2243, reward 369.0, memory_length 2000, epsilon 0.13258791214758273, time 724.0, rides 122\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 2244, reward 587.0, memory_length 2000, epsilon 0.1324685830266499, time 743.0, rides 130\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 2245, reward 983.0, memory_length 2000, epsilon 0.13234936130192593, time 728.0, rides 142\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2246, reward 741.0, memory_length 2000, epsilon 0.1322302468767542, time 729.0, rides 125\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 2247, reward 538.0, memory_length 2000, epsilon 0.13211123965456512, time 728.0, rides 136\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2248, reward 722.0, memory_length 2000, epsilon 0.131992339538876, time 729.0, rides 117\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2249, reward 609.0, memory_length 2000, epsilon 0.13187354643329102, time 724.0, rides 130\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 2250, reward 908.0, memory_length 2000, epsilon 0.13175486024150107, time 737.0, rides 126\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 2251, reward 817.0, memory_length 2000, epsilon 0.1316362808672837, time 729.0, rides 126\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 2252, reward 663.0, memory_length 2000, epsilon 0.13151780821450315, time 727.0, rides 124\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 2253, reward 526.0, memory_length 2000, epsilon 0.1313994421871101, time 722.0, rides 132\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 2254, reward 496.0, memory_length 2000, epsilon 0.1312811826891417, time 726.0, rides 131\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 2255, reward 569.0, memory_length 2000, epsilon 0.13116302962472148, time 733.0, rides 138\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 2256, reward 982.0, memory_length 2000, epsilon 0.13104498289805924, time 721.0, rides 145\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2257, reward 443.0, memory_length 2000, epsilon 0.130927042413451, time 726.0, rides 124\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 2258, reward 444.0, memory_length 2000, epsilon 0.13080920807527888, time 729.0, rides 134\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2259, reward 966.0, memory_length 2000, epsilon 0.13069147978801113, time 729.0, rides 140\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 2260, reward 791.0, memory_length 2000, epsilon 0.13057385745620192, time 724.0, rides 132\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2261, reward 745.0, memory_length 2000, epsilon 0.13045634098449135, time 729.0, rides 117\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2262, reward 743.0, memory_length 2000, epsilon 0.13033893027760532, time 730.0, rides 140\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 2263, reward 931.0, memory_length 2000, epsilon 0.13022162524035547, time 727.0, rides 138\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2264, reward 607.0, memory_length 2000, epsilon 0.13010442577763914, time 723.0, rides 129\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2265, reward 488.0, memory_length 2000, epsilon 0.12998733179443928, time 735.0, rides 128\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 2266, reward 840.0, memory_length 2000, epsilon 0.12987034319582427, time 727.0, rides 133\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 2267, reward 797.0, memory_length 2000, epsilon 0.12975345988694803, time 736.0, rides 128\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 2268, reward 828.0, memory_length 2000, epsilon 0.12963668177304977, time 736.0, rides 138\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 2269, reward 893.0, memory_length 2000, epsilon 0.12952000875945402, time 728.0, rides 133\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2270, reward 794.0, memory_length 2000, epsilon 0.1294034407515705, time 726.0, rides 123\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 2271, reward 865.0, memory_length 2000, epsilon 0.12928697765489408, time 729.0, rides 142\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 2272, reward 865.0, memory_length 2000, epsilon 0.12917061937500468, time 723.0, rides 124\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2273, reward 825.0, memory_length 2000, epsilon 0.12905436581756718, time 735.0, rides 133\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2274, reward 680.0, memory_length 2000, epsilon 0.12893821688833138, time 729.0, rides 127\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 2275, reward 549.0, memory_length 2000, epsilon 0.12882217249313188, time 725.0, rides 135\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 2276, reward 628.0, memory_length 2000, epsilon 0.12870623253788807, time 724.0, rides 131\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 2277, reward 922.0, memory_length 2000, epsilon 0.12859039692860397, time 725.0, rides 140\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2278, reward 687.0, memory_length 2000, epsilon 0.12847466557136822, time 737.0, rides 130\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 2279, reward 716.0, memory_length 2000, epsilon 0.128359038372354, time 730.0, rides 117\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 2280, reward 735.0, memory_length 2000, epsilon 0.12824351523781888, time 724.0, rides 124\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2281, reward 723.0, memory_length 2000, epsilon 0.12812809607410483, time 727.0, rides 129\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2282, reward 1101.0, memory_length 2000, epsilon 0.12801278078763814, time 736.0, rides 124\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2283, reward 634.0, memory_length 2000, epsilon 0.12789756928492926, time 721.0, rides 124\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 2284, reward 733.0, memory_length 2000, epsilon 0.12778246147257283, time 725.0, rides 130\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2285, reward 387.0, memory_length 2000, epsilon 0.1276674572572475, time 723.0, rides 134\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 2286, reward 947.0, memory_length 2000, epsilon 0.12755255654571598, time 726.0, rides 136\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 2287, reward 846.0, memory_length 2000, epsilon 0.12743775924482484, time 726.0, rides 124\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 2288, reward 628.0, memory_length 2000, epsilon 0.1273230652615045, time 731.0, rides 130\n",
      "Initial State is  [1, 12, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2289, reward 867.0, memory_length 2000, epsilon 0.12720847450276915, time 725.0, rides 121\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2290, reward 744.0, memory_length 2000, epsilon 0.12709398687571666, time 732.0, rides 135\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 2291, reward 917.0, memory_length 2000, epsilon 0.1269796022875285, time 729.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2292, reward 798.0, memory_length 2000, epsilon 0.1268653206454697, time 722.0, rides 126\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 2293, reward 880.0, memory_length 2000, epsilon 0.1267511418568888, time 727.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2294, reward 660.0, memory_length 2000, epsilon 0.1266370658292176, time 730.0, rides 137\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 2295, reward 990.0, memory_length 2000, epsilon 0.12652309246997132, time 738.0, rides 133\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2296, reward 788.0, memory_length 2000, epsilon 0.12640922168674834, time 726.0, rides 123\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 2297, reward 1052.0, memory_length 2000, epsilon 0.12629545338723028, time 728.0, rides 132\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 2298, reward 739.0, memory_length 2000, epsilon 0.12618178747918177, time 727.0, rides 136\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 2299, reward 827.0, memory_length 2000, epsilon 0.1260682238704505, time 727.0, rides 128\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2300, reward 575.0, memory_length 2000, epsilon 0.12595476246896709, time 724.0, rides 126\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2301, reward 418.0, memory_length 2000, epsilon 0.125841403182745, time 731.0, rides 124\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2302, reward 1039.0, memory_length 2000, epsilon 0.12572814591988052, time 732.0, rides 136\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 2303, reward 662.0, memory_length 2000, epsilon 0.12561499058855263, time 731.0, rides 145\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 2304, reward 674.0, memory_length 2000, epsilon 0.12550193709702293, time 730.0, rides 141\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2305, reward 813.0, memory_length 2000, epsilon 0.1253889853536356, time 742.0, rides 136\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 2306, reward 760.0, memory_length 2000, epsilon 0.12527613526681733, time 728.0, rides 141\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 2307, reward 936.0, memory_length 2000, epsilon 0.12516338674507718, time 733.0, rides 144\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 2308, reward 793.0, memory_length 2000, epsilon 0.1250507396970066, time 726.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2309, reward 827.0, memory_length 2000, epsilon 0.1249381940312793, time 724.0, rides 128\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 2310, reward 620.0, memory_length 2000, epsilon 0.12482574965665115, time 732.0, rides 119\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 2311, reward 743.0, memory_length 2000, epsilon 0.12471340648196017, time 728.0, rides 130\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2312, reward 645.0, memory_length 2000, epsilon 0.1246011644161264, time 729.0, rides 131\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2313, reward 338.0, memory_length 2000, epsilon 0.12448902336815189, time 738.0, rides 128\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 2314, reward 775.0, memory_length 2000, epsilon 0.12437698324712056, time 742.0, rides 143\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 2315, reward 553.0, memory_length 2000, epsilon 0.12426504396219815, time 728.0, rides 128\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 2316, reward 737.0, memory_length 2000, epsilon 0.12415320542263217, time 735.0, rides 129\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 2317, reward 914.0, memory_length 2000, epsilon 0.1240414675377518, time 728.0, rides 155\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 2318, reward 553.0, memory_length 2000, epsilon 0.12392983021696782, time 727.0, rides 142\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 2319, reward 868.0, memory_length 2000, epsilon 0.12381829336977256, time 726.0, rides 126\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2320, reward 819.0, memory_length 2000, epsilon 0.12370685690573976, time 731.0, rides 127\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2321, reward 744.0, memory_length 2000, epsilon 0.1235955207345246, time 723.0, rides 128\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 2322, reward 713.0, memory_length 2000, epsilon 0.12348428476586353, time 729.0, rides 123\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 2323, reward 1049.0, memory_length 2000, epsilon 0.12337314890957425, time 746.0, rides 151\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2324, reward 865.0, memory_length 2000, epsilon 0.12326211307555564, time 742.0, rides 140\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2325, reward 1058.0, memory_length 2000, epsilon 0.12315117717378764, time 735.0, rides 137\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 2326, reward 878.0, memory_length 2000, epsilon 0.12304034111433122, time 736.0, rides 132\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 2327, reward 483.0, memory_length 2000, epsilon 0.12292960480732833, time 737.0, rides 134\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 2328, reward 820.0, memory_length 2000, epsilon 0.12281896816300172, time 723.0, rides 129\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 2329, reward 693.0, memory_length 2000, epsilon 0.12270843109165502, time 728.0, rides 128\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2330, reward 915.0, memory_length 2000, epsilon 0.12259799350367254, time 722.0, rides 140\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 2331, reward 652.0, memory_length 2000, epsilon 0.12248765530951923, time 730.0, rides 144\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2332, reward 932.0, memory_length 2000, epsilon 0.12237741641974066, time 734.0, rides 131\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 2333, reward 1137.0, memory_length 2000, epsilon 0.12226727674496289, time 730.0, rides 135\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 2334, reward 989.0, memory_length 2000, epsilon 0.12215723619589243, time 721.0, rides 140\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2335, reward 756.0, memory_length 2000, epsilon 0.12204729468331613, time 725.0, rides 129\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2336, reward 711.0, memory_length 2000, epsilon 0.12193745211810114, time 723.0, rides 122\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 2337, reward 658.0, memory_length 2000, epsilon 0.12182770841119485, time 724.0, rides 125\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 2338, reward 848.0, memory_length 2000, epsilon 0.12171806347362477, time 734.0, rides 136\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2339, reward 949.0, memory_length 2000, epsilon 0.1216085172164985, time 728.0, rides 126\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 2340, reward 836.0, memory_length 2000, epsilon 0.12149906955100365, time 726.0, rides 126\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2341, reward 830.0, memory_length 2000, epsilon 0.12138972038840774, time 733.0, rides 135\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 2342, reward 698.0, memory_length 2000, epsilon 0.12128046964005817, time 725.0, rides 125\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 2343, reward 1069.0, memory_length 2000, epsilon 0.12117131721738213, time 733.0, rides 135\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 2344, reward 961.0, memory_length 2000, epsilon 0.12106226303188648, time 728.0, rides 126\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2345, reward 784.0, memory_length 2000, epsilon 0.12095330699515779, time 734.0, rides 133\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 2346, reward 689.0, memory_length 2000, epsilon 0.12084444901886214, time 733.0, rides 128\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 2347, reward 795.0, memory_length 2000, epsilon 0.12073568901474516, time 725.0, rides 151\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 2348, reward 835.0, memory_length 2000, epsilon 0.12062702689463188, time 729.0, rides 131\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 2349, reward 747.0, memory_length 2000, epsilon 0.12051846257042671, time 736.0, rides 138\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2350, reward 1070.0, memory_length 2000, epsilon 0.12040999595411332, time 720.0, rides 128\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2351, reward 1278.0, memory_length 2000, epsilon 0.12030162695775462, time 727.0, rides 136\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 2352, reward 606.0, memory_length 2000, epsilon 0.12019335549349264, time 736.0, rides 139\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 2353, reward 841.0, memory_length 2000, epsilon 0.12008518147354849, time 724.0, rides 134\n",
      "Initial State is  [3, 9, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2354, reward 546.0, memory_length 2000, epsilon 0.1199771048102223, time 726.0, rides 132\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 2355, reward 948.0, memory_length 2000, epsilon 0.11986912541589309, time 730.0, rides 134\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2356, reward 763.0, memory_length 2000, epsilon 0.11976124320301879, time 722.0, rides 130\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 2357, reward 625.0, memory_length 2000, epsilon 0.11965345808413606, time 726.0, rides 124\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 2358, reward 690.0, memory_length 2000, epsilon 0.11954576997186034, time 725.0, rides 124\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 2359, reward 869.0, memory_length 2000, epsilon 0.11943817877888566, time 730.0, rides 142\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 2360, reward 795.0, memory_length 2000, epsilon 0.11933068441798465, time 725.0, rides 128\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 2361, reward 673.0, memory_length 2000, epsilon 0.11922328680200847, time 726.0, rides 127\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2362, reward 756.0, memory_length 2000, epsilon 0.11911598584388666, time 725.0, rides 130\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 2363, reward 767.0, memory_length 2000, epsilon 0.11900878145662716, time 722.0, rides 133\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 2364, reward 850.0, memory_length 2000, epsilon 0.1189016735533162, time 730.0, rides 123\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 2365, reward 722.0, memory_length 2000, epsilon 0.11879466204711821, time 725.0, rides 139\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 2366, reward 576.0, memory_length 2000, epsilon 0.1186877468512758, time 730.0, rides 129\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 2367, reward 796.0, memory_length 2000, epsilon 0.11858092787910965, time 738.0, rides 136\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2368, reward 646.0, memory_length 2000, epsilon 0.11847420504401845, time 723.0, rides 129\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 2369, reward 867.0, memory_length 2000, epsilon 0.11836757825947884, time 741.0, rides 132\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 2370, reward 1114.0, memory_length 2000, epsilon 0.11826104743904531, time 726.0, rides 136\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 2371, reward 909.0, memory_length 2000, epsilon 0.11815461249635016, time 728.0, rides 133\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 2372, reward 702.0, memory_length 2000, epsilon 0.11804827334510344, time 728.0, rides 140\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 2373, reward 981.0, memory_length 2000, epsilon 0.11794202989909285, time 727.0, rides 130\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 2374, reward 945.0, memory_length 2000, epsilon 0.11783588207218366, time 735.0, rides 135\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 2375, reward 660.0, memory_length 2000, epsilon 0.1177298297783187, time 734.0, rides 141\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2376, reward 604.0, memory_length 2000, epsilon 0.1176238729315182, time 726.0, rides 139\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 2377, reward 807.0, memory_length 2000, epsilon 0.11751801144587984, time 723.0, rides 130\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 2378, reward 818.0, memory_length 2000, epsilon 0.11741224523557854, time 729.0, rides 141\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 2379, reward 643.0, memory_length 2000, epsilon 0.11730657421486652, time 726.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2380, reward 623.0, memory_length 2000, epsilon 0.11720099829807314, time 725.0, rides 133\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2381, reward 746.0, memory_length 2000, epsilon 0.11709551739960487, time 721.0, rides 135\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2382, reward 760.0, memory_length 2000, epsilon 0.11699013143394522, time 736.0, rides 129\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 2383, reward 410.0, memory_length 2000, epsilon 0.11688484031565467, time 725.0, rides 136\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2384, reward 919.0, memory_length 2000, epsilon 0.11677964395937059, time 730.0, rides 132\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 2385, reward 490.0, memory_length 2000, epsilon 0.11667454227980716, time 720.0, rides 133\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 2386, reward 603.0, memory_length 2000, epsilon 0.11656953519175532, time 730.0, rides 136\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 2387, reward 682.0, memory_length 2000, epsilon 0.11646462261008274, time 727.0, rides 135\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 2388, reward 850.0, memory_length 2000, epsilon 0.11635980444973366, time 722.0, rides 127\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 2389, reward 611.0, memory_length 2000, epsilon 0.1162550806257289, time 722.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 2390, reward 741.0, memory_length 2000, epsilon 0.11615045105316574, time 739.0, rides 124\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 2391, reward 702.0, memory_length 2000, epsilon 0.11604591564721789, time 729.0, rides 137\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 2392, reward 832.0, memory_length 2000, epsilon 0.1159414743231354, time 728.0, rides 135\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 2393, reward 524.0, memory_length 2000, epsilon 0.11583712699624457, time 728.0, rides 137\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 2394, reward 930.0, memory_length 2000, epsilon 0.11573287358194795, time 728.0, rides 123\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2395, reward 827.0, memory_length 2000, epsilon 0.11562871399572419, time 724.0, rides 132\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2396, reward 522.0, memory_length 2000, epsilon 0.11552464815312803, time 724.0, rides 118\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 2397, reward 960.0, memory_length 2000, epsilon 0.11542067596979022, time 734.0, rides 133\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2398, reward 903.0, memory_length 2000, epsilon 0.11531679736141741, time 720.0, rides 141\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 2399, reward 1049.0, memory_length 2000, epsilon 0.11521301224379213, time 729.0, rides 133\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 2400, reward 1006.0, memory_length 2000, epsilon 0.11510932053277272, time 727.0, rides 144\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 2401, reward 1002.0, memory_length 2000, epsilon 0.11500572214429322, time 733.0, rides 128\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 2402, reward 862.0, memory_length 2000, epsilon 0.11490221699436336, time 735.0, rides 151\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 2403, reward 383.0, memory_length 2000, epsilon 0.11479880499906843, time 728.0, rides 141\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 2404, reward 711.0, memory_length 2000, epsilon 0.11469548607456927, time 726.0, rides 142\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2405, reward 1020.0, memory_length 2000, epsilon 0.11459226013710215, time 728.0, rides 138\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 2406, reward 715.0, memory_length 2000, epsilon 0.11448912710297876, time 727.0, rides 134\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 2407, reward 1174.0, memory_length 2000, epsilon 0.11438608688858608, time 727.0, rides 133\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 2408, reward 723.0, memory_length 2000, epsilon 0.11428313941038636, time 727.0, rides 135\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 2409, reward 695.0, memory_length 2000, epsilon 0.11418028458491701, time 729.0, rides 127\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 2410, reward 952.0, memory_length 2000, epsilon 0.11407752232879058, time 730.0, rides 149\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 2411, reward 813.0, memory_length 2000, epsilon 0.11397485255869466, time 726.0, rides 120\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 2412, reward 724.0, memory_length 2000, epsilon 0.11387227519139184, time 737.0, rides 120\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 2413, reward 838.0, memory_length 2000, epsilon 0.11376979014371959, time 727.0, rides 132\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 2414, reward 797.0, memory_length 2000, epsilon 0.11366739733259024, time 733.0, rides 128\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 2415, reward 802.0, memory_length 2000, epsilon 0.1135650966749909, time 724.0, rides 121\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 2416, reward 1065.0, memory_length 2000, epsilon 0.11346288808798341, time 728.0, rides 138\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2417, reward 1078.0, memory_length 2000, epsilon 0.11336077148870423, time 732.0, rides 128\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 2418, reward 651.0, memory_length 2000, epsilon 0.11325874679436439, time 730.0, rides 119\n",
      "Initial State is  [3, 3, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2419, reward 593.0, memory_length 2000, epsilon 0.11315681392224945, time 731.0, rides 133\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 2420, reward 658.0, memory_length 2000, epsilon 0.11305497278971943, time 721.0, rides 136\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2421, reward 715.0, memory_length 2000, epsilon 0.11295322331420868, time 738.0, rides 136\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2422, reward 847.0, memory_length 2000, epsilon 0.11285156541322588, time 729.0, rides 124\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 2423, reward 808.0, memory_length 2000, epsilon 0.11274999900435398, time 730.0, rides 137\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 2424, reward 624.0, memory_length 2000, epsilon 0.11264852400525006, time 730.0, rides 123\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 2425, reward 788.0, memory_length 2000, epsilon 0.11254714033364534, time 720.0, rides 136\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2426, reward 714.0, memory_length 2000, epsilon 0.11244584790734506, time 739.0, rides 133\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 2427, reward 802.0, memory_length 2000, epsilon 0.11234464664422845, time 731.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 2428, reward 733.0, memory_length 2000, epsilon 0.11224353646224865, time 726.0, rides 148\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2429, reward 745.0, memory_length 2000, epsilon 0.11214251727943263, time 738.0, rides 137\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2430, reward 763.0, memory_length 2000, epsilon 0.11204158901388113, time 726.0, rides 129\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 2431, reward 1053.0, memory_length 2000, epsilon 0.11194075158376864, time 731.0, rides 128\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 2432, reward 1073.0, memory_length 2000, epsilon 0.11184000490734325, time 730.0, rides 136\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 2433, reward 711.0, memory_length 2000, epsilon 0.11173934890292664, time 733.0, rides 126\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2434, reward 971.0, memory_length 2000, epsilon 0.111638783488914, time 726.0, rides 138\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2435, reward 876.0, memory_length 2000, epsilon 0.11153830858377398, time 730.0, rides 136\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 2436, reward 1044.0, memory_length 2000, epsilon 0.11143792410604858, time 725.0, rides 137\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2437, reward 779.0, memory_length 2000, epsilon 0.11133762997435313, time 728.0, rides 126\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 2438, reward 1054.0, memory_length 2000, epsilon 0.11123742610737622, time 734.0, rides 126\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 2439, reward 838.0, memory_length 2000, epsilon 0.11113731242387959, time 730.0, rides 152\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 2440, reward 876.0, memory_length 2000, epsilon 0.11103728884269809, time 735.0, rides 135\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 2441, reward 962.0, memory_length 2000, epsilon 0.11093735528273967, time 739.0, rides 129\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2442, reward 775.0, memory_length 2000, epsilon 0.1108375116629852, time 724.0, rides 122\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 2443, reward 968.0, memory_length 2000, epsilon 0.1107377579024885, time 729.0, rides 139\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 2444, reward 568.0, memory_length 2000, epsilon 0.11063809392037627, time 735.0, rides 129\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2445, reward 752.0, memory_length 2000, epsilon 0.11053851963584793, time 726.0, rides 131\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 2446, reward 902.0, memory_length 2000, epsilon 0.11043903496817567, time 738.0, rides 123\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2447, reward 1032.0, memory_length 2000, epsilon 0.1103396398367043, time 725.0, rides 126\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 2448, reward 617.0, memory_length 2000, epsilon 0.11024033416085127, time 732.0, rides 130\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2449, reward 892.0, memory_length 2000, epsilon 0.11014111786010651, time 723.0, rides 140\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2450, reward 778.0, memory_length 2000, epsilon 0.1100419908540324, time 732.0, rides 127\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 2451, reward 668.0, memory_length 2000, epsilon 0.10994295306226377, time 730.0, rides 131\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 2452, reward 815.0, memory_length 2000, epsilon 0.10984400440450773, time 733.0, rides 129\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2453, reward 947.0, memory_length 2000, epsilon 0.10974514480054368, time 728.0, rides 144\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 2454, reward 665.0, memory_length 2000, epsilon 0.10964637417022319, time 729.0, rides 141\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 2455, reward 571.0, memory_length 2000, epsilon 0.10954769243346998, time 726.0, rides 128\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 2456, reward 627.0, memory_length 2000, epsilon 0.10944909951027985, time 730.0, rides 149\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 2457, reward 879.0, memory_length 2000, epsilon 0.1093505953207206, time 729.0, rides 134\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 2458, reward 537.0, memory_length 2000, epsilon 0.10925217978493194, time 730.0, rides 141\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2459, reward 635.0, memory_length 2000, epsilon 0.10915385282312551, time 731.0, rides 129\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 2460, reward 680.0, memory_length 2000, epsilon 0.1090556143555847, time 729.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2461, reward 501.0, memory_length 2000, epsilon 0.10895746430266467, time 726.0, rides 130\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 2462, reward 996.0, memory_length 2000, epsilon 0.10885940258479228, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 2463, reward 1001.0, memory_length 2000, epsilon 0.10876142912246596, time 728.0, rides 130\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2464, reward 537.0, memory_length 2000, epsilon 0.10866354383625575, time 723.0, rides 123\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 2465, reward 851.0, memory_length 2000, epsilon 0.10856574664680312, time 730.0, rides 132\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2466, reward 716.0, memory_length 2000, epsilon 0.10846803747482099, time 721.0, rides 152\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 2467, reward 1124.0, memory_length 2000, epsilon 0.10837041624109366, time 730.0, rides 126\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 2468, reward 907.0, memory_length 2000, epsilon 0.10827288286647667, time 728.0, rides 145\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2469, reward 1084.0, memory_length 2000, epsilon 0.10817543727189684, time 728.0, rides 136\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 2470, reward 388.0, memory_length 2000, epsilon 0.10807807937835213, time 725.0, rides 131\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2471, reward 938.0, memory_length 2000, epsilon 0.10798080910691162, time 725.0, rides 131\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 2472, reward 1068.0, memory_length 2000, epsilon 0.10788362637871539, time 723.0, rides 148\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 2473, reward 429.0, memory_length 2000, epsilon 0.10778653111497455, time 726.0, rides 127\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 2474, reward 908.0, memory_length 2000, epsilon 0.10768952323697108, time 727.0, rides 132\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2475, reward 765.0, memory_length 2000, epsilon 0.1075926026660578, time 728.0, rides 127\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2476, reward 873.0, memory_length 2000, epsilon 0.10749576932365836, time 734.0, rides 129\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2477, reward 643.0, memory_length 2000, epsilon 0.10739902313126706, time 729.0, rides 116\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2478, reward 1016.0, memory_length 2000, epsilon 0.10730236401044892, time 723.0, rides 129\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 2479, reward 1017.0, memory_length 2000, epsilon 0.10720579188283952, time 736.0, rides 142\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 2480, reward 887.0, memory_length 2000, epsilon 0.10710930667014495, time 724.0, rides 136\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 2481, reward 979.0, memory_length 2000, epsilon 0.10701290829414183, time 725.0, rides 139\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 2482, reward 818.0, memory_length 2000, epsilon 0.10691659667667709, time 727.0, rides 119\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 2483, reward 585.0, memory_length 2000, epsilon 0.10682037173966809, time 735.0, rides 134\n",
      "Initial State is  [4, 16, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2484, reward 477.0, memory_length 2000, epsilon 0.10672423340510238, time 727.0, rides 127\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 2485, reward 939.0, memory_length 2000, epsilon 0.10662818159503779, time 727.0, rides 136\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2486, reward 911.0, memory_length 2000, epsilon 0.10653221623160225, time 727.0, rides 141\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2487, reward 1056.0, memory_length 2000, epsilon 0.1064363372369938, time 729.0, rides 142\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 2488, reward 954.0, memory_length 2000, epsilon 0.1063405445334805, time 728.0, rides 135\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2489, reward 1056.0, memory_length 2000, epsilon 0.10624483804340037, time 727.0, rides 136\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 2490, reward 689.0, memory_length 2000, epsilon 0.10614921768916132, time 726.0, rides 134\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2491, reward 775.0, memory_length 2000, epsilon 0.10605368339324107, time 729.0, rides 151\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 2492, reward 1070.0, memory_length 2000, epsilon 0.10595823507818716, time 720.0, rides 134\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 2493, reward 787.0, memory_length 2000, epsilon 0.10586287266661679, time 725.0, rides 133\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2494, reward 601.0, memory_length 2000, epsilon 0.10576759608121683, time 730.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 2495, reward 888.0, memory_length 2000, epsilon 0.10567240524474374, time 732.0, rides 128\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2496, reward 814.0, memory_length 2000, epsilon 0.10557730008002346, time 730.0, rides 129\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2497, reward 790.0, memory_length 2000, epsilon 0.10548228050995144, time 729.0, rides 129\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 2498, reward 889.0, memory_length 2000, epsilon 0.10538734645749248, time 726.0, rides 131\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 2499, reward 1012.0, memory_length 2000, epsilon 0.10529249784568073, time 736.0, rides 126\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 2500, reward 718.0, memory_length 2000, epsilon 0.10519773459761962, time 731.0, rides 128\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 2501, reward 527.0, memory_length 2000, epsilon 0.10510305663648176, time 724.0, rides 129\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 2502, reward 816.0, memory_length 2000, epsilon 0.10500846388550893, time 726.0, rides 124\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 2503, reward 698.0, memory_length 2000, epsilon 0.10491395626801196, time 730.0, rides 136\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 2504, reward 863.0, memory_length 2000, epsilon 0.10481953370737075, time 728.0, rides 132\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2505, reward 988.0, memory_length 2000, epsilon 0.10472519612703411, time 726.0, rides 137\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 2506, reward 820.0, memory_length 2000, epsilon 0.10463094345051978, time 733.0, rides 128\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 2507, reward 842.0, memory_length 2000, epsilon 0.1045367756014143, time 732.0, rides 121\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 2508, reward 326.0, memory_length 2000, epsilon 0.10444269250337303, time 726.0, rides 128\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2509, reward 859.0, memory_length 2000, epsilon 0.10434869408011999, time 731.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 2510, reward 1045.0, memory_length 2000, epsilon 0.10425478025544788, time 732.0, rides 129\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 2511, reward 874.0, memory_length 2000, epsilon 0.10416095095321798, time 729.0, rides 128\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 2512, reward 763.0, memory_length 2000, epsilon 0.10406720609736009, time 730.0, rides 131\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 2513, reward 638.0, memory_length 2000, epsilon 0.10397354561187246, time 726.0, rides 113\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 2514, reward 621.0, memory_length 2000, epsilon 0.10387996942082177, time 729.0, rides 137\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2515, reward 1045.0, memory_length 2000, epsilon 0.10378647744834303, time 730.0, rides 123\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2516, reward 745.0, memory_length 2000, epsilon 0.10369306961863953, time 733.0, rides 129\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2517, reward 1057.0, memory_length 2000, epsilon 0.10359974585598275, time 736.0, rides 122\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 2518, reward 858.0, memory_length 2000, epsilon 0.10350650608471236, time 734.0, rides 132\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2519, reward 830.0, memory_length 2000, epsilon 0.10341335022923612, time 730.0, rides 138\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 2520, reward 527.0, memory_length 2000, epsilon 0.10332027821402981, time 730.0, rides 125\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2521, reward 720.0, memory_length 2000, epsilon 0.10322728996363718, time 731.0, rides 117\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2522, reward 573.0, memory_length 2000, epsilon 0.1031343854026699, time 729.0, rides 136\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 2523, reward 844.0, memory_length 2000, epsilon 0.1030415644558075, time 732.0, rides 117\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2524, reward 1089.0, memory_length 2000, epsilon 0.10294882704779727, time 738.0, rides 132\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 2525, reward 874.0, memory_length 2000, epsilon 0.10285617310345425, time 726.0, rides 131\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 2526, reward 713.0, memory_length 2000, epsilon 0.10276360254766115, time 725.0, rides 123\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 2527, reward 879.0, memory_length 2000, epsilon 0.10267111530536825, time 726.0, rides 131\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 2528, reward 451.0, memory_length 2000, epsilon 0.10257871130159342, time 721.0, rides 130\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 2529, reward 645.0, memory_length 2000, epsilon 0.10248639046142198, time 730.0, rides 115\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 2530, reward 1199.0, memory_length 2000, epsilon 0.1023941527100067, time 723.0, rides 140\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 2531, reward 796.0, memory_length 2000, epsilon 0.10230199797256768, time 727.0, rides 129\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 2532, reward 623.0, memory_length 2000, epsilon 0.10220992617439237, time 730.0, rides 125\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 2533, reward 648.0, memory_length 2000, epsilon 0.10211793724083541, time 730.0, rides 138\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2534, reward 639.0, memory_length 2000, epsilon 0.10202603109731866, time 722.0, rides 135\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 2535, reward 930.0, memory_length 2000, epsilon 0.10193420766933106, time 724.0, rides 139\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 2536, reward 548.0, memory_length 2000, epsilon 0.10184246688242866, time 729.0, rides 136\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 2537, reward 1099.0, memory_length 2000, epsilon 0.10175080866223447, time 734.0, rides 133\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 2538, reward 556.0, memory_length 2000, epsilon 0.10165923293443846, time 732.0, rides 125\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 2539, reward 832.0, memory_length 2000, epsilon 0.10156773962479747, time 733.0, rides 133\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 2540, reward 787.0, memory_length 2000, epsilon 0.10147632865913515, time 731.0, rides 137\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2541, reward 1159.0, memory_length 2000, epsilon 0.10138499996334194, time 731.0, rides 134\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 2542, reward 696.0, memory_length 2000, epsilon 0.10129375346337492, time 728.0, rides 135\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 2543, reward 893.0, memory_length 2000, epsilon 0.10120258908525788, time 731.0, rides 125\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 2544, reward 789.0, memory_length 2000, epsilon 0.10111150675508114, time 735.0, rides 128\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 2545, reward 993.0, memory_length 2000, epsilon 0.10102050639900156, time 728.0, rides 135\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 2546, reward 724.0, memory_length 2000, epsilon 0.10092958794324246, time 731.0, rides 146\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 2547, reward 843.0, memory_length 2000, epsilon 0.10083875131409353, time 728.0, rides 151\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2548, reward 727.0, memory_length 2000, epsilon 0.10074799643791085, time 730.0, rides 125\n",
      "Initial State is  [3, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2549, reward 793.0, memory_length 2000, epsilon 0.10065732324111673, time 729.0, rides 135\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2550, reward 748.0, memory_length 2000, epsilon 0.10056673165019972, time 725.0, rides 138\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 2551, reward 734.0, memory_length 2000, epsilon 0.10047622159171454, time 727.0, rides 144\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 2552, reward 631.0, memory_length 2000, epsilon 0.100385792992282, time 731.0, rides 135\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 2553, reward 773.0, memory_length 2000, epsilon 0.10029544577858894, time 735.0, rides 140\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 2554, reward 354.0, memory_length 2000, epsilon 0.10020517987738821, time 721.0, rides 126\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2555, reward 1060.0, memory_length 2000, epsilon 0.10011499521549856, time 724.0, rides 133\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 2556, reward 953.0, memory_length 2000, epsilon 0.10002489171980461, time 732.0, rides 150\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 2557, reward 1011.0, memory_length 2000, epsilon 0.09993486931725679, time 726.0, rides 131\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 2558, reward 1266.0, memory_length 2000, epsilon 0.09984492793487125, time 728.0, rides 141\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 2559, reward 711.0, memory_length 2000, epsilon 0.09975506749972987, time 732.0, rides 130\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 2560, reward 1183.0, memory_length 2000, epsilon 0.09966528793898011, time 724.0, rides 132\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2561, reward 1050.0, memory_length 2000, epsilon 0.09957558917983503, time 725.0, rides 133\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 2562, reward 754.0, memory_length 2000, epsilon 0.09948597114957318, time 724.0, rides 140\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 2563, reward 687.0, memory_length 2000, epsilon 0.09939643377553856, time 725.0, rides 126\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 2564, reward 684.0, memory_length 2000, epsilon 0.09930697698514057, time 726.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 2565, reward 835.0, memory_length 2000, epsilon 0.09921760070585395, time 731.0, rides 140\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 2566, reward 574.0, memory_length 2000, epsilon 0.09912830486521867, time 724.0, rides 128\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2567, reward 828.0, memory_length 2000, epsilon 0.09903908939083998, time 725.0, rides 132\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 2568, reward 690.0, memory_length 2000, epsilon 0.09894995421038823, time 736.0, rides 122\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2569, reward 946.0, memory_length 2000, epsilon 0.09886089925159888, time 731.0, rides 147\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2570, reward 770.0, memory_length 2000, epsilon 0.09877192444227244, time 723.0, rides 122\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 2571, reward 906.0, memory_length 2000, epsilon 0.09868302971027439, time 731.0, rides 137\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 2572, reward 934.0, memory_length 2000, epsilon 0.09859421498353514, time 732.0, rides 120\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 2573, reward 802.0, memory_length 2000, epsilon 0.09850548019004995, time 726.0, rides 135\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 2574, reward 680.0, memory_length 2000, epsilon 0.09841682525787891, time 725.0, rides 124\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 2575, reward 624.0, memory_length 2000, epsilon 0.09832825011514681, time 724.0, rides 120\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2576, reward 984.0, memory_length 2000, epsilon 0.09823975469004319, time 727.0, rides 113\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 2577, reward 630.0, memory_length 2000, epsilon 0.09815133891082214, time 731.0, rides 127\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2578, reward 1147.0, memory_length 2000, epsilon 0.0980630027058024, time 729.0, rides 145\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 2579, reward 767.0, memory_length 2000, epsilon 0.09797474600336717, time 734.0, rides 134\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 2580, reward 887.0, memory_length 2000, epsilon 0.09788656873196414, time 729.0, rides 136\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2581, reward 1029.0, memory_length 2000, epsilon 0.09779847082010537, time 732.0, rides 134\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 2582, reward 261.0, memory_length 2000, epsilon 0.09771045219636727, time 726.0, rides 132\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 2583, reward 480.0, memory_length 2000, epsilon 0.09762251278939055, time 734.0, rides 136\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2584, reward 546.0, memory_length 2000, epsilon 0.0975346525278801, time 732.0, rides 140\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 2585, reward 821.0, memory_length 2000, epsilon 0.097446871340605, time 722.0, rides 129\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 2586, reward 1013.0, memory_length 2000, epsilon 0.09735916915639846, time 726.0, rides 139\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2587, reward 705.0, memory_length 2000, epsilon 0.0972715459041577, time 725.0, rides 120\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2588, reward 687.0, memory_length 2000, epsilon 0.09718400151284395, time 724.0, rides 130\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2589, reward 889.0, memory_length 2000, epsilon 0.09709653591148239, time 733.0, rides 126\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 2590, reward 918.0, memory_length 2000, epsilon 0.09700914902916205, time 735.0, rides 129\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 2591, reward 770.0, memory_length 2000, epsilon 0.09692184079503581, time 729.0, rides 136\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 2592, reward 1135.0, memory_length 2000, epsilon 0.09683461113832027, time 729.0, rides 138\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 2593, reward 828.0, memory_length 2000, epsilon 0.09674745998829579, time 729.0, rides 132\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2594, reward 835.0, memory_length 2000, epsilon 0.09666038727430631, time 739.0, rides 134\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 2595, reward 647.0, memory_length 2000, epsilon 0.09657339292575944, time 729.0, rides 125\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 2596, reward 602.0, memory_length 2000, epsilon 0.09648647687212625, time 731.0, rides 126\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 2597, reward 624.0, memory_length 2000, epsilon 0.09639963904294133, time 731.0, rides 128\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 2598, reward 553.0, memory_length 2000, epsilon 0.09631287936780268, time 723.0, rides 126\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2599, reward 827.0, memory_length 2000, epsilon 0.09622619777637166, time 724.0, rides 140\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 2600, reward 902.0, memory_length 2000, epsilon 0.09613959419837292, time 726.0, rides 128\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 2601, reward 697.0, memory_length 2000, epsilon 0.09605306856359438, time 726.0, rides 124\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 2602, reward 747.0, memory_length 2000, epsilon 0.09596662080188714, time 730.0, rides 145\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2603, reward 718.0, memory_length 2000, epsilon 0.09588025084316544, time 727.0, rides 141\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 2604, reward 658.0, memory_length 2000, epsilon 0.0957939586174066, time 735.0, rides 130\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 2605, reward 1097.0, memory_length 2000, epsilon 0.09570774405465093, time 730.0, rides 151\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 2606, reward 591.0, memory_length 2000, epsilon 0.09562160708500175, time 723.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2607, reward 639.0, memory_length 2000, epsilon 0.09553554763862525, time 724.0, rides 139\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 2608, reward 973.0, memory_length 2000, epsilon 0.09544956564575048, time 729.0, rides 138\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 2609, reward 1105.0, memory_length 2000, epsilon 0.09536366103666931, time 726.0, rides 154\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 2610, reward 791.0, memory_length 2000, epsilon 0.0952778337417363, time 726.0, rides 132\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 2611, reward 674.0, memory_length 2000, epsilon 0.09519208369136874, time 732.0, rides 138\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2612, reward 740.0, memory_length 2000, epsilon 0.09510641081604651, time 726.0, rides 131\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 2613, reward 693.0, memory_length 2000, epsilon 0.09502081504631207, time 731.0, rides 119\n",
      "Initial State is  [2, 5, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2614, reward 477.0, memory_length 2000, epsilon 0.0949352963127704, time 727.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 2615, reward 531.0, memory_length 2000, epsilon 0.09484985454608891, time 726.0, rides 121\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2616, reward 849.0, memory_length 2000, epsilon 0.09476448967699742, time 729.0, rides 141\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 2617, reward 1004.0, memory_length 2000, epsilon 0.09467920163628812, time 729.0, rides 120\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 2618, reward 974.0, memory_length 2000, epsilon 0.09459399035481546, time 727.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2619, reward 622.0, memory_length 2000, epsilon 0.09450885576349612, time 724.0, rides 139\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 2620, reward 714.0, memory_length 2000, epsilon 0.09442379779330896, time 734.0, rides 126\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2621, reward 795.0, memory_length 2000, epsilon 0.09433881637529498, time 729.0, rides 117\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 2622, reward 736.0, memory_length 2000, epsilon 0.09425391144055721, time 725.0, rides 133\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 2623, reward 964.0, memory_length 2000, epsilon 0.0941690829202607, time 729.0, rides 125\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2624, reward 912.0, memory_length 2000, epsilon 0.09408433074563247, time 734.0, rides 154\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 2625, reward 1150.0, memory_length 2000, epsilon 0.0939996548479614, time 722.0, rides 134\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 2626, reward 644.0, memory_length 2000, epsilon 0.09391505515859823, time 733.0, rides 128\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2627, reward 732.0, memory_length 2000, epsilon 0.09383053160895549, time 729.0, rides 119\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 2628, reward 732.0, memory_length 2000, epsilon 0.09374608413050743, time 729.0, rides 129\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 2629, reward 1139.0, memory_length 2000, epsilon 0.09366171265478998, time 734.0, rides 128\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 2630, reward 740.0, memory_length 2000, epsilon 0.09357741711340067, time 736.0, rides 136\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 2631, reward 706.0, memory_length 2000, epsilon 0.09349319743799861, time 728.0, rides 134\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 2632, reward 929.0, memory_length 2000, epsilon 0.0934090535603044, time 725.0, rides 126\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 2633, reward 960.0, memory_length 2000, epsilon 0.09332498541210013, time 732.0, rides 145\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 2634, reward 721.0, memory_length 2000, epsilon 0.09324099292522924, time 727.0, rides 132\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 2635, reward 721.0, memory_length 2000, epsilon 0.09315707603159652, time 728.0, rides 133\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 2636, reward 613.0, memory_length 2000, epsilon 0.09307323466316808, time 731.0, rides 126\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 2637, reward 871.0, memory_length 2000, epsilon 0.09298946875197123, time 724.0, rides 121\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 2638, reward 622.0, memory_length 2000, epsilon 0.09290577823009445, time 730.0, rides 146\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 2639, reward 838.0, memory_length 2000, epsilon 0.09282216302968736, time 736.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2640, reward 1104.0, memory_length 2000, epsilon 0.09273862308296064, time 740.0, rides 123\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 2641, reward 1059.0, memory_length 2000, epsilon 0.09265515832218597, time 731.0, rides 138\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 2642, reward 686.0, memory_length 2000, epsilon 0.092571768679696, time 723.0, rides 125\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2643, reward 1007.0, memory_length 2000, epsilon 0.09248845408788428, time 730.0, rides 136\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2644, reward 1186.0, memory_length 2000, epsilon 0.09240521447920519, time 728.0, rides 137\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 2645, reward 531.0, memory_length 2000, epsilon 0.09232204978617391, time 727.0, rides 115\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 2646, reward 938.0, memory_length 2000, epsilon 0.09223895994136636, time 731.0, rides 126\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2647, reward 934.0, memory_length 2000, epsilon 0.09215594487741913, time 731.0, rides 136\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 2648, reward 747.0, memory_length 2000, epsilon 0.09207300452702945, time 729.0, rides 129\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 2649, reward 626.0, memory_length 2000, epsilon 0.09199013882295512, time 727.0, rides 137\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2650, reward 975.0, memory_length 2000, epsilon 0.09190734769801447, time 725.0, rides 126\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 2651, reward 954.0, memory_length 2000, epsilon 0.09182463108508625, time 728.0, rides 139\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 2652, reward 762.0, memory_length 2000, epsilon 0.09174198891710966, time 728.0, rides 132\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 2653, reward 554.0, memory_length 2000, epsilon 0.09165942112708426, time 725.0, rides 128\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 2654, reward 976.0, memory_length 2000, epsilon 0.09157692764806989, time 731.0, rides 119\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 2655, reward 758.0, memory_length 2000, epsilon 0.09149450841318663, time 729.0, rides 140\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 2656, reward 934.0, memory_length 2000, epsilon 0.09141216335561475, time 731.0, rides 129\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2657, reward 553.0, memory_length 2000, epsilon 0.0913298924085947, time 726.0, rides 135\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 2658, reward 864.0, memory_length 2000, epsilon 0.09124769550542695, time 732.0, rides 136\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 2659, reward 743.0, memory_length 2000, epsilon 0.09116557257947207, time 725.0, rides 129\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 2660, reward 677.0, memory_length 2000, epsilon 0.09108352356415055, time 729.0, rides 121\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 2661, reward 617.0, memory_length 2000, epsilon 0.0910015483929428, time 731.0, rides 127\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 2662, reward 793.0, memory_length 2000, epsilon 0.09091964699938916, time 733.0, rides 162\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2663, reward 588.0, memory_length 2000, epsilon 0.09083781931708972, time 727.0, rides 120\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 2664, reward 574.0, memory_length 2000, epsilon 0.09075606527970434, time 728.0, rides 117\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2665, reward 965.0, memory_length 2000, epsilon 0.09067438482095261, time 728.0, rides 132\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 2666, reward 864.0, memory_length 2000, epsilon 0.09059277787461376, time 727.0, rides 138\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 2667, reward 780.0, memory_length 2000, epsilon 0.09051124437452661, time 727.0, rides 130\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 2668, reward 529.0, memory_length 2000, epsilon 0.09042978425458953, time 725.0, rides 134\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 2669, reward 804.0, memory_length 2000, epsilon 0.0903483974487604, time 732.0, rides 125\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 2670, reward 921.0, memory_length 2000, epsilon 0.09026708389105652, time 727.0, rides 129\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 2671, reward 962.0, memory_length 2000, epsilon 0.09018584351555457, time 722.0, rides 129\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 2672, reward 929.0, memory_length 2000, epsilon 0.09010467625639057, time 727.0, rides 123\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 2673, reward 852.0, memory_length 2000, epsilon 0.09002358204775981, time 732.0, rides 140\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 2674, reward 512.0, memory_length 2000, epsilon 0.08994256082391683, time 722.0, rides 132\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2675, reward 369.0, memory_length 2000, epsilon 0.08986161251917531, time 731.0, rides 124\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2676, reward 947.0, memory_length 2000, epsilon 0.08978073706790805, time 724.0, rides 128\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 2677, reward 648.0, memory_length 2000, epsilon 0.08969993440454693, time 728.0, rides 128\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 2678, reward 704.0, memory_length 2000, epsilon 0.08961920446358283, time 732.0, rides 128\n",
      "Initial State is  [0, 20, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2679, reward 1219.0, memory_length 2000, epsilon 0.08953854717956561, time 727.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 2680, reward 1062.0, memory_length 2000, epsilon 0.089457962487104, time 726.0, rides 134\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2681, reward 809.0, memory_length 2000, epsilon 0.08937745032086561, time 728.0, rides 131\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 2682, reward 875.0, memory_length 2000, epsilon 0.08929701061557684, time 729.0, rides 128\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 2683, reward 749.0, memory_length 2000, epsilon 0.08921664330602282, time 730.0, rides 130\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2684, reward 1047.0, memory_length 2000, epsilon 0.0891363483270474, time 730.0, rides 142\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2685, reward 955.0, memory_length 2000, epsilon 0.08905612561355306, time 730.0, rides 123\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2686, reward 807.0, memory_length 2000, epsilon 0.08897597510050086, time 726.0, rides 132\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 2687, reward 761.0, memory_length 2000, epsilon 0.0888958967229104, time 737.0, rides 125\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2688, reward 785.0, memory_length 2000, epsilon 0.08881589041585979, time 729.0, rides 136\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 2689, reward 665.0, memory_length 2000, epsilon 0.08873595611448551, time 727.0, rides 133\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2690, reward 1039.0, memory_length 2000, epsilon 0.08865609375398247, time 728.0, rides 129\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2691, reward 592.0, memory_length 2000, epsilon 0.08857630326960388, time 723.0, rides 120\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 2692, reward 903.0, memory_length 2000, epsilon 0.08849658459666124, time 727.0, rides 114\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 2693, reward 1011.0, memory_length 2000, epsilon 0.08841693767052423, time 729.0, rides 134\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2694, reward 1155.0, memory_length 2000, epsilon 0.08833736242662076, time 724.0, rides 131\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 2695, reward 541.0, memory_length 2000, epsilon 0.0882578588004368, time 723.0, rides 120\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 2696, reward 529.0, memory_length 2000, epsilon 0.0881784267275164, time 722.0, rides 135\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2697, reward 1069.0, memory_length 2000, epsilon 0.08809906614346164, time 729.0, rides 135\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 2698, reward 1029.0, memory_length 2000, epsilon 0.08801977698393251, time 729.0, rides 136\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 2699, reward 776.0, memory_length 2000, epsilon 0.08794055918464697, time 724.0, rides 133\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2700, reward 771.0, memory_length 2000, epsilon 0.08786141268138078, time 730.0, rides 123\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 2701, reward 848.0, memory_length 2000, epsilon 0.08778233740996755, time 731.0, rides 147\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 2702, reward 935.0, memory_length 2000, epsilon 0.08770333330629858, time 728.0, rides 124\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 2703, reward 728.0, memory_length 2000, epsilon 0.0876244003063229, time 728.0, rides 123\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 2704, reward 981.0, memory_length 2000, epsilon 0.08754553834604721, time 727.0, rides 127\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2705, reward 702.0, memory_length 2000, epsilon 0.08746674736153577, time 729.0, rides 132\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2706, reward 838.0, memory_length 2000, epsilon 0.08738802728891039, time 729.0, rides 127\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 2707, reward 670.0, memory_length 2000, epsilon 0.08730937806435037, time 724.0, rides 125\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2708, reward 764.0, memory_length 2000, epsilon 0.08723079962409244, time 729.0, rides 120\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 2709, reward 819.0, memory_length 2000, epsilon 0.08715229190443076, time 726.0, rides 128\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2710, reward 877.0, memory_length 2000, epsilon 0.08707385484171677, time 725.0, rides 128\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 2711, reward 451.0, memory_length 2000, epsilon 0.08699548837235922, time 724.0, rides 142\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 2712, reward 960.0, memory_length 2000, epsilon 0.0869171924328241, time 725.0, rides 125\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2713, reward 671.0, memory_length 2000, epsilon 0.08683896695963456, time 731.0, rides 127\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2714, reward 918.0, memory_length 2000, epsilon 0.08676081188937089, time 731.0, rides 141\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2715, reward 787.0, memory_length 2000, epsilon 0.08668272715867045, time 731.0, rides 126\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2716, reward 737.0, memory_length 2000, epsilon 0.08660471270422765, time 726.0, rides 123\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 2717, reward 898.0, memory_length 2000, epsilon 0.08652676846279385, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2718, reward 679.0, memory_length 2000, epsilon 0.08644889437117734, time 726.0, rides 135\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 2719, reward 790.0, memory_length 2000, epsilon 0.08637109036624328, time 731.0, rides 137\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 2720, reward 771.0, memory_length 2000, epsilon 0.08629335638491366, time 736.0, rides 132\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 2721, reward 1042.0, memory_length 2000, epsilon 0.08621569236416723, time 727.0, rides 148\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 2722, reward 962.0, memory_length 2000, epsilon 0.08613809824103948, time 732.0, rides 129\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2723, reward 832.0, memory_length 2000, epsilon 0.08606057395262254, time 729.0, rides 139\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 2724, reward 1019.0, memory_length 2000, epsilon 0.08598311943606518, time 740.0, rides 131\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 2725, reward 1102.0, memory_length 2000, epsilon 0.08590573462857272, time 728.0, rides 134\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 2726, reward 910.0, memory_length 2000, epsilon 0.085828419467407, time 731.0, rides 135\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 2727, reward 663.0, memory_length 2000, epsilon 0.08575117388988633, time 729.0, rides 125\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 2728, reward 918.0, memory_length 2000, epsilon 0.08567399783338543, time 726.0, rides 124\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 2729, reward 676.0, memory_length 2000, epsilon 0.08559689123533538, time 726.0, rides 128\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 2730, reward 788.0, memory_length 2000, epsilon 0.08551985403322358, time 731.0, rides 121\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2731, reward 773.0, memory_length 2000, epsilon 0.08544288616459368, time 723.0, rides 152\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2732, reward 915.0, memory_length 2000, epsilon 0.08536598756704554, time 726.0, rides 124\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 2733, reward 804.0, memory_length 2000, epsilon 0.0852891581782352, time 729.0, rides 121\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2734, reward 487.0, memory_length 2000, epsilon 0.08521239793587478, time 727.0, rides 125\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 2735, reward 822.0, memory_length 2000, epsilon 0.08513570677773248, time 723.0, rides 130\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 2736, reward 677.0, memory_length 2000, epsilon 0.08505908464163252, time 723.0, rides 139\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 2737, reward 778.0, memory_length 2000, epsilon 0.08498253146545505, time 730.0, rides 115\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2738, reward 923.0, memory_length 2000, epsilon 0.08490604718713614, time 732.0, rides 126\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2739, reward 1066.0, memory_length 2000, epsilon 0.08482963174466772, time 733.0, rides 127\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2740, reward 389.0, memory_length 2000, epsilon 0.08475328507609751, time 726.0, rides 124\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 2741, reward 628.0, memory_length 2000, epsilon 0.08467700711952902, time 724.0, rides 129\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 2742, reward 870.0, memory_length 2000, epsilon 0.08460079781312145, time 735.0, rides 128\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 2743, reward 944.0, memory_length 2000, epsilon 0.08452465709508963, time 732.0, rides 130\n",
      "Initial State is  [3, 19, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2744, reward 931.0, memory_length 2000, epsilon 0.08444858490370405, time 732.0, rides 137\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2745, reward 1081.0, memory_length 2000, epsilon 0.08437258117729071, time 727.0, rides 120\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2746, reward 1072.0, memory_length 2000, epsilon 0.08429664585423115, time 733.0, rides 138\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 2747, reward 488.0, memory_length 2000, epsilon 0.08422077887296234, time 730.0, rides 145\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2748, reward 885.0, memory_length 2000, epsilon 0.08414498017197668, time 724.0, rides 146\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2749, reward 769.0, memory_length 2000, epsilon 0.08406924968982189, time 738.0, rides 146\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2750, reward 571.0, memory_length 2000, epsilon 0.08399358736510106, time 731.0, rides 134\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 2751, reward 1012.0, memory_length 2000, epsilon 0.08391799313647247, time 731.0, rides 128\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2752, reward 759.0, memory_length 2000, epsilon 0.08384246694264964, time 727.0, rides 135\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 2753, reward 980.0, memory_length 2000, epsilon 0.08376700872240125, time 721.0, rides 132\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 2754, reward 1040.0, memory_length 2000, epsilon 0.0836916184145511, time 735.0, rides 139\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2755, reward 940.0, memory_length 2000, epsilon 0.083616295957978, time 725.0, rides 141\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2756, reward 880.0, memory_length 2000, epsilon 0.08354104129161581, time 723.0, rides 135\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 2757, reward 950.0, memory_length 2000, epsilon 0.08346585435445336, time 729.0, rides 135\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 2758, reward 1101.0, memory_length 2000, epsilon 0.08339073508553435, time 726.0, rides 124\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 2759, reward 786.0, memory_length 2000, epsilon 0.08331568342395737, time 734.0, rides 132\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2760, reward 933.0, memory_length 2000, epsilon 0.0832406993088758, time 727.0, rides 138\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 2761, reward 888.0, memory_length 2000, epsilon 0.08316578267949781, time 736.0, rides 135\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 2762, reward 782.0, memory_length 2000, epsilon 0.08309093347508627, time 726.0, rides 118\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2763, reward 771.0, memory_length 2000, epsilon 0.0830161516349587, time 727.0, rides 136\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 2764, reward 1051.0, memory_length 2000, epsilon 0.08294143709848723, time 729.0, rides 131\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 2765, reward 859.0, memory_length 2000, epsilon 0.08286678980509858, time 733.0, rides 134\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 2766, reward 941.0, memory_length 2000, epsilon 0.08279220969427399, time 732.0, rides 124\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 2767, reward 919.0, memory_length 2000, epsilon 0.08271769670554914, time 729.0, rides 147\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 2768, reward 780.0, memory_length 2000, epsilon 0.08264325077851414, time 722.0, rides 127\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 2769, reward 697.0, memory_length 2000, epsilon 0.08256887185281347, time 731.0, rides 126\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 2770, reward 1019.0, memory_length 2000, epsilon 0.08249455986814594, time 730.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 2771, reward 709.0, memory_length 2000, epsilon 0.0824203147642646, time 733.0, rides 123\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 2772, reward 804.0, memory_length 2000, epsilon 0.08234613648097676, time 728.0, rides 158\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 2773, reward 748.0, memory_length 2000, epsilon 0.08227202495814388, time 730.0, rides 119\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 2774, reward 576.0, memory_length 2000, epsilon 0.08219798013568155, time 729.0, rides 139\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 2775, reward 899.0, memory_length 2000, epsilon 0.08212400195355944, time 733.0, rides 142\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2776, reward 1040.0, memory_length 2000, epsilon 0.08205009035180123, time 723.0, rides 132\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 2777, reward 839.0, memory_length 2000, epsilon 0.08197624527048461, time 724.0, rides 135\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 2778, reward 793.0, memory_length 2000, epsilon 0.08190246664974117, time 727.0, rides 131\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 2779, reward 634.0, memory_length 2000, epsilon 0.0818287544297564, time 724.0, rides 122\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 2780, reward 891.0, memory_length 2000, epsilon 0.08175510855076962, time 720.0, rides 128\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 2781, reward 807.0, memory_length 2000, epsilon 0.08168152895307393, time 728.0, rides 134\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2782, reward 865.0, memory_length 2000, epsilon 0.08160801557701616, time 731.0, rides 124\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2783, reward 846.0, memory_length 2000, epsilon 0.08153456836299684, time 725.0, rides 130\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 2784, reward 1027.0, memory_length 2000, epsilon 0.08146118725147014, time 726.0, rides 143\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2785, reward 1128.0, memory_length 2000, epsilon 0.08138787218294381, time 727.0, rides 151\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 2786, reward 844.0, memory_length 2000, epsilon 0.08131462309797917, time 730.0, rides 136\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2787, reward 780.0, memory_length 2000, epsilon 0.08124143993719099, time 725.0, rides 131\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 2788, reward 1043.0, memory_length 2000, epsilon 0.08116832264124751, time 726.0, rides 126\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 2789, reward 826.0, memory_length 2000, epsilon 0.0810952711508704, time 729.0, rides 142\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 2790, reward 688.0, memory_length 2000, epsilon 0.08102228540683461, time 726.0, rides 142\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 2791, reward 586.0, memory_length 2000, epsilon 0.08094936534996845, time 725.0, rides 122\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 2792, reward 874.0, memory_length 2000, epsilon 0.08087651092115349, time 737.0, rides 126\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2793, reward 1008.0, memory_length 2000, epsilon 0.08080372206132444, time 733.0, rides 146\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 2794, reward 923.0, memory_length 2000, epsilon 0.08073099871146924, time 728.0, rides 136\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2795, reward 664.0, memory_length 2000, epsilon 0.08065834081262892, time 728.0, rides 127\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2796, reward 1005.0, memory_length 2000, epsilon 0.08058574830589756, time 730.0, rides 138\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 2797, reward 906.0, memory_length 2000, epsilon 0.08051322113242225, time 726.0, rides 145\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 2798, reward 531.0, memory_length 2000, epsilon 0.08044075923340308, time 734.0, rides 138\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 2799, reward 809.0, memory_length 2000, epsilon 0.08036836255009301, time 735.0, rides 130\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 2800, reward 979.0, memory_length 2000, epsilon 0.08029603102379793, time 733.0, rides 143\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 2801, reward 489.0, memory_length 2000, epsilon 0.0802237645958765, time 723.0, rides 139\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 2802, reward 889.0, memory_length 2000, epsilon 0.08015156320774021, time 730.0, rides 139\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 2803, reward 818.0, memory_length 2000, epsilon 0.08007942680085324, time 729.0, rides 147\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 2804, reward 762.0, memory_length 2000, epsilon 0.08000735531673248, time 733.0, rides 131\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2805, reward 1104.0, memory_length 2000, epsilon 0.07993534869694742, time 728.0, rides 137\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 2806, reward 510.0, memory_length 2000, epsilon 0.07986340688312017, time 727.0, rides 136\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 2807, reward 706.0, memory_length 2000, epsilon 0.07979152981692536, time 735.0, rides 141\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 2808, reward 714.0, memory_length 2000, epsilon 0.07971971744009013, time 727.0, rides 130\n",
      "Initial State is  [3, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2809, reward 640.0, memory_length 2000, epsilon 0.07964796969439404, time 727.0, rides 146\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 2810, reward 856.0, memory_length 2000, epsilon 0.07957628652166908, time 724.0, rides 132\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2811, reward 728.0, memory_length 2000, epsilon 0.07950466786379957, time 726.0, rides 140\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2812, reward 632.0, memory_length 2000, epsilon 0.07943311366272215, time 731.0, rides 134\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 2813, reward 1015.0, memory_length 2000, epsilon 0.07936162386042571, time 728.0, rides 142\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 2814, reward 1086.0, memory_length 2000, epsilon 0.07929019839895132, time 731.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 2815, reward 543.0, memory_length 2000, epsilon 0.07921883722039226, time 731.0, rides 132\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2816, reward 898.0, memory_length 2000, epsilon 0.07914754026689391, time 728.0, rides 128\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2817, reward 891.0, memory_length 2000, epsilon 0.07907630748065371, time 731.0, rides 127\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 2818, reward 1011.0, memory_length 2000, epsilon 0.07900513880392113, time 728.0, rides 129\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 2819, reward 554.0, memory_length 2000, epsilon 0.0789340341789976, time 721.0, rides 129\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2820, reward 795.0, memory_length 2000, epsilon 0.07886299354823649, time 731.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 2821, reward 1067.0, memory_length 2000, epsilon 0.07879201685404308, time 730.0, rides 140\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 2822, reward 745.0, memory_length 2000, epsilon 0.07872110403887445, time 728.0, rides 126\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 2823, reward 925.0, memory_length 2000, epsilon 0.07865025504523945, time 726.0, rides 123\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 2824, reward 748.0, memory_length 2000, epsilon 0.07857946981569874, time 727.0, rides 134\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 2825, reward 919.0, memory_length 2000, epsilon 0.07850874829286461, time 742.0, rides 141\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 2826, reward 975.0, memory_length 2000, epsilon 0.07843809041940103, time 726.0, rides 151\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 2827, reward 854.0, memory_length 2000, epsilon 0.07836749613802357, time 731.0, rides 126\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2828, reward 964.0, memory_length 2000, epsilon 0.07829696539149936, time 731.0, rides 127\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 2829, reward 761.0, memory_length 2000, epsilon 0.07822649812264701, time 729.0, rides 137\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 2830, reward 812.0, memory_length 2000, epsilon 0.07815609427433663, time 722.0, rides 143\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 2831, reward 718.0, memory_length 2000, epsilon 0.07808575378948973, time 724.0, rides 138\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 2832, reward 734.0, memory_length 2000, epsilon 0.07801547661107919, time 737.0, rides 134\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2833, reward 600.0, memory_length 2000, epsilon 0.07794526268212922, time 737.0, rides 118\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 2834, reward 714.0, memory_length 2000, epsilon 0.0778751119457153, time 732.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2835, reward 713.0, memory_length 2000, epsilon 0.07780502434496415, time 727.0, rides 147\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 2836, reward 1112.0, memory_length 2000, epsilon 0.07773499982305368, time 726.0, rides 136\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 2837, reward 716.0, memory_length 2000, epsilon 0.07766503832321293, time 722.0, rides 137\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2838, reward 899.0, memory_length 2000, epsilon 0.07759513978872204, time 724.0, rides 147\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 2839, reward 1104.0, memory_length 2000, epsilon 0.07752530416291219, time 731.0, rides 136\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 2840, reward 724.0, memory_length 2000, epsilon 0.07745553138916557, time 724.0, rides 134\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2841, reward 833.0, memory_length 2000, epsilon 0.07738582141091532, time 727.0, rides 140\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 2842, reward 1065.0, memory_length 2000, epsilon 0.0773161741716455, time 736.0, rides 141\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 2843, reward 1144.0, memory_length 2000, epsilon 0.07724658961489102, time 742.0, rides 131\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 2844, reward 575.0, memory_length 2000, epsilon 0.07717706768423761, time 735.0, rides 142\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 2845, reward 945.0, memory_length 2000, epsilon 0.0771076083233218, time 747.0, rides 143\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2846, reward 618.0, memory_length 2000, epsilon 0.0770382114758308, time 731.0, rides 118\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 2847, reward 695.0, memory_length 2000, epsilon 0.07696887708550255, time 725.0, rides 137\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 2848, reward 1082.0, memory_length 2000, epsilon 0.0768996050961256, time 733.0, rides 148\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 2849, reward 763.0, memory_length 2000, epsilon 0.0768303954515391, time 730.0, rides 135\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 2850, reward 814.0, memory_length 2000, epsilon 0.07676124809563271, time 728.0, rides 142\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2851, reward 1058.0, memory_length 2000, epsilon 0.07669216297234664, time 732.0, rides 137\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 2852, reward 959.0, memory_length 2000, epsilon 0.07662314002567153, time 745.0, rides 133\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 2853, reward 881.0, memory_length 2000, epsilon 0.07655417919964842, time 722.0, rides 127\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 2854, reward 877.0, memory_length 2000, epsilon 0.07648528043836873, time 728.0, rides 125\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 2855, reward 828.0, memory_length 2000, epsilon 0.0764164436859742, time 728.0, rides 134\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 2856, reward 933.0, memory_length 2000, epsilon 0.07634766888665681, time 730.0, rides 135\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 2857, reward 918.0, memory_length 2000, epsilon 0.07627895598465882, time 737.0, rides 142\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 2858, reward 847.0, memory_length 2000, epsilon 0.07621030492427262, time 741.0, rides 148\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2859, reward 997.0, memory_length 2000, epsilon 0.07614171564984078, time 726.0, rides 138\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 2860, reward 1044.0, memory_length 2000, epsilon 0.07607318810575592, time 729.0, rides 135\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2861, reward 1082.0, memory_length 2000, epsilon 0.07600472223646074, time 725.0, rides 127\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 2862, reward 746.0, memory_length 2000, epsilon 0.07593631798644793, time 727.0, rides 125\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 2863, reward 880.0, memory_length 2000, epsilon 0.07586797530026013, time 725.0, rides 132\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 2864, reward 679.0, memory_length 2000, epsilon 0.0757996941224899, time 723.0, rides 126\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 2865, reward 1049.0, memory_length 2000, epsilon 0.07573147439777965, time 729.0, rides 129\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 2866, reward 763.0, memory_length 2000, epsilon 0.07566331607082165, time 728.0, rides 142\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 2867, reward 1160.0, memory_length 2000, epsilon 0.07559521908635791, time 734.0, rides 140\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 2868, reward 936.0, memory_length 2000, epsilon 0.07552718338918019, time 729.0, rides 128\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 2869, reward 1169.0, memory_length 2000, epsilon 0.07545920892412993, time 730.0, rides 144\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 2870, reward 897.0, memory_length 2000, epsilon 0.07539129563609821, time 730.0, rides 142\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2871, reward 831.0, memory_length 2000, epsilon 0.07532344347002572, time 724.0, rides 143\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 2872, reward 743.0, memory_length 2000, epsilon 0.07525565237090269, time 745.0, rides 133\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 2873, reward 979.0, memory_length 2000, epsilon 0.07518792228376887, time 731.0, rides 133\n",
      "Initial State is  [1, 13, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2874, reward 1056.0, memory_length 2000, epsilon 0.07512025315371348, time 734.0, rides 137\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 2875, reward 820.0, memory_length 2000, epsilon 0.07505264492587514, time 730.0, rides 123\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 2876, reward 941.0, memory_length 2000, epsilon 0.07498509754544186, time 721.0, rides 135\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 2877, reward 768.0, memory_length 2000, epsilon 0.07491761095765095, time 744.0, rides 140\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 2878, reward 1042.0, memory_length 2000, epsilon 0.07485018510778907, time 721.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 2879, reward 821.0, memory_length 2000, epsilon 0.07478281994119206, time 725.0, rides 138\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 2880, reward 901.0, memory_length 2000, epsilon 0.07471551540324498, time 730.0, rides 124\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 2881, reward 743.0, memory_length 2000, epsilon 0.07464827143938206, time 730.0, rides 128\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2882, reward 1372.0, memory_length 2000, epsilon 0.07458108799508661, time 721.0, rides 144\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 2883, reward 666.0, memory_length 2000, epsilon 0.07451396501589104, time 731.0, rides 147\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 2884, reward 704.0, memory_length 2000, epsilon 0.07444690244737674, time 734.0, rides 142\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 2885, reward 922.0, memory_length 2000, epsilon 0.0743799002351741, time 728.0, rides 142\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 2886, reward 655.0, memory_length 2000, epsilon 0.07431295832496244, time 724.0, rides 129\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 2887, reward 680.0, memory_length 2000, epsilon 0.07424607666246998, time 726.0, rides 128\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2888, reward 898.0, memory_length 2000, epsilon 0.07417925519347375, time 731.0, rides 133\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 2889, reward 885.0, memory_length 2000, epsilon 0.07411249386379962, time 731.0, rides 142\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 2890, reward 800.0, memory_length 2000, epsilon 0.07404579261932219, time 729.0, rides 147\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2891, reward 966.0, memory_length 2000, epsilon 0.0739791514059648, time 729.0, rides 154\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 2892, reward 1018.0, memory_length 2000, epsilon 0.07391257016969943, time 727.0, rides 123\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2893, reward 914.0, memory_length 2000, epsilon 0.0738460488565467, time 731.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 2894, reward 848.0, memory_length 2000, epsilon 0.07377958741257581, time 724.0, rides 121\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 2895, reward 769.0, memory_length 2000, epsilon 0.0737131857839045, time 727.0, rides 137\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2896, reward 1027.0, memory_length 2000, epsilon 0.07364684391669898, time 736.0, rides 141\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 2897, reward 893.0, memory_length 2000, epsilon 0.07358056175717395, time 736.0, rides 135\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2898, reward 767.0, memory_length 2000, epsilon 0.0735143392515925, time 728.0, rides 122\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 2899, reward 683.0, memory_length 2000, epsilon 0.07344817634626606, time 721.0, rides 128\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 2900, reward 921.0, memory_length 2000, epsilon 0.07338207298755442, time 728.0, rides 131\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 2901, reward 848.0, memory_length 2000, epsilon 0.07331602912186562, time 728.0, rides 135\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 2902, reward 696.0, memory_length 2000, epsilon 0.07325004469565594, time 727.0, rides 133\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2903, reward 772.0, memory_length 2000, epsilon 0.07318411965542984, time 727.0, rides 126\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2904, reward 849.0, memory_length 2000, epsilon 0.07311825394773995, time 730.0, rides 128\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2905, reward 708.0, memory_length 2000, epsilon 0.07305244751918698, time 722.0, rides 127\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 2906, reward 794.0, memory_length 2000, epsilon 0.07298670031641971, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 2907, reward 740.0, memory_length 2000, epsilon 0.07292101228613493, time 723.0, rides 130\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 2908, reward 932.0, memory_length 2000, epsilon 0.07285538337507741, time 725.0, rides 141\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 2909, reward 1104.0, memory_length 2000, epsilon 0.07278981353003984, time 729.0, rides 126\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 2910, reward 1014.0, memory_length 2000, epsilon 0.0727243026978628, time 735.0, rides 140\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 2911, reward 765.0, memory_length 2000, epsilon 0.07265885082543472, time 727.0, rides 129\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 2912, reward 1171.0, memory_length 2000, epsilon 0.07259345785969183, time 723.0, rides 121\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 2913, reward 690.0, memory_length 2000, epsilon 0.0725281237476181, time 733.0, rides 126\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 2914, reward 894.0, memory_length 2000, epsilon 0.07246284843624524, time 720.0, rides 123\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 2915, reward 732.0, memory_length 2000, epsilon 0.07239763187265262, time 728.0, rides 130\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 2916, reward 881.0, memory_length 2000, epsilon 0.07233247400396724, time 726.0, rides 128\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 2917, reward 1097.0, memory_length 2000, epsilon 0.07226737477736367, time 726.0, rides 132\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 2918, reward 527.0, memory_length 2000, epsilon 0.07220233414006404, time 732.0, rides 134\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2919, reward 795.0, memory_length 2000, epsilon 0.07213735203933798, time 726.0, rides 125\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2920, reward 1100.0, memory_length 2000, epsilon 0.07207242842250257, time 725.0, rides 129\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 2921, reward 752.0, memory_length 2000, epsilon 0.07200756323692231, time 725.0, rides 132\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2922, reward 954.0, memory_length 2000, epsilon 0.07194275643000908, time 725.0, rides 133\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2923, reward 992.0, memory_length 2000, epsilon 0.07187800794922207, time 735.0, rides 137\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 2924, reward 949.0, memory_length 2000, epsilon 0.07181331774206777, time 736.0, rides 123\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 2925, reward 947.0, memory_length 2000, epsilon 0.07174868575609991, time 726.0, rides 122\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2926, reward 889.0, memory_length 2000, epsilon 0.07168411193891942, time 727.0, rides 126\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 2927, reward 707.0, memory_length 2000, epsilon 0.07161959623817439, time 722.0, rides 125\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 2928, reward 977.0, memory_length 2000, epsilon 0.07155513860156003, time 727.0, rides 141\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 2929, reward 1006.0, memory_length 2000, epsilon 0.07149073897681862, time 728.0, rides 135\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 2930, reward 646.0, memory_length 2000, epsilon 0.07142639731173948, time 730.0, rides 128\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2931, reward 1004.0, memory_length 2000, epsilon 0.07136211355415892, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 2932, reward 910.0, memory_length 2000, epsilon 0.07129788765196017, time 731.0, rides 139\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2933, reward 624.0, memory_length 2000, epsilon 0.07123371955307341, time 730.0, rides 135\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 2934, reward 762.0, memory_length 2000, epsilon 0.07116960920547565, time 728.0, rides 140\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2935, reward 1041.0, memory_length 2000, epsilon 0.07110555655719071, time 726.0, rides 130\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 2936, reward 564.0, memory_length 2000, epsilon 0.07104156155628924, time 720.0, rides 132\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 2937, reward 797.0, memory_length 2000, epsilon 0.07097762415088858, time 730.0, rides 131\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 2938, reward 830.0, memory_length 2000, epsilon 0.07091374428915279, time 730.0, rides 125\n",
      "Initial State is  [1, 17, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2939, reward 872.0, memory_length 2000, epsilon 0.07084992191929254, time 731.0, rides 130\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 2940, reward 725.0, memory_length 2000, epsilon 0.07078615698956518, time 722.0, rides 123\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2941, reward 725.0, memory_length 2000, epsilon 0.07072244944827458, time 729.0, rides 122\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 2942, reward 499.0, memory_length 2000, epsilon 0.07065879924377112, time 734.0, rides 135\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 2943, reward 672.0, memory_length 2000, epsilon 0.07059520632445172, time 734.0, rides 139\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2944, reward 856.0, memory_length 2000, epsilon 0.07053167063875972, time 728.0, rides 125\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 2945, reward 852.0, memory_length 2000, epsilon 0.07046819213518483, time 736.0, rides 136\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2946, reward 645.0, memory_length 2000, epsilon 0.07040477076226316, time 733.0, rides 130\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2947, reward 943.0, memory_length 2000, epsilon 0.07034140646857712, time 723.0, rides 138\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 2948, reward 745.0, memory_length 2000, epsilon 0.07027809920275539, time 726.0, rides 131\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 2949, reward 660.0, memory_length 2000, epsilon 0.07021484891347292, time 731.0, rides 116\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 2950, reward 839.0, memory_length 2000, epsilon 0.0701516555494508, time 733.0, rides 133\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 2951, reward 699.0, memory_length 2000, epsilon 0.07008851905945629, time 728.0, rides 142\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 2952, reward 449.0, memory_length 2000, epsilon 0.07002543939230278, time 734.0, rides 133\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 2953, reward 1018.0, memory_length 2000, epsilon 0.06996241649684971, time 736.0, rides 132\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 2954, reward 839.0, memory_length 2000, epsilon 0.06989945032200255, time 721.0, rides 122\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2955, reward 1057.0, memory_length 2000, epsilon 0.06983654081671274, time 728.0, rides 128\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 2956, reward 1122.0, memory_length 2000, epsilon 0.06977368792997769, time 730.0, rides 126\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 2957, reward 941.0, memory_length 2000, epsilon 0.06971089161084071, time 731.0, rides 123\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 2958, reward 674.0, memory_length 2000, epsilon 0.06964815180839096, time 729.0, rides 140\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2959, reward 894.0, memory_length 2000, epsilon 0.0695854684717634, time 731.0, rides 133\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 2960, reward 1054.0, memory_length 2000, epsilon 0.06952284155013881, time 725.0, rides 129\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 2961, reward 903.0, memory_length 2000, epsilon 0.06946027099274368, time 729.0, rides 126\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 2962, reward 858.0, memory_length 2000, epsilon 0.06939775674885021, time 738.0, rides 138\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 2963, reward 1261.0, memory_length 2000, epsilon 0.06933529876777625, time 734.0, rides 138\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 2964, reward 991.0, memory_length 2000, epsilon 0.06927289699888525, time 724.0, rides 132\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2965, reward 1123.0, memory_length 2000, epsilon 0.06921055139158626, time 732.0, rides 133\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 2966, reward 939.0, memory_length 2000, epsilon 0.06914826189533382, time 726.0, rides 127\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 2967, reward 1064.0, memory_length 2000, epsilon 0.06908602845962802, time 724.0, rides 135\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2968, reward 859.0, memory_length 2000, epsilon 0.06902385103401436, time 727.0, rides 141\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2969, reward 667.0, memory_length 2000, epsilon 0.06896172956808375, time 725.0, rides 121\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2970, reward 914.0, memory_length 2000, epsilon 0.06889966401147248, time 732.0, rides 128\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2971, reward 1077.0, memory_length 2000, epsilon 0.06883765431386214, time 730.0, rides 148\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2972, reward 840.0, memory_length 2000, epsilon 0.06877570042497967, time 728.0, rides 133\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 2973, reward 818.0, memory_length 2000, epsilon 0.06871380229459718, time 724.0, rides 131\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 2974, reward 610.0, memory_length 2000, epsilon 0.06865195987253205, time 732.0, rides 119\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2975, reward 922.0, memory_length 2000, epsilon 0.06859017310864676, time 730.0, rides 126\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 2976, reward 1000.0, memory_length 2000, epsilon 0.06852844195284898, time 727.0, rides 133\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 2977, reward 848.0, memory_length 2000, epsilon 0.06846676635509141, time 722.0, rides 126\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 2978, reward 819.0, memory_length 2000, epsilon 0.06840514626537184, time 736.0, rides 126\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 2979, reward 709.0, memory_length 2000, epsilon 0.068343581633733, time 728.0, rides 114\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2980, reward 1019.0, memory_length 2000, epsilon 0.06828207241026264, time 734.0, rides 121\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 2981, reward 1114.0, memory_length 2000, epsilon 0.06822061854509341, time 728.0, rides 129\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 2982, reward 759.0, memory_length 2000, epsilon 0.06815921998840282, time 725.0, rides 110\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 2983, reward 809.0, memory_length 2000, epsilon 0.06809787669041326, time 724.0, rides 120\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2984, reward 770.0, memory_length 2000, epsilon 0.06803658860139189, time 725.0, rides 137\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 2985, reward 614.0, memory_length 2000, epsilon 0.06797535567165064, time 726.0, rides 134\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2986, reward 963.0, memory_length 2000, epsilon 0.06791417785154616, time 728.0, rides 124\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2987, reward 1037.0, memory_length 2000, epsilon 0.06785305509147976, time 727.0, rides 134\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 2988, reward 830.0, memory_length 2000, epsilon 0.06779198734189743, time 725.0, rides 128\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 2989, reward 870.0, memory_length 2000, epsilon 0.06773097455328972, time 723.0, rides 127\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2990, reward 878.0, memory_length 2000, epsilon 0.06767001667619175, time 730.0, rides 136\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 2991, reward 708.0, memory_length 2000, epsilon 0.06760911366118318, time 731.0, rides 140\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 2992, reward 761.0, memory_length 2000, epsilon 0.0675482654588881, time 720.0, rides 135\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 2993, reward 932.0, memory_length 2000, epsilon 0.0674874720199751, time 724.0, rides 112\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2994, reward 786.0, memory_length 2000, epsilon 0.06742673329515712, time 727.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 2995, reward 876.0, memory_length 2000, epsilon 0.06736604923519147, time 731.0, rides 132\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 2996, reward 796.0, memory_length 2000, epsilon 0.0673054197908798, time 730.0, rides 154\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 2997, reward 434.0, memory_length 2000, epsilon 0.06724484491306801, time 724.0, rides 141\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 2998, reward 643.0, memory_length 2000, epsilon 0.06718432455264625, time 732.0, rides 131\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 2999, reward 1031.0, memory_length 2000, epsilon 0.06712385866054887, time 745.0, rides 129\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3000, reward 974.0, memory_length 2000, epsilon 0.06706344718775438, time 732.0, rides 127\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 3001, reward 798.0, memory_length 2000, epsilon 0.0670030900852854, time 728.0, rides 122\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 3002, reward 781.0, memory_length 2000, epsilon 0.06694278730420865, time 723.0, rides 121\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 3003, reward 1187.0, memory_length 2000, epsilon 0.06688253879563485, time 729.0, rides 125\n",
      "Initial State is  [2, 9, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3004, reward 730.0, memory_length 2000, epsilon 0.06682234451071878, time 728.0, rides 133\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 3005, reward 817.0, memory_length 2000, epsilon 0.06676220440065914, time 728.0, rides 127\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 3006, reward 906.0, memory_length 2000, epsilon 0.06670211841669854, time 728.0, rides 141\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3007, reward 999.0, memory_length 2000, epsilon 0.06664208651012352, time 727.0, rides 130\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 3008, reward 751.0, memory_length 2000, epsilon 0.06658210863226441, time 730.0, rides 124\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 3009, reward 788.0, memory_length 2000, epsilon 0.06652218473449537, time 731.0, rides 143\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 3010, reward 844.0, memory_length 2000, epsilon 0.06646231476823432, time 722.0, rides 120\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 3011, reward 775.0, memory_length 2000, epsilon 0.06640249868494291, time 727.0, rides 126\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3012, reward 813.0, memory_length 2000, epsilon 0.06634273643612647, time 732.0, rides 126\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 3013, reward 867.0, memory_length 2000, epsilon 0.06628302797333395, time 728.0, rides 129\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 3014, reward 821.0, memory_length 2000, epsilon 0.06622337324815795, time 723.0, rides 128\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3015, reward 934.0, memory_length 2000, epsilon 0.06616377221223461, time 728.0, rides 137\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 3016, reward 904.0, memory_length 2000, epsilon 0.06610422481724361, time 734.0, rides 131\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 3017, reward 969.0, memory_length 2000, epsilon 0.06604473101490808, time 725.0, rides 143\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3018, reward 781.0, memory_length 2000, epsilon 0.06598529075699466, time 726.0, rides 128\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 3019, reward 647.0, memory_length 2000, epsilon 0.06592590399531337, time 729.0, rides 136\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3020, reward 839.0, memory_length 2000, epsilon 0.06586657068171758, time 726.0, rides 127\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 3021, reward 1085.0, memory_length 2000, epsilon 0.06580729076810404, time 733.0, rides 133\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3022, reward 1170.0, memory_length 2000, epsilon 0.06574806420641274, time 728.0, rides 133\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 3023, reward 1176.0, memory_length 2000, epsilon 0.06568889094862697, time 731.0, rides 140\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 3024, reward 645.0, memory_length 2000, epsilon 0.0656297709467732, time 728.0, rides 131\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 3025, reward 727.0, memory_length 2000, epsilon 0.06557070415292111, time 728.0, rides 133\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 3026, reward 914.0, memory_length 2000, epsilon 0.06551169051918349, time 728.0, rides 124\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 3027, reward 698.0, memory_length 2000, epsilon 0.06545272999771622, time 729.0, rides 129\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 3028, reward 1213.0, memory_length 2000, epsilon 0.06539382254071827, time 725.0, rides 133\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 3029, reward 817.0, memory_length 2000, epsilon 0.06533496810043161, time 724.0, rides 131\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 3030, reward 648.0, memory_length 2000, epsilon 0.06527616662914122, time 730.0, rides 137\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 3031, reward 776.0, memory_length 2000, epsilon 0.065217418079175, time 724.0, rides 142\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 3032, reward 1100.0, memory_length 2000, epsilon 0.06515872240290374, time 731.0, rides 125\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3033, reward 1300.0, memory_length 2000, epsilon 0.06510007955274112, time 732.0, rides 127\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 3034, reward 1035.0, memory_length 2000, epsilon 0.06504148948114366, time 725.0, rides 143\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3035, reward 1241.0, memory_length 2000, epsilon 0.06498295214061063, time 729.0, rides 144\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 3036, reward 850.0, memory_length 2000, epsilon 0.06492446748368408, time 733.0, rides 139\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 3037, reward 657.0, memory_length 2000, epsilon 0.06486603546294877, time 732.0, rides 130\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 3038, reward 800.0, memory_length 2000, epsilon 0.06480765603103211, time 731.0, rides 128\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 3039, reward 897.0, memory_length 2000, epsilon 0.06474932914060419, time 729.0, rides 142\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 3040, reward 856.0, memory_length 2000, epsilon 0.06469105474437764, time 727.0, rides 124\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 3041, reward 834.0, memory_length 2000, epsilon 0.0646328327951077, time 729.0, rides 124\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 3042, reward 814.0, memory_length 2000, epsilon 0.0645746632455921, time 732.0, rides 125\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 3043, reward 740.0, memory_length 2000, epsilon 0.06451654604867108, time 721.0, rides 130\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3044, reward 622.0, memory_length 2000, epsilon 0.06445848115722727, time 729.0, rides 130\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 3045, reward 707.0, memory_length 2000, epsilon 0.06440046852418577, time 731.0, rides 131\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 3046, reward 867.0, memory_length 2000, epsilon 0.064342508102514, time 720.0, rides 136\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3047, reward 740.0, memory_length 2000, epsilon 0.06428459984522174, time 727.0, rides 130\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 3048, reward 1040.0, memory_length 2000, epsilon 0.06422674370536104, time 727.0, rides 121\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 3049, reward 1042.0, memory_length 2000, epsilon 0.06416893963602621, time 726.0, rides 135\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 3050, reward 617.0, memory_length 2000, epsilon 0.0641111875903538, time 726.0, rides 133\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3051, reward 741.0, memory_length 2000, epsilon 0.06405348752152247, time 726.0, rides 142\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 3052, reward 750.0, memory_length 2000, epsilon 0.0639958393827531, time 730.0, rides 142\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3053, reward 892.0, memory_length 2000, epsilon 0.06393824312730863, time 732.0, rides 143\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3054, reward 555.0, memory_length 2000, epsilon 0.06388069870849405, time 731.0, rides 127\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 3055, reward 807.0, memory_length 2000, epsilon 0.06382320607965641, time 727.0, rides 125\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 3056, reward 898.0, memory_length 2000, epsilon 0.06376576519418473, time 733.0, rides 145\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 3057, reward 866.0, memory_length 2000, epsilon 0.06370837600550996, time 722.0, rides 121\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 3058, reward 1014.0, memory_length 2000, epsilon 0.063651038467105, time 732.0, rides 124\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 3059, reward 942.0, memory_length 2000, epsilon 0.0635937525324846, time 726.0, rides 130\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 3060, reward 894.0, memory_length 2000, epsilon 0.06353651815520536, time 735.0, rides 128\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3061, reward 1067.0, memory_length 2000, epsilon 0.06347933528886568, time 730.0, rides 124\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3062, reward 645.0, memory_length 2000, epsilon 0.0634222038871057, time 726.0, rides 139\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3063, reward 824.0, memory_length 2000, epsilon 0.06336512390360731, time 732.0, rides 135\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 3064, reward 913.0, memory_length 2000, epsilon 0.06330809529209407, time 723.0, rides 140\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 3065, reward 1017.0, memory_length 2000, epsilon 0.06325111800633118, time 721.0, rides 130\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3066, reward 676.0, memory_length 2000, epsilon 0.06319419200012548, time 728.0, rides 122\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 3067, reward 1069.0, memory_length 2000, epsilon 0.06313731722732537, time 740.0, rides 140\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 3068, reward 800.0, memory_length 2000, epsilon 0.06308049364182078, time 734.0, rides 124\n",
      "Initial State is  [3, 15, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3069, reward 1026.0, memory_length 2000, epsilon 0.06302372119754314, time 726.0, rides 128\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 3070, reward 877.0, memory_length 2000, epsilon 0.06296699984846535, time 731.0, rides 131\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 3071, reward 784.0, memory_length 2000, epsilon 0.06291032954860173, time 733.0, rides 122\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3072, reward 798.0, memory_length 2000, epsilon 0.06285371025200799, time 726.0, rides 129\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 3073, reward 882.0, memory_length 2000, epsilon 0.06279714191278118, time 726.0, rides 129\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 3074, reward 716.0, memory_length 2000, epsilon 0.06274062448505968, time 725.0, rides 135\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3075, reward 874.0, memory_length 2000, epsilon 0.06268415792302312, time 730.0, rides 141\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3076, reward 929.0, memory_length 2000, epsilon 0.0626277421808924, time 736.0, rides 139\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 3077, reward 968.0, memory_length 2000, epsilon 0.06257137721292959, time 735.0, rides 113\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 3078, reward 846.0, memory_length 2000, epsilon 0.06251506297343795, time 731.0, rides 120\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 3079, reward 995.0, memory_length 2000, epsilon 0.06245879941676186, time 729.0, rides 137\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 3080, reward 857.0, memory_length 2000, epsilon 0.06240258649728677, time 734.0, rides 113\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 3081, reward 766.0, memory_length 2000, epsilon 0.06234642416943921, time 725.0, rides 149\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3082, reward 917.0, memory_length 2000, epsilon 0.062290312387686717, time 728.0, rides 143\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 3083, reward 798.0, memory_length 2000, epsilon 0.0622342511065378, time 723.0, rides 132\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3084, reward 611.0, memory_length 2000, epsilon 0.06217824028054191, time 736.0, rides 124\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 3085, reward 904.0, memory_length 2000, epsilon 0.06212227986428942, time 723.0, rides 148\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3086, reward 609.0, memory_length 2000, epsilon 0.06206636981241156, time 732.0, rides 120\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 3087, reward 433.0, memory_length 2000, epsilon 0.06201051007958039, time 733.0, rides 125\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3088, reward 1159.0, memory_length 2000, epsilon 0.061954700620508764, time 736.0, rides 138\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 3089, reward 1161.0, memory_length 2000, epsilon 0.06189894138995031, time 731.0, rides 138\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 3090, reward 1079.0, memory_length 2000, epsilon 0.06184323234269935, time 731.0, rides 138\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 3091, reward 931.0, memory_length 2000, epsilon 0.061787573433590925, time 730.0, rides 129\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 3092, reward 868.0, memory_length 2000, epsilon 0.06173196461750069, time 732.0, rides 136\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3093, reward 868.0, memory_length 2000, epsilon 0.06167640584934494, time 735.0, rides 142\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 3094, reward 1097.0, memory_length 2000, epsilon 0.06162089708408053, time 728.0, rides 141\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3095, reward 672.0, memory_length 2000, epsilon 0.061565438276704854, time 723.0, rides 119\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3096, reward 1021.0, memory_length 2000, epsilon 0.06151002938225582, time 721.0, rides 133\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3097, reward 772.0, memory_length 2000, epsilon 0.061454670355811786, time 734.0, rides 118\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 3098, reward 941.0, memory_length 2000, epsilon 0.061399361152491554, time 723.0, rides 143\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 3099, reward 807.0, memory_length 2000, epsilon 0.06134410172745431, time 722.0, rides 134\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3100, reward 930.0, memory_length 2000, epsilon 0.0612888920358996, time 732.0, rides 132\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 3101, reward 990.0, memory_length 2000, epsilon 0.06123373203306729, time 730.0, rides 142\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 3102, reward 544.0, memory_length 2000, epsilon 0.06117862167423753, time 726.0, rides 154\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 3103, reward 784.0, memory_length 2000, epsilon 0.061123560914730715, time 728.0, rides 128\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 3104, reward 1060.0, memory_length 2000, epsilon 0.06106854970990746, time 723.0, rides 140\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 3105, reward 880.0, memory_length 2000, epsilon 0.06101358801516854, time 724.0, rides 121\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 3106, reward 683.0, memory_length 2000, epsilon 0.06095867578595489, time 724.0, rides 136\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 3107, reward 705.0, memory_length 2000, epsilon 0.06090381297774753, time 722.0, rides 141\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 3108, reward 1135.0, memory_length 2000, epsilon 0.06084899954606756, time 731.0, rides 133\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 3109, reward 974.0, memory_length 2000, epsilon 0.0607942354464761, time 725.0, rides 134\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3110, reward 1044.0, memory_length 2000, epsilon 0.06073952063457427, time 726.0, rides 131\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3111, reward 1185.0, memory_length 2000, epsilon 0.06068485506600316, time 732.0, rides 127\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 3112, reward 877.0, memory_length 2000, epsilon 0.06063023869644375, time 727.0, rides 131\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 3113, reward 812.0, memory_length 2000, epsilon 0.06057567148161695, time 732.0, rides 123\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 3114, reward 993.0, memory_length 2000, epsilon 0.0605211533772835, time 724.0, rides 125\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 3115, reward 789.0, memory_length 2000, epsilon 0.06046668433924394, time 726.0, rides 133\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3116, reward 573.0, memory_length 2000, epsilon 0.06041226432333862, time 736.0, rides 131\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3117, reward 919.0, memory_length 2000, epsilon 0.06035789328544761, time 728.0, rides 137\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 3118, reward 632.0, memory_length 2000, epsilon 0.06030357118149071, time 728.0, rides 124\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 3119, reward 1084.0, memory_length 2000, epsilon 0.06024929796742737, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 3120, reward 936.0, memory_length 2000, epsilon 0.06019507359925668, time 734.0, rides 123\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 3121, reward 940.0, memory_length 2000, epsilon 0.06014089803301735, time 729.0, rides 130\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 3122, reward 792.0, memory_length 2000, epsilon 0.06008677122478764, time 731.0, rides 119\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 3123, reward 899.0, memory_length 2000, epsilon 0.06003269313068533, time 727.0, rides 140\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 3124, reward 802.0, memory_length 2000, epsilon 0.05997866370686771, time 728.0, rides 120\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 3125, reward 1041.0, memory_length 2000, epsilon 0.05992468290953153, time 726.0, rides 126\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 3126, reward 1060.0, memory_length 2000, epsilon 0.059870750694912954, time 722.0, rides 132\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 3127, reward 871.0, memory_length 2000, epsilon 0.05981686701928753, time 726.0, rides 144\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3128, reward 754.0, memory_length 2000, epsilon 0.05976303183897017, time 727.0, rides 136\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 3129, reward 1218.0, memory_length 2000, epsilon 0.0597092451103151, time 738.0, rides 130\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3130, reward 964.0, memory_length 2000, epsilon 0.05965550678971582, time 723.0, rides 128\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3131, reward 996.0, memory_length 2000, epsilon 0.059601816833605076, time 729.0, rides 161\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 3132, reward 965.0, memory_length 2000, epsilon 0.05954817519845483, time 729.0, rides 126\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 3133, reward 932.0, memory_length 2000, epsilon 0.05949458184077622, time 727.0, rides 140\n",
      "Initial State is  [0, 9, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3134, reward 795.0, memory_length 2000, epsilon 0.05944103671711952, time 727.0, rides 129\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3135, reward 946.0, memory_length 2000, epsilon 0.059387539784074114, time 735.0, rides 132\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 3136, reward 669.0, memory_length 2000, epsilon 0.059334090998268446, time 732.0, rides 134\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 3137, reward 796.0, memory_length 2000, epsilon 0.059280690316370004, time 734.0, rides 134\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 3138, reward 640.0, memory_length 2000, epsilon 0.05922733769508527, time 728.0, rides 129\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 3139, reward 911.0, memory_length 2000, epsilon 0.05917403309115969, time 728.0, rides 128\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 3140, reward 979.0, memory_length 2000, epsilon 0.059120776461377644, time 730.0, rides 144\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 3141, reward 732.0, memory_length 2000, epsilon 0.059067567762562403, time 724.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 3142, reward 951.0, memory_length 2000, epsilon 0.059014406951576094, time 732.0, rides 127\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3143, reward 820.0, memory_length 2000, epsilon 0.05896129398531968, time 731.0, rides 129\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 3144, reward 694.0, memory_length 2000, epsilon 0.05890822882073289, time 728.0, rides 127\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3145, reward 782.0, memory_length 2000, epsilon 0.05885521141479423, time 726.0, rides 129\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 3146, reward 803.0, memory_length 2000, epsilon 0.058802241724520914, time 728.0, rides 129\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 3147, reward 1087.0, memory_length 2000, epsilon 0.058749319706968846, time 732.0, rides 123\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 3148, reward 537.0, memory_length 2000, epsilon 0.05869644531923257, time 729.0, rides 118\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 3149, reward 1109.0, memory_length 2000, epsilon 0.05864361851844526, time 736.0, rides 132\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 3150, reward 836.0, memory_length 2000, epsilon 0.05859083926177866, time 728.0, rides 115\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3151, reward 805.0, memory_length 2000, epsilon 0.05853810750644306, time 727.0, rides 129\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 3152, reward 992.0, memory_length 2000, epsilon 0.05848542320968726, time 731.0, rides 136\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3153, reward 762.0, memory_length 2000, epsilon 0.058432786328798544, time 728.0, rides 133\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 3154, reward 916.0, memory_length 2000, epsilon 0.058380196821102626, time 724.0, rides 133\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 3155, reward 999.0, memory_length 2000, epsilon 0.05832765464396363, time 741.0, rides 137\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3156, reward 972.0, memory_length 2000, epsilon 0.05827515975478406, time 723.0, rides 114\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 3157, reward 907.0, memory_length 2000, epsilon 0.05822271211100476, time 730.0, rides 131\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 3158, reward 882.0, memory_length 2000, epsilon 0.05817031167010485, time 729.0, rides 137\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 3159, reward 770.0, memory_length 2000, epsilon 0.05811795838960175, time 729.0, rides 137\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3160, reward 902.0, memory_length 2000, epsilon 0.05806565222705111, time 724.0, rides 145\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3161, reward 1165.0, memory_length 2000, epsilon 0.05801339314004676, time 735.0, rides 138\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 3162, reward 991.0, memory_length 2000, epsilon 0.05796118108622072, time 739.0, rides 120\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3163, reward 910.0, memory_length 2000, epsilon 0.057909016023243116, time 729.0, rides 141\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 3164, reward 972.0, memory_length 2000, epsilon 0.057856897908822195, time 726.0, rides 128\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3165, reward 837.0, memory_length 2000, epsilon 0.057804826700704255, time 732.0, rides 131\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 3166, reward 979.0, memory_length 2000, epsilon 0.05775280235667362, time 720.0, rides 131\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 3167, reward 645.0, memory_length 2000, epsilon 0.05770082483455261, time 739.0, rides 133\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 3168, reward 658.0, memory_length 2000, epsilon 0.057648894092201516, time 732.0, rides 132\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 3169, reward 367.0, memory_length 2000, epsilon 0.05759701008751853, time 732.0, rides 131\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 3170, reward 954.0, memory_length 2000, epsilon 0.05754517277843976, time 731.0, rides 145\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 3171, reward 801.0, memory_length 2000, epsilon 0.05749338212293917, time 726.0, rides 141\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3172, reward 667.0, memory_length 2000, epsilon 0.05744163807902852, time 729.0, rides 122\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 3173, reward 891.0, memory_length 2000, epsilon 0.0573899406047574, time 736.0, rides 134\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 3174, reward 587.0, memory_length 2000, epsilon 0.05733828965821312, time 724.0, rides 132\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 3175, reward 960.0, memory_length 2000, epsilon 0.057286685197520726, time 727.0, rides 129\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 3176, reward 654.0, memory_length 2000, epsilon 0.057235127180842955, time 723.0, rides 129\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 3177, reward 1051.0, memory_length 2000, epsilon 0.05718361556638019, time 728.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 3178, reward 698.0, memory_length 2000, epsilon 0.05713215031237045, time 726.0, rides 141\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 3179, reward 737.0, memory_length 2000, epsilon 0.057080731377089314, time 725.0, rides 135\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 3180, reward 502.0, memory_length 2000, epsilon 0.05702935871884993, time 727.0, rides 132\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3181, reward 822.0, memory_length 2000, epsilon 0.05697803229600297, time 729.0, rides 143\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 3182, reward 848.0, memory_length 2000, epsilon 0.056926752066936565, time 737.0, rides 142\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 3183, reward 785.0, memory_length 2000, epsilon 0.05687551799007632, time 738.0, rides 134\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 3184, reward 745.0, memory_length 2000, epsilon 0.05682433002388525, time 731.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3185, reward 787.0, memory_length 2000, epsilon 0.05677318812686375, time 727.0, rides 145\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 3186, reward 662.0, memory_length 2000, epsilon 0.056722092257549574, time 726.0, rides 131\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 3187, reward 779.0, memory_length 2000, epsilon 0.056671042374517776, time 726.0, rides 140\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 3188, reward 831.0, memory_length 2000, epsilon 0.05662003843638071, time 731.0, rides 147\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 3189, reward 955.0, memory_length 2000, epsilon 0.056569080401787965, time 728.0, rides 148\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 3190, reward 977.0, memory_length 2000, epsilon 0.056518168229426353, time 730.0, rides 139\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 3191, reward 508.0, memory_length 2000, epsilon 0.05646730187801987, time 729.0, rides 128\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 3192, reward 1025.0, memory_length 2000, epsilon 0.056416481306329654, time 727.0, rides 130\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 3193, reward 747.0, memory_length 2000, epsilon 0.056365706473153955, time 726.0, rides 127\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 3194, reward 882.0, memory_length 2000, epsilon 0.05631497733732812, time 729.0, rides 133\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 3195, reward 949.0, memory_length 2000, epsilon 0.05626429385772452, time 724.0, rides 130\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 3196, reward 719.0, memory_length 2000, epsilon 0.05621365599325257, time 725.0, rides 140\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 3197, reward 734.0, memory_length 2000, epsilon 0.056163063702858645, time 723.0, rides 136\n",
      "Initial State is  [2, 15, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3198, reward 1161.0, memory_length 2000, epsilon 0.056112516945526075, time 726.0, rides 127\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 3199, reward 1002.0, memory_length 2000, epsilon 0.0560620156802751, time 722.0, rides 134\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 3200, reward 941.0, memory_length 2000, epsilon 0.05601155986616285, time 734.0, rides 144\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 3201, reward 945.0, memory_length 2000, epsilon 0.055961149462283304, time 731.0, rides 135\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 3202, reward 947.0, memory_length 2000, epsilon 0.05591078442776725, time 734.0, rides 150\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3203, reward 822.0, memory_length 2000, epsilon 0.05586046472178226, time 729.0, rides 123\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 3204, reward 1086.0, memory_length 2000, epsilon 0.05581019030353265, time 728.0, rides 131\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 3205, reward 950.0, memory_length 2000, epsilon 0.05575996113225947, time 741.0, rides 134\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 3206, reward 760.0, memory_length 2000, epsilon 0.05570977716724044, time 726.0, rides 123\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3207, reward 767.0, memory_length 2000, epsilon 0.05565963836778992, time 727.0, rides 132\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3208, reward 945.0, memory_length 2000, epsilon 0.05560954469325891, time 729.0, rides 131\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 3209, reward 688.0, memory_length 2000, epsilon 0.055559496103034976, time 728.0, rides 127\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 3210, reward 688.0, memory_length 2000, epsilon 0.05550949255654224, time 722.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3211, reward 977.0, memory_length 2000, epsilon 0.05545953401324136, time 741.0, rides 135\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 3212, reward 1250.0, memory_length 2000, epsilon 0.05540962043262944, time 730.0, rides 142\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 3213, reward 727.0, memory_length 2000, epsilon 0.055359751774240074, time 724.0, rides 127\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 3214, reward 936.0, memory_length 2000, epsilon 0.055309927997643255, time 727.0, rides 133\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3215, reward 874.0, memory_length 2000, epsilon 0.05526014906244538, time 729.0, rides 126\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 3216, reward 1286.0, memory_length 2000, epsilon 0.055210414928289174, time 725.0, rides 144\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 3217, reward 1033.0, memory_length 2000, epsilon 0.05516072555485371, time 731.0, rides 148\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3218, reward 1216.0, memory_length 2000, epsilon 0.05511108090185434, time 722.0, rides 134\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 3219, reward 814.0, memory_length 2000, epsilon 0.05506148092904267, time 722.0, rides 134\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3220, reward 467.0, memory_length 2000, epsilon 0.05501192559620653, time 724.0, rides 135\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 3221, reward 833.0, memory_length 2000, epsilon 0.054962414863169946, time 733.0, rides 126\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3222, reward 1137.0, memory_length 2000, epsilon 0.054912948689793094, time 728.0, rides 138\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 3223, reward 707.0, memory_length 2000, epsilon 0.054863527035972276, time 728.0, rides 138\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 3224, reward 1208.0, memory_length 2000, epsilon 0.0548141498616399, time 727.0, rides 137\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3225, reward 837.0, memory_length 2000, epsilon 0.05476481712676442, time 723.0, rides 131\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 3226, reward 959.0, memory_length 2000, epsilon 0.05471552879135033, time 728.0, rides 138\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 3227, reward 803.0, memory_length 2000, epsilon 0.054666284815438115, time 727.0, rides 130\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 3228, reward 1184.0, memory_length 2000, epsilon 0.05461708515910422, time 733.0, rides 126\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3229, reward 740.0, memory_length 2000, epsilon 0.05456792978246102, time 731.0, rides 129\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3230, reward 603.0, memory_length 2000, epsilon 0.0545188186456568, time 731.0, rides 126\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 3231, reward 758.0, memory_length 2000, epsilon 0.05446975170887571, time 727.0, rides 110\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 3232, reward 1109.0, memory_length 2000, epsilon 0.05442072893233772, time 728.0, rides 130\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 3233, reward 886.0, memory_length 2000, epsilon 0.05437175027629862, time 723.0, rides 136\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 3234, reward 916.0, memory_length 2000, epsilon 0.05432281570104995, time 729.0, rides 138\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 3235, reward 1011.0, memory_length 2000, epsilon 0.05427392516691901, time 724.0, rides 135\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 3236, reward 1075.0, memory_length 2000, epsilon 0.05422507863426878, time 727.0, rides 115\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3237, reward 706.0, memory_length 2000, epsilon 0.05417627606349794, time 727.0, rides 133\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 3238, reward 1094.0, memory_length 2000, epsilon 0.054127517415040786, time 724.0, rides 130\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 3239, reward 893.0, memory_length 2000, epsilon 0.05407880264936725, time 726.0, rides 138\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3240, reward 862.0, memory_length 2000, epsilon 0.054030131726982816, time 726.0, rides 120\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 3241, reward 710.0, memory_length 2000, epsilon 0.05398150460842853, time 731.0, rides 130\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 3242, reward 863.0, memory_length 2000, epsilon 0.053932921254280945, time 730.0, rides 139\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3243, reward 987.0, memory_length 2000, epsilon 0.05388438162515209, time 724.0, rides 127\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 3244, reward 678.0, memory_length 2000, epsilon 0.053835885681689455, time 727.0, rides 139\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 3245, reward 950.0, memory_length 2000, epsilon 0.053787433384575936, time 726.0, rides 128\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 3246, reward 628.0, memory_length 2000, epsilon 0.05373902469452982, time 733.0, rides 139\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 3247, reward 775.0, memory_length 2000, epsilon 0.05369065957230474, time 738.0, rides 128\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3248, reward 597.0, memory_length 2000, epsilon 0.05364233797868966, time 726.0, rides 127\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 3249, reward 997.0, memory_length 2000, epsilon 0.05359405987450884, time 726.0, rides 131\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 3250, reward 856.0, memory_length 2000, epsilon 0.05354582522062178, time 736.0, rides 146\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 3251, reward 742.0, memory_length 2000, epsilon 0.053497633977923224, time 735.0, rides 139\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 3252, reward 809.0, memory_length 2000, epsilon 0.05344948610734309, time 735.0, rides 151\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 3253, reward 1075.0, memory_length 2000, epsilon 0.05340138156984648, time 735.0, rides 144\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3254, reward 546.0, memory_length 2000, epsilon 0.05335332032643362, time 730.0, rides 149\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 3255, reward 595.0, memory_length 2000, epsilon 0.05330530233813983, time 726.0, rides 138\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 3256, reward 794.0, memory_length 2000, epsilon 0.0532573275660355, time 742.0, rides 136\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 3257, reward 486.0, memory_length 2000, epsilon 0.05320939597122607, time 730.0, rides 133\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 3258, reward 1009.0, memory_length 2000, epsilon 0.05316150751485197, time 726.0, rides 134\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 3259, reward 547.0, memory_length 2000, epsilon 0.053113662158088604, time 733.0, rides 134\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 3260, reward 1038.0, memory_length 2000, epsilon 0.053065859862146326, time 728.0, rides 133\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 3261, reward 954.0, memory_length 2000, epsilon 0.053018100588270396, time 726.0, rides 149\n",
      "Initial State is  [3, 10, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3262, reward 587.0, memory_length 2000, epsilon 0.05297038429774095, time 731.0, rides 125\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3263, reward 1017.0, memory_length 2000, epsilon 0.05292271095187299, time 729.0, rides 145\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 3264, reward 1063.0, memory_length 2000, epsilon 0.0528750805120163, time 721.0, rides 141\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 3265, reward 928.0, memory_length 2000, epsilon 0.052827492939555486, time 728.0, rides 133\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3266, reward 816.0, memory_length 2000, epsilon 0.052779948195909886, time 725.0, rides 143\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3267, reward 632.0, memory_length 2000, epsilon 0.052732446242533565, time 726.0, rides 132\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 3268, reward 686.0, memory_length 2000, epsilon 0.05268498704091528, time 735.0, rides 129\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3269, reward 909.0, memory_length 2000, epsilon 0.05263757055257846, time 722.0, rides 122\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 3270, reward 794.0, memory_length 2000, epsilon 0.052590196739081135, time 727.0, rides 126\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 3271, reward 1243.0, memory_length 2000, epsilon 0.05254286556201596, time 736.0, rides 130\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 3272, reward 788.0, memory_length 2000, epsilon 0.05249557698301015, time 724.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3273, reward 1042.0, memory_length 2000, epsilon 0.05244833096372544, time 726.0, rides 121\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 3274, reward 648.0, memory_length 2000, epsilon 0.05240112746585809, time 727.0, rides 132\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 3275, reward 1003.0, memory_length 2000, epsilon 0.052353966451138816, time 727.0, rides 129\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3276, reward 967.0, memory_length 2000, epsilon 0.05230684788133279, time 724.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 3277, reward 930.0, memory_length 2000, epsilon 0.05225977171823959, time 731.0, rides 132\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3278, reward 927.0, memory_length 2000, epsilon 0.05221273792369317, time 739.0, rides 141\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 3279, reward 677.0, memory_length 2000, epsilon 0.052165746459561846, time 739.0, rides 120\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3280, reward 866.0, memory_length 2000, epsilon 0.052118797287748236, time 728.0, rides 141\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3281, reward 841.0, memory_length 2000, epsilon 0.052071890370189264, time 733.0, rides 123\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 3282, reward 759.0, memory_length 2000, epsilon 0.05202502566885609, time 734.0, rides 137\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 3283, reward 965.0, memory_length 2000, epsilon 0.05197820314575412, time 722.0, rides 133\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3284, reward 1070.0, memory_length 2000, epsilon 0.05193142276292294, time 728.0, rides 126\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 3285, reward 720.0, memory_length 2000, epsilon 0.05188468448243631, time 728.0, rides 128\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 3286, reward 888.0, memory_length 2000, epsilon 0.05183798826640211, time 736.0, rides 144\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3287, reward 1120.0, memory_length 2000, epsilon 0.05179133407696235, time 732.0, rides 140\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 3288, reward 859.0, memory_length 2000, epsilon 0.05174472187629308, time 737.0, rides 143\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 3289, reward 654.0, memory_length 2000, epsilon 0.05169815162660442, time 727.0, rides 135\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 3290, reward 966.0, memory_length 2000, epsilon 0.051651623290140475, time 736.0, rides 124\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 3291, reward 723.0, memory_length 2000, epsilon 0.051605136829179346, time 726.0, rides 127\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3292, reward 1219.0, memory_length 2000, epsilon 0.05155869220603308, time 727.0, rides 140\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3293, reward 1085.0, memory_length 2000, epsilon 0.05151228938304765, time 724.0, rides 139\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 3294, reward 841.0, memory_length 2000, epsilon 0.05146592832260291, time 724.0, rides 135\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 3295, reward 916.0, memory_length 2000, epsilon 0.05141960898711257, time 724.0, rides 141\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 3296, reward 650.0, memory_length 2000, epsilon 0.05137333133902417, time 730.0, rides 137\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 3297, reward 887.0, memory_length 2000, epsilon 0.05132709534081905, time 730.0, rides 145\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 3298, reward 786.0, memory_length 2000, epsilon 0.05128090095501231, time 727.0, rides 136\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 3299, reward 946.0, memory_length 2000, epsilon 0.0512347481441528, time 730.0, rides 140\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 3300, reward 856.0, memory_length 2000, epsilon 0.05118863687082306, time 730.0, rides 155\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3301, reward 975.0, memory_length 2000, epsilon 0.05114256709763932, time 727.0, rides 131\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3302, reward 856.0, memory_length 2000, epsilon 0.05109653878725144, time 728.0, rides 141\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 3303, reward 1110.0, memory_length 2000, epsilon 0.051050551902342915, time 732.0, rides 139\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 3304, reward 823.0, memory_length 2000, epsilon 0.05100460640563081, time 723.0, rides 149\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3305, reward 1193.0, memory_length 2000, epsilon 0.05095870225986574, time 726.0, rides 121\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 3306, reward 721.0, memory_length 2000, epsilon 0.05091283942783186, time 724.0, rides 138\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 3307, reward 927.0, memory_length 2000, epsilon 0.05086701787234681, time 726.0, rides 134\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3308, reward 988.0, memory_length 2000, epsilon 0.0508212375562617, time 722.0, rides 139\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3309, reward 1161.0, memory_length 2000, epsilon 0.05077549844246106, time 729.0, rides 129\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3310, reward 963.0, memory_length 2000, epsilon 0.050729800493862845, time 729.0, rides 141\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3311, reward 743.0, memory_length 2000, epsilon 0.05068414367341837, time 728.0, rides 135\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3312, reward 744.0, memory_length 2000, epsilon 0.05063852794411229, time 724.0, rides 135\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 3313, reward 986.0, memory_length 2000, epsilon 0.05059295326896259, time 728.0, rides 151\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 3314, reward 1203.0, memory_length 2000, epsilon 0.05054741961102052, time 731.0, rides 131\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3315, reward 644.0, memory_length 2000, epsilon 0.050501926933370606, time 722.0, rides 126\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 3316, reward 896.0, memory_length 2000, epsilon 0.050456475199130574, time 723.0, rides 139\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 3317, reward 685.0, memory_length 2000, epsilon 0.050411064371451354, time 729.0, rides 131\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 3318, reward 1154.0, memory_length 2000, epsilon 0.05036569441351705, time 730.0, rides 138\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 3319, reward 861.0, memory_length 2000, epsilon 0.05032036528854488, time 729.0, rides 138\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 3320, reward 940.0, memory_length 2000, epsilon 0.05027507695978519, time 727.0, rides 128\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3321, reward 719.0, memory_length 2000, epsilon 0.05022982939052138, time 725.0, rides 125\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 3322, reward 834.0, memory_length 2000, epsilon 0.05018462254406991, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 3323, reward 860.0, memory_length 2000, epsilon 0.05013945638378025, time 725.0, rides 130\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 3324, reward 777.0, memory_length 2000, epsilon 0.050094330873034845, time 728.0, rides 143\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3325, reward 836.0, memory_length 2000, epsilon 0.05004924597524912, time 731.0, rides 117\n",
      "Initial State is  [0, 18, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3326, reward 647.0, memory_length 2000, epsilon 0.05000420165387139, time 728.0, rides 128\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3327, reward 782.0, memory_length 2000, epsilon 0.049959197872382906, time 732.0, rides 125\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 3328, reward 1001.0, memory_length 2000, epsilon 0.04991423459429776, time 728.0, rides 141\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 3329, reward 666.0, memory_length 2000, epsilon 0.04986931178316289, time 735.0, rides 131\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 3330, reward 743.0, memory_length 2000, epsilon 0.04982442940255804, time 728.0, rides 144\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 3331, reward 886.0, memory_length 2000, epsilon 0.049779587416095734, time 724.0, rides 129\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 3332, reward 827.0, memory_length 2000, epsilon 0.04973478578742125, time 733.0, rides 126\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 3333, reward 860.0, memory_length 2000, epsilon 0.04969002448021257, time 729.0, rides 148\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3334, reward 976.0, memory_length 2000, epsilon 0.04964530345818038, time 734.0, rides 123\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3335, reward 1284.0, memory_length 2000, epsilon 0.04960062268506801, time 728.0, rides 130\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 3336, reward 904.0, memory_length 2000, epsilon 0.049555982124651454, time 734.0, rides 143\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3337, reward 827.0, memory_length 2000, epsilon 0.04951138174073927, time 723.0, rides 139\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 3338, reward 933.0, memory_length 2000, epsilon 0.0494668214971726, time 734.0, rides 131\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 3339, reward 920.0, memory_length 2000, epsilon 0.049422301357825146, time 729.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 3340, reward 979.0, memory_length 2000, epsilon 0.049377821286603105, time 723.0, rides 127\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 3341, reward 1136.0, memory_length 2000, epsilon 0.049333381247445164, time 730.0, rides 136\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 3342, reward 944.0, memory_length 2000, epsilon 0.049288981204322464, time 728.0, rides 127\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 3343, reward 772.0, memory_length 2000, epsilon 0.04924462112123857, time 729.0, rides 140\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 3344, reward 895.0, memory_length 2000, epsilon 0.04920030096222946, time 725.0, rides 125\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 3345, reward 901.0, memory_length 2000, epsilon 0.049156020691363454, time 726.0, rides 127\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 3346, reward 839.0, memory_length 2000, epsilon 0.049111780272741226, time 725.0, rides 129\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 3347, reward 1069.0, memory_length 2000, epsilon 0.049067579670495756, time 725.0, rides 124\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 3348, reward 1076.0, memory_length 2000, epsilon 0.049023418848792306, time 727.0, rides 145\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3349, reward 936.0, memory_length 2000, epsilon 0.04897929777182839, time 724.0, rides 131\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3350, reward 966.0, memory_length 2000, epsilon 0.04893521640383375, time 729.0, rides 137\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 3351, reward 979.0, memory_length 2000, epsilon 0.0488911747090703, time 728.0, rides 129\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 3352, reward 899.0, memory_length 2000, epsilon 0.04884717265183213, time 730.0, rides 146\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3353, reward 837.0, memory_length 2000, epsilon 0.048803210196445485, time 730.0, rides 135\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 3354, reward 1001.0, memory_length 2000, epsilon 0.04875928730726868, time 726.0, rides 136\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 3355, reward 655.0, memory_length 2000, epsilon 0.048715403948692136, time 728.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3356, reward 856.0, memory_length 2000, epsilon 0.048671560085138316, time 724.0, rides 135\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 3357, reward 951.0, memory_length 2000, epsilon 0.04862775568106169, time 730.0, rides 128\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 3358, reward 1089.0, memory_length 2000, epsilon 0.04858399070094873, time 730.0, rides 139\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 3359, reward 1023.0, memory_length 2000, epsilon 0.04854026510931787, time 721.0, rides 132\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 3360, reward 706.0, memory_length 2000, epsilon 0.04849657887071949, time 727.0, rides 128\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 3361, reward 962.0, memory_length 2000, epsilon 0.04845293194973584, time 726.0, rides 141\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 3362, reward 1021.0, memory_length 2000, epsilon 0.04840932431098108, time 722.0, rides 128\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3363, reward 1017.0, memory_length 2000, epsilon 0.048365755919101194, time 734.0, rides 133\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 3364, reward 847.0, memory_length 2000, epsilon 0.048322226738774, time 734.0, rides 135\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 3365, reward 931.0, memory_length 2000, epsilon 0.04827873673470911, time 726.0, rides 129\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3366, reward 1015.0, memory_length 2000, epsilon 0.04823528587164787, time 731.0, rides 140\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 3367, reward 826.0, memory_length 2000, epsilon 0.04819187411436338, time 726.0, rides 120\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3368, reward 709.0, memory_length 2000, epsilon 0.04814850142766045, time 734.0, rides 142\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 3369, reward 753.0, memory_length 2000, epsilon 0.04810516777637556, time 732.0, rides 135\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 3370, reward 849.0, memory_length 2000, epsilon 0.04806187312537682, time 726.0, rides 139\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3371, reward 739.0, memory_length 2000, epsilon 0.048018617439563975, time 724.0, rides 124\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 3372, reward 925.0, memory_length 2000, epsilon 0.047975400683868366, time 735.0, rides 138\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 3373, reward 486.0, memory_length 2000, epsilon 0.047932222823252886, time 729.0, rides 119\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 3374, reward 1051.0, memory_length 2000, epsilon 0.04788908382271196, time 729.0, rides 138\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3375, reward 1001.0, memory_length 2000, epsilon 0.047845983647271516, time 725.0, rides 122\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 3376, reward 940.0, memory_length 2000, epsilon 0.04780292226198897, time 728.0, rides 125\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3377, reward 578.0, memory_length 2000, epsilon 0.04775989963195318, time 725.0, rides 131\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 3378, reward 1096.0, memory_length 2000, epsilon 0.04771691572228442, time 733.0, rides 130\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 3379, reward 874.0, memory_length 2000, epsilon 0.04767397049813436, time 726.0, rides 141\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3380, reward 1056.0, memory_length 2000, epsilon 0.047631063924686044, time 722.0, rides 137\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 3381, reward 974.0, memory_length 2000, epsilon 0.04758819596715383, time 721.0, rides 130\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 3382, reward 983.0, memory_length 2000, epsilon 0.04754536659078339, time 733.0, rides 141\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 3383, reward 797.0, memory_length 2000, epsilon 0.047502575760851685, time 732.0, rides 152\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 3384, reward 783.0, memory_length 2000, epsilon 0.047459823442666915, time 728.0, rides 126\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 3385, reward 629.0, memory_length 2000, epsilon 0.047417109601568516, time 724.0, rides 143\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 3386, reward 766.0, memory_length 2000, epsilon 0.047374434202927106, time 728.0, rides 117\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 3387, reward 1138.0, memory_length 2000, epsilon 0.04733179721214447, time 724.0, rides 149\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 3388, reward 1008.0, memory_length 2000, epsilon 0.04728919859465354, time 724.0, rides 134\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 3389, reward 910.0, memory_length 2000, epsilon 0.04724663831591835, time 733.0, rides 139\n",
      "Initial State is  [4, 19, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3390, reward 1051.0, memory_length 2000, epsilon 0.04720411634143402, time 732.0, rides 134\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 3391, reward 530.0, memory_length 2000, epsilon 0.04716163263672673, time 728.0, rides 126\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 3392, reward 961.0, memory_length 2000, epsilon 0.04711918716735367, time 731.0, rides 136\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3393, reward 864.0, memory_length 2000, epsilon 0.047076779898903055, time 731.0, rides 122\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3394, reward 848.0, memory_length 2000, epsilon 0.04703441079699404, time 735.0, rides 130\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3395, reward 739.0, memory_length 2000, epsilon 0.046992079827276746, time 729.0, rides 131\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3396, reward 608.0, memory_length 2000, epsilon 0.0469497869554322, time 732.0, rides 130\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 3397, reward 1270.0, memory_length 2000, epsilon 0.04690753214717231, time 723.0, rides 123\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 3398, reward 894.0, memory_length 2000, epsilon 0.04686531536823985, time 731.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 3399, reward 545.0, memory_length 2000, epsilon 0.04682313658440844, time 721.0, rides 132\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 3400, reward 1000.0, memory_length 2000, epsilon 0.04678099576148247, time 726.0, rides 130\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3401, reward 539.0, memory_length 2000, epsilon 0.04673889286529714, time 732.0, rides 135\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3402, reward 1147.0, memory_length 2000, epsilon 0.04669682786171837, time 724.0, rides 145\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3403, reward 837.0, memory_length 2000, epsilon 0.04665480071664282, time 729.0, rides 147\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 3404, reward 785.0, memory_length 2000, epsilon 0.046612811395997836, time 728.0, rides 128\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3405, reward 700.0, memory_length 2000, epsilon 0.046570859865741436, time 729.0, rides 142\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 3406, reward 951.0, memory_length 2000, epsilon 0.04652894609186227, time 727.0, rides 149\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3407, reward 887.0, memory_length 2000, epsilon 0.046487070040379594, time 733.0, rides 144\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3408, reward 1114.0, memory_length 2000, epsilon 0.046445231677343254, time 730.0, rides 135\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 3409, reward 1092.0, memory_length 2000, epsilon 0.04640343096883365, time 729.0, rides 139\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 3410, reward 902.0, memory_length 2000, epsilon 0.046361667880961695, time 731.0, rides 138\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 3411, reward 684.0, memory_length 2000, epsilon 0.04631994237986883, time 725.0, rides 137\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 3412, reward 797.0, memory_length 2000, epsilon 0.046278254431726944, time 733.0, rides 136\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 3413, reward 621.0, memory_length 2000, epsilon 0.046236604002738386, time 727.0, rides 134\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 3414, reward 932.0, memory_length 2000, epsilon 0.04619499105913592, time 725.0, rides 151\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 3415, reward 480.0, memory_length 2000, epsilon 0.0461534155671827, time 734.0, rides 126\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3416, reward 1063.0, memory_length 2000, epsilon 0.046111877493172235, time 731.0, rides 121\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 3417, reward 910.0, memory_length 2000, epsilon 0.04607037680342838, time 726.0, rides 137\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 3418, reward 739.0, memory_length 2000, epsilon 0.04602891346430529, time 727.0, rides 142\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 3419, reward 608.0, memory_length 2000, epsilon 0.04598748744218742, time 721.0, rides 149\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3420, reward 796.0, memory_length 2000, epsilon 0.04594609870348945, time 732.0, rides 129\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3421, reward 569.0, memory_length 2000, epsilon 0.04590474721465631, time 734.0, rides 125\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 3422, reward 504.0, memory_length 2000, epsilon 0.04586343294216312, time 730.0, rides 134\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 3423, reward 977.0, memory_length 2000, epsilon 0.04582215585251517, time 734.0, rides 137\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3424, reward 694.0, memory_length 2000, epsilon 0.04578091591224791, time 726.0, rides 131\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3425, reward 1262.0, memory_length 2000, epsilon 0.04573971308792688, time 725.0, rides 128\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 3426, reward 999.0, memory_length 2000, epsilon 0.04569854734614775, time 725.0, rides 136\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 3427, reward 968.0, memory_length 2000, epsilon 0.045657418653536216, time 727.0, rides 146\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 3428, reward 695.0, memory_length 2000, epsilon 0.045616326976748035, time 727.0, rides 148\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 3429, reward 930.0, memory_length 2000, epsilon 0.045575272282468965, time 730.0, rides 140\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 3430, reward 880.0, memory_length 2000, epsilon 0.04553425453741474, time 728.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3431, reward 955.0, memory_length 2000, epsilon 0.04549327370833107, time 732.0, rides 125\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 3432, reward 1029.0, memory_length 2000, epsilon 0.04545232976199357, time 723.0, rides 137\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 3433, reward 1052.0, memory_length 2000, epsilon 0.04541142266520778, time 723.0, rides 143\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 3434, reward 979.0, memory_length 2000, epsilon 0.04537055238480909, time 725.0, rides 145\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 3435, reward 1122.0, memory_length 2000, epsilon 0.04532971888766276, time 731.0, rides 144\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 3436, reward 793.0, memory_length 2000, epsilon 0.045288922140663865, time 728.0, rides 128\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3437, reward 951.0, memory_length 2000, epsilon 0.04524816211073727, time 725.0, rides 138\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 3438, reward 1072.0, memory_length 2000, epsilon 0.045207438764837606, time 736.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 3439, reward 1258.0, memory_length 2000, epsilon 0.04516675206994925, time 732.0, rides 131\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3440, reward 655.0, memory_length 2000, epsilon 0.045126101993086296, time 728.0, rides 128\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 3441, reward 867.0, memory_length 2000, epsilon 0.045085488501292514, time 725.0, rides 131\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 3442, reward 898.0, memory_length 2000, epsilon 0.04504491156164135, time 733.0, rides 134\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 3443, reward 883.0, memory_length 2000, epsilon 0.04500437114123587, time 737.0, rides 134\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 3444, reward 940.0, memory_length 2000, epsilon 0.04496386720720876, time 727.0, rides 126\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 3445, reward 935.0, memory_length 2000, epsilon 0.044923399726722275, time 728.0, rides 147\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 3446, reward 938.0, memory_length 2000, epsilon 0.044882968666968226, time 729.0, rides 134\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 3447, reward 880.0, memory_length 2000, epsilon 0.04484257399516795, time 728.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3448, reward 909.0, memory_length 2000, epsilon 0.0448022156785723, time 728.0, rides 131\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 3449, reward 733.0, memory_length 2000, epsilon 0.04476189368446159, time 730.0, rides 143\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 3450, reward 788.0, memory_length 2000, epsilon 0.04472160798014557, time 726.0, rides 142\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3451, reward 1024.0, memory_length 2000, epsilon 0.04468135853296344, time 733.0, rides 141\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 3452, reward 915.0, memory_length 2000, epsilon 0.04464114531028377, time 727.0, rides 149\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3453, reward 897.0, memory_length 2000, epsilon 0.044600968279504515, time 729.0, rides 143\n",
      "Initial State is  [2, 22, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3454, reward 1084.0, memory_length 2000, epsilon 0.04456082740805296, time 730.0, rides 150\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3455, reward 804.0, memory_length 2000, epsilon 0.044520722663385706, time 728.0, rides 139\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 3456, reward 609.0, memory_length 2000, epsilon 0.04448065401298866, time 727.0, rides 123\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3457, reward 906.0, memory_length 2000, epsilon 0.04444062142437697, time 726.0, rides 145\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3458, reward 998.0, memory_length 2000, epsilon 0.04440062486509503, time 737.0, rides 132\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 3459, reward 909.0, memory_length 2000, epsilon 0.04436066430271644, time 731.0, rides 137\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3460, reward 1176.0, memory_length 2000, epsilon 0.044320739704844, time 730.0, rides 132\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 3461, reward 1013.0, memory_length 2000, epsilon 0.04428085103910964, time 727.0, rides 138\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 3462, reward 498.0, memory_length 2000, epsilon 0.044240998273174445, time 730.0, rides 140\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 3463, reward 870.0, memory_length 2000, epsilon 0.04420118137472859, time 731.0, rides 144\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3464, reward 1188.0, memory_length 2000, epsilon 0.04416140031149133, time 736.0, rides 140\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 3465, reward 1189.0, memory_length 2000, epsilon 0.04412165505121099, time 730.0, rides 129\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 3466, reward 570.0, memory_length 2000, epsilon 0.0440819455616649, time 727.0, rides 140\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 3467, reward 708.0, memory_length 2000, epsilon 0.0440422718106594, time 732.0, rides 141\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 3468, reward 767.0, memory_length 2000, epsilon 0.04400263376602981, time 729.0, rides 128\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 3469, reward 767.0, memory_length 2000, epsilon 0.04396303139564038, time 733.0, rides 141\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 3470, reward 801.0, memory_length 2000, epsilon 0.0439234646673843, time 726.0, rides 145\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 3471, reward 828.0, memory_length 2000, epsilon 0.04388393354918366, time 730.0, rides 133\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 3472, reward 898.0, memory_length 2000, epsilon 0.04384443800898939, time 723.0, rides 144\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 3473, reward 585.0, memory_length 2000, epsilon 0.0438049780147813, time 725.0, rides 139\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 3474, reward 881.0, memory_length 2000, epsilon 0.043765553534568, time 726.0, rides 133\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 3475, reward 936.0, memory_length 2000, epsilon 0.04372616453638689, time 720.0, rides 143\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3476, reward 1101.0, memory_length 2000, epsilon 0.04368681098830414, time 740.0, rides 133\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3477, reward 943.0, memory_length 2000, epsilon 0.04364749285841466, time 727.0, rides 143\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3478, reward 940.0, memory_length 2000, epsilon 0.04360821011484209, time 723.0, rides 130\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 3479, reward 627.0, memory_length 2000, epsilon 0.04356896272573873, time 722.0, rides 140\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 3480, reward 1047.0, memory_length 2000, epsilon 0.04352975065928556, time 729.0, rides 140\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3481, reward 776.0, memory_length 2000, epsilon 0.04349057388369221, time 734.0, rides 135\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 3482, reward 918.0, memory_length 2000, epsilon 0.04345143236719688, time 726.0, rides 133\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 3483, reward 812.0, memory_length 2000, epsilon 0.0434123260780664, time 722.0, rides 128\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 3484, reward 875.0, memory_length 2000, epsilon 0.04337325498459614, time 722.0, rides 125\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 3485, reward 814.0, memory_length 2000, epsilon 0.04333421905511001, time 726.0, rides 130\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 3486, reward 814.0, memory_length 2000, epsilon 0.043295218257960406, time 730.0, rides 133\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 3487, reward 746.0, memory_length 2000, epsilon 0.04325625256152824, time 730.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 3488, reward 811.0, memory_length 2000, epsilon 0.04321732193422287, time 730.0, rides 136\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 3489, reward 1054.0, memory_length 2000, epsilon 0.04317842634448207, time 727.0, rides 125\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 3490, reward 967.0, memory_length 2000, epsilon 0.04313956576077203, time 721.0, rides 129\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 3491, reward 771.0, memory_length 2000, epsilon 0.04310074015158734, time 727.0, rides 127\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 3492, reward 908.0, memory_length 2000, epsilon 0.04306194948545091, time 729.0, rides 120\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 3493, reward 992.0, memory_length 2000, epsilon 0.043023193730914004, time 731.0, rides 129\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 3494, reward 1054.0, memory_length 2000, epsilon 0.04298447285655618, time 735.0, rides 132\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3495, reward 1029.0, memory_length 2000, epsilon 0.04294578683098528, time 730.0, rides 138\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 3496, reward 919.0, memory_length 2000, epsilon 0.04290713562283739, time 728.0, rides 135\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 3497, reward 822.0, memory_length 2000, epsilon 0.04286851920077684, time 724.0, rides 127\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 3498, reward 879.0, memory_length 2000, epsilon 0.04282993753349614, time 720.0, rides 134\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3499, reward 1167.0, memory_length 2000, epsilon 0.042791390589716, time 727.0, rides 128\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 3500, reward 956.0, memory_length 2000, epsilon 0.04275287833818525, time 733.0, rides 144\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3501, reward 931.0, memory_length 2000, epsilon 0.04271440074768088, time 728.0, rides 133\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3502, reward 1015.0, memory_length 2000, epsilon 0.042675957787007966, time 731.0, rides 131\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 3503, reward 1180.0, memory_length 2000, epsilon 0.04263754942499966, time 729.0, rides 135\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3504, reward 711.0, memory_length 2000, epsilon 0.042599175630517155, time 733.0, rides 148\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 3505, reward 853.0, memory_length 2000, epsilon 0.04256083637244969, time 726.0, rides 136\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 3506, reward 1067.0, memory_length 2000, epsilon 0.04252253161971448, time 728.0, rides 141\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 3507, reward 1134.0, memory_length 2000, epsilon 0.04248426134125674, time 727.0, rides 131\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 3508, reward 1264.0, memory_length 2000, epsilon 0.04244602550604961, time 726.0, rides 142\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3509, reward 528.0, memory_length 2000, epsilon 0.04240782408309417, time 727.0, rides 135\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3510, reward 862.0, memory_length 2000, epsilon 0.04236965704141938, time 730.0, rides 130\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3511, reward 785.0, memory_length 2000, epsilon 0.042331524350082105, time 728.0, rides 123\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3512, reward 1176.0, memory_length 2000, epsilon 0.04229342597816703, time 722.0, rides 132\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 3513, reward 738.0, memory_length 2000, epsilon 0.04225536189478668, time 729.0, rides 139\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 3514, reward 1041.0, memory_length 2000, epsilon 0.04221733206908137, time 732.0, rides 137\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3515, reward 1124.0, memory_length 2000, epsilon 0.042179336470219195, time 724.0, rides 132\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 3516, reward 730.0, memory_length 2000, epsilon 0.042141375067396, time 726.0, rides 141\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 3517, reward 1006.0, memory_length 2000, epsilon 0.04210344782983534, time 735.0, rides 131\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 3518, reward 949.0, memory_length 2000, epsilon 0.04206555472678849, time 733.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3519, reward 1013.0, memory_length 2000, epsilon 0.04202769572753438, time 722.0, rides 121\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3520, reward 889.0, memory_length 2000, epsilon 0.04198987080137959, time 729.0, rides 130\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 3521, reward 601.0, memory_length 2000, epsilon 0.04195207991765835, time 733.0, rides 129\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3522, reward 669.0, memory_length 2000, epsilon 0.041914323045732456, time 724.0, rides 121\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3523, reward 859.0, memory_length 2000, epsilon 0.0418766001549913, time 725.0, rides 130\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 3524, reward 995.0, memory_length 2000, epsilon 0.0418389112148518, time 732.0, rides 133\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 3525, reward 713.0, memory_length 2000, epsilon 0.041801256194758434, time 726.0, rides 132\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3526, reward 749.0, memory_length 2000, epsilon 0.04176363506418315, time 729.0, rides 132\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 3527, reward 703.0, memory_length 2000, epsilon 0.041726047792625384, time 724.0, rides 126\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 3528, reward 875.0, memory_length 2000, epsilon 0.04168849434961202, time 729.0, rides 145\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 3529, reward 716.0, memory_length 2000, epsilon 0.04165097470469737, time 732.0, rides 139\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 3530, reward 1097.0, memory_length 2000, epsilon 0.041613488827463144, time 730.0, rides 141\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 3531, reward 751.0, memory_length 2000, epsilon 0.04157603668751843, time 726.0, rides 141\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 3532, reward 1277.0, memory_length 2000, epsilon 0.041538618254499664, time 723.0, rides 133\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3533, reward 642.0, memory_length 2000, epsilon 0.04150123349807061, time 736.0, rides 137\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 3534, reward 1023.0, memory_length 2000, epsilon 0.04146388238792235, time 734.0, rides 134\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 3535, reward 859.0, memory_length 2000, epsilon 0.041426564893773214, time 729.0, rides 133\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 3536, reward 670.0, memory_length 2000, epsilon 0.041389280985368815, time 722.0, rides 125\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 3537, reward 523.0, memory_length 2000, epsilon 0.04135203063248198, time 726.0, rides 134\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 3538, reward 1054.0, memory_length 2000, epsilon 0.041314813804912746, time 729.0, rides 132\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 3539, reward 662.0, memory_length 2000, epsilon 0.04127763047248832, time 727.0, rides 142\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 3540, reward 877.0, memory_length 2000, epsilon 0.04124048060506308, time 729.0, rides 141\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 3541, reward 816.0, memory_length 2000, epsilon 0.04120336417251852, time 727.0, rides 150\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3542, reward 913.0, memory_length 2000, epsilon 0.04116628114476325, time 730.0, rides 129\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3543, reward 745.0, memory_length 2000, epsilon 0.04112923149173296, time 732.0, rides 134\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 3544, reward 670.0, memory_length 2000, epsilon 0.0410922151833904, time 735.0, rides 147\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3545, reward 1067.0, memory_length 2000, epsilon 0.04105523218972535, time 729.0, rides 131\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 3546, reward 895.0, memory_length 2000, epsilon 0.0410182824807546, time 728.0, rides 134\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 3547, reward 617.0, memory_length 2000, epsilon 0.04098136602652192, time 735.0, rides 131\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 3548, reward 882.0, memory_length 2000, epsilon 0.04094448279709805, time 731.0, rides 127\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3549, reward 931.0, memory_length 2000, epsilon 0.040907632762580665, time 729.0, rides 129\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 3550, reward 1112.0, memory_length 2000, epsilon 0.04087081589309434, time 729.0, rides 128\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 3551, reward 1096.0, memory_length 2000, epsilon 0.040834032158790556, time 729.0, rides 142\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 3552, reward 602.0, memory_length 2000, epsilon 0.04079728152984764, time 731.0, rides 124\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 3553, reward 670.0, memory_length 2000, epsilon 0.04076056397647078, time 733.0, rides 123\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 3554, reward 972.0, memory_length 2000, epsilon 0.04072387946889196, time 744.0, rides 142\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 3555, reward 768.0, memory_length 2000, epsilon 0.040687227977369955, time 731.0, rides 135\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 3556, reward 998.0, memory_length 2000, epsilon 0.04065060947219032, time 731.0, rides 130\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3557, reward 1243.0, memory_length 2000, epsilon 0.040614023923665345, time 726.0, rides 126\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 3558, reward 726.0, memory_length 2000, epsilon 0.040577471302134044, time 733.0, rides 140\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3559, reward 978.0, memory_length 2000, epsilon 0.04054095157796212, time 730.0, rides 137\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 3560, reward 763.0, memory_length 2000, epsilon 0.040504464721541955, time 728.0, rides 156\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3561, reward 1072.0, memory_length 2000, epsilon 0.04046801070329257, time 730.0, rides 130\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 3562, reward 1004.0, memory_length 2000, epsilon 0.0404315894936596, time 735.0, rides 139\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 3563, reward 1036.0, memory_length 2000, epsilon 0.04039520106311531, time 727.0, rides 136\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 3564, reward 926.0, memory_length 2000, epsilon 0.040358845382158504, time 733.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 3565, reward 821.0, memory_length 2000, epsilon 0.04032252242131456, time 740.0, rides 145\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 3566, reward 1061.0, memory_length 2000, epsilon 0.04028623215113537, time 731.0, rides 133\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3567, reward 1089.0, memory_length 2000, epsilon 0.04024997454219935, time 728.0, rides 133\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 3568, reward 927.0, memory_length 2000, epsilon 0.04021374956511137, time 727.0, rides 140\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 3569, reward 1124.0, memory_length 2000, epsilon 0.04017755719050277, time 728.0, rides 138\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 3570, reward 779.0, memory_length 2000, epsilon 0.040141397389031316, time 733.0, rides 140\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 3571, reward 1073.0, memory_length 2000, epsilon 0.04010527013138119, time 731.0, rides 146\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 3572, reward 987.0, memory_length 2000, epsilon 0.04006917538826295, time 725.0, rides 138\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 3573, reward 1057.0, memory_length 2000, epsilon 0.04003311313041351, time 729.0, rides 138\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 3574, reward 969.0, memory_length 2000, epsilon 0.03999708332859614, time 727.0, rides 143\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3575, reward 1196.0, memory_length 2000, epsilon 0.0399610859536004, time 731.0, rides 140\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 3576, reward 765.0, memory_length 2000, epsilon 0.03992512097624216, time 732.0, rides 141\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3577, reward 777.0, memory_length 2000, epsilon 0.03988918836736354, time 726.0, rides 140\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3578, reward 976.0, memory_length 2000, epsilon 0.039853288097832916, time 725.0, rides 134\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3579, reward 787.0, memory_length 2000, epsilon 0.03981742013854487, time 724.0, rides 144\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 3580, reward 1211.0, memory_length 2000, epsilon 0.039781584460420176, time 732.0, rides 133\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3581, reward 1173.0, memory_length 2000, epsilon 0.0397457810344058, time 727.0, rides 141\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 3582, reward 1093.0, memory_length 2000, epsilon 0.03971000983147483, time 724.0, rides 138\n",
      "Initial State is  [1, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3583, reward 1106.0, memory_length 2000, epsilon 0.039674270822626506, time 725.0, rides 145\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 3584, reward 856.0, memory_length 2000, epsilon 0.03963856397888614, time 727.0, rides 130\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 3585, reward 970.0, memory_length 2000, epsilon 0.03960288927130514, time 730.0, rides 139\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 3586, reward 748.0, memory_length 2000, epsilon 0.03956724667096097, time 723.0, rides 132\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3587, reward 656.0, memory_length 2000, epsilon 0.039531636148957106, time 726.0, rides 148\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 3588, reward 771.0, memory_length 2000, epsilon 0.039496057676423044, time 729.0, rides 142\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 3589, reward 1216.0, memory_length 2000, epsilon 0.039460511224514265, time 729.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 3590, reward 751.0, memory_length 2000, epsilon 0.039424996764412204, time 728.0, rides 125\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 3591, reward 895.0, memory_length 2000, epsilon 0.03938951426732423, time 727.0, rides 134\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 3592, reward 850.0, memory_length 2000, epsilon 0.03935406370448364, time 731.0, rides 136\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3593, reward 975.0, memory_length 2000, epsilon 0.0393186450471496, time 722.0, rides 136\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 3594, reward 683.0, memory_length 2000, epsilon 0.03928325826660717, time 724.0, rides 123\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 3595, reward 919.0, memory_length 2000, epsilon 0.03924790333416722, time 727.0, rides 142\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 3596, reward 947.0, memory_length 2000, epsilon 0.03921258022116647, time 726.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3597, reward 966.0, memory_length 2000, epsilon 0.03917728889896742, time 725.0, rides 147\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 3598, reward 1035.0, memory_length 2000, epsilon 0.03914202933895835, time 728.0, rides 141\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 3599, reward 1055.0, memory_length 2000, epsilon 0.03910680151255329, time 738.0, rides 122\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 3600, reward 946.0, memory_length 2000, epsilon 0.03907160539119199, time 726.0, rides 128\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 3601, reward 946.0, memory_length 2000, epsilon 0.039036440946339915, time 729.0, rides 123\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 3602, reward 950.0, memory_length 2000, epsilon 0.039001308149488205, time 736.0, rides 139\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 3603, reward 899.0, memory_length 2000, epsilon 0.038966206972153666, time 731.0, rides 135\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 3604, reward 859.0, memory_length 2000, epsilon 0.03893113738587873, time 728.0, rides 131\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3605, reward 1067.0, memory_length 2000, epsilon 0.038896099362231436, time 727.0, rides 133\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 3606, reward 1152.0, memory_length 2000, epsilon 0.038861092872805425, time 727.0, rides 143\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 3607, reward 876.0, memory_length 2000, epsilon 0.0388261178892199, time 728.0, rides 131\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 3608, reward 1062.0, memory_length 2000, epsilon 0.0387911743831196, time 725.0, rides 127\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3609, reward 548.0, memory_length 2000, epsilon 0.038756262326174795, time 726.0, rides 143\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 3610, reward 986.0, memory_length 2000, epsilon 0.038721381690081234, time 727.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 3611, reward 940.0, memory_length 2000, epsilon 0.03868653244656016, time 728.0, rides 146\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3612, reward 1191.0, memory_length 2000, epsilon 0.038651714567358254, time 727.0, rides 130\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 3613, reward 576.0, memory_length 2000, epsilon 0.03861692802424763, time 731.0, rides 130\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3614, reward 822.0, memory_length 2000, epsilon 0.03858217278902581, time 738.0, rides 120\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 3615, reward 721.0, memory_length 2000, epsilon 0.038547448833515685, time 726.0, rides 124\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 3616, reward 1268.0, memory_length 2000, epsilon 0.03851275612956552, time 733.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 3617, reward 1346.0, memory_length 2000, epsilon 0.03847809464904891, time 730.0, rides 138\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3618, reward 989.0, memory_length 2000, epsilon 0.03844346436386476, time 733.0, rides 145\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 3619, reward 1027.0, memory_length 2000, epsilon 0.038408865245937285, time 726.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 3620, reward 1104.0, memory_length 2000, epsilon 0.03837429726721594, time 735.0, rides 136\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 3621, reward 836.0, memory_length 2000, epsilon 0.038339760399675446, time 731.0, rides 130\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3622, reward 984.0, memory_length 2000, epsilon 0.03830525461531574, time 726.0, rides 126\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 3623, reward 726.0, memory_length 2000, epsilon 0.038270779886161954, time 737.0, rides 142\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3624, reward 989.0, memory_length 2000, epsilon 0.038236336184264405, time 724.0, rides 128\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 3625, reward 871.0, memory_length 2000, epsilon 0.03820192348169857, time 729.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3626, reward 779.0, memory_length 2000, epsilon 0.03816754175056504, time 727.0, rides 141\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 3627, reward 815.0, memory_length 2000, epsilon 0.03813319096298953, time 731.0, rides 122\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 3628, reward 875.0, memory_length 2000, epsilon 0.038098871091122845, time 727.0, rides 138\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 3629, reward 645.0, memory_length 2000, epsilon 0.03806458210714083, time 733.0, rides 120\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 3630, reward 1143.0, memory_length 2000, epsilon 0.0380303239832444, time 734.0, rides 143\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 3631, reward 944.0, memory_length 2000, epsilon 0.03799609669165948, time 724.0, rides 135\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 3632, reward 853.0, memory_length 2000, epsilon 0.03796190020463699, time 727.0, rides 127\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 3633, reward 833.0, memory_length 2000, epsilon 0.03792773449445282, time 723.0, rides 127\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 3634, reward 896.0, memory_length 2000, epsilon 0.03789359953340781, time 732.0, rides 123\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 3635, reward 985.0, memory_length 2000, epsilon 0.03785949529382775, time 726.0, rides 124\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3636, reward 849.0, memory_length 2000, epsilon 0.037825421748063304, time 725.0, rides 138\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 3637, reward 1087.0, memory_length 2000, epsilon 0.037791378868490044, time 728.0, rides 123\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 3638, reward 557.0, memory_length 2000, epsilon 0.0377573666275084, time 729.0, rides 128\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 3639, reward 1088.0, memory_length 2000, epsilon 0.037723384997543644, time 730.0, rides 126\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 3640, reward 929.0, memory_length 2000, epsilon 0.037689433951045855, time 730.0, rides 129\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 3641, reward 945.0, memory_length 2000, epsilon 0.03765551346048991, time 731.0, rides 131\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 3642, reward 691.0, memory_length 2000, epsilon 0.03762162349837547, time 729.0, rides 118\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3643, reward 885.0, memory_length 2000, epsilon 0.03758776403722693, time 729.0, rides 142\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3644, reward 949.0, memory_length 2000, epsilon 0.03755393504959343, time 734.0, rides 141\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 3645, reward 811.0, memory_length 2000, epsilon 0.03752013650804879, time 730.0, rides 142\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 3646, reward 988.0, memory_length 2000, epsilon 0.03748636838519155, time 726.0, rides 131\n",
      "Initial State is  [0, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3647, reward 524.0, memory_length 2000, epsilon 0.03745263065364488, time 728.0, rides 121\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 3648, reward 708.0, memory_length 2000, epsilon 0.0374189232860566, time 728.0, rides 116\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 3649, reward 701.0, memory_length 2000, epsilon 0.03738524625509915, time 731.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 3650, reward 783.0, memory_length 2000, epsilon 0.03735159953346956, time 733.0, rides 140\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 3651, reward 900.0, memory_length 2000, epsilon 0.03731798309388944, time 729.0, rides 135\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3652, reward 1015.0, memory_length 2000, epsilon 0.037284396909104935, time 728.0, rides 136\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 3653, reward 1167.0, memory_length 2000, epsilon 0.037250840951886736, time 732.0, rides 133\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 3654, reward 1323.0, memory_length 2000, epsilon 0.037217315195030035, time 730.0, rides 124\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3655, reward 996.0, memory_length 2000, epsilon 0.03718381961135451, time 723.0, rides 127\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 3656, reward 928.0, memory_length 2000, epsilon 0.03715035417370429, time 725.0, rides 122\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 3657, reward 1106.0, memory_length 2000, epsilon 0.03711691885494796, time 725.0, rides 133\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 3658, reward 676.0, memory_length 2000, epsilon 0.03708351362797851, time 733.0, rides 136\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 3659, reward 1139.0, memory_length 2000, epsilon 0.037050138465713325, time 729.0, rides 137\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 3660, reward 1150.0, memory_length 2000, epsilon 0.03701679334109418, time 725.0, rides 133\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3661, reward 1084.0, memory_length 2000, epsilon 0.036983478227087196, time 730.0, rides 132\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3662, reward 778.0, memory_length 2000, epsilon 0.03695019309668282, time 728.0, rides 136\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 3663, reward 342.0, memory_length 2000, epsilon 0.036916937922895805, time 727.0, rides 119\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 3664, reward 961.0, memory_length 2000, epsilon 0.036883712678765196, time 727.0, rides 138\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 3665, reward 1111.0, memory_length 2000, epsilon 0.036850517337354304, time 726.0, rides 153\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3666, reward 1085.0, memory_length 2000, epsilon 0.036817351871750684, time 725.0, rides 126\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 3667, reward 1224.0, memory_length 2000, epsilon 0.03678421625506611, time 729.0, rides 129\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 3668, reward 872.0, memory_length 2000, epsilon 0.03675111046043655, time 731.0, rides 137\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3669, reward 1072.0, memory_length 2000, epsilon 0.036718034461022155, time 722.0, rides 125\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 3670, reward 1008.0, memory_length 2000, epsilon 0.03668498823000724, time 725.0, rides 140\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3671, reward 915.0, memory_length 2000, epsilon 0.03665197174060023, time 732.0, rides 120\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 3672, reward 895.0, memory_length 2000, epsilon 0.03661898496603369, time 730.0, rides 145\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3673, reward 937.0, memory_length 2000, epsilon 0.03658602787956426, time 729.0, rides 129\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 3674, reward 1003.0, memory_length 2000, epsilon 0.03655310045447265, time 734.0, rides 149\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 3675, reward 1045.0, memory_length 2000, epsilon 0.036520202664063625, time 727.0, rides 138\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 3676, reward 585.0, memory_length 2000, epsilon 0.03648733448166597, time 732.0, rides 131\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 3677, reward 1150.0, memory_length 2000, epsilon 0.036454495880632466, time 735.0, rides 142\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 3678, reward 975.0, memory_length 2000, epsilon 0.0364216868343399, time 729.0, rides 130\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 3679, reward 654.0, memory_length 2000, epsilon 0.03638890731618899, time 736.0, rides 132\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 3680, reward 686.0, memory_length 2000, epsilon 0.03635615729960442, time 729.0, rides 130\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 3681, reward 913.0, memory_length 2000, epsilon 0.036323436758034774, time 727.0, rides 138\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 3682, reward 659.0, memory_length 2000, epsilon 0.036290745664952544, time 726.0, rides 127\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3683, reward 1006.0, memory_length 2000, epsilon 0.036258083993854086, time 731.0, rides 149\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 3684, reward 793.0, memory_length 2000, epsilon 0.03622545171825962, time 729.0, rides 151\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 3685, reward 854.0, memory_length 2000, epsilon 0.03619284881171318, time 729.0, rides 132\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 3686, reward 897.0, memory_length 2000, epsilon 0.03616027524778264, time 734.0, rides 140\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 3687, reward 985.0, memory_length 2000, epsilon 0.036127731000059636, time 726.0, rides 136\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 3688, reward 874.0, memory_length 2000, epsilon 0.03609521604215958, time 738.0, rides 135\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3689, reward 1012.0, memory_length 2000, epsilon 0.03606273034772164, time 726.0, rides 128\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 3690, reward 1168.0, memory_length 2000, epsilon 0.036030273890408686, time 725.0, rides 131\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 3691, reward 1110.0, memory_length 2000, epsilon 0.035997846643907316, time 724.0, rides 135\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3692, reward 1043.0, memory_length 2000, epsilon 0.0359654485819278, time 729.0, rides 127\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3693, reward 883.0, memory_length 2000, epsilon 0.03593307967820407, time 730.0, rides 136\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 3694, reward 564.0, memory_length 2000, epsilon 0.03590073990649369, time 722.0, rides 131\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 3695, reward 637.0, memory_length 2000, epsilon 0.03586842924057784, time 727.0, rides 143\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 3696, reward 831.0, memory_length 2000, epsilon 0.035836147654261324, time 727.0, rides 131\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3697, reward 643.0, memory_length 2000, epsilon 0.03580389512137249, time 722.0, rides 129\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3698, reward 968.0, memory_length 2000, epsilon 0.03577167161576326, time 728.0, rides 143\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 3699, reward 1056.0, memory_length 2000, epsilon 0.03573947711130907, time 730.0, rides 147\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 3700, reward 878.0, memory_length 2000, epsilon 0.035707311581908895, time 726.0, rides 128\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3701, reward 1029.0, memory_length 2000, epsilon 0.035675175001485177, time 732.0, rides 145\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 3702, reward 1000.0, memory_length 2000, epsilon 0.03564306734398384, time 725.0, rides 135\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 3703, reward 734.0, memory_length 2000, epsilon 0.035610988583374255, time 726.0, rides 143\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3704, reward 664.0, memory_length 2000, epsilon 0.03557893869364922, time 728.0, rides 130\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 3705, reward 803.0, memory_length 2000, epsilon 0.035546917648824936, time 730.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 3706, reward 936.0, memory_length 2000, epsilon 0.03551492542294099, time 726.0, rides 128\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3707, reward 1151.0, memory_length 2000, epsilon 0.03548296199006035, time 723.0, rides 145\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 3708, reward 968.0, memory_length 2000, epsilon 0.035451027324269295, time 723.0, rides 124\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 3709, reward 895.0, memory_length 2000, epsilon 0.035419121399677456, time 724.0, rides 127\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 3710, reward 1011.0, memory_length 2000, epsilon 0.03538724419041774, time 730.0, rides 131\n",
      "Initial State is  [1, 0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3711, reward 917.0, memory_length 2000, epsilon 0.03535539567064636, time 731.0, rides 135\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 3712, reward 931.0, memory_length 2000, epsilon 0.03532357581454278, time 725.0, rides 147\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 3713, reward 1083.0, memory_length 2000, epsilon 0.035291784596309696, time 724.0, rides 129\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3714, reward 976.0, memory_length 2000, epsilon 0.035260021990173016, time 732.0, rides 137\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 3715, reward 683.0, memory_length 2000, epsilon 0.03522828797038186, time 726.0, rides 129\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3716, reward 925.0, memory_length 2000, epsilon 0.03519658251120852, time 726.0, rides 147\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 3717, reward 1021.0, memory_length 2000, epsilon 0.03516490558694843, time 724.0, rides 134\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3718, reward 1411.0, memory_length 2000, epsilon 0.035133257171920174, time 724.0, rides 139\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3719, reward 746.0, memory_length 2000, epsilon 0.035101637240465444, time 723.0, rides 132\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 3720, reward 1091.0, memory_length 2000, epsilon 0.035070045766949026, time 731.0, rides 149\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 3721, reward 1019.0, memory_length 2000, epsilon 0.03503848272575877, time 734.0, rides 138\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 3722, reward 1110.0, memory_length 2000, epsilon 0.035006948091305584, time 730.0, rides 137\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3723, reward 1075.0, memory_length 2000, epsilon 0.03497544183802341, time 727.0, rides 131\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3724, reward 1052.0, memory_length 2000, epsilon 0.03494396394036919, time 723.0, rides 131\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 3725, reward 897.0, memory_length 2000, epsilon 0.034912514372822855, time 728.0, rides 133\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3726, reward 597.0, memory_length 2000, epsilon 0.034881093109887316, time 732.0, rides 138\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 3727, reward 780.0, memory_length 2000, epsilon 0.034849700126088415, time 732.0, rides 131\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 3728, reward 846.0, memory_length 2000, epsilon 0.03481833539597493, time 722.0, rides 140\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 3729, reward 780.0, memory_length 2000, epsilon 0.034786998894118557, time 727.0, rides 128\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 3730, reward 705.0, memory_length 2000, epsilon 0.03475569059511385, time 731.0, rides 127\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 3731, reward 794.0, memory_length 2000, epsilon 0.03472441047357825, time 731.0, rides 136\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3732, reward 834.0, memory_length 2000, epsilon 0.03469315850415203, time 722.0, rides 139\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 3733, reward 1096.0, memory_length 2000, epsilon 0.03466193466149829, time 728.0, rides 142\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 3734, reward 1057.0, memory_length 2000, epsilon 0.034630738920302946, time 729.0, rides 134\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 3735, reward 1250.0, memory_length 2000, epsilon 0.03459957125527467, time 730.0, rides 119\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3736, reward 859.0, memory_length 2000, epsilon 0.034568431641144926, time 727.0, rides 132\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3737, reward 950.0, memory_length 2000, epsilon 0.034537320052667894, time 733.0, rides 131\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 3738, reward 1270.0, memory_length 2000, epsilon 0.03450623646462049, time 731.0, rides 130\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 3739, reward 1091.0, memory_length 2000, epsilon 0.03447518085180233, time 724.0, rides 145\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3740, reward 1079.0, memory_length 2000, epsilon 0.03444415318903571, time 726.0, rides 142\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3741, reward 1102.0, memory_length 2000, epsilon 0.03441315345116558, time 731.0, rides 146\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 3742, reward 1074.0, memory_length 2000, epsilon 0.03438218161305953, time 735.0, rides 132\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 3743, reward 1321.0, memory_length 2000, epsilon 0.03435123764960778, time 720.0, rides 134\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3744, reward 910.0, memory_length 2000, epsilon 0.034320321535723126, time 734.0, rides 138\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 3745, reward 900.0, memory_length 2000, epsilon 0.034289433246340977, time 735.0, rides 140\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3746, reward 1098.0, memory_length 2000, epsilon 0.03425857275641927, time 731.0, rides 134\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 3747, reward 1097.0, memory_length 2000, epsilon 0.03422774004093849, time 730.0, rides 130\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 3748, reward 1010.0, memory_length 2000, epsilon 0.034196935074901645, time 725.0, rides 132\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3749, reward 711.0, memory_length 2000, epsilon 0.03416615783333423, time 730.0, rides 134\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3750, reward 954.0, memory_length 2000, epsilon 0.03413540829128423, time 723.0, rides 120\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 3751, reward 1133.0, memory_length 2000, epsilon 0.03410468642382208, time 730.0, rides 131\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3752, reward 915.0, memory_length 2000, epsilon 0.03407399220604063, time 738.0, rides 132\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 3753, reward 928.0, memory_length 2000, epsilon 0.034043325613055196, time 729.0, rides 130\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3754, reward 821.0, memory_length 2000, epsilon 0.034012686620003445, time 730.0, rides 123\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3755, reward 1083.0, memory_length 2000, epsilon 0.03398207520204544, time 729.0, rides 139\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3756, reward 822.0, memory_length 2000, epsilon 0.0339514913343636, time 732.0, rides 127\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3757, reward 951.0, memory_length 2000, epsilon 0.03392093499216267, time 725.0, rides 128\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 3758, reward 764.0, memory_length 2000, epsilon 0.033890406150669725, time 734.0, rides 129\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 3759, reward 795.0, memory_length 2000, epsilon 0.03385990478513412, time 724.0, rides 138\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 3760, reward 738.0, memory_length 2000, epsilon 0.0338294308708275, time 736.0, rides 131\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3761, reward 979.0, memory_length 2000, epsilon 0.033798984383043754, time 727.0, rides 123\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3762, reward 1022.0, memory_length 2000, epsilon 0.03376856529709901, time 726.0, rides 134\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 3763, reward 860.0, memory_length 2000, epsilon 0.03373817358833162, time 730.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3764, reward 965.0, memory_length 2000, epsilon 0.03370780923210212, time 724.0, rides 142\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3765, reward 879.0, memory_length 2000, epsilon 0.033677472203793225, time 733.0, rides 134\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3766, reward 860.0, memory_length 2000, epsilon 0.03364716247880981, time 726.0, rides 155\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3767, reward 883.0, memory_length 2000, epsilon 0.033616880032578886, time 729.0, rides 128\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3768, reward 1053.0, memory_length 2000, epsilon 0.03358662484054956, time 729.0, rides 125\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 3769, reward 832.0, memory_length 2000, epsilon 0.03355639687819307, time 730.0, rides 148\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 3770, reward 1152.0, memory_length 2000, epsilon 0.033526196121002695, time 731.0, rides 132\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3771, reward 1073.0, memory_length 2000, epsilon 0.03349602254449379, time 734.0, rides 145\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3772, reward 1031.0, memory_length 2000, epsilon 0.03346587612420374, time 734.0, rides 132\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 3773, reward 1119.0, memory_length 2000, epsilon 0.03343575683569196, time 735.0, rides 134\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 3774, reward 1194.0, memory_length 2000, epsilon 0.033405664654539834, time 733.0, rides 151\n",
      "Initial State is  [2, 20, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3775, reward 596.0, memory_length 2000, epsilon 0.03337559955635075, time 720.0, rides 141\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 3776, reward 965.0, memory_length 2000, epsilon 0.033345561516750034, time 724.0, rides 154\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3777, reward 1074.0, memory_length 2000, epsilon 0.03331555051138496, time 735.0, rides 127\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3778, reward 1119.0, memory_length 2000, epsilon 0.033285566515924715, time 727.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3779, reward 1036.0, memory_length 2000, epsilon 0.03325560950606038, time 728.0, rides 140\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 3780, reward 795.0, memory_length 2000, epsilon 0.033225679457504924, time 727.0, rides 126\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 3781, reward 686.0, memory_length 2000, epsilon 0.03319577634599317, time 723.0, rides 135\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 3782, reward 768.0, memory_length 2000, epsilon 0.033165900147281775, time 730.0, rides 141\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 3783, reward 917.0, memory_length 2000, epsilon 0.03313605083714922, time 723.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 3784, reward 996.0, memory_length 2000, epsilon 0.033106228391395785, time 723.0, rides 127\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 3785, reward 794.0, memory_length 2000, epsilon 0.03307643278584353, time 729.0, rides 139\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 3786, reward 883.0, memory_length 2000, epsilon 0.033046663996336274, time 728.0, rides 124\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3787, reward 644.0, memory_length 2000, epsilon 0.03301692199873957, time 732.0, rides 127\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 3788, reward 1448.0, memory_length 2000, epsilon 0.0329872067689407, time 735.0, rides 142\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 3789, reward 657.0, memory_length 2000, epsilon 0.03295751828284865, time 729.0, rides 129\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3790, reward 1120.0, memory_length 2000, epsilon 0.032927856516394086, time 726.0, rides 132\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3791, reward 1007.0, memory_length 2000, epsilon 0.032898221445529334, time 731.0, rides 130\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 3792, reward 1171.0, memory_length 2000, epsilon 0.03286861304622836, time 725.0, rides 142\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 3793, reward 1082.0, memory_length 2000, epsilon 0.03283903129448675, time 736.0, rides 135\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 3794, reward 1185.0, memory_length 2000, epsilon 0.03280947616632171, time 737.0, rides 136\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 3795, reward 877.0, memory_length 2000, epsilon 0.03277994763777202, time 726.0, rides 127\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 3796, reward 1179.0, memory_length 2000, epsilon 0.03275044568489802, time 731.0, rides 132\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 3797, reward 846.0, memory_length 2000, epsilon 0.03272097028378161, time 739.0, rides 140\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 3798, reward 1245.0, memory_length 2000, epsilon 0.032691521410526204, time 725.0, rides 131\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 3799, reward 945.0, memory_length 2000, epsilon 0.03266209904125673, time 730.0, rides 137\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3800, reward 1074.0, memory_length 2000, epsilon 0.032632703152119594, time 724.0, rides 146\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 3801, reward 908.0, memory_length 2000, epsilon 0.03260333371928269, time 736.0, rides 122\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 3802, reward 894.0, memory_length 2000, epsilon 0.03257399071893533, time 735.0, rides 138\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 3803, reward 973.0, memory_length 2000, epsilon 0.03254467412728829, time 727.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3804, reward 880.0, memory_length 2000, epsilon 0.03251538392057373, time 728.0, rides 124\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 3805, reward 1096.0, memory_length 2000, epsilon 0.03248612007504521, time 722.0, rides 152\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3806, reward 523.0, memory_length 2000, epsilon 0.03245688256697767, time 730.0, rides 129\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 3807, reward 868.0, memory_length 2000, epsilon 0.032427671372667395, time 723.0, rides 130\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 3808, reward 914.0, memory_length 2000, epsilon 0.03239848646843199, time 723.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 3809, reward 640.0, memory_length 2000, epsilon 0.0323693278306104, time 729.0, rides 131\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 3810, reward 550.0, memory_length 2000, epsilon 0.03234019543556285, time 726.0, rides 146\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3811, reward 1017.0, memory_length 2000, epsilon 0.03231108925967084, time 726.0, rides 142\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 3812, reward 1110.0, memory_length 2000, epsilon 0.03228200927933714, time 726.0, rides 154\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 3813, reward 1069.0, memory_length 2000, epsilon 0.032252955470985736, time 724.0, rides 134\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 3814, reward 672.0, memory_length 2000, epsilon 0.03222392781106185, time 722.0, rides 131\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3815, reward 637.0, memory_length 2000, epsilon 0.03219492627603189, time 725.0, rides 124\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 3816, reward 1188.0, memory_length 2000, epsilon 0.03216595084238346, time 725.0, rides 130\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 3817, reward 1007.0, memory_length 2000, epsilon 0.032137001486625315, time 724.0, rides 137\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 3818, reward 941.0, memory_length 2000, epsilon 0.03210807818528735, time 728.0, rides 126\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 3819, reward 1091.0, memory_length 2000, epsilon 0.032079180914920596, time 728.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3820, reward 1163.0, memory_length 2000, epsilon 0.03205030965209717, time 731.0, rides 139\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3821, reward 1155.0, memory_length 2000, epsilon 0.03202146437341028, time 728.0, rides 135\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 3822, reward 1096.0, memory_length 2000, epsilon 0.03199264505547421, time 729.0, rides 136\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3823, reward 725.0, memory_length 2000, epsilon 0.031963851674924285, time 723.0, rides 130\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 3824, reward 1311.0, memory_length 2000, epsilon 0.031935084208416856, time 729.0, rides 124\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 3825, reward 1073.0, memory_length 2000, epsilon 0.03190634263262928, time 731.0, rides 133\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 3826, reward 949.0, memory_length 2000, epsilon 0.03187762692425991, time 725.0, rides 140\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 3827, reward 952.0, memory_length 2000, epsilon 0.031848937060028074, time 726.0, rides 142\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 3828, reward 1157.0, memory_length 2000, epsilon 0.03182027301667405, time 722.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 3829, reward 1109.0, memory_length 2000, epsilon 0.03179163477095904, time 736.0, rides 135\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 3830, reward 867.0, memory_length 2000, epsilon 0.031763022299665176, time 732.0, rides 134\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3831, reward 874.0, memory_length 2000, epsilon 0.031734435579595474, time 725.0, rides 127\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 3832, reward 767.0, memory_length 2000, epsilon 0.03170587458757384, time 721.0, rides 120\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3833, reward 1032.0, memory_length 2000, epsilon 0.03167733930044502, time 729.0, rides 138\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 3834, reward 685.0, memory_length 2000, epsilon 0.03164882969507462, time 727.0, rides 133\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3835, reward 1035.0, memory_length 2000, epsilon 0.03162034574834905, time 729.0, rides 134\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3836, reward 853.0, memory_length 2000, epsilon 0.03159188743717554, time 730.0, rides 130\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 3837, reward 1171.0, memory_length 2000, epsilon 0.03156345473848208, time 731.0, rides 142\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 3838, reward 981.0, memory_length 2000, epsilon 0.031535047629217446, time 728.0, rides 139\n",
      "Initial State is  [4, 8, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3839, reward 860.0, memory_length 2000, epsilon 0.03150666608635115, time 729.0, rides 143\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 3840, reward 929.0, memory_length 2000, epsilon 0.031478310086873434, time 731.0, rides 142\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 3841, reward 655.0, memory_length 2000, epsilon 0.03144997960779525, time 732.0, rides 138\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 3842, reward 1154.0, memory_length 2000, epsilon 0.031421674626148234, time 725.0, rides 130\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 3843, reward 716.0, memory_length 2000, epsilon 0.0313933951189847, time 725.0, rides 128\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3844, reward 1151.0, memory_length 2000, epsilon 0.031365141063377615, time 722.0, rides 141\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 3845, reward 1051.0, memory_length 2000, epsilon 0.031336912436420575, time 736.0, rides 142\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3846, reward 1137.0, memory_length 2000, epsilon 0.0313087092152278, time 727.0, rides 124\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 3847, reward 1218.0, memory_length 2000, epsilon 0.031280531376934095, time 736.0, rides 148\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 3848, reward 865.0, memory_length 2000, epsilon 0.03125237889869485, time 737.0, rides 127\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 3849, reward 965.0, memory_length 2000, epsilon 0.031224251757686027, time 728.0, rides 128\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3850, reward 791.0, memory_length 2000, epsilon 0.03119614993110411, time 727.0, rides 146\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3851, reward 1108.0, memory_length 2000, epsilon 0.031168073396166115, time 727.0, rides 138\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 3852, reward 780.0, memory_length 2000, epsilon 0.031140022130109565, time 723.0, rides 142\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3853, reward 456.0, memory_length 2000, epsilon 0.031111996110192466, time 725.0, rides 135\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3854, reward 699.0, memory_length 2000, epsilon 0.031083995313693293, time 730.0, rides 136\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 3855, reward 896.0, memory_length 2000, epsilon 0.031056019717910967, time 725.0, rides 140\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 3856, reward 844.0, memory_length 2000, epsilon 0.031028069300164846, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 3857, reward 686.0, memory_length 2000, epsilon 0.031000144037794698, time 731.0, rides 134\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 3858, reward 913.0, memory_length 2000, epsilon 0.030972243908160682, time 728.0, rides 132\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3859, reward 574.0, memory_length 2000, epsilon 0.030944368888643336, time 734.0, rides 153\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 3860, reward 875.0, memory_length 2000, epsilon 0.030916518956643557, time 733.0, rides 147\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 3861, reward 985.0, memory_length 2000, epsilon 0.030888694089582575, time 720.0, rides 141\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3862, reward 1237.0, memory_length 2000, epsilon 0.03086089426490195, time 727.0, rides 141\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 3863, reward 1267.0, memory_length 2000, epsilon 0.03083311946006354, time 727.0, rides 137\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 3864, reward 968.0, memory_length 2000, epsilon 0.030805369652549482, time 726.0, rides 124\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 3865, reward 980.0, memory_length 2000, epsilon 0.03077764481986219, time 730.0, rides 143\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 3866, reward 853.0, memory_length 2000, epsilon 0.03074994493952431, time 733.0, rides 122\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3867, reward 1247.0, memory_length 2000, epsilon 0.03072226998907874, time 731.0, rides 147\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 3868, reward 1125.0, memory_length 2000, epsilon 0.030694619946088568, time 728.0, rides 137\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 3869, reward 1063.0, memory_length 2000, epsilon 0.030666994788137086, time 721.0, rides 137\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 3870, reward 901.0, memory_length 2000, epsilon 0.03063939449282776, time 728.0, rides 135\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3871, reward 1130.0, memory_length 2000, epsilon 0.030611819037784215, time 729.0, rides 128\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3872, reward 788.0, memory_length 2000, epsilon 0.03058426840065021, time 729.0, rides 129\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 3873, reward 965.0, memory_length 2000, epsilon 0.030556742559089623, time 734.0, rides 131\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 3874, reward 1299.0, memory_length 2000, epsilon 0.03052924149078644, time 726.0, rides 140\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 3875, reward 939.0, memory_length 2000, epsilon 0.030501765173444734, time 724.0, rides 144\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 3876, reward 951.0, memory_length 2000, epsilon 0.030474313584788634, time 730.0, rides 132\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3877, reward 989.0, memory_length 2000, epsilon 0.030446886702562324, time 726.0, rides 137\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3878, reward 611.0, memory_length 2000, epsilon 0.03041948450453002, time 736.0, rides 133\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3879, reward 1005.0, memory_length 2000, epsilon 0.03039210696847594, time 725.0, rides 143\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3880, reward 885.0, memory_length 2000, epsilon 0.030364754072204313, time 732.0, rides 147\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 3881, reward 1221.0, memory_length 2000, epsilon 0.03033742579353933, time 733.0, rides 148\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 3882, reward 868.0, memory_length 2000, epsilon 0.030310122110325143, time 730.0, rides 155\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 3883, reward 1042.0, memory_length 2000, epsilon 0.03028284300042585, time 725.0, rides 132\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3884, reward 992.0, memory_length 2000, epsilon 0.03025558844172547, time 729.0, rides 132\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 3885, reward 1009.0, memory_length 2000, epsilon 0.030228358412127915, time 724.0, rides 146\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 3886, reward 844.0, memory_length 2000, epsilon 0.030201152889557, time 727.0, rides 127\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 3887, reward 901.0, memory_length 2000, epsilon 0.0301739718519564, time 732.0, rides 151\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 3888, reward 904.0, memory_length 2000, epsilon 0.030146815277289636, time 727.0, rides 148\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 3889, reward 767.0, memory_length 2000, epsilon 0.030119683143540073, time 730.0, rides 132\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3890, reward 971.0, memory_length 2000, epsilon 0.030092575428710886, time 727.0, rides 130\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3891, reward 1179.0, memory_length 2000, epsilon 0.030065492110825046, time 738.0, rides 135\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3892, reward 825.0, memory_length 2000, epsilon 0.030038433167925302, time 736.0, rides 134\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 3893, reward 632.0, memory_length 2000, epsilon 0.03001139857807417, time 734.0, rides 134\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3894, reward 986.0, memory_length 2000, epsilon 0.0299843883193539, time 723.0, rides 145\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 3895, reward 1066.0, memory_length 2000, epsilon 0.029957402369866482, time 734.0, rides 135\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 3896, reward 1117.0, memory_length 2000, epsilon 0.029930440707733603, time 729.0, rides 152\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 3897, reward 986.0, memory_length 2000, epsilon 0.029903503311096643, time 730.0, rides 133\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 3898, reward 980.0, memory_length 2000, epsilon 0.029876590158116657, time 722.0, rides 126\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 3899, reward 809.0, memory_length 2000, epsilon 0.029849701226974352, time 724.0, rides 138\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 3900, reward 866.0, memory_length 2000, epsilon 0.029822836495870076, time 732.0, rides 137\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 3901, reward 890.0, memory_length 2000, epsilon 0.029795995943023793, time 730.0, rides 131\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 3902, reward 950.0, memory_length 2000, epsilon 0.029769179546675073, time 727.0, rides 136\n",
      "Initial State is  [3, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3903, reward 1092.0, memory_length 2000, epsilon 0.029742387285083063, time 725.0, rides 145\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 3904, reward 892.0, memory_length 2000, epsilon 0.029715619136526487, time 729.0, rides 158\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 3905, reward 1207.0, memory_length 2000, epsilon 0.029688875079303612, time 731.0, rides 143\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3906, reward 829.0, memory_length 2000, epsilon 0.02966215509173224, time 729.0, rides 126\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 3907, reward 1143.0, memory_length 2000, epsilon 0.02963545915214968, time 736.0, rides 141\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 3908, reward 943.0, memory_length 2000, epsilon 0.029608787238912745, time 724.0, rides 132\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3909, reward 1070.0, memory_length 2000, epsilon 0.029582139330397723, time 723.0, rides 135\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 3910, reward 909.0, memory_length 2000, epsilon 0.029555515405000364, time 734.0, rides 126\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 3911, reward 1206.0, memory_length 2000, epsilon 0.029528915441135863, time 729.0, rides 129\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 3912, reward 756.0, memory_length 2000, epsilon 0.02950233941723884, time 726.0, rides 134\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 3913, reward 833.0, memory_length 2000, epsilon 0.029475787311763323, time 722.0, rides 136\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3914, reward 1145.0, memory_length 2000, epsilon 0.029449259103182735, time 730.0, rides 136\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 3915, reward 1000.0, memory_length 2000, epsilon 0.02942275476998987, time 728.0, rides 141\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3916, reward 836.0, memory_length 2000, epsilon 0.02939627429069688, time 729.0, rides 122\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 3917, reward 498.0, memory_length 2000, epsilon 0.029369817643835252, time 723.0, rides 124\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 3918, reward 728.0, memory_length 2000, epsilon 0.0293433848079558, time 729.0, rides 120\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 3919, reward 860.0, memory_length 2000, epsilon 0.02931697576162864, time 733.0, rides 134\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3920, reward 1055.0, memory_length 2000, epsilon 0.029290590483443176, time 727.0, rides 141\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3921, reward 769.0, memory_length 2000, epsilon 0.029264228952008076, time 732.0, rides 133\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 3922, reward 986.0, memory_length 2000, epsilon 0.02923789114595127, time 724.0, rides 136\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 3923, reward 949.0, memory_length 2000, epsilon 0.029211577043919915, time 722.0, rides 128\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 3924, reward 1057.0, memory_length 2000, epsilon 0.02918528662458039, time 728.0, rides 133\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3925, reward 756.0, memory_length 2000, epsilon 0.029159019866618265, time 727.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 3926, reward 692.0, memory_length 2000, epsilon 0.029132776748738307, time 731.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3927, reward 829.0, memory_length 2000, epsilon 0.02910655724966444, time 731.0, rides 136\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 3928, reward 1071.0, memory_length 2000, epsilon 0.029080361348139742, time 725.0, rides 138\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 3929, reward 587.0, memory_length 2000, epsilon 0.029054189022926415, time 728.0, rides 130\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3930, reward 977.0, memory_length 2000, epsilon 0.02902804025280578, time 733.0, rides 126\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 3931, reward 1301.0, memory_length 2000, epsilon 0.029001915016578256, time 731.0, rides 132\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3932, reward 912.0, memory_length 2000, epsilon 0.028975813293063334, time 723.0, rides 121\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 3933, reward 795.0, memory_length 2000, epsilon 0.028949735061099578, time 734.0, rides 133\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 3934, reward 1215.0, memory_length 2000, epsilon 0.028923680299544587, time 729.0, rides 132\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 3935, reward 930.0, memory_length 2000, epsilon 0.028897648987274996, time 722.0, rides 136\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 3936, reward 1154.0, memory_length 2000, epsilon 0.02887164110318645, time 727.0, rides 141\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 3937, reward 731.0, memory_length 2000, epsilon 0.02884565662619358, time 727.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3938, reward 906.0, memory_length 2000, epsilon 0.028819695535230005, time 728.0, rides 119\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 3939, reward 959.0, memory_length 2000, epsilon 0.028793757809248297, time 725.0, rides 123\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 3940, reward 1097.0, memory_length 2000, epsilon 0.028767843427219972, time 728.0, rides 137\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 3941, reward 1064.0, memory_length 2000, epsilon 0.028741952368135475, time 722.0, rides 137\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 3942, reward 761.0, memory_length 2000, epsilon 0.028716084611004153, time 727.0, rides 128\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 3943, reward 941.0, memory_length 2000, epsilon 0.028690240134854248, time 727.0, rides 129\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3944, reward 1136.0, memory_length 2000, epsilon 0.02866441891873288, time 723.0, rides 123\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 3945, reward 794.0, memory_length 2000, epsilon 0.02863862094170602, time 732.0, rides 142\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 3946, reward 1054.0, memory_length 2000, epsilon 0.028612846182858483, time 728.0, rides 142\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 3947, reward 1060.0, memory_length 2000, epsilon 0.02858709462129391, time 733.0, rides 128\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 3948, reward 1032.0, memory_length 2000, epsilon 0.028561366236134745, time 731.0, rides 127\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 3949, reward 814.0, memory_length 2000, epsilon 0.028535661006522224, time 726.0, rides 136\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3950, reward 886.0, memory_length 2000, epsilon 0.028509978911616354, time 729.0, rides 131\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 3951, reward 999.0, memory_length 2000, epsilon 0.0284843199305959, time 726.0, rides 138\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 3952, reward 1131.0, memory_length 2000, epsilon 0.028458684042658364, time 725.0, rides 120\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 3953, reward 1063.0, memory_length 2000, epsilon 0.028433071227019973, time 727.0, rides 148\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 3954, reward 1006.0, memory_length 2000, epsilon 0.028407481462915656, time 733.0, rides 135\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3955, reward 1148.0, memory_length 2000, epsilon 0.02838191472959903, time 732.0, rides 142\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 3956, reward 910.0, memory_length 2000, epsilon 0.028356371006342394, time 725.0, rides 140\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 3957, reward 1056.0, memory_length 2000, epsilon 0.028330850272436685, time 727.0, rides 124\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 3958, reward 992.0, memory_length 2000, epsilon 0.028305352507191493, time 725.0, rides 128\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 3959, reward 1024.0, memory_length 2000, epsilon 0.02827987768993502, time 726.0, rides 137\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 3960, reward 935.0, memory_length 2000, epsilon 0.02825442580001408, time 727.0, rides 127\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 3961, reward 1017.0, memory_length 2000, epsilon 0.028228996816794066, time 732.0, rides 144\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 3962, reward 970.0, memory_length 2000, epsilon 0.02820359071965895, time 733.0, rides 123\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 3963, reward 1146.0, memory_length 2000, epsilon 0.028178207488011257, time 727.0, rides 128\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3964, reward 984.0, memory_length 2000, epsilon 0.028152847101272045, time 724.0, rides 131\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 3965, reward 975.0, memory_length 2000, epsilon 0.0281275095388809, time 737.0, rides 127\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3966, reward 825.0, memory_length 2000, epsilon 0.028102194780295908, time 728.0, rides 125\n",
      "Initial State is  [4, 21, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3967, reward 906.0, memory_length 2000, epsilon 0.028076902804993642, time 722.0, rides 128\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 3968, reward 768.0, memory_length 2000, epsilon 0.028051633592469146, time 725.0, rides 134\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 3969, reward 1003.0, memory_length 2000, epsilon 0.028026387122235923, time 729.0, rides 125\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 3970, reward 695.0, memory_length 2000, epsilon 0.02800116337382591, time 731.0, rides 126\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 3971, reward 989.0, memory_length 2000, epsilon 0.027975962326789467, time 722.0, rides 133\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 3972, reward 1298.0, memory_length 2000, epsilon 0.027950783960695356, time 728.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 3973, reward 1279.0, memory_length 2000, epsilon 0.02792562825513073, time 733.0, rides 140\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 3974, reward 1141.0, memory_length 2000, epsilon 0.027900495189701113, time 733.0, rides 136\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3975, reward 947.0, memory_length 2000, epsilon 0.027875384744030382, time 729.0, rides 131\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3976, reward 561.0, memory_length 2000, epsilon 0.027850296897760755, time 729.0, rides 137\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 3977, reward 938.0, memory_length 2000, epsilon 0.02782523163055277, time 728.0, rides 127\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 3978, reward 1185.0, memory_length 2000, epsilon 0.02780018892208527, time 739.0, rides 137\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3979, reward 850.0, memory_length 2000, epsilon 0.027775168752055393, time 726.0, rides 130\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3980, reward 822.0, memory_length 2000, epsilon 0.027750171100178543, time 728.0, rides 126\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3981, reward 1110.0, memory_length 2000, epsilon 0.027725195946188382, time 729.0, rides 125\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3982, reward 791.0, memory_length 2000, epsilon 0.027700243269836812, time 726.0, rides 127\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 3983, reward 1095.0, memory_length 2000, epsilon 0.02767531305089396, time 727.0, rides 140\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3984, reward 1093.0, memory_length 2000, epsilon 0.027650405269148155, time 729.0, rides 137\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 3985, reward 1089.0, memory_length 2000, epsilon 0.02762551990440592, time 729.0, rides 137\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 3986, reward 605.0, memory_length 2000, epsilon 0.027600656936491955, time 729.0, rides 126\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 3987, reward 736.0, memory_length 2000, epsilon 0.02757581634524911, time 731.0, rides 128\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 3988, reward 1103.0, memory_length 2000, epsilon 0.027550998110538384, time 729.0, rides 135\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3989, reward 728.0, memory_length 2000, epsilon 0.0275262022122389, time 736.0, rides 136\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 3990, reward 782.0, memory_length 2000, epsilon 0.027501428630247883, time 734.0, rides 133\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 3991, reward 1377.0, memory_length 2000, epsilon 0.02747667734448066, time 731.0, rides 136\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 3992, reward 887.0, memory_length 2000, epsilon 0.027451948334870628, time 726.0, rides 125\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3993, reward 1315.0, memory_length 2000, epsilon 0.027427241581369242, time 728.0, rides 126\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 3994, reward 856.0, memory_length 2000, epsilon 0.02740255706394601, time 725.0, rides 128\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 3995, reward 800.0, memory_length 2000, epsilon 0.027377894762588458, time 734.0, rides 136\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 3996, reward 904.0, memory_length 2000, epsilon 0.027353254657302126, time 724.0, rides 130\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3997, reward 663.0, memory_length 2000, epsilon 0.027328636728110554, time 731.0, rides 130\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 3998, reward 731.0, memory_length 2000, epsilon 0.027304040955055255, time 731.0, rides 133\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 3999, reward 1128.0, memory_length 2000, epsilon 0.027279467318195704, time 723.0, rides 133\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 4000, reward 919.0, memory_length 2000, epsilon 0.027254915797609327, time 738.0, rides 139\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 4001, reward 1151.0, memory_length 2000, epsilon 0.02723038637339148, time 732.0, rides 146\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 4002, reward 929.0, memory_length 2000, epsilon 0.027205879025655428, time 723.0, rides 123\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4003, reward 919.0, memory_length 2000, epsilon 0.02718139373453234, time 730.0, rides 143\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 4004, reward 1155.0, memory_length 2000, epsilon 0.02715693048017126, time 723.0, rides 125\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 4005, reward 829.0, memory_length 2000, epsilon 0.027132489242739106, time 730.0, rides 118\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 4006, reward 817.0, memory_length 2000, epsilon 0.02710807000242064, time 731.0, rides 145\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 4007, reward 896.0, memory_length 2000, epsilon 0.027083672739418464, time 732.0, rides 149\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4008, reward 967.0, memory_length 2000, epsilon 0.027059297433952988, time 728.0, rides 145\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 4009, reward 939.0, memory_length 2000, epsilon 0.02703494406626243, time 732.0, rides 144\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4010, reward 932.0, memory_length 2000, epsilon 0.027010612616602796, time 730.0, rides 129\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 4011, reward 722.0, memory_length 2000, epsilon 0.026986303065247852, time 728.0, rides 128\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 4012, reward 995.0, memory_length 2000, epsilon 0.026962015392489127, time 726.0, rides 137\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 4013, reward 1117.0, memory_length 2000, epsilon 0.026937749578635886, time 730.0, rides 143\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 4014, reward 849.0, memory_length 2000, epsilon 0.026913505604015113, time 730.0, rides 140\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 4015, reward 956.0, memory_length 2000, epsilon 0.0268892834489715, time 730.0, rides 141\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 4016, reward 890.0, memory_length 2000, epsilon 0.026865083093867426, time 729.0, rides 145\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 4017, reward 818.0, memory_length 2000, epsilon 0.026840904519082946, time 734.0, rides 133\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 4018, reward 1043.0, memory_length 2000, epsilon 0.02681674770501577, time 736.0, rides 120\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 4019, reward 953.0, memory_length 2000, epsilon 0.026792612632081256, time 730.0, rides 142\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 4020, reward 916.0, memory_length 2000, epsilon 0.02676849928071238, time 726.0, rides 125\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 4021, reward 795.0, memory_length 2000, epsilon 0.02674440763135974, time 728.0, rides 146\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 4022, reward 950.0, memory_length 2000, epsilon 0.026720337664491518, time 729.0, rides 122\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 4023, reward 833.0, memory_length 2000, epsilon 0.026696289360593473, time 729.0, rides 135\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 4024, reward 1228.0, memory_length 2000, epsilon 0.02667226270016894, time 732.0, rides 139\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 4025, reward 780.0, memory_length 2000, epsilon 0.026648257663738788, time 736.0, rides 130\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 4026, reward 959.0, memory_length 2000, epsilon 0.02662427423184142, time 735.0, rides 130\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 4027, reward 699.0, memory_length 2000, epsilon 0.026600312385032764, time 730.0, rides 130\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 4028, reward 1103.0, memory_length 2000, epsilon 0.026576372103886234, time 732.0, rides 135\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4029, reward 422.0, memory_length 2000, epsilon 0.026552453368992736, time 735.0, rides 133\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 4030, reward 825.0, memory_length 2000, epsilon 0.026528556160960642, time 727.0, rides 154\n",
      "Initial State is  [3, 18, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4031, reward 953.0, memory_length 2000, epsilon 0.026504680460415778, time 738.0, rides 125\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4032, reward 955.0, memory_length 2000, epsilon 0.026480826248001403, time 738.0, rides 137\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 4033, reward 970.0, memory_length 2000, epsilon 0.0264569935043782, time 723.0, rides 136\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 4034, reward 660.0, memory_length 2000, epsilon 0.02643318221022426, time 725.0, rides 141\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 4035, reward 827.0, memory_length 2000, epsilon 0.02640939234623506, time 734.0, rides 138\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 4036, reward 1115.0, memory_length 2000, epsilon 0.026385623893123447, time 734.0, rides 128\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4037, reward 1006.0, memory_length 2000, epsilon 0.026361876831619637, time 724.0, rides 135\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 4038, reward 946.0, memory_length 2000, epsilon 0.026338151142471178, time 732.0, rides 144\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 4039, reward 1004.0, memory_length 2000, epsilon 0.026314446806442952, time 725.0, rides 139\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 4040, reward 885.0, memory_length 2000, epsilon 0.026290763804317153, time 730.0, rides 138\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4041, reward 1147.0, memory_length 2000, epsilon 0.026267102116893266, time 732.0, rides 134\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 4042, reward 964.0, memory_length 2000, epsilon 0.026243461724988062, time 726.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 4043, reward 763.0, memory_length 2000, epsilon 0.02621984260943557, time 724.0, rides 138\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4044, reward 1354.0, memory_length 2000, epsilon 0.02619624475108708, time 729.0, rides 137\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 4045, reward 1022.0, memory_length 2000, epsilon 0.0261726681308111, time 741.0, rides 121\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4046, reward 941.0, memory_length 2000, epsilon 0.02614911272949337, time 732.0, rides 131\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 4047, reward 738.0, memory_length 2000, epsilon 0.026125578528036826, time 727.0, rides 132\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 4048, reward 1145.0, memory_length 2000, epsilon 0.02610206550736159, time 730.0, rides 137\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 4049, reward 801.0, memory_length 2000, epsilon 0.026078573648404966, time 723.0, rides 135\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 4050, reward 1000.0, memory_length 2000, epsilon 0.0260551029321214, time 726.0, rides 134\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 4051, reward 1105.0, memory_length 2000, epsilon 0.026031653339482493, time 732.0, rides 136\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 4052, reward 956.0, memory_length 2000, epsilon 0.02600822485147696, time 727.0, rides 133\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4053, reward 964.0, memory_length 2000, epsilon 0.025984817449110627, time 734.0, rides 132\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 4054, reward 1184.0, memory_length 2000, epsilon 0.025961431113406427, time 726.0, rides 131\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 4055, reward 883.0, memory_length 2000, epsilon 0.02593806582540436, time 726.0, rides 127\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 4056, reward 1039.0, memory_length 2000, epsilon 0.025914721566161494, time 733.0, rides 136\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4057, reward 820.0, memory_length 2000, epsilon 0.025891398316751947, time 729.0, rides 138\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 4058, reward 1146.0, memory_length 2000, epsilon 0.02586809605826687, time 722.0, rides 126\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 4059, reward 1166.0, memory_length 2000, epsilon 0.02584481477181443, time 728.0, rides 137\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4060, reward 1081.0, memory_length 2000, epsilon 0.025821554438519797, time 729.0, rides 131\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 4061, reward 1041.0, memory_length 2000, epsilon 0.02579831503952513, time 730.0, rides 149\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 4062, reward 967.0, memory_length 2000, epsilon 0.025775096555989554, time 732.0, rides 136\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4063, reward 858.0, memory_length 2000, epsilon 0.025751898969089162, time 721.0, rides 123\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4064, reward 1030.0, memory_length 2000, epsilon 0.025728722260016983, time 730.0, rides 140\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 4065, reward 900.0, memory_length 2000, epsilon 0.025705566409982967, time 731.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4066, reward 942.0, memory_length 2000, epsilon 0.025682431400213982, time 729.0, rides 131\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 4067, reward 860.0, memory_length 2000, epsilon 0.02565931721195379, time 734.0, rides 133\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 4068, reward 946.0, memory_length 2000, epsilon 0.02563622382646303, time 723.0, rides 129\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 4069, reward 1111.0, memory_length 2000, epsilon 0.025613151225019212, time 724.0, rides 138\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 4070, reward 675.0, memory_length 2000, epsilon 0.025590099388916696, time 737.0, rides 130\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 4071, reward 822.0, memory_length 2000, epsilon 0.02556706829946667, time 734.0, rides 134\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4072, reward 1146.0, memory_length 2000, epsilon 0.025544057937997147, time 725.0, rides 140\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 4073, reward 1070.0, memory_length 2000, epsilon 0.02552106828585295, time 727.0, rides 120\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 4074, reward 443.0, memory_length 2000, epsilon 0.02549809932439568, time 732.0, rides 124\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 4075, reward 773.0, memory_length 2000, epsilon 0.025475151035003724, time 729.0, rides 142\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 4076, reward 924.0, memory_length 2000, epsilon 0.02545222339907222, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4077, reward 1072.0, memory_length 2000, epsilon 0.025429316398013053, time 729.0, rides 124\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 4078, reward 864.0, memory_length 2000, epsilon 0.025406430013254842, time 739.0, rides 131\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 4079, reward 781.0, memory_length 2000, epsilon 0.025383564226242914, time 725.0, rides 132\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4080, reward 1172.0, memory_length 2000, epsilon 0.025360719018439296, time 727.0, rides 136\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 4081, reward 975.0, memory_length 2000, epsilon 0.0253378943713227, time 724.0, rides 128\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 4082, reward 937.0, memory_length 2000, epsilon 0.02531509026638851, time 726.0, rides 125\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4083, reward 999.0, memory_length 2000, epsilon 0.02529230668514876, time 732.0, rides 130\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 4084, reward 799.0, memory_length 2000, epsilon 0.02526954360913213, time 726.0, rides 137\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 4085, reward 969.0, memory_length 2000, epsilon 0.02524680101988391, time 724.0, rides 137\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4086, reward 924.0, memory_length 2000, epsilon 0.025224078898966013, time 729.0, rides 144\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4087, reward 1067.0, memory_length 2000, epsilon 0.025201377227956942, time 726.0, rides 151\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 4088, reward 910.0, memory_length 2000, epsilon 0.02517869598845178, time 724.0, rides 134\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 4089, reward 1113.0, memory_length 2000, epsilon 0.025156035162062173, time 731.0, rides 130\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 4090, reward 696.0, memory_length 2000, epsilon 0.025133394730416318, time 727.0, rides 145\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4091, reward 797.0, memory_length 2000, epsilon 0.02511077467515894, time 730.0, rides 126\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 4092, reward 1139.0, memory_length 2000, epsilon 0.025088174977951298, time 733.0, rides 148\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 4093, reward 899.0, memory_length 2000, epsilon 0.025065595620471143, time 728.0, rides 131\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4094, reward 1172.0, memory_length 2000, epsilon 0.025043036584412717, time 726.0, rides 148\n",
      "Initial State is  [3, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4095, reward 797.0, memory_length 2000, epsilon 0.025020497851486745, time 725.0, rides 137\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 4096, reward 686.0, memory_length 2000, epsilon 0.024997979403420408, time 726.0, rides 138\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4097, reward 1193.0, memory_length 2000, epsilon 0.02497548122195733, time 732.0, rides 144\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 4098, reward 771.0, memory_length 2000, epsilon 0.024953003288857568, time 727.0, rides 141\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4099, reward 1085.0, memory_length 2000, epsilon 0.024930545585897596, time 723.0, rides 144\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4100, reward 954.0, memory_length 2000, epsilon 0.024908108094870287, time 723.0, rides 136\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 4101, reward 1155.0, memory_length 2000, epsilon 0.024885690797584903, time 729.0, rides 139\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 4102, reward 493.0, memory_length 2000, epsilon 0.024863293675867076, time 725.0, rides 137\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4103, reward 987.0, memory_length 2000, epsilon 0.024840916711558796, time 729.0, rides 133\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 4104, reward 1058.0, memory_length 2000, epsilon 0.024818559886518394, time 722.0, rides 137\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 4105, reward 1003.0, memory_length 2000, epsilon 0.024796223182620526, time 730.0, rides 141\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4106, reward 1022.0, memory_length 2000, epsilon 0.024773906581756166, time 729.0, rides 130\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 4107, reward 991.0, memory_length 2000, epsilon 0.024751610065832586, time 726.0, rides 137\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4108, reward 1002.0, memory_length 2000, epsilon 0.024729333616773336, time 730.0, rides 136\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 4109, reward 928.0, memory_length 2000, epsilon 0.024707077216518242, time 727.0, rides 124\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 4110, reward 1178.0, memory_length 2000, epsilon 0.024684840847023375, time 727.0, rides 140\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4111, reward 482.0, memory_length 2000, epsilon 0.02466262449026105, time 725.0, rides 135\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 4112, reward 1270.0, memory_length 2000, epsilon 0.024640428128219816, time 731.0, rides 141\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 4113, reward 1067.0, memory_length 2000, epsilon 0.02461825174290442, time 733.0, rides 140\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 4114, reward 1121.0, memory_length 2000, epsilon 0.024596095316335807, time 727.0, rides 138\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 4115, reward 572.0, memory_length 2000, epsilon 0.024573958830551103, time 733.0, rides 131\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 4116, reward 977.0, memory_length 2000, epsilon 0.024551842267603607, time 733.0, rides 136\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 4117, reward 1187.0, memory_length 2000, epsilon 0.024529745609562763, time 727.0, rides 141\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 4118, reward 688.0, memory_length 2000, epsilon 0.024507668838514157, time 725.0, rides 126\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 4119, reward 848.0, memory_length 2000, epsilon 0.024485611936559494, time 728.0, rides 129\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 4120, reward 867.0, memory_length 2000, epsilon 0.02446357488581659, time 734.0, rides 139\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 4121, reward 879.0, memory_length 2000, epsilon 0.024441557668419354, time 728.0, rides 149\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 4122, reward 870.0, memory_length 2000, epsilon 0.024419560266517776, time 733.0, rides 139\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 4123, reward 1402.0, memory_length 2000, epsilon 0.02439758266227791, time 724.0, rides 144\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 4124, reward 878.0, memory_length 2000, epsilon 0.02437562483788186, time 726.0, rides 138\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 4125, reward 1220.0, memory_length 2000, epsilon 0.024353686775527766, time 731.0, rides 138\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 4126, reward 1142.0, memory_length 2000, epsilon 0.024331768457429792, time 728.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 4127, reward 1112.0, memory_length 2000, epsilon 0.024309869865818106, time 730.0, rides 127\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4128, reward 1120.0, memory_length 2000, epsilon 0.024287990982938868, time 737.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4129, reward 1049.0, memory_length 2000, epsilon 0.024266131791054222, time 723.0, rides 145\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 4130, reward 731.0, memory_length 2000, epsilon 0.024244292272442274, time 723.0, rides 129\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 4131, reward 814.0, memory_length 2000, epsilon 0.024222472409397077, time 736.0, rides 124\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 4132, reward 932.0, memory_length 2000, epsilon 0.024200672184228618, time 727.0, rides 124\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 4133, reward 917.0, memory_length 2000, epsilon 0.024178891579262812, time 731.0, rides 133\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 4134, reward 708.0, memory_length 2000, epsilon 0.024157130576841476, time 728.0, rides 123\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 4135, reward 1184.0, memory_length 2000, epsilon 0.02413538915932232, time 733.0, rides 125\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 4136, reward 1061.0, memory_length 2000, epsilon 0.024113667309078927, time 727.0, rides 135\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 4137, reward 1312.0, memory_length 2000, epsilon 0.024091965008500756, time 726.0, rides 148\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 4138, reward 796.0, memory_length 2000, epsilon 0.024070282239993104, time 730.0, rides 144\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 4139, reward 1037.0, memory_length 2000, epsilon 0.02404861898597711, time 723.0, rides 119\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 4140, reward 1061.0, memory_length 2000, epsilon 0.02402697522888973, time 730.0, rides 129\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 4141, reward 581.0, memory_length 2000, epsilon 0.024005350951183727, time 721.0, rides 123\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4142, reward 900.0, memory_length 2000, epsilon 0.023983746135327663, time 728.0, rides 119\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 4143, reward 787.0, memory_length 2000, epsilon 0.02396216076380587, time 732.0, rides 122\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4144, reward 524.0, memory_length 2000, epsilon 0.023940594819118442, time 727.0, rides 140\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 4145, reward 647.0, memory_length 2000, epsilon 0.023919048283781236, time 728.0, rides 119\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 4146, reward 789.0, memory_length 2000, epsilon 0.023897521140325832, time 721.0, rides 123\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 4147, reward 965.0, memory_length 2000, epsilon 0.023876013371299538, time 728.0, rides 131\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4148, reward 891.0, memory_length 2000, epsilon 0.023854524959265367, time 733.0, rides 143\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 4149, reward 947.0, memory_length 2000, epsilon 0.023833055886802026, time 727.0, rides 128\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 4150, reward 992.0, memory_length 2000, epsilon 0.023811606136503904, time 733.0, rides 137\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 4151, reward 943.0, memory_length 2000, epsilon 0.02379017569098105, time 734.0, rides 123\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 4152, reward 829.0, memory_length 2000, epsilon 0.023768764532859168, time 730.0, rides 133\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 4153, reward 768.0, memory_length 2000, epsilon 0.023747372644779594, time 726.0, rides 133\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 4154, reward 861.0, memory_length 2000, epsilon 0.02372600000939929, time 723.0, rides 144\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 4155, reward 847.0, memory_length 2000, epsilon 0.023704646609390832, time 726.0, rides 139\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4156, reward 1015.0, memory_length 2000, epsilon 0.02368331242744238, time 731.0, rides 132\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 4157, reward 1024.0, memory_length 2000, epsilon 0.023661997446257684, time 731.0, rides 134\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 4158, reward 1084.0, memory_length 2000, epsilon 0.023640701648556053, time 732.0, rides 120\n",
      "Initial State is  [0, 21, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4159, reward 904.0, memory_length 2000, epsilon 0.023619425017072353, time 738.0, rides 124\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 4160, reward 994.0, memory_length 2000, epsilon 0.02359816753455699, time 732.0, rides 141\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 4161, reward 1052.0, memory_length 2000, epsilon 0.023576929183775887, time 731.0, rides 149\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4162, reward 1294.0, memory_length 2000, epsilon 0.023555709947510488, time 736.0, rides 143\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 4163, reward 833.0, memory_length 2000, epsilon 0.02353450980855773, time 728.0, rides 142\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 4164, reward 827.0, memory_length 2000, epsilon 0.023513328749730028, time 722.0, rides 150\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 4165, reward 1067.0, memory_length 2000, epsilon 0.02349216675385527, time 728.0, rides 140\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 4166, reward 1028.0, memory_length 2000, epsilon 0.023471023803776803, time 724.0, rides 142\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 4167, reward 1205.0, memory_length 2000, epsilon 0.023449899882353402, time 728.0, rides 132\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 4168, reward 1261.0, memory_length 2000, epsilon 0.023428794972459283, time 725.0, rides 131\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4169, reward 793.0, memory_length 2000, epsilon 0.02340770905698407, time 725.0, rides 144\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4170, reward 1234.0, memory_length 2000, epsilon 0.023386642118832783, time 740.0, rides 146\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 4171, reward 1026.0, memory_length 2000, epsilon 0.023365594140925833, time 726.0, rides 139\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 4172, reward 1062.0, memory_length 2000, epsilon 0.023344565106199, time 729.0, rides 134\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 4173, reward 1059.0, memory_length 2000, epsilon 0.02332355499760342, time 733.0, rides 131\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 4174, reward 1191.0, memory_length 2000, epsilon 0.023302563798105577, time 726.0, rides 140\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4175, reward 846.0, memory_length 2000, epsilon 0.02328159149068728, time 733.0, rides 138\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 4176, reward 922.0, memory_length 2000, epsilon 0.023260638058345662, time 728.0, rides 122\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 4177, reward 1045.0, memory_length 2000, epsilon 0.02323970348409315, time 733.0, rides 131\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4178, reward 1229.0, memory_length 2000, epsilon 0.023218787750957467, time 723.0, rides 128\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 4179, reward 1282.0, memory_length 2000, epsilon 0.023197890841981605, time 728.0, rides 141\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 4180, reward 1208.0, memory_length 2000, epsilon 0.02317701274022382, time 727.0, rides 133\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 4181, reward 953.0, memory_length 2000, epsilon 0.02315615342875762, time 731.0, rides 129\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4182, reward 1111.0, memory_length 2000, epsilon 0.023135312890671736, time 731.0, rides 132\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 4183, reward 1039.0, memory_length 2000, epsilon 0.023114491109070132, time 729.0, rides 142\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4184, reward 915.0, memory_length 2000, epsilon 0.02309368806707197, time 735.0, rides 143\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4185, reward 734.0, memory_length 2000, epsilon 0.023072903747811607, time 730.0, rides 124\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4186, reward 880.0, memory_length 2000, epsilon 0.023052138134438575, time 732.0, rides 135\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4187, reward 901.0, memory_length 2000, epsilon 0.02303139121011758, time 727.0, rides 129\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 4188, reward 817.0, memory_length 2000, epsilon 0.023010662958028474, time 731.0, rides 144\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4189, reward 990.0, memory_length 2000, epsilon 0.022989953361366246, time 726.0, rides 141\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4190, reward 1038.0, memory_length 2000, epsilon 0.022969262403341018, time 727.0, rides 145\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 4191, reward 953.0, memory_length 2000, epsilon 0.02294859006717801, time 729.0, rides 139\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4192, reward 817.0, memory_length 2000, epsilon 0.02292793633611755, time 734.0, rides 135\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 4193, reward 855.0, memory_length 2000, epsilon 0.022907301193415042, time 728.0, rides 145\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 4194, reward 968.0, memory_length 2000, epsilon 0.022886684622340968, time 722.0, rides 139\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4195, reward 910.0, memory_length 2000, epsilon 0.02286608660618086, time 723.0, rides 129\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 4196, reward 733.0, memory_length 2000, epsilon 0.0228455071282353, time 734.0, rides 128\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 4197, reward 862.0, memory_length 2000, epsilon 0.022824946171819887, time 731.0, rides 144\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 4198, reward 984.0, memory_length 2000, epsilon 0.022804403720265248, time 731.0, rides 135\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 4199, reward 1142.0, memory_length 2000, epsilon 0.022783879756917008, time 724.0, rides 147\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4200, reward 1006.0, memory_length 2000, epsilon 0.022763374265135784, time 730.0, rides 132\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4201, reward 1128.0, memory_length 2000, epsilon 0.022742887228297162, time 731.0, rides 141\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 4202, reward 1003.0, memory_length 2000, epsilon 0.022722418629791696, time 725.0, rides 136\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 4203, reward 881.0, memory_length 2000, epsilon 0.022701968453024884, time 727.0, rides 130\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 4204, reward 633.0, memory_length 2000, epsilon 0.02268153668141716, time 724.0, rides 126\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 4205, reward 1208.0, memory_length 2000, epsilon 0.022661123298403887, time 722.0, rides 146\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4206, reward 1031.0, memory_length 2000, epsilon 0.022640728287435324, time 727.0, rides 137\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 4207, reward 1091.0, memory_length 2000, epsilon 0.02262035163197663, time 724.0, rides 148\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4208, reward 1054.0, memory_length 2000, epsilon 0.02259999331550785, time 726.0, rides 136\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 4209, reward 1102.0, memory_length 2000, epsilon 0.022579653321523892, time 740.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 4210, reward 1063.0, memory_length 2000, epsilon 0.022559331633534522, time 731.0, rides 150\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 4211, reward 529.0, memory_length 2000, epsilon 0.022539028235064342, time 729.0, rides 123\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 4212, reward 927.0, memory_length 2000, epsilon 0.022518743109652784, time 729.0, rides 132\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 4213, reward 903.0, memory_length 2000, epsilon 0.022498476240854097, time 726.0, rides 140\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4214, reward 1225.0, memory_length 2000, epsilon 0.022478227612237327, time 725.0, rides 128\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 4215, reward 1103.0, memory_length 2000, epsilon 0.022457997207386313, time 732.0, rides 136\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 4216, reward 809.0, memory_length 2000, epsilon 0.022437785009899666, time 731.0, rides 139\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 4217, reward 889.0, memory_length 2000, epsilon 0.022417591003390757, time 724.0, rides 124\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 4218, reward 965.0, memory_length 2000, epsilon 0.022397415171487706, time 723.0, rides 138\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 4219, reward 1000.0, memory_length 2000, epsilon 0.022377257497833366, time 733.0, rides 135\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 4220, reward 900.0, memory_length 2000, epsilon 0.022357117966085315, time 727.0, rides 157\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 4221, reward 1090.0, memory_length 2000, epsilon 0.022336996559915837, time 726.0, rides 127\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 4222, reward 1205.0, memory_length 2000, epsilon 0.02231689326301191, time 725.0, rides 140\n",
      "Initial State is  [2, 2, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4223, reward 883.0, memory_length 2000, epsilon 0.0222968080590752, time 730.0, rides 137\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 4224, reward 1052.0, memory_length 2000, epsilon 0.022276740931822032, time 726.0, rides 130\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 4225, reward 778.0, memory_length 2000, epsilon 0.022256691864983393, time 723.0, rides 134\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4226, reward 881.0, memory_length 2000, epsilon 0.022236660842304908, time 724.0, rides 142\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 4227, reward 670.0, memory_length 2000, epsilon 0.022216647847546834, time 725.0, rides 138\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 4228, reward 999.0, memory_length 2000, epsilon 0.02219665286448404, time 727.0, rides 129\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 4229, reward 763.0, memory_length 2000, epsilon 0.022176675876906006, time 735.0, rides 140\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 4230, reward 1054.0, memory_length 2000, epsilon 0.02215671686861679, time 729.0, rides 132\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 4231, reward 972.0, memory_length 2000, epsilon 0.022136775823435033, time 729.0, rides 130\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 4232, reward 1121.0, memory_length 2000, epsilon 0.022116852725193942, time 743.0, rides 142\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 4233, reward 917.0, memory_length 2000, epsilon 0.02209694755774127, time 724.0, rides 125\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 4234, reward 1140.0, memory_length 2000, epsilon 0.022077060304939302, time 729.0, rides 132\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4235, reward 1150.0, memory_length 2000, epsilon 0.022057190950664857, time 726.0, rides 140\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 4236, reward 1226.0, memory_length 2000, epsilon 0.02203733947880926, time 730.0, rides 119\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 4237, reward 928.0, memory_length 2000, epsilon 0.02201750587327833, time 722.0, rides 133\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4238, reward 1128.0, memory_length 2000, epsilon 0.02199769011799238, time 729.0, rides 122\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 4239, reward 765.0, memory_length 2000, epsilon 0.021977892196886187, time 739.0, rides 133\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 4240, reward 752.0, memory_length 2000, epsilon 0.02195811209390899, time 721.0, rides 140\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4241, reward 1059.0, memory_length 2000, epsilon 0.021938349793024472, time 733.0, rides 133\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4242, reward 940.0, memory_length 2000, epsilon 0.02191860527821075, time 726.0, rides 128\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 4243, reward 741.0, memory_length 2000, epsilon 0.02189887853346036, time 735.0, rides 128\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 4244, reward 838.0, memory_length 2000, epsilon 0.021879169542780245, time 724.0, rides 130\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4245, reward 1000.0, memory_length 2000, epsilon 0.021859478290191744, time 730.0, rides 127\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 4246, reward 754.0, memory_length 2000, epsilon 0.02183980475973057, time 735.0, rides 130\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 4247, reward 794.0, memory_length 2000, epsilon 0.021820148935446815, time 737.0, rides 137\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 4248, reward 1358.0, memory_length 2000, epsilon 0.021800510801404913, time 728.0, rides 141\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4249, reward 1239.0, memory_length 2000, epsilon 0.021780890341683647, time 729.0, rides 136\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 4250, reward 1169.0, memory_length 2000, epsilon 0.021761287540376133, time 721.0, rides 131\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 4251, reward 913.0, memory_length 2000, epsilon 0.021741702381589796, time 731.0, rides 139\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 4252, reward 919.0, memory_length 2000, epsilon 0.021722134849446365, time 729.0, rides 130\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 4253, reward 884.0, memory_length 2000, epsilon 0.021702584928081862, time 727.0, rides 143\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4254, reward 1071.0, memory_length 2000, epsilon 0.021683052601646588, time 730.0, rides 133\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 4255, reward 846.0, memory_length 2000, epsilon 0.021663537854305106, time 726.0, rides 145\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 4256, reward 1268.0, memory_length 2000, epsilon 0.02164404067023623, time 721.0, rides 134\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4257, reward 864.0, memory_length 2000, epsilon 0.021624561033633017, time 730.0, rides 134\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4258, reward 889.0, memory_length 2000, epsilon 0.021605098928702746, time 730.0, rides 130\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4259, reward 877.0, memory_length 2000, epsilon 0.021585654339666912, time 722.0, rides 129\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 4260, reward 1081.0, memory_length 2000, epsilon 0.02156622725076121, time 724.0, rides 134\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 4261, reward 1063.0, memory_length 2000, epsilon 0.021546817646235526, time 724.0, rides 130\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 4262, reward 927.0, memory_length 2000, epsilon 0.021527425510353915, time 722.0, rides 138\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 4263, reward 631.0, memory_length 2000, epsilon 0.021508050827394595, time 736.0, rides 127\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4264, reward 864.0, memory_length 2000, epsilon 0.02148869358164994, time 734.0, rides 140\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 4265, reward 961.0, memory_length 2000, epsilon 0.021469353757426455, time 728.0, rides 135\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4266, reward 916.0, memory_length 2000, epsilon 0.02145003133904477, time 732.0, rides 127\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 4267, reward 847.0, memory_length 2000, epsilon 0.02143072631083963, time 727.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4268, reward 1167.0, memory_length 2000, epsilon 0.021411438657159873, time 725.0, rides 134\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4269, reward 1258.0, memory_length 2000, epsilon 0.02139216836236843, time 726.0, rides 128\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4270, reward 988.0, memory_length 2000, epsilon 0.021372915410842297, time 727.0, rides 123\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 4271, reward 896.0, memory_length 2000, epsilon 0.02135367978697254, time 731.0, rides 142\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 4272, reward 855.0, memory_length 2000, epsilon 0.021334461475164265, time 739.0, rides 130\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 4273, reward 1070.0, memory_length 2000, epsilon 0.021315260459836616, time 737.0, rides 139\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4274, reward 790.0, memory_length 2000, epsilon 0.021296076725422764, time 727.0, rides 141\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 4275, reward 1274.0, memory_length 2000, epsilon 0.021276910256369883, time 732.0, rides 142\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 4276, reward 877.0, memory_length 2000, epsilon 0.02125776103713915, time 729.0, rides 130\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 4277, reward 887.0, memory_length 2000, epsilon 0.021238629052205724, time 725.0, rides 125\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 4278, reward 996.0, memory_length 2000, epsilon 0.021219514286058738, time 725.0, rides 132\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 4279, reward 937.0, memory_length 2000, epsilon 0.021200416723201283, time 724.0, rides 137\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 4280, reward 929.0, memory_length 2000, epsilon 0.021181336348150403, time 743.0, rides 133\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 4281, reward 875.0, memory_length 2000, epsilon 0.021162273145437067, time 731.0, rides 129\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 4282, reward 998.0, memory_length 2000, epsilon 0.021143227099606175, time 726.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 4283, reward 1209.0, memory_length 2000, epsilon 0.021124198195216527, time 732.0, rides 125\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4284, reward 927.0, memory_length 2000, epsilon 0.02110518641684083, time 734.0, rides 130\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4285, reward 1028.0, memory_length 2000, epsilon 0.021086191749065675, time 728.0, rides 129\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 4286, reward 1290.0, memory_length 2000, epsilon 0.021067214176491517, time 729.0, rides 141\n",
      "Initial State is  [0, 18, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4287, reward 1050.0, memory_length 2000, epsilon 0.021048253683732674, time 727.0, rides 123\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 4288, reward 644.0, memory_length 2000, epsilon 0.021029310255417315, time 732.0, rides 132\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 4289, reward 756.0, memory_length 2000, epsilon 0.02101038387618744, time 726.0, rides 122\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 4290, reward 773.0, memory_length 2000, epsilon 0.02099147453069887, time 726.0, rides 141\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 4291, reward 1126.0, memory_length 2000, epsilon 0.02097258220362124, time 728.0, rides 123\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 4292, reward 1182.0, memory_length 2000, epsilon 0.020953706879637983, time 725.0, rides 130\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 4293, reward 579.0, memory_length 2000, epsilon 0.020934848543446308, time 727.0, rides 126\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4294, reward 924.0, memory_length 2000, epsilon 0.020916007179757206, time 736.0, rides 132\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 4295, reward 903.0, memory_length 2000, epsilon 0.020897182773295424, time 725.0, rides 125\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4296, reward 1116.0, memory_length 2000, epsilon 0.02087837530879946, time 726.0, rides 125\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 4297, reward 819.0, memory_length 2000, epsilon 0.02085958477102154, time 725.0, rides 128\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 4298, reward 755.0, memory_length 2000, epsilon 0.02084081114472762, time 732.0, rides 139\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 4299, reward 1120.0, memory_length 2000, epsilon 0.020822054414697363, time 727.0, rides 147\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 4300, reward 695.0, memory_length 2000, epsilon 0.020803314565724134, time 726.0, rides 122\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4301, reward 961.0, memory_length 2000, epsilon 0.020784591582614982, time 729.0, rides 131\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4302, reward 862.0, memory_length 2000, epsilon 0.02076588545019063, time 722.0, rides 133\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 4303, reward 840.0, memory_length 2000, epsilon 0.020747196153285456, time 730.0, rides 125\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4304, reward 934.0, memory_length 2000, epsilon 0.0207285236767475, time 729.0, rides 131\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 4305, reward 959.0, memory_length 2000, epsilon 0.020709868005438427, time 735.0, rides 134\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 4306, reward 1372.0, memory_length 2000, epsilon 0.02069122912423353, time 731.0, rides 130\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 4307, reward 1101.0, memory_length 2000, epsilon 0.020672607018021722, time 724.0, rides 143\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4308, reward 801.0, memory_length 2000, epsilon 0.020654001671705502, time 736.0, rides 124\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 4309, reward 849.0, memory_length 2000, epsilon 0.02063541307020097, time 738.0, rides 126\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4310, reward 704.0, memory_length 2000, epsilon 0.020616841198437787, time 725.0, rides 136\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 4311, reward 688.0, memory_length 2000, epsilon 0.020598286041359194, time 721.0, rides 136\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4312, reward 1040.0, memory_length 2000, epsilon 0.020579747583921972, time 730.0, rides 133\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 4313, reward 1253.0, memory_length 2000, epsilon 0.020561225811096442, time 731.0, rides 133\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 4314, reward 744.0, memory_length 2000, epsilon 0.020542720707866457, time 725.0, rides 124\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 4315, reward 928.0, memory_length 2000, epsilon 0.020524232259229377, time 729.0, rides 124\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4316, reward 912.0, memory_length 2000, epsilon 0.02050576045019607, time 730.0, rides 134\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 4317, reward 806.0, memory_length 2000, epsilon 0.020487305265790894, time 729.0, rides 144\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4318, reward 940.0, memory_length 2000, epsilon 0.02046886669105168, time 733.0, rides 129\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4319, reward 1141.0, memory_length 2000, epsilon 0.020450444711029733, time 738.0, rides 119\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 4320, reward 1088.0, memory_length 2000, epsilon 0.020432039310789806, time 724.0, rides 133\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4321, reward 1081.0, memory_length 2000, epsilon 0.020413650475410095, time 729.0, rides 142\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 4322, reward 660.0, memory_length 2000, epsilon 0.020395278189982227, time 741.0, rides 140\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 4323, reward 886.0, memory_length 2000, epsilon 0.020376922439611242, time 723.0, rides 143\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 4324, reward 715.0, memory_length 2000, epsilon 0.020358583209415592, time 733.0, rides 136\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 4325, reward 831.0, memory_length 2000, epsilon 0.02034026048452712, time 734.0, rides 135\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 4326, reward 1087.0, memory_length 2000, epsilon 0.020321954250091045, time 732.0, rides 131\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 4327, reward 961.0, memory_length 2000, epsilon 0.02030366449126596, time 732.0, rides 141\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 4328, reward 635.0, memory_length 2000, epsilon 0.020285391193223822, time 726.0, rides 129\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 4329, reward 1087.0, memory_length 2000, epsilon 0.02026713434114992, time 726.0, rides 126\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 4330, reward 1230.0, memory_length 2000, epsilon 0.020248893920242886, time 731.0, rides 139\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 4331, reward 722.0, memory_length 2000, epsilon 0.020230669915714667, time 723.0, rides 127\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4332, reward 928.0, memory_length 2000, epsilon 0.020212462312790523, time 729.0, rides 128\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 4333, reward 1198.0, memory_length 2000, epsilon 0.020194271096709012, time 730.0, rides 138\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4334, reward 1222.0, memory_length 2000, epsilon 0.020176096252721973, time 729.0, rides 149\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 4335, reward 863.0, memory_length 2000, epsilon 0.020157937766094522, time 725.0, rides 134\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4336, reward 998.0, memory_length 2000, epsilon 0.020139795622105036, time 724.0, rides 122\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 4337, reward 1021.0, memory_length 2000, epsilon 0.020121669806045142, time 729.0, rides 122\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 4338, reward 821.0, memory_length 2000, epsilon 0.020103560303219702, time 727.0, rides 131\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4339, reward 968.0, memory_length 2000, epsilon 0.020085467098946805, time 725.0, rides 131\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4340, reward 523.0, memory_length 2000, epsilon 0.020067390178557753, time 727.0, rides 136\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4341, reward 606.0, memory_length 2000, epsilon 0.02004932952739705, time 724.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 4342, reward 913.0, memory_length 2000, epsilon 0.020031285130822394, time 731.0, rides 122\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4343, reward 848.0, memory_length 2000, epsilon 0.020013256974204655, time 729.0, rides 137\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 4344, reward 873.0, memory_length 2000, epsilon 0.01999524504292787, time 727.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4345, reward 884.0, memory_length 2000, epsilon 0.019977249322389236, time 729.0, rides 124\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 4346, reward 1200.0, memory_length 2000, epsilon 0.019959269797999085, time 725.0, rides 143\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 4347, reward 833.0, memory_length 2000, epsilon 0.019941306455180885, time 730.0, rides 140\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 4348, reward 923.0, memory_length 2000, epsilon 0.019923359279371222, time 731.0, rides 141\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 4349, reward 946.0, memory_length 2000, epsilon 0.019905428256019788, time 736.0, rides 123\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 4350, reward 1203.0, memory_length 2000, epsilon 0.01988751337058937, time 727.0, rides 138\n",
      "Initial State is  [1, 23, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4351, reward 932.0, memory_length 2000, epsilon 0.01986961460855584, time 720.0, rides 132\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4352, reward 711.0, memory_length 2000, epsilon 0.01985173195540814, time 730.0, rides 140\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4353, reward 1201.0, memory_length 2000, epsilon 0.019833865396648272, time 723.0, rides 125\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 4354, reward 890.0, memory_length 2000, epsilon 0.019816014917791287, time 729.0, rides 133\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 4355, reward 1073.0, memory_length 2000, epsilon 0.019798180504365274, time 728.0, rides 125\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 4356, reward 1128.0, memory_length 2000, epsilon 0.019780362141911347, time 729.0, rides 140\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 4357, reward 933.0, memory_length 2000, epsilon 0.019762559815983627, time 724.0, rides 130\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4358, reward 988.0, memory_length 2000, epsilon 0.01974477351214924, time 729.0, rides 134\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4359, reward 991.0, memory_length 2000, epsilon 0.019727003215988307, time 723.0, rides 145\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4360, reward 969.0, memory_length 2000, epsilon 0.01970924891309392, time 729.0, rides 131\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 4361, reward 729.0, memory_length 2000, epsilon 0.019691510589072134, time 734.0, rides 131\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 4362, reward 734.0, memory_length 2000, epsilon 0.01967378822954197, time 726.0, rides 147\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 4363, reward 989.0, memory_length 2000, epsilon 0.019656081820135382, time 724.0, rides 125\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4364, reward 721.0, memory_length 2000, epsilon 0.01963839134649726, time 727.0, rides 131\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 4365, reward 918.0, memory_length 2000, epsilon 0.01962071679428541, time 729.0, rides 135\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 4366, reward 976.0, memory_length 2000, epsilon 0.019603058149170554, time 730.0, rides 120\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 4367, reward 791.0, memory_length 2000, epsilon 0.019585415396836302, time 723.0, rides 132\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 4368, reward 1002.0, memory_length 2000, epsilon 0.01956778852297915, time 731.0, rides 139\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4369, reward 1051.0, memory_length 2000, epsilon 0.019550177513308467, time 727.0, rides 123\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4370, reward 950.0, memory_length 2000, epsilon 0.01953258235354649, time 720.0, rides 133\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 4371, reward 1427.0, memory_length 2000, epsilon 0.0195150030294283, time 727.0, rides 142\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 4372, reward 1350.0, memory_length 2000, epsilon 0.019497439526701812, time 733.0, rides 145\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 4373, reward 1210.0, memory_length 2000, epsilon 0.01947989183112778, time 726.0, rides 137\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 4374, reward 1045.0, memory_length 2000, epsilon 0.019462359928479764, time 734.0, rides 134\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 4375, reward 1091.0, memory_length 2000, epsilon 0.019444843804544133, time 731.0, rides 138\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4376, reward 698.0, memory_length 2000, epsilon 0.01942734344512004, time 723.0, rides 123\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 4377, reward 1010.0, memory_length 2000, epsilon 0.019409858836019433, time 734.0, rides 135\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 4378, reward 1136.0, memory_length 2000, epsilon 0.019392389963067014, time 729.0, rides 122\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 4379, reward 894.0, memory_length 2000, epsilon 0.019374936812100254, time 733.0, rides 146\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 4380, reward 795.0, memory_length 2000, epsilon 0.019357499368969362, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 4381, reward 842.0, memory_length 2000, epsilon 0.01934007761953729, time 728.0, rides 125\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 4382, reward 1030.0, memory_length 2000, epsilon 0.019322671549679708, time 732.0, rides 138\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4383, reward 896.0, memory_length 2000, epsilon 0.019305281145284996, time 725.0, rides 130\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 4384, reward 1285.0, memory_length 2000, epsilon 0.01928790639225424, time 725.0, rides 142\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 4385, reward 943.0, memory_length 2000, epsilon 0.01927054727650121, time 734.0, rides 126\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4386, reward 992.0, memory_length 2000, epsilon 0.019253203783952358, time 729.0, rides 142\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4387, reward 1175.0, memory_length 2000, epsilon 0.0192358759005468, time 726.0, rides 127\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 4388, reward 896.0, memory_length 2000, epsilon 0.019218563612236308, time 728.0, rides 145\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 4389, reward 946.0, memory_length 2000, epsilon 0.019201266904985297, time 727.0, rides 127\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 4390, reward 1020.0, memory_length 2000, epsilon 0.01918398576477081, time 734.0, rides 133\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4391, reward 1028.0, memory_length 2000, epsilon 0.019166720177582516, time 725.0, rides 136\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 4392, reward 806.0, memory_length 2000, epsilon 0.019149470129422693, time 722.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4393, reward 1084.0, memory_length 2000, epsilon 0.01913223560630621, time 726.0, rides 138\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 4394, reward 932.0, memory_length 2000, epsilon 0.019115016594260535, time 729.0, rides 144\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 4395, reward 893.0, memory_length 2000, epsilon 0.0190978130793257, time 733.0, rides 139\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 4396, reward 1098.0, memory_length 2000, epsilon 0.019080625047554308, time 729.0, rides 137\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 4397, reward 895.0, memory_length 2000, epsilon 0.019063452485011508, time 730.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 4398, reward 766.0, memory_length 2000, epsilon 0.019046295377774997, time 732.0, rides 131\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 4399, reward 1063.0, memory_length 2000, epsilon 0.019029153711935, time 726.0, rides 144\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 4400, reward 1182.0, memory_length 2000, epsilon 0.01901202747359426, time 730.0, rides 131\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4401, reward 1314.0, memory_length 2000, epsilon 0.018994916648868022, time 734.0, rides 139\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 4402, reward 941.0, memory_length 2000, epsilon 0.018977821223884042, time 732.0, rides 141\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 4403, reward 814.0, memory_length 2000, epsilon 0.018960741184782547, time 725.0, rides 139\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 4404, reward 1030.0, memory_length 2000, epsilon 0.01894367651771624, time 728.0, rides 132\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 4405, reward 871.0, memory_length 2000, epsilon 0.018926627208850296, time 731.0, rides 148\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 4406, reward 1184.0, memory_length 2000, epsilon 0.01890959324436233, time 724.0, rides 140\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 4407, reward 786.0, memory_length 2000, epsilon 0.018892574610442404, time 726.0, rides 137\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4408, reward 889.0, memory_length 2000, epsilon 0.018875571293293005, time 728.0, rides 132\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 4409, reward 765.0, memory_length 2000, epsilon 0.01885858327912904, time 727.0, rides 130\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 4410, reward 1243.0, memory_length 2000, epsilon 0.018841610554177823, time 727.0, rides 148\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4411, reward 995.0, memory_length 2000, epsilon 0.018824653104679064, time 732.0, rides 137\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 4412, reward 789.0, memory_length 2000, epsilon 0.018807710916884855, time 733.0, rides 131\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 4413, reward 961.0, memory_length 2000, epsilon 0.018790783977059657, time 735.0, rides 138\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4414, reward 768.0, memory_length 2000, epsilon 0.018773872271480304, time 725.0, rides 145\n",
      "Initial State is  [1, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4415, reward 926.0, memory_length 2000, epsilon 0.01875697578643597, time 734.0, rides 135\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4416, reward 956.0, memory_length 2000, epsilon 0.018740094508228177, time 732.0, rides 134\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4417, reward 807.0, memory_length 2000, epsilon 0.01872322842317077, time 729.0, rides 148\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 4418, reward 708.0, memory_length 2000, epsilon 0.018706377517589915, time 722.0, rides 136\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 4419, reward 969.0, memory_length 2000, epsilon 0.018689541777824083, time 734.0, rides 130\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4420, reward 1023.0, memory_length 2000, epsilon 0.01867272119022404, time 729.0, rides 128\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 4421, reward 1147.0, memory_length 2000, epsilon 0.01865591574115284, time 728.0, rides 140\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 4422, reward 471.0, memory_length 2000, epsilon 0.018639125416985803, time 727.0, rides 121\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4423, reward 927.0, memory_length 2000, epsilon 0.018622350204110516, time 725.0, rides 138\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 4424, reward 713.0, memory_length 2000, epsilon 0.018605590088926816, time 728.0, rides 138\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 4425, reward 1157.0, memory_length 2000, epsilon 0.018588845057846783, time 730.0, rides 127\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 4426, reward 985.0, memory_length 2000, epsilon 0.01857211509729472, time 725.0, rides 147\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 4427, reward 1079.0, memory_length 2000, epsilon 0.018555400193707154, time 730.0, rides 142\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 4428, reward 1194.0, memory_length 2000, epsilon 0.018538700333532818, time 728.0, rides 142\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 4429, reward 1028.0, memory_length 2000, epsilon 0.01852201550323264, time 728.0, rides 137\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 4430, reward 991.0, memory_length 2000, epsilon 0.01850534568927973, time 726.0, rides 136\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 4431, reward 860.0, memory_length 2000, epsilon 0.018488690878159377, time 727.0, rides 134\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4432, reward 751.0, memory_length 2000, epsilon 0.018472051056369034, time 728.0, rides 120\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 4433, reward 1106.0, memory_length 2000, epsilon 0.0184554262104183, time 725.0, rides 127\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 4434, reward 787.0, memory_length 2000, epsilon 0.018438816326828925, time 727.0, rides 128\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 4435, reward 1021.0, memory_length 2000, epsilon 0.01842222139213478, time 725.0, rides 134\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4436, reward 813.0, memory_length 2000, epsilon 0.018405641392881856, time 728.0, rides 133\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 4437, reward 670.0, memory_length 2000, epsilon 0.01838907631562826, time 731.0, rides 133\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 4438, reward 1148.0, memory_length 2000, epsilon 0.018372526146944193, time 733.0, rides 138\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 4439, reward 1097.0, memory_length 2000, epsilon 0.018355990873411943, time 728.0, rides 136\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 4440, reward 1006.0, memory_length 2000, epsilon 0.01833947048162587, time 728.0, rides 141\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4441, reward 1224.0, memory_length 2000, epsilon 0.018322964958192408, time 729.0, rides 133\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 4442, reward 760.0, memory_length 2000, epsilon 0.018306474289730035, time 733.0, rides 137\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 4443, reward 975.0, memory_length 2000, epsilon 0.018289998462869276, time 723.0, rides 140\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 4444, reward 1045.0, memory_length 2000, epsilon 0.018273537464252695, time 726.0, rides 131\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 4445, reward 634.0, memory_length 2000, epsilon 0.018257091280534866, time 727.0, rides 134\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 4446, reward 746.0, memory_length 2000, epsilon 0.018240659898382385, time 732.0, rides 130\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 4447, reward 972.0, memory_length 2000, epsilon 0.01822424330447384, time 732.0, rides 148\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 4448, reward 1009.0, memory_length 2000, epsilon 0.018207841485499813, time 728.0, rides 130\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 4449, reward 1080.0, memory_length 2000, epsilon 0.018191454428162862, time 730.0, rides 134\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 4450, reward 614.0, memory_length 2000, epsilon 0.018175082119177514, time 732.0, rides 127\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 4451, reward 995.0, memory_length 2000, epsilon 0.018158724545270254, time 723.0, rides 135\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 4452, reward 1068.0, memory_length 2000, epsilon 0.01814238169317951, time 729.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 4453, reward 737.0, memory_length 2000, epsilon 0.018126053549655647, time 726.0, rides 143\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 4454, reward 1036.0, memory_length 2000, epsilon 0.018109740101460957, time 722.0, rides 119\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4455, reward 1065.0, memory_length 2000, epsilon 0.01809344133536964, time 730.0, rides 129\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 4456, reward 1114.0, memory_length 2000, epsilon 0.01807715723816781, time 724.0, rides 145\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4457, reward 1043.0, memory_length 2000, epsilon 0.018060887796653456, time 727.0, rides 130\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 4458, reward 1007.0, memory_length 2000, epsilon 0.018044632997636468, time 726.0, rides 136\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 4459, reward 822.0, memory_length 2000, epsilon 0.018028392827938593, time 739.0, rides 123\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 4460, reward 910.0, memory_length 2000, epsilon 0.018012167274393448, time 723.0, rides 147\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 4461, reward 921.0, memory_length 2000, epsilon 0.017995956323846495, time 724.0, rides 137\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 4462, reward 1168.0, memory_length 2000, epsilon 0.017979759963155033, time 727.0, rides 130\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 4463, reward 832.0, memory_length 2000, epsilon 0.017963578179188193, time 730.0, rides 134\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 4464, reward 972.0, memory_length 2000, epsilon 0.017947410958826925, time 739.0, rides 123\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 4465, reward 880.0, memory_length 2000, epsilon 0.01793125828896398, time 731.0, rides 125\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 4466, reward 956.0, memory_length 2000, epsilon 0.017915120156503914, time 730.0, rides 146\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 4467, reward 880.0, memory_length 2000, epsilon 0.01789899654836306, time 744.0, rides 133\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 4468, reward 1107.0, memory_length 2000, epsilon 0.017882887451469532, time 731.0, rides 133\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 4469, reward 972.0, memory_length 2000, epsilon 0.01786679285276321, time 729.0, rides 137\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4470, reward 758.0, memory_length 2000, epsilon 0.017850712739195723, time 729.0, rides 142\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4471, reward 882.0, memory_length 2000, epsilon 0.017834647097730447, time 733.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4472, reward 798.0, memory_length 2000, epsilon 0.01781859591534249, time 724.0, rides 140\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 4473, reward 832.0, memory_length 2000, epsilon 0.01780255917901868, time 730.0, rides 128\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 4474, reward 1043.0, memory_length 2000, epsilon 0.017786536875757562, time 734.0, rides 154\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4475, reward 1102.0, memory_length 2000, epsilon 0.01777052899256938, time 731.0, rides 140\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4476, reward 1200.0, memory_length 2000, epsilon 0.01775453551647607, time 740.0, rides 134\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4477, reward 1137.0, memory_length 2000, epsilon 0.01773855643451124, time 730.0, rides 138\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4478, reward 1050.0, memory_length 2000, epsilon 0.017722591733720178, time 731.0, rides 133\n",
      "Initial State is  [3, 13, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4479, reward 817.0, memory_length 2000, epsilon 0.01770664140115983, time 727.0, rides 128\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 4480, reward 1025.0, memory_length 2000, epsilon 0.017690705423898785, time 723.0, rides 149\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 4481, reward 806.0, memory_length 2000, epsilon 0.017674783789017275, time 732.0, rides 131\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 4482, reward 720.0, memory_length 2000, epsilon 0.017658876483607158, time 725.0, rides 129\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4483, reward 940.0, memory_length 2000, epsilon 0.017642983494771912, time 727.0, rides 136\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 4484, reward 1039.0, memory_length 2000, epsilon 0.017627104809626617, time 724.0, rides 130\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4485, reward 1164.0, memory_length 2000, epsilon 0.017611240415297953, time 730.0, rides 138\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4486, reward 1065.0, memory_length 2000, epsilon 0.017595390298924183, time 724.0, rides 140\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 4487, reward 814.0, memory_length 2000, epsilon 0.01757955444765515, time 728.0, rides 125\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 4488, reward 1027.0, memory_length 2000, epsilon 0.01756373284865226, time 726.0, rides 135\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 4489, reward 690.0, memory_length 2000, epsilon 0.017547925489088474, time 743.0, rides 137\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 4490, reward 676.0, memory_length 2000, epsilon 0.017532132356148294, time 731.0, rides 123\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 4491, reward 834.0, memory_length 2000, epsilon 0.01751635343702776, time 725.0, rides 122\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4492, reward 1150.0, memory_length 2000, epsilon 0.017500588718934434, time 733.0, rides 142\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4493, reward 1278.0, memory_length 2000, epsilon 0.017484838189087394, time 730.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4494, reward 1122.0, memory_length 2000, epsilon 0.017469101834717216, time 731.0, rides 114\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4495, reward 849.0, memory_length 2000, epsilon 0.01745337964306597, time 726.0, rides 134\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4496, reward 745.0, memory_length 2000, epsilon 0.01743767160138721, time 731.0, rides 136\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 4497, reward 988.0, memory_length 2000, epsilon 0.01742197769694596, time 729.0, rides 136\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4498, reward 542.0, memory_length 2000, epsilon 0.01740629791701871, time 726.0, rides 127\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4499, reward 1007.0, memory_length 2000, epsilon 0.01739063224889339, time 725.0, rides 127\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 4500, reward 681.0, memory_length 2000, epsilon 0.017374980679869388, time 728.0, rides 123\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4501, reward 802.0, memory_length 2000, epsilon 0.017359343197257505, time 724.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4502, reward 885.0, memory_length 2000, epsilon 0.017343719788379973, time 725.0, rides 137\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 4503, reward 1227.0, memory_length 2000, epsilon 0.01732811044057043, time 723.0, rides 145\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4504, reward 726.0, memory_length 2000, epsilon 0.017312515141173917, time 736.0, rides 144\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4505, reward 946.0, memory_length 2000, epsilon 0.01729693387754686, time 723.0, rides 127\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 4506, reward 736.0, memory_length 2000, epsilon 0.017281366637057066, time 721.0, rides 140\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 4507, reward 1052.0, memory_length 2000, epsilon 0.017265813407083715, time 733.0, rides 141\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 4508, reward 967.0, memory_length 2000, epsilon 0.01725027417501734, time 728.0, rides 126\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4509, reward 678.0, memory_length 2000, epsilon 0.017234748928259824, time 727.0, rides 133\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4510, reward 938.0, memory_length 2000, epsilon 0.017219237654224392, time 725.0, rides 129\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 4511, reward 833.0, memory_length 2000, epsilon 0.017203740340335588, time 728.0, rides 150\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 4512, reward 872.0, memory_length 2000, epsilon 0.017188256974029287, time 728.0, rides 133\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 4513, reward 912.0, memory_length 2000, epsilon 0.01717278754275266, time 730.0, rides 131\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4514, reward 943.0, memory_length 2000, epsilon 0.017157332033964183, time 732.0, rides 142\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 4515, reward 612.0, memory_length 2000, epsilon 0.017141890435133617, time 727.0, rides 136\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 4516, reward 871.0, memory_length 2000, epsilon 0.017126462733741996, time 727.0, rides 134\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 4517, reward 902.0, memory_length 2000, epsilon 0.01711104891728163, time 724.0, rides 131\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 4518, reward 897.0, memory_length 2000, epsilon 0.017095648973256074, time 740.0, rides 125\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4519, reward 1100.0, memory_length 2000, epsilon 0.017080262889180145, time 726.0, rides 131\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 4520, reward 822.0, memory_length 2000, epsilon 0.01706489065257988, time 722.0, rides 122\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4521, reward 807.0, memory_length 2000, epsilon 0.01704953225099256, time 729.0, rides 125\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4522, reward 1170.0, memory_length 2000, epsilon 0.017034187671966666, time 732.0, rides 134\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 4523, reward 650.0, memory_length 2000, epsilon 0.017018856903061895, time 724.0, rides 119\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 4524, reward 1044.0, memory_length 2000, epsilon 0.017003539931849138, time 721.0, rides 137\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 4525, reward 818.0, memory_length 2000, epsilon 0.016988236745910473, time 727.0, rides 128\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 4526, reward 653.0, memory_length 2000, epsilon 0.016972947332839154, time 732.0, rides 127\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 4527, reward 950.0, memory_length 2000, epsilon 0.016957671680239598, time 725.0, rides 123\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 4528, reward 1036.0, memory_length 2000, epsilon 0.016942409775727384, time 726.0, rides 145\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 4529, reward 937.0, memory_length 2000, epsilon 0.01692716160692923, time 724.0, rides 134\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 4530, reward 976.0, memory_length 2000, epsilon 0.016911927161482994, time 728.0, rides 121\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 4531, reward 1158.0, memory_length 2000, epsilon 0.01689670642703766, time 729.0, rides 133\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 4532, reward 846.0, memory_length 2000, epsilon 0.016881499391253326, time 731.0, rides 135\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 4533, reward 819.0, memory_length 2000, epsilon 0.0168663060418012, time 730.0, rides 130\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 4534, reward 943.0, memory_length 2000, epsilon 0.01685112636636358, time 729.0, rides 122\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4535, reward 875.0, memory_length 2000, epsilon 0.016835960352633853, time 726.0, rides 148\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 4536, reward 815.0, memory_length 2000, epsilon 0.01682080798831648, time 731.0, rides 127\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 4537, reward 779.0, memory_length 2000, epsilon 0.016805669261126997, time 737.0, rides 128\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4538, reward 833.0, memory_length 2000, epsilon 0.016790544158791984, time 726.0, rides 132\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 4539, reward 1001.0, memory_length 2000, epsilon 0.01677543266904907, time 729.0, rides 136\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 4540, reward 1139.0, memory_length 2000, epsilon 0.016760334779646925, time 731.0, rides 120\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 4541, reward 1151.0, memory_length 2000, epsilon 0.01674525047834524, time 727.0, rides 131\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 4542, reward 835.0, memory_length 2000, epsilon 0.016730179752914732, time 729.0, rides 130\n",
      "Initial State is  [1, 13, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4543, reward 964.0, memory_length 2000, epsilon 0.016715122591137107, time 726.0, rides 136\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 4544, reward 878.0, memory_length 2000, epsilon 0.016700078980805083, time 734.0, rides 128\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 4545, reward 1074.0, memory_length 2000, epsilon 0.016685048909722357, time 731.0, rides 132\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 4546, reward 785.0, memory_length 2000, epsilon 0.016670032365703608, time 723.0, rides 128\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 4547, reward 836.0, memory_length 2000, epsilon 0.016655029336574475, time 729.0, rides 132\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4548, reward 917.0, memory_length 2000, epsilon 0.016640039810171557, time 726.0, rides 140\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 4549, reward 671.0, memory_length 2000, epsilon 0.0166250637743424, time 729.0, rides 131\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 4550, reward 1182.0, memory_length 2000, epsilon 0.016610101216945495, time 729.0, rides 120\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 4551, reward 921.0, memory_length 2000, epsilon 0.016595152125850245, time 731.0, rides 140\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 4552, reward 860.0, memory_length 2000, epsilon 0.01658021648893698, time 724.0, rides 124\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4553, reward 872.0, memory_length 2000, epsilon 0.016565294294096936, time 728.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 4554, reward 1095.0, memory_length 2000, epsilon 0.01655038552923225, time 729.0, rides 139\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 4555, reward 1018.0, memory_length 2000, epsilon 0.01653549018225594, time 724.0, rides 134\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 4556, reward 898.0, memory_length 2000, epsilon 0.01652060824109191, time 721.0, rides 138\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 4557, reward 745.0, memory_length 2000, epsilon 0.016505739693674925, time 730.0, rides 130\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4558, reward 761.0, memory_length 2000, epsilon 0.016490884527950618, time 732.0, rides 134\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 4559, reward 904.0, memory_length 2000, epsilon 0.016476042731875463, time 726.0, rides 121\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4560, reward 1003.0, memory_length 2000, epsilon 0.016461214293416775, time 732.0, rides 121\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 4561, reward 809.0, memory_length 2000, epsilon 0.0164463992005527, time 722.0, rides 129\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 4562, reward 725.0, memory_length 2000, epsilon 0.016431597441272202, time 727.0, rides 132\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 4563, reward 726.0, memory_length 2000, epsilon 0.016416809003575058, time 731.0, rides 124\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 4564, reward 716.0, memory_length 2000, epsilon 0.01640203387547184, time 731.0, rides 128\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 4565, reward 868.0, memory_length 2000, epsilon 0.016387272044983917, time 722.0, rides 124\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4566, reward 804.0, memory_length 2000, epsilon 0.01637252350014343, time 726.0, rides 139\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4567, reward 810.0, memory_length 2000, epsilon 0.0163577882289933, time 725.0, rides 133\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4568, reward 839.0, memory_length 2000, epsilon 0.016343066219587206, time 725.0, rides 121\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 4569, reward 792.0, memory_length 2000, epsilon 0.016328357459989576, time 732.0, rides 132\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 4570, reward 1161.0, memory_length 2000, epsilon 0.016313661938275586, time 734.0, rides 129\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 4571, reward 952.0, memory_length 2000, epsilon 0.016298979642531138, time 725.0, rides 126\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 4572, reward 1212.0, memory_length 2000, epsilon 0.01628431056085286, time 739.0, rides 143\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4573, reward 926.0, memory_length 2000, epsilon 0.016269654681348094, time 732.0, rides 130\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 4574, reward 1060.0, memory_length 2000, epsilon 0.01625501199213488, time 736.0, rides 138\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 4575, reward 787.0, memory_length 2000, epsilon 0.01624038248134196, time 724.0, rides 139\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 4576, reward 771.0, memory_length 2000, epsilon 0.016225766137108754, time 727.0, rides 121\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 4577, reward 1135.0, memory_length 2000, epsilon 0.016211162947585355, time 731.0, rides 126\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 4578, reward 823.0, memory_length 2000, epsilon 0.01619657290093253, time 730.0, rides 133\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 4579, reward 1030.0, memory_length 2000, epsilon 0.01618199598532169, time 731.0, rides 136\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 4580, reward 866.0, memory_length 2000, epsilon 0.0161674321889349, time 733.0, rides 136\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 4581, reward 695.0, memory_length 2000, epsilon 0.01615288149996486, time 729.0, rides 140\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 4582, reward 824.0, memory_length 2000, epsilon 0.01613834390661489, time 732.0, rides 137\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 4583, reward 741.0, memory_length 2000, epsilon 0.016123819397098938, time 728.0, rides 122\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 4584, reward 1170.0, memory_length 2000, epsilon 0.01610930795964155, time 734.0, rides 144\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 4585, reward 1026.0, memory_length 2000, epsilon 0.016094809582477873, time 728.0, rides 137\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 4586, reward 921.0, memory_length 2000, epsilon 0.016080324253853643, time 729.0, rides 130\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4587, reward 792.0, memory_length 2000, epsilon 0.016065851962025174, time 725.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 4588, reward 680.0, memory_length 2000, epsilon 0.01605139269525935, time 737.0, rides 135\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 4589, reward 899.0, memory_length 2000, epsilon 0.016036946441833618, time 729.0, rides 128\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 4590, reward 835.0, memory_length 2000, epsilon 0.016022513190035968, time 731.0, rides 140\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4591, reward 803.0, memory_length 2000, epsilon 0.016008092928164935, time 734.0, rides 135\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4592, reward 937.0, memory_length 2000, epsilon 0.015993685644529586, time 729.0, rides 138\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 4593, reward 713.0, memory_length 2000, epsilon 0.015979291327449508, time 728.0, rides 142\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 4594, reward 1121.0, memory_length 2000, epsilon 0.015964909965254803, time 730.0, rides 121\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 4595, reward 718.0, memory_length 2000, epsilon 0.015950541546286074, time 729.0, rides 114\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 4596, reward 654.0, memory_length 2000, epsilon 0.015936186058894415, time 727.0, rides 146\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4597, reward 784.0, memory_length 2000, epsilon 0.01592184349144141, time 738.0, rides 133\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 4598, reward 1106.0, memory_length 2000, epsilon 0.015907513832299113, time 721.0, rides 147\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4599, reward 754.0, memory_length 2000, epsilon 0.015893197069850044, time 733.0, rides 126\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4600, reward 1011.0, memory_length 2000, epsilon 0.015878893192487177, time 729.0, rides 142\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 4601, reward 611.0, memory_length 2000, epsilon 0.01586460218861394, time 734.0, rides 134\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 4602, reward 969.0, memory_length 2000, epsilon 0.015850324046644187, time 727.0, rides 149\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 4603, reward 929.0, memory_length 2000, epsilon 0.015836058755002207, time 724.0, rides 138\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 4604, reward 1043.0, memory_length 2000, epsilon 0.015821806302122706, time 728.0, rides 123\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 4605, reward 807.0, memory_length 2000, epsilon 0.015807566676450797, time 732.0, rides 143\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 4606, reward 698.0, memory_length 2000, epsilon 0.01579333986644199, time 723.0, rides 130\n",
      "Initial State is  [4, 11, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4607, reward 840.0, memory_length 2000, epsilon 0.015779125860562192, time 725.0, rides 140\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 4608, reward 931.0, memory_length 2000, epsilon 0.015764924647287685, time 731.0, rides 123\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 4609, reward 996.0, memory_length 2000, epsilon 0.015750736215105126, time 722.0, rides 134\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4610, reward 943.0, memory_length 2000, epsilon 0.01573656055251153, time 729.0, rides 131\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 4611, reward 852.0, memory_length 2000, epsilon 0.01572239764801427, time 726.0, rides 123\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4612, reward 1100.0, memory_length 2000, epsilon 0.015708247490131055, time 738.0, rides 131\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4613, reward 972.0, memory_length 2000, epsilon 0.015694110067389938, time 732.0, rides 129\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 4614, reward 954.0, memory_length 2000, epsilon 0.015679985368329288, time 722.0, rides 141\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 4615, reward 913.0, memory_length 2000, epsilon 0.015665873381497792, time 728.0, rides 147\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 4616, reward 849.0, memory_length 2000, epsilon 0.015651774095454443, time 731.0, rides 127\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4617, reward 1193.0, memory_length 2000, epsilon 0.015637687498768534, time 723.0, rides 146\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 4618, reward 1139.0, memory_length 2000, epsilon 0.015623613580019643, time 726.0, rides 128\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4619, reward 742.0, memory_length 2000, epsilon 0.015609552327797625, time 730.0, rides 120\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 4620, reward 714.0, memory_length 2000, epsilon 0.015595503730702606, time 728.0, rides 132\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 4621, reward 1240.0, memory_length 2000, epsilon 0.015581467777344973, time 725.0, rides 143\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4622, reward 629.0, memory_length 2000, epsilon 0.015567444456345362, time 723.0, rides 140\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4623, reward 805.0, memory_length 2000, epsilon 0.015553433756334651, time 729.0, rides 137\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 4624, reward 1000.0, memory_length 2000, epsilon 0.01553943566595395, time 727.0, rides 141\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 4625, reward 974.0, memory_length 2000, epsilon 0.015525450173854592, time 728.0, rides 135\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4626, reward 977.0, memory_length 2000, epsilon 0.015511477268698122, time 728.0, rides 135\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 4627, reward 1193.0, memory_length 2000, epsilon 0.015497516939156294, time 730.0, rides 135\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4628, reward 1228.0, memory_length 2000, epsilon 0.015483569173911053, time 722.0, rides 130\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 4629, reward 941.0, memory_length 2000, epsilon 0.015469633961654534, time 729.0, rides 128\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 4630, reward 1066.0, memory_length 2000, epsilon 0.015455711291089044, time 732.0, rides 133\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 4631, reward 981.0, memory_length 2000, epsilon 0.015441801150927064, time 734.0, rides 135\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4632, reward 1080.0, memory_length 2000, epsilon 0.01542790352989123, time 733.0, rides 128\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 4633, reward 706.0, memory_length 2000, epsilon 0.015414018416714328, time 733.0, rides 131\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 4634, reward 1009.0, memory_length 2000, epsilon 0.015400145800139285, time 730.0, rides 139\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4635, reward 628.0, memory_length 2000, epsilon 0.01538628566891916, time 729.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 4636, reward 925.0, memory_length 2000, epsilon 0.015372438011817131, time 731.0, rides 147\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4637, reward 882.0, memory_length 2000, epsilon 0.015358602817606495, time 728.0, rides 130\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4638, reward 956.0, memory_length 2000, epsilon 0.01534478007507065, time 723.0, rides 148\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4639, reward 847.0, memory_length 2000, epsilon 0.015330969773003087, time 734.0, rides 140\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 4640, reward 950.0, memory_length 2000, epsilon 0.015317171900207384, time 724.0, rides 132\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 4641, reward 1131.0, memory_length 2000, epsilon 0.015303386445497197, time 728.0, rides 145\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4642, reward 1212.0, memory_length 2000, epsilon 0.01528961339769625, time 724.0, rides 134\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 4643, reward 1122.0, memory_length 2000, epsilon 0.015275852745638323, time 729.0, rides 142\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 4644, reward 1112.0, memory_length 2000, epsilon 0.01526210447816725, time 730.0, rides 134\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4645, reward 1111.0, memory_length 2000, epsilon 0.015248368584136899, time 733.0, rides 123\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4646, reward 853.0, memory_length 2000, epsilon 0.015234645052411176, time 723.0, rides 142\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4647, reward 666.0, memory_length 2000, epsilon 0.015220933871864005, time 729.0, rides 140\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4648, reward 820.0, memory_length 2000, epsilon 0.015207235031379327, time 736.0, rides 142\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 4649, reward 936.0, memory_length 2000, epsilon 0.015193548519851085, time 720.0, rides 137\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 4650, reward 1028.0, memory_length 2000, epsilon 0.015179874326183219, time 727.0, rides 156\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 4651, reward 925.0, memory_length 2000, epsilon 0.015166212439289653, time 731.0, rides 150\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 4652, reward 995.0, memory_length 2000, epsilon 0.015152562848094292, time 724.0, rides 136\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 4653, reward 717.0, memory_length 2000, epsilon 0.015138925541531007, time 726.0, rides 154\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4654, reward 897.0, memory_length 2000, epsilon 0.015125300508543629, time 725.0, rides 139\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4655, reward 704.0, memory_length 2000, epsilon 0.01511168773808594, time 733.0, rides 137\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4656, reward 1075.0, memory_length 2000, epsilon 0.015098087219121663, time 733.0, rides 137\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 4657, reward 853.0, memory_length 2000, epsilon 0.015084498940624453, time 723.0, rides 143\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 4658, reward 1039.0, memory_length 2000, epsilon 0.015070922891577892, time 735.0, rides 150\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4659, reward 686.0, memory_length 2000, epsilon 0.015057359060975472, time 734.0, rides 122\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 4660, reward 756.0, memory_length 2000, epsilon 0.015043807437820593, time 721.0, rides 147\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 4661, reward 939.0, memory_length 2000, epsilon 0.015030268011126554, time 735.0, rides 145\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 4662, reward 965.0, memory_length 2000, epsilon 0.01501674076991654, time 736.0, rides 128\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 4663, reward 1027.0, memory_length 2000, epsilon 0.015003225703223613, time 737.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 4664, reward 888.0, memory_length 2000, epsilon 0.014989722800090711, time 724.0, rides 137\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 4665, reward 1080.0, memory_length 2000, epsilon 0.01497623204957063, time 732.0, rides 134\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 4666, reward 693.0, memory_length 2000, epsilon 0.014962753440726015, time 725.0, rides 134\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 4667, reward 1036.0, memory_length 2000, epsilon 0.01494928696262936, time 723.0, rides 137\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 4668, reward 961.0, memory_length 2000, epsilon 0.014935832604362995, time 728.0, rides 138\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4669, reward 992.0, memory_length 2000, epsilon 0.014922390355019069, time 736.0, rides 141\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 4670, reward 948.0, memory_length 2000, epsilon 0.014908960203699551, time 731.0, rides 132\n",
      "Initial State is  [1, 21, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4671, reward 643.0, memory_length 2000, epsilon 0.014895542139516221, time 722.0, rides 133\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4672, reward 855.0, memory_length 2000, epsilon 0.014882136151590656, time 733.0, rides 140\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4673, reward 852.0, memory_length 2000, epsilon 0.014868742229054224, time 730.0, rides 157\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 4674, reward 732.0, memory_length 2000, epsilon 0.014855360361048075, time 733.0, rides 137\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 4675, reward 875.0, memory_length 2000, epsilon 0.01484199053672313, time 724.0, rides 138\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 4676, reward 1049.0, memory_length 2000, epsilon 0.01482863274524008, time 720.0, rides 133\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 4677, reward 934.0, memory_length 2000, epsilon 0.014815286975769363, time 726.0, rides 129\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4678, reward 983.0, memory_length 2000, epsilon 0.01480195321749117, time 732.0, rides 142\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 4679, reward 1088.0, memory_length 2000, epsilon 0.014788631459595428, time 730.0, rides 133\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 4680, reward 872.0, memory_length 2000, epsilon 0.014775321691281791, time 733.0, rides 124\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 4681, reward 997.0, memory_length 2000, epsilon 0.014762023901759638, time 731.0, rides 130\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 4682, reward 1054.0, memory_length 2000, epsilon 0.014748738080248054, time 730.0, rides 136\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 4683, reward 758.0, memory_length 2000, epsilon 0.014735464215975831, time 730.0, rides 136\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4684, reward 893.0, memory_length 2000, epsilon 0.014722202298181452, time 724.0, rides 134\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 4685, reward 952.0, memory_length 2000, epsilon 0.014708952316113088, time 728.0, rides 130\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4686, reward 798.0, memory_length 2000, epsilon 0.014695714259028585, time 729.0, rides 139\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 4687, reward 718.0, memory_length 2000, epsilon 0.01468248811619546, time 727.0, rides 133\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 4688, reward 999.0, memory_length 2000, epsilon 0.014669273876890885, time 734.0, rides 140\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 4689, reward 1082.0, memory_length 2000, epsilon 0.014656071530401682, time 727.0, rides 137\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 4690, reward 637.0, memory_length 2000, epsilon 0.014642881066024321, time 725.0, rides 128\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4691, reward 784.0, memory_length 2000, epsilon 0.0146297024730649, time 729.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 4692, reward 929.0, memory_length 2000, epsilon 0.01461653574083914, time 731.0, rides 123\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 4693, reward 981.0, memory_length 2000, epsilon 0.014603380858672384, time 733.0, rides 129\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4694, reward 767.0, memory_length 2000, epsilon 0.01459023781589958, time 723.0, rides 125\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 4695, reward 1110.0, memory_length 2000, epsilon 0.01457710660186527, time 731.0, rides 130\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 4696, reward 619.0, memory_length 2000, epsilon 0.014563987205923591, time 730.0, rides 128\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4697, reward 1060.0, memory_length 2000, epsilon 0.01455087961743826, time 727.0, rides 142\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 4698, reward 677.0, memory_length 2000, epsilon 0.014537783825782564, time 726.0, rides 126\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 4699, reward 920.0, memory_length 2000, epsilon 0.01452469982033936, time 729.0, rides 147\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 4700, reward 1065.0, memory_length 2000, epsilon 0.014511627590501053, time 729.0, rides 149\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 4701, reward 796.0, memory_length 2000, epsilon 0.014498567125669602, time 728.0, rides 133\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 4702, reward 1052.0, memory_length 2000, epsilon 0.014485518415256499, time 727.0, rides 140\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 4703, reward 761.0, memory_length 2000, epsilon 0.014472481448682767, time 730.0, rides 122\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4704, reward 934.0, memory_length 2000, epsilon 0.014459456215378952, time 730.0, rides 130\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 4705, reward 680.0, memory_length 2000, epsilon 0.01444644270478511, time 729.0, rides 133\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 4706, reward 942.0, memory_length 2000, epsilon 0.014433440906350804, time 727.0, rides 129\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 4707, reward 947.0, memory_length 2000, epsilon 0.014420450809535088, time 733.0, rides 132\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 4708, reward 866.0, memory_length 2000, epsilon 0.014407472403806507, time 724.0, rides 130\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 4709, reward 1106.0, memory_length 2000, epsilon 0.014394505678643081, time 726.0, rides 121\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 4710, reward 836.0, memory_length 2000, epsilon 0.014381550623532302, time 727.0, rides 127\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4711, reward 962.0, memory_length 2000, epsilon 0.014368607227971123, time 731.0, rides 138\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4712, reward 767.0, memory_length 2000, epsilon 0.014355675481465949, time 722.0, rides 127\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 4713, reward 823.0, memory_length 2000, epsilon 0.014342755373532629, time 734.0, rides 140\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 4714, reward 843.0, memory_length 2000, epsilon 0.014329846893696449, time 725.0, rides 128\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 4715, reward 830.0, memory_length 2000, epsilon 0.014316950031492122, time 722.0, rides 128\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4716, reward 1070.0, memory_length 2000, epsilon 0.014304064776463779, time 728.0, rides 121\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 4717, reward 953.0, memory_length 2000, epsilon 0.01429119111816496, time 729.0, rides 121\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 4718, reward 815.0, memory_length 2000, epsilon 0.014278329046158611, time 730.0, rides 124\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 4719, reward 1209.0, memory_length 2000, epsilon 0.014265478550017068, time 737.0, rides 147\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4720, reward 841.0, memory_length 2000, epsilon 0.014252639619322053, time 732.0, rides 129\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4721, reward 1042.0, memory_length 2000, epsilon 0.014239812243664662, time 735.0, rides 138\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 4722, reward 855.0, memory_length 2000, epsilon 0.014226996412645364, time 725.0, rides 134\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4723, reward 720.0, memory_length 2000, epsilon 0.014214192115873983, time 725.0, rides 130\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 4724, reward 994.0, memory_length 2000, epsilon 0.014201399342969696, time 733.0, rides 130\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4725, reward 1008.0, memory_length 2000, epsilon 0.014188618083561023, time 733.0, rides 130\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4726, reward 797.0, memory_length 2000, epsilon 0.014175848327285818, time 728.0, rides 128\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 4727, reward 1009.0, memory_length 2000, epsilon 0.01416309006379126, time 733.0, rides 131\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 4728, reward 1265.0, memory_length 2000, epsilon 0.014150343282733848, time 733.0, rides 142\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 4729, reward 1115.0, memory_length 2000, epsilon 0.014137607973779387, time 732.0, rides 142\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 4730, reward 1173.0, memory_length 2000, epsilon 0.014124884126602986, time 727.0, rides 141\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4731, reward 860.0, memory_length 2000, epsilon 0.014112171730889043, time 727.0, rides 127\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 4732, reward 1323.0, memory_length 2000, epsilon 0.014099470776331243, time 731.0, rides 139\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 4733, reward 944.0, memory_length 2000, epsilon 0.014086781252632545, time 736.0, rides 123\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 4734, reward 776.0, memory_length 2000, epsilon 0.014074103149505175, time 731.0, rides 127\n",
      "Initial State is  [1, 4, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4735, reward 697.0, memory_length 2000, epsilon 0.01406143645667062, time 728.0, rides 128\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 4736, reward 902.0, memory_length 2000, epsilon 0.014048781163859617, time 729.0, rides 129\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 4737, reward 1112.0, memory_length 2000, epsilon 0.014036137260812143, time 726.0, rides 138\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 4738, reward 1126.0, memory_length 2000, epsilon 0.014023504737277412, time 734.0, rides 129\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 4739, reward 971.0, memory_length 2000, epsilon 0.014010883583013861, time 720.0, rides 135\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 4740, reward 917.0, memory_length 2000, epsilon 0.013998273787789148, time 731.0, rides 144\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4741, reward 863.0, memory_length 2000, epsilon 0.013985675341380139, time 728.0, rides 148\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4742, reward 654.0, memory_length 2000, epsilon 0.013973088233572897, time 723.0, rides 120\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 4743, reward 957.0, memory_length 2000, epsilon 0.013960512454162681, time 724.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 4744, reward 1161.0, memory_length 2000, epsilon 0.013947947992953935, time 732.0, rides 130\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4745, reward 841.0, memory_length 2000, epsilon 0.013935394839760275, time 725.0, rides 134\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4746, reward 810.0, memory_length 2000, epsilon 0.013922852984404491, time 724.0, rides 144\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4747, reward 880.0, memory_length 2000, epsilon 0.013910322416718527, time 725.0, rides 127\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 4748, reward 953.0, memory_length 2000, epsilon 0.01389780312654348, time 729.0, rides 133\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 4749, reward 1219.0, memory_length 2000, epsilon 0.013885295103729592, time 731.0, rides 139\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 4750, reward 653.0, memory_length 2000, epsilon 0.013872798338136235, time 730.0, rides 124\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4751, reward 1074.0, memory_length 2000, epsilon 0.013860312819631912, time 724.0, rides 127\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 4752, reward 849.0, memory_length 2000, epsilon 0.013847838538094244, time 736.0, rides 124\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 4753, reward 902.0, memory_length 2000, epsilon 0.013835375483409958, time 733.0, rides 148\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 4754, reward 1119.0, memory_length 2000, epsilon 0.01382292364547489, time 726.0, rides 139\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 4755, reward 791.0, memory_length 2000, epsilon 0.013810483014193962, time 728.0, rides 125\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 4756, reward 945.0, memory_length 2000, epsilon 0.013798053579481188, time 726.0, rides 135\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 4757, reward 1024.0, memory_length 2000, epsilon 0.013785635331259654, time 731.0, rides 137\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 4758, reward 1207.0, memory_length 2000, epsilon 0.01377322825946152, time 724.0, rides 128\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 4759, reward 681.0, memory_length 2000, epsilon 0.013760832354028005, time 728.0, rides 131\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4760, reward 1016.0, memory_length 2000, epsilon 0.01374844760490938, time 730.0, rides 141\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4761, reward 1053.0, memory_length 2000, epsilon 0.013736074002064962, time 732.0, rides 128\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 4762, reward 1133.0, memory_length 2000, epsilon 0.013723711535463104, time 726.0, rides 138\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 4763, reward 1259.0, memory_length 2000, epsilon 0.013711360195081186, time 729.0, rides 141\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 4764, reward 1009.0, memory_length 2000, epsilon 0.013699019970905613, time 728.0, rides 137\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4765, reward 1289.0, memory_length 2000, epsilon 0.013686690852931798, time 728.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 4766, reward 1036.0, memory_length 2000, epsilon 0.013674372831164159, time 731.0, rides 130\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 4767, reward 967.0, memory_length 2000, epsilon 0.013662065895616112, time 739.0, rides 131\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 4768, reward 1097.0, memory_length 2000, epsilon 0.013649770036310058, time 726.0, rides 140\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 4769, reward 989.0, memory_length 2000, epsilon 0.013637485243277379, time 722.0, rides 140\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 4770, reward 1045.0, memory_length 2000, epsilon 0.013625211506558429, time 727.0, rides 136\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 4771, reward 919.0, memory_length 2000, epsilon 0.013612948816202525, time 726.0, rides 144\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 4772, reward 860.0, memory_length 2000, epsilon 0.013600697162267942, time 731.0, rides 145\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 4773, reward 867.0, memory_length 2000, epsilon 0.0135884565348219, time 731.0, rides 143\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4774, reward 924.0, memory_length 2000, epsilon 0.013576226923940561, time 737.0, rides 143\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 4775, reward 836.0, memory_length 2000, epsilon 0.013564008319709015, time 725.0, rides 141\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 4776, reward 979.0, memory_length 2000, epsilon 0.013551800712221276, time 728.0, rides 135\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 4777, reward 780.0, memory_length 2000, epsilon 0.013539604091580277, time 733.0, rides 136\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4778, reward 975.0, memory_length 2000, epsilon 0.013527418447897854, time 723.0, rides 140\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 4779, reward 1062.0, memory_length 2000, epsilon 0.013515243771294745, time 732.0, rides 146\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 4780, reward 1134.0, memory_length 2000, epsilon 0.01350308005190058, time 729.0, rides 134\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 4781, reward 791.0, memory_length 2000, epsilon 0.013490927279853869, time 733.0, rides 126\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4782, reward 1123.0, memory_length 2000, epsilon 0.013478785445302, time 726.0, rides 143\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 4783, reward 1154.0, memory_length 2000, epsilon 0.013466654538401228, time 736.0, rides 130\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4784, reward 963.0, memory_length 2000, epsilon 0.013454534549316667, time 728.0, rides 135\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 4785, reward 1161.0, memory_length 2000, epsilon 0.013442425468222283, time 732.0, rides 152\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 4786, reward 1014.0, memory_length 2000, epsilon 0.013430327285300882, time 726.0, rides 141\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 4787, reward 937.0, memory_length 2000, epsilon 0.013418239990744112, time 734.0, rides 135\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 4788, reward 1024.0, memory_length 2000, epsilon 0.013406163574752442, time 726.0, rides 157\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4789, reward 1299.0, memory_length 2000, epsilon 0.013394098027535165, time 728.0, rides 137\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 4790, reward 996.0, memory_length 2000, epsilon 0.013382043339310383, time 729.0, rides 123\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 4791, reward 1024.0, memory_length 2000, epsilon 0.013369999500305004, time 724.0, rides 130\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 4792, reward 1083.0, memory_length 2000, epsilon 0.01335796650075473, time 725.0, rides 126\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 4793, reward 804.0, memory_length 2000, epsilon 0.013345944330904051, time 729.0, rides 147\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4794, reward 1021.0, memory_length 2000, epsilon 0.013333932981006238, time 733.0, rides 144\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 4795, reward 999.0, memory_length 2000, epsilon 0.013321932441323332, time 727.0, rides 145\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 4796, reward 1217.0, memory_length 2000, epsilon 0.01330994270212614, time 734.0, rides 138\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 4797, reward 1031.0, memory_length 2000, epsilon 0.013297963753694226, time 729.0, rides 139\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4798, reward 1029.0, memory_length 2000, epsilon 0.013285995586315902, time 736.0, rides 135\n",
      "Initial State is  [1, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4799, reward 827.0, memory_length 2000, epsilon 0.013274038190288218, time 730.0, rides 130\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4800, reward 786.0, memory_length 2000, epsilon 0.013262091555916958, time 723.0, rides 139\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 4801, reward 752.0, memory_length 2000, epsilon 0.013250155673516633, time 727.0, rides 123\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 4802, reward 919.0, memory_length 2000, epsilon 0.013238230533410467, time 732.0, rides 127\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 4803, reward 838.0, memory_length 2000, epsilon 0.013226316125930398, time 725.0, rides 129\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 4804, reward 1089.0, memory_length 2000, epsilon 0.013214412441417061, time 728.0, rides 137\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4805, reward 1239.0, memory_length 2000, epsilon 0.013202519470219786, time 728.0, rides 147\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 4806, reward 1065.0, memory_length 2000, epsilon 0.013190637202696589, time 727.0, rides 127\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4807, reward 943.0, memory_length 2000, epsilon 0.013178765629214162, time 731.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 4808, reward 812.0, memory_length 2000, epsilon 0.013166904740147868, time 729.0, rides 136\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 4809, reward 1117.0, memory_length 2000, epsilon 0.013155054525881735, time 724.0, rides 129\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4810, reward 1043.0, memory_length 2000, epsilon 0.013143214976808442, time 732.0, rides 143\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4811, reward 1007.0, memory_length 2000, epsilon 0.013131386083329314, time 729.0, rides 137\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 4812, reward 891.0, memory_length 2000, epsilon 0.013119567835854317, time 738.0, rides 138\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 4813, reward 1134.0, memory_length 2000, epsilon 0.013107760224802048, time 740.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 4814, reward 1034.0, memory_length 2000, epsilon 0.013095963240599726, time 732.0, rides 123\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4815, reward 1050.0, memory_length 2000, epsilon 0.013084176873683186, time 727.0, rides 150\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4816, reward 863.0, memory_length 2000, epsilon 0.013072401114496871, time 723.0, rides 144\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 4817, reward 834.0, memory_length 2000, epsilon 0.013060635953493823, time 722.0, rides 135\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 4818, reward 932.0, memory_length 2000, epsilon 0.013048881381135679, time 726.0, rides 149\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 4819, reward 794.0, memory_length 2000, epsilon 0.013037137387892656, time 729.0, rides 145\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 4820, reward 1070.0, memory_length 2000, epsilon 0.013025403964243553, time 723.0, rides 142\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 4821, reward 905.0, memory_length 2000, epsilon 0.013013681100675733, time 730.0, rides 146\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4822, reward 1109.0, memory_length 2000, epsilon 0.013001968787685125, time 723.0, rides 137\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4823, reward 1038.0, memory_length 2000, epsilon 0.012990267015776208, time 733.0, rides 129\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 4824, reward 875.0, memory_length 2000, epsilon 0.01297857577546201, time 729.0, rides 139\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4825, reward 849.0, memory_length 2000, epsilon 0.012966895057264094, time 730.0, rides 124\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 4826, reward 802.0, memory_length 2000, epsilon 0.012955224851712556, time 730.0, rides 137\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 4827, reward 1135.0, memory_length 2000, epsilon 0.012943565149346015, time 731.0, rides 123\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 4828, reward 1248.0, memory_length 2000, epsilon 0.012931915940711605, time 732.0, rides 130\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4829, reward 813.0, memory_length 2000, epsilon 0.012920277216364963, time 726.0, rides 129\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 4830, reward 1054.0, memory_length 2000, epsilon 0.012908648966870235, time 731.0, rides 134\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 4831, reward 925.0, memory_length 2000, epsilon 0.012897031182800051, time 738.0, rides 145\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4832, reward 560.0, memory_length 2000, epsilon 0.01288542385473553, time 732.0, rides 132\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 4833, reward 583.0, memory_length 2000, epsilon 0.01287382697326627, time 730.0, rides 137\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4834, reward 741.0, memory_length 2000, epsilon 0.01286224052899033, time 728.0, rides 150\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 4835, reward 810.0, memory_length 2000, epsilon 0.012850664512514237, time 728.0, rides 127\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4836, reward 1133.0, memory_length 2000, epsilon 0.012839098914452974, time 725.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 4837, reward 978.0, memory_length 2000, epsilon 0.012827543725429966, time 722.0, rides 145\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4838, reward 951.0, memory_length 2000, epsilon 0.012815998936077079, time 737.0, rides 135\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 4839, reward 1103.0, memory_length 2000, epsilon 0.01280446453703461, time 723.0, rides 139\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4840, reward 1245.0, memory_length 2000, epsilon 0.012792940518951279, time 724.0, rides 139\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4841, reward 988.0, memory_length 2000, epsilon 0.012781426872484222, time 736.0, rides 133\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 4842, reward 968.0, memory_length 2000, epsilon 0.012769923588298987, time 724.0, rides 145\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4843, reward 873.0, memory_length 2000, epsilon 0.012758430657069518, time 733.0, rides 125\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 4844, reward 909.0, memory_length 2000, epsilon 0.012746948069478155, time 725.0, rides 119\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 4845, reward 991.0, memory_length 2000, epsilon 0.012735475816215624, time 736.0, rides 136\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 4846, reward 1108.0, memory_length 2000, epsilon 0.01272401388798103, time 735.0, rides 151\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 4847, reward 945.0, memory_length 2000, epsilon 0.012712562275481848, time 736.0, rides 126\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 4848, reward 822.0, memory_length 2000, epsilon 0.012701120969433913, time 731.0, rides 133\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4849, reward 897.0, memory_length 2000, epsilon 0.012689689960561423, time 737.0, rides 138\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 4850, reward 890.0, memory_length 2000, epsilon 0.012678269239596918, time 727.0, rides 140\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 4851, reward 1103.0, memory_length 2000, epsilon 0.01266685879728128, time 737.0, rides 131\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 4852, reward 573.0, memory_length 2000, epsilon 0.012655458624363727, time 729.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 4853, reward 1138.0, memory_length 2000, epsilon 0.0126440687116018, time 729.0, rides 135\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4854, reward 1015.0, memory_length 2000, epsilon 0.012632689049761357, time 729.0, rides 151\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 4855, reward 847.0, memory_length 2000, epsilon 0.012621319629616571, time 732.0, rides 140\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 4856, reward 550.0, memory_length 2000, epsilon 0.012609960441949916, time 729.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 4857, reward 826.0, memory_length 2000, epsilon 0.01259861147755216, time 727.0, rides 138\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 4858, reward 968.0, memory_length 2000, epsilon 0.012587272727222362, time 729.0, rides 141\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 4859, reward 990.0, memory_length 2000, epsilon 0.012575944181767862, time 725.0, rides 139\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 4860, reward 1022.0, memory_length 2000, epsilon 0.01256462583200427, time 723.0, rides 130\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 4861, reward 1035.0, memory_length 2000, epsilon 0.012553317668755467, time 725.0, rides 140\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4862, reward 868.0, memory_length 2000, epsilon 0.012542019682853588, time 727.0, rides 135\n",
      "Initial State is  [4, 8, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4863, reward 688.0, memory_length 2000, epsilon 0.01253073186513902, time 728.0, rides 136\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 4864, reward 991.0, memory_length 2000, epsilon 0.012519454206460393, time 737.0, rides 133\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 4865, reward 912.0, memory_length 2000, epsilon 0.012508186697674579, time 724.0, rides 132\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 4866, reward 1050.0, memory_length 2000, epsilon 0.012496929329646671, time 726.0, rides 127\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 4867, reward 709.0, memory_length 2000, epsilon 0.012485682093249989, time 721.0, rides 127\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 4868, reward 1211.0, memory_length 2000, epsilon 0.012474444979366063, time 730.0, rides 137\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 4869, reward 963.0, memory_length 2000, epsilon 0.012463217978884633, time 726.0, rides 133\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4870, reward 1012.0, memory_length 2000, epsilon 0.012452001082703636, time 731.0, rides 134\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 4871, reward 977.0, memory_length 2000, epsilon 0.012440794281729202, time 732.0, rides 124\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 4872, reward 803.0, memory_length 2000, epsilon 0.012429597566875646, time 728.0, rides 127\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 4873, reward 1167.0, memory_length 2000, epsilon 0.012418410929065458, time 730.0, rides 129\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 4874, reward 627.0, memory_length 2000, epsilon 0.012407234359229299, time 727.0, rides 126\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4875, reward 918.0, memory_length 2000, epsilon 0.012396067848305992, time 730.0, rides 130\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 4876, reward 694.0, memory_length 2000, epsilon 0.012384911387242516, time 728.0, rides 146\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4877, reward 1088.0, memory_length 2000, epsilon 0.012373764966993998, time 731.0, rides 135\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 4878, reward 1106.0, memory_length 2000, epsilon 0.012362628578523703, time 721.0, rides 138\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4879, reward 1192.0, memory_length 2000, epsilon 0.012351502212803032, time 721.0, rides 129\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 4880, reward 767.0, memory_length 2000, epsilon 0.01234038586081151, time 730.0, rides 130\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 4881, reward 914.0, memory_length 2000, epsilon 0.01232927951353678, time 726.0, rides 135\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 4882, reward 1002.0, memory_length 2000, epsilon 0.012318183161974597, time 722.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4883, reward 963.0, memory_length 2000, epsilon 0.01230709679712882, time 727.0, rides 136\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 4884, reward 1063.0, memory_length 2000, epsilon 0.012296020410011403, time 731.0, rides 128\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 4885, reward 922.0, memory_length 2000, epsilon 0.012284953991642393, time 728.0, rides 142\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 4886, reward 997.0, memory_length 2000, epsilon 0.012273897533049914, time 729.0, rides 132\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4887, reward 886.0, memory_length 2000, epsilon 0.01226285102527017, time 731.0, rides 127\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 4888, reward 1194.0, memory_length 2000, epsilon 0.012251814459347426, time 728.0, rides 136\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 4889, reward 850.0, memory_length 2000, epsilon 0.012240787826334013, time 726.0, rides 125\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4890, reward 910.0, memory_length 2000, epsilon 0.012229771117290312, time 723.0, rides 137\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4891, reward 1070.0, memory_length 2000, epsilon 0.01221876432328475, time 732.0, rides 132\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4892, reward 988.0, memory_length 2000, epsilon 0.012207767435393794, time 727.0, rides 136\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 4893, reward 1151.0, memory_length 2000, epsilon 0.01219678044470194, time 722.0, rides 121\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 4894, reward 989.0, memory_length 2000, epsilon 0.012185803342301708, time 730.0, rides 130\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 4895, reward 962.0, memory_length 2000, epsilon 0.012174836119293637, time 730.0, rides 120\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4896, reward 1085.0, memory_length 2000, epsilon 0.012163878766786273, time 725.0, rides 122\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 4897, reward 964.0, memory_length 2000, epsilon 0.012152931275896166, time 729.0, rides 126\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4898, reward 852.0, memory_length 2000, epsilon 0.012141993637747858, time 730.0, rides 122\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4899, reward 1061.0, memory_length 2000, epsilon 0.012131065843473884, time 730.0, rides 137\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4900, reward 753.0, memory_length 2000, epsilon 0.012120147884214758, time 726.0, rides 135\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4901, reward 714.0, memory_length 2000, epsilon 0.012109239751118965, time 723.0, rides 146\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 4902, reward 815.0, memory_length 2000, epsilon 0.012098341435342958, time 731.0, rides 149\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 4903, reward 854.0, memory_length 2000, epsilon 0.01208745292805115, time 727.0, rides 125\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 4904, reward 785.0, memory_length 2000, epsilon 0.012076574220415904, time 724.0, rides 133\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 4905, reward 944.0, memory_length 2000, epsilon 0.01206570530361753, time 733.0, rides 140\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4906, reward 986.0, memory_length 2000, epsilon 0.012054846168844275, time 727.0, rides 146\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 4907, reward 937.0, memory_length 2000, epsilon 0.012043996807292314, time 730.0, rides 135\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 4908, reward 1165.0, memory_length 2000, epsilon 0.01203315721016575, time 722.0, rides 133\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 4909, reward 650.0, memory_length 2000, epsilon 0.0120223273686766, time 725.0, rides 129\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 4910, reward 1039.0, memory_length 2000, epsilon 0.012011507274044791, time 728.0, rides 129\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 4911, reward 438.0, memory_length 2000, epsilon 0.01200069691749815, time 737.0, rides 129\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 4912, reward 1131.0, memory_length 2000, epsilon 0.011989896290272401, time 728.0, rides 131\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 4913, reward 1138.0, memory_length 2000, epsilon 0.011979105383611157, time 730.0, rides 137\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 4914, reward 1092.0, memory_length 2000, epsilon 0.011968324188765906, time 733.0, rides 127\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4915, reward 629.0, memory_length 2000, epsilon 0.011957552696996016, time 729.0, rides 127\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 4916, reward 821.0, memory_length 2000, epsilon 0.01194679089956872, time 733.0, rides 130\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 4917, reward 931.0, memory_length 2000, epsilon 0.01193603878775911, time 732.0, rides 131\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4918, reward 1166.0, memory_length 2000, epsilon 0.011925296352850126, time 731.0, rides 121\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 4919, reward 1130.0, memory_length 2000, epsilon 0.01191456358613256, time 730.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4920, reward 899.0, memory_length 2000, epsilon 0.011903840478905041, time 726.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4921, reward 1021.0, memory_length 2000, epsilon 0.011893127022474026, time 730.0, rides 137\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 4922, reward 1080.0, memory_length 2000, epsilon 0.0118824232081538, time 736.0, rides 136\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4923, reward 969.0, memory_length 2000, epsilon 0.011871729027266461, time 727.0, rides 142\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 4924, reward 1053.0, memory_length 2000, epsilon 0.011861044471141922, time 728.0, rides 136\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4925, reward 1030.0, memory_length 2000, epsilon 0.011850369531117894, time 729.0, rides 135\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 4926, reward 1040.0, memory_length 2000, epsilon 0.011839704198539887, time 720.0, rides 132\n",
      "Initial State is  [4, 15, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4927, reward 1021.0, memory_length 2000, epsilon 0.011829048464761202, time 737.0, rides 135\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 4928, reward 907.0, memory_length 2000, epsilon 0.011818402321142917, time 728.0, rides 128\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 4929, reward 665.0, memory_length 2000, epsilon 0.011807765759053887, time 721.0, rides 127\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 4930, reward 1100.0, memory_length 2000, epsilon 0.011797138769870739, time 732.0, rides 126\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 4931, reward 1000.0, memory_length 2000, epsilon 0.011786521344977855, time 729.0, rides 141\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 4932, reward 779.0, memory_length 2000, epsilon 0.011775913475767374, time 725.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 4933, reward 1159.0, memory_length 2000, epsilon 0.011765315153639183, time 731.0, rides 138\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 4934, reward 768.0, memory_length 2000, epsilon 0.011754726370000908, time 723.0, rides 141\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4935, reward 789.0, memory_length 2000, epsilon 0.011744147116267907, time 729.0, rides 136\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4936, reward 1075.0, memory_length 2000, epsilon 0.011733577383863266, time 726.0, rides 117\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 4937, reward 1040.0, memory_length 2000, epsilon 0.01172301716421779, time 732.0, rides 125\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 4938, reward 1187.0, memory_length 2000, epsilon 0.011712466448769993, time 733.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4939, reward 932.0, memory_length 2000, epsilon 0.0117019252289661, time 733.0, rides 121\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 4940, reward 926.0, memory_length 2000, epsilon 0.011691393496260031, time 727.0, rides 132\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4941, reward 953.0, memory_length 2000, epsilon 0.011680871242113396, time 720.0, rides 126\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 4942, reward 900.0, memory_length 2000, epsilon 0.011670358457995494, time 729.0, rides 131\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 4943, reward 783.0, memory_length 2000, epsilon 0.011659855135383299, time 743.0, rides 133\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4944, reward 785.0, memory_length 2000, epsilon 0.011649361265761453, time 722.0, rides 115\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4945, reward 786.0, memory_length 2000, epsilon 0.011638876840622267, time 731.0, rides 115\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4946, reward 1030.0, memory_length 2000, epsilon 0.011628401851465707, time 727.0, rides 130\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 4947, reward 742.0, memory_length 2000, epsilon 0.011617936289799388, time 726.0, rides 124\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 4948, reward 976.0, memory_length 2000, epsilon 0.011607480147138569, time 731.0, rides 140\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 4949, reward 1077.0, memory_length 2000, epsilon 0.011597033415006144, time 725.0, rides 137\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 4950, reward 1098.0, memory_length 2000, epsilon 0.011586596084932638, time 731.0, rides 130\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 4951, reward 1034.0, memory_length 2000, epsilon 0.011576168148456198, time 727.0, rides 133\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 4952, reward 1001.0, memory_length 2000, epsilon 0.011565749597122588, time 722.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4953, reward 836.0, memory_length 2000, epsilon 0.011555340422485178, time 726.0, rides 125\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 4954, reward 632.0, memory_length 2000, epsilon 0.011544940616104941, time 731.0, rides 133\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4955, reward 1119.0, memory_length 2000, epsilon 0.011534550169550448, time 729.0, rides 142\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 4956, reward 936.0, memory_length 2000, epsilon 0.011524169074397852, time 728.0, rides 128\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 4957, reward 809.0, memory_length 2000, epsilon 0.011513797322230894, time 725.0, rides 129\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4958, reward 882.0, memory_length 2000, epsilon 0.011503434904640886, time 729.0, rides 125\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 4959, reward 983.0, memory_length 2000, epsilon 0.011493081813226709, time 729.0, rides 130\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 4960, reward 942.0, memory_length 2000, epsilon 0.011482738039594804, time 734.0, rides 138\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 4961, reward 1232.0, memory_length 2000, epsilon 0.011472403575359169, time 729.0, rides 125\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 4962, reward 918.0, memory_length 2000, epsilon 0.011462078412141346, time 722.0, rides 138\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 4963, reward 754.0, memory_length 2000, epsilon 0.011451762541570418, time 732.0, rides 136\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 4964, reward 993.0, memory_length 2000, epsilon 0.011441455955283003, time 737.0, rides 141\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 4965, reward 799.0, memory_length 2000, epsilon 0.011431158644923249, time 728.0, rides 143\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 4966, reward 1002.0, memory_length 2000, epsilon 0.011420870602142818, time 722.0, rides 136\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 4967, reward 1024.0, memory_length 2000, epsilon 0.01141059181860089, time 730.0, rides 133\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 4968, reward 1205.0, memory_length 2000, epsilon 0.011400322285964149, time 727.0, rides 133\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 4969, reward 865.0, memory_length 2000, epsilon 0.01139006199590678, time 726.0, rides 154\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 4970, reward 846.0, memory_length 2000, epsilon 0.011379810940110464, time 728.0, rides 143\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4971, reward 886.0, memory_length 2000, epsilon 0.011369569110264365, time 732.0, rides 132\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 4972, reward 1071.0, memory_length 2000, epsilon 0.011359336498065127, time 734.0, rides 133\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4973, reward 1051.0, memory_length 2000, epsilon 0.011349113095216868, time 724.0, rides 130\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 4974, reward 969.0, memory_length 2000, epsilon 0.011338898893431173, time 739.0, rides 139\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 4975, reward 943.0, memory_length 2000, epsilon 0.011328693884427084, time 729.0, rides 138\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 4976, reward 915.0, memory_length 2000, epsilon 0.0113184980599311, time 722.0, rides 124\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 4977, reward 805.0, memory_length 2000, epsilon 0.01130831141167716, time 726.0, rides 124\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 4978, reward 878.0, memory_length 2000, epsilon 0.011298133931406652, time 741.0, rides 137\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 4979, reward 949.0, memory_length 2000, epsilon 0.011287965610868386, time 730.0, rides 142\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 4980, reward 896.0, memory_length 2000, epsilon 0.011277806441818604, time 723.0, rides 126\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 4981, reward 1133.0, memory_length 2000, epsilon 0.011267656416020967, time 727.0, rides 127\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4982, reward 876.0, memory_length 2000, epsilon 0.011257515525246549, time 728.0, rides 133\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 4983, reward 1000.0, memory_length 2000, epsilon 0.011247383761273827, time 731.0, rides 135\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 4984, reward 869.0, memory_length 2000, epsilon 0.01123726111588868, time 731.0, rides 135\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 4985, reward 931.0, memory_length 2000, epsilon 0.01122714758088438, time 720.0, rides 133\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4986, reward 848.0, memory_length 2000, epsilon 0.011217043148061585, time 728.0, rides 139\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4987, reward 873.0, memory_length 2000, epsilon 0.01120694780922833, time 725.0, rides 158\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 4988, reward 960.0, memory_length 2000, epsilon 0.011196861556200024, time 726.0, rides 131\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4989, reward 1024.0, memory_length 2000, epsilon 0.011186784380799444, time 722.0, rides 134\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 4990, reward 1113.0, memory_length 2000, epsilon 0.011176716274856724, time 723.0, rides 141\n",
      "Initial State is  [0, 4, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4991, reward 1007.0, memory_length 2000, epsilon 0.011166657230209353, time 724.0, rides 135\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4992, reward 839.0, memory_length 2000, epsilon 0.011156607238702165, time 728.0, rides 147\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 4993, reward 771.0, memory_length 2000, epsilon 0.011146566292187332, time 726.0, rides 132\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4994, reward 1185.0, memory_length 2000, epsilon 0.011136534382524363, time 723.0, rides 129\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4995, reward 1155.0, memory_length 2000, epsilon 0.01112651150158009, time 738.0, rides 137\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4996, reward 749.0, memory_length 2000, epsilon 0.011116497641228669, time 728.0, rides 129\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4997, reward 1068.0, memory_length 2000, epsilon 0.011106492793351562, time 728.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4998, reward 1099.0, memory_length 2000, epsilon 0.011096496949837546, time 734.0, rides 135\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4999, reward 614.0, memory_length 2000, epsilon 0.011086510102582693, time 733.0, rides 140\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5000, reward 894.0, memory_length 2000, epsilon 0.011076532243490369, time 735.0, rides 131\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 5001, reward 936.0, memory_length 2000, epsilon 0.011066563364471227, time 729.0, rides 140\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 5002, reward 1038.0, memory_length 2000, epsilon 0.011056603457443203, time 729.0, rides 130\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5003, reward 871.0, memory_length 2000, epsilon 0.011046652514331503, time 729.0, rides 133\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5004, reward 1024.0, memory_length 2000, epsilon 0.011036710527068604, time 728.0, rides 137\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 5005, reward 969.0, memory_length 2000, epsilon 0.011026777487594243, time 731.0, rides 127\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5006, reward 993.0, memory_length 2000, epsilon 0.011016853387855408, time 728.0, rides 141\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 5007, reward 944.0, memory_length 2000, epsilon 0.011006938219806337, time 734.0, rides 142\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 5008, reward 1252.0, memory_length 2000, epsilon 0.010997031975408512, time 731.0, rides 128\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5009, reward 905.0, memory_length 2000, epsilon 0.010987134646630644, time 737.0, rides 131\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 5010, reward 1007.0, memory_length 2000, epsilon 0.010977246225448677, time 726.0, rides 138\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 5011, reward 1049.0, memory_length 2000, epsilon 0.010967366703845773, time 730.0, rides 138\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 5012, reward 877.0, memory_length 2000, epsilon 0.010957496073812311, time 729.0, rides 127\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5013, reward 871.0, memory_length 2000, epsilon 0.010947634327345879, time 728.0, rides 150\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 5014, reward 1186.0, memory_length 2000, epsilon 0.010937781456451268, time 726.0, rides 148\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 5015, reward 876.0, memory_length 2000, epsilon 0.010927937453140461, time 731.0, rides 142\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5016, reward 517.0, memory_length 2000, epsilon 0.010918102309432635, time 723.0, rides 144\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 5017, reward 1076.0, memory_length 2000, epsilon 0.010908276017354146, time 728.0, rides 141\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 5018, reward 1012.0, memory_length 2000, epsilon 0.010898458568938526, time 724.0, rides 135\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 5019, reward 783.0, memory_length 2000, epsilon 0.010888649956226482, time 732.0, rides 134\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 5020, reward 767.0, memory_length 2000, epsilon 0.010878850171265877, time 732.0, rides 143\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 5021, reward 740.0, memory_length 2000, epsilon 0.010869059206111737, time 721.0, rides 142\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 5022, reward 868.0, memory_length 2000, epsilon 0.010859277052826237, time 731.0, rides 142\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 5023, reward 945.0, memory_length 2000, epsilon 0.010849503703478694, time 734.0, rides 136\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5024, reward 1111.0, memory_length 2000, epsilon 0.010839739150145562, time 731.0, rides 134\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 5025, reward 830.0, memory_length 2000, epsilon 0.010829983384910431, time 724.0, rides 137\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 5026, reward 703.0, memory_length 2000, epsilon 0.010820236399864012, time 723.0, rides 125\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 5027, reward 1014.0, memory_length 2000, epsilon 0.010810498187104134, time 724.0, rides 145\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5028, reward 689.0, memory_length 2000, epsilon 0.01080076873873574, time 725.0, rides 134\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 5029, reward 755.0, memory_length 2000, epsilon 0.010791048046870878, time 726.0, rides 140\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5030, reward 851.0, memory_length 2000, epsilon 0.010781336103628695, time 723.0, rides 144\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 5031, reward 797.0, memory_length 2000, epsilon 0.010771632901135428, time 724.0, rides 127\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 5032, reward 976.0, memory_length 2000, epsilon 0.010761938431524407, time 732.0, rides 149\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 5033, reward 839.0, memory_length 2000, epsilon 0.010752252686936034, time 726.0, rides 137\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 5034, reward 1069.0, memory_length 2000, epsilon 0.010742575659517792, time 725.0, rides 132\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5035, reward 999.0, memory_length 2000, epsilon 0.010732907341424226, time 726.0, rides 129\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 5036, reward 874.0, memory_length 2000, epsilon 0.010723247724816944, time 727.0, rides 137\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 5037, reward 828.0, memory_length 2000, epsilon 0.010713596801864608, time 730.0, rides 129\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 5038, reward 1046.0, memory_length 2000, epsilon 0.01070395456474293, time 726.0, rides 134\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5039, reward 914.0, memory_length 2000, epsilon 0.01069432100563466, time 720.0, rides 136\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 5040, reward 850.0, memory_length 2000, epsilon 0.01068469611672959, time 733.0, rides 145\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5041, reward 1226.0, memory_length 2000, epsilon 0.010675079890224533, time 729.0, rides 138\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 5042, reward 921.0, memory_length 2000, epsilon 0.010665472318323332, time 726.0, rides 128\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 5043, reward 937.0, memory_length 2000, epsilon 0.01065587339323684, time 723.0, rides 135\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 5044, reward 868.0, memory_length 2000, epsilon 0.010646283107182927, time 743.0, rides 136\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5045, reward 939.0, memory_length 2000, epsilon 0.010636701452386462, time 729.0, rides 130\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 5046, reward 842.0, memory_length 2000, epsilon 0.010627128421079313, time 730.0, rides 136\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5047, reward 1160.0, memory_length 2000, epsilon 0.010617564005500343, time 736.0, rides 129\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 5048, reward 690.0, memory_length 2000, epsilon 0.010608008197895391, time 726.0, rides 138\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 5049, reward 915.0, memory_length 2000, epsilon 0.010598460990517285, time 724.0, rides 139\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 5050, reward 855.0, memory_length 2000, epsilon 0.01058892237562582, time 727.0, rides 129\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 5051, reward 966.0, memory_length 2000, epsilon 0.010579392345487756, time 729.0, rides 139\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 5052, reward 753.0, memory_length 2000, epsilon 0.010569870892376817, time 729.0, rides 140\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 5053, reward 881.0, memory_length 2000, epsilon 0.010560358008573677, time 722.0, rides 130\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5054, reward 770.0, memory_length 2000, epsilon 0.010550853686365961, time 728.0, rides 139\n",
      "Initial State is  [0, 12, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5055, reward 848.0, memory_length 2000, epsilon 0.010541357918048232, time 728.0, rides 135\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 5056, reward 988.0, memory_length 2000, epsilon 0.010531870695921989, time 735.0, rides 128\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 5057, reward 678.0, memory_length 2000, epsilon 0.01052239201229566, time 735.0, rides 143\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 5058, reward 1049.0, memory_length 2000, epsilon 0.010512921859484593, time 730.0, rides 135\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 5059, reward 806.0, memory_length 2000, epsilon 0.010503460229811057, time 734.0, rides 123\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 5060, reward 1064.0, memory_length 2000, epsilon 0.010494007115604227, time 730.0, rides 141\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 5061, reward 836.0, memory_length 2000, epsilon 0.010484562509200183, time 729.0, rides 137\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5062, reward 937.0, memory_length 2000, epsilon 0.010475126402941903, time 722.0, rides 139\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 5063, reward 1012.0, memory_length 2000, epsilon 0.010465698789179256, time 723.0, rides 127\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 5064, reward 802.0, memory_length 2000, epsilon 0.010456279660268995, time 732.0, rides 149\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5065, reward 921.0, memory_length 2000, epsilon 0.010446869008574753, time 733.0, rides 138\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 5066, reward 793.0, memory_length 2000, epsilon 0.010437466826467035, time 725.0, rides 130\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 5067, reward 1089.0, memory_length 2000, epsilon 0.010428073106323214, time 724.0, rides 135\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 5068, reward 1112.0, memory_length 2000, epsilon 0.010418687840527522, time 737.0, rides 116\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 5069, reward 1014.0, memory_length 2000, epsilon 0.010409311021471046, time 729.0, rides 141\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 5070, reward 1122.0, memory_length 2000, epsilon 0.010399942641551722, time 730.0, rides 126\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 5071, reward 1118.0, memory_length 2000, epsilon 0.010390582693174326, time 727.0, rides 140\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 5072, reward 959.0, memory_length 2000, epsilon 0.01038123116875047, time 726.0, rides 130\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 5073, reward 1034.0, memory_length 2000, epsilon 0.010371888060698595, time 727.0, rides 134\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 5074, reward 1246.0, memory_length 2000, epsilon 0.010362553361443965, time 727.0, rides 154\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5075, reward 1228.0, memory_length 2000, epsilon 0.010353227063418666, time 725.0, rides 140\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 5076, reward 1092.0, memory_length 2000, epsilon 0.010343909159061589, time 731.0, rides 148\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 5077, reward 904.0, memory_length 2000, epsilon 0.010334599640818433, time 732.0, rides 143\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 5078, reward 991.0, memory_length 2000, epsilon 0.010325298501141696, time 724.0, rides 126\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 5079, reward 714.0, memory_length 2000, epsilon 0.010316005732490668, time 726.0, rides 148\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 5080, reward 1085.0, memory_length 2000, epsilon 0.010306721327331427, time 730.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 5081, reward 1188.0, memory_length 2000, epsilon 0.010297445278136828, time 723.0, rides 125\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5082, reward 798.0, memory_length 2000, epsilon 0.010288177577386506, time 725.0, rides 125\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5083, reward 1284.0, memory_length 2000, epsilon 0.010278918217566858, time 737.0, rides 133\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 5084, reward 1015.0, memory_length 2000, epsilon 0.010269667191171047, time 721.0, rides 133\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5085, reward 812.0, memory_length 2000, epsilon 0.010260424490698994, time 736.0, rides 128\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 5086, reward 1184.0, memory_length 2000, epsilon 0.010251190108657365, time 729.0, rides 131\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5087, reward 1156.0, memory_length 2000, epsilon 0.010241964037559573, time 728.0, rides 138\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 5088, reward 1216.0, memory_length 2000, epsilon 0.010232746269925768, time 721.0, rides 139\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 5089, reward 857.0, memory_length 2000, epsilon 0.010223536798282836, time 732.0, rides 124\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 5090, reward 704.0, memory_length 2000, epsilon 0.010214335615164381, time 723.0, rides 124\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 5091, reward 546.0, memory_length 2000, epsilon 0.010205142713110732, time 733.0, rides 129\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 5092, reward 885.0, memory_length 2000, epsilon 0.010195958084668933, time 728.0, rides 133\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 5093, reward 1164.0, memory_length 2000, epsilon 0.010186781722392731, time 725.0, rides 132\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 5094, reward 1068.0, memory_length 2000, epsilon 0.010177613618842578, time 724.0, rides 123\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 5095, reward 835.0, memory_length 2000, epsilon 0.01016845376658562, time 740.0, rides 128\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5096, reward 958.0, memory_length 2000, epsilon 0.010159302158195693, time 731.0, rides 131\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 5097, reward 671.0, memory_length 2000, epsilon 0.010150158786253317, time 724.0, rides 139\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 5098, reward 1025.0, memory_length 2000, epsilon 0.010141023643345688, time 727.0, rides 141\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 5099, reward 968.0, memory_length 2000, epsilon 0.010131896722066677, time 724.0, rides 128\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 5100, reward 721.0, memory_length 2000, epsilon 0.010122778015016817, time 725.0, rides 136\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 5101, reward 1076.0, memory_length 2000, epsilon 0.0101136675148033, time 724.0, rides 135\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5102, reward 1019.0, memory_length 2000, epsilon 0.010104565214039978, time 726.0, rides 143\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5103, reward 876.0, memory_length 2000, epsilon 0.010095471105347342, time 734.0, rides 128\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 5104, reward 1069.0, memory_length 2000, epsilon 0.01008638518135253, time 736.0, rides 124\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 5105, reward 949.0, memory_length 2000, epsilon 0.010077307434689313, time 728.0, rides 127\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5106, reward 889.0, memory_length 2000, epsilon 0.010068237857998092, time 734.0, rides 132\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 5107, reward 826.0, memory_length 2000, epsilon 0.010059176443925894, time 729.0, rides 117\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 5108, reward 1063.0, memory_length 2000, epsilon 0.01005012318512636, time 722.0, rides 127\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 5109, reward 1165.0, memory_length 2000, epsilon 0.010041078074259746, time 730.0, rides 149\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 5110, reward 1031.0, memory_length 2000, epsilon 0.010032041103992912, time 723.0, rides 131\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5111, reward 814.0, memory_length 2000, epsilon 0.010023012266999318, time 728.0, rides 129\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 5112, reward 1102.0, memory_length 2000, epsilon 0.010013991555959018, time 729.0, rides 132\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 5113, reward 816.0, memory_length 2000, epsilon 0.010004978963558654, time 732.0, rides 132\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 5114, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 5115, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 5116, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 5117, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 5118, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 21, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5119, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 5120, reward 1308.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 5121, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 5122, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5123, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5124, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 5125, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 5126, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 5127, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5128, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 5129, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 5130, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5131, reward 1280.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 5132, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5133, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 5134, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5135, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 5136, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 5137, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 5138, reward 1415.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 5139, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 130\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 5140, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 5141, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 5142, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 157\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 5143, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5144, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5145, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 5146, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 5147, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 5148, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 5149, reward 1346.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 5150, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5151, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 5152, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 5153, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 5154, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 5155, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5156, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 152\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 5157, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 5158, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 5159, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5160, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5161, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 144\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5162, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 5163, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 5164, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 5165, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 5166, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 5167, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 5168, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 5169, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5170, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 5171, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 5172, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 145\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 5173, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5174, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5175, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5176, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 5177, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 5178, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 5179, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 5180, reward 1377.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5181, reward 1373.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 5182, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 11, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5183, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5184, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 5185, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5186, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 5187, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 5188, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 5189, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 5190, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 5191, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 5192, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5193, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 5194, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5195, reward 1358.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 5196, reward 1291.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 5197, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 5198, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5199, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 5200, reward 578.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 5201, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 5202, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 5203, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 5204, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 5205, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 5206, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 5207, reward 1325.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 5208, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 5209, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 5210, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 5211, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 5212, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5213, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5214, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5215, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 5216, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 5217, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 5218, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 5219, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 5220, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 5221, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 5222, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5223, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 5224, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 5225, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 5226, reward 540.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 5227, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 5228, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 5229, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 5230, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5231, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 5232, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 5233, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 5234, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5235, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 5236, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 5237, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 5238, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5239, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 5240, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 5241, reward 1298.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 5242, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5243, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 157\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 5244, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5245, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5246, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5247, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 5248, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5249, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 5250, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 5251, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 5252, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 5253, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 5254, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5255, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5256, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5257, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5258, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 5259, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 5260, reward 1368.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 149\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 5261, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 5262, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5263, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 5264, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 5265, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 5266, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5267, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 5268, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 5269, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 5270, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 5271, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 5272, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 5273, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 5274, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 5275, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5276, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5277, reward 1375.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 161\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5278, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 5279, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 5280, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5281, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 5282, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 5283, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5284, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 5285, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5286, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 5287, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 5288, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 5289, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 5290, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 5291, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 5292, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5293, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 5294, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5295, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5296, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 5297, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 5298, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5299, reward 1425.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5300, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5301, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 5302, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5303, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5304, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 5305, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 5306, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5307, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5308, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5309, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 5310, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5311, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5312, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 5313, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 5314, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 5315, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5316, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5317, reward 1267.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 5318, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5319, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5320, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5321, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 5322, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5323, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 5324, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 5325, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 5326, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5327, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 5328, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 5329, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 5330, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 5331, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 5332, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5333, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5334, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 5335, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 5336, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 5337, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5338, reward 1300.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 5339, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 5340, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5341, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5342, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 5343, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5344, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 5345, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 5346, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 5347, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5348, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5349, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 5350, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5351, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 130\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 5352, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 5353, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 5354, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5355, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5356, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 5357, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 5358, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5359, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5360, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 5361, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5362, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5363, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 5364, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5365, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5366, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5367, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5368, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 5369, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 5370, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 5371, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5372, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5373, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 5374, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 5375, reward 584.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 22, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5376, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5377, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5378, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 5379, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 5380, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 5381, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 5382, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 5383, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 5384, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 5385, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 5386, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 5387, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 5388, reward 1330.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 5389, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 5390, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5391, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 5392, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 116\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 5393, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 5394, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5395, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 5396, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 5397, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 5398, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 5399, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 5400, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 5401, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 5402, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5403, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 5404, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5405, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5406, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 5407, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 5408, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5409, reward 1404.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 5410, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 5411, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 5412, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 5413, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 5414, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 5415, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 5416, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 5417, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5418, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5419, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 5420, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5421, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 5422, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 5423, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5424, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5425, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 5426, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5427, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5428, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 5429, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 5430, reward 1267.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5431, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 118\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 5432, reward 1489.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 5433, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 5434, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5435, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 5436, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 5437, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 5438, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 5439, reward 459.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 5440, reward 1362.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 5, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5441, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 5442, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 5443, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 5444, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 5445, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 121\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 5446, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 5447, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 5448, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 5449, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 5450, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 5451, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5452, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5453, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 5454, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 5455, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5456, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 5457, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 5458, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 5459, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 5460, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 5461, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 5462, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 5463, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5464, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 5465, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 5466, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 153\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 5467, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 5468, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5469, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 5470, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 5471, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 5472, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 5473, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 5474, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 123\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 5475, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 5476, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 5477, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 5478, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 5479, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 5480, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5481, reward 521.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 5482, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 5483, reward 638.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 5484, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 5485, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 5486, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 5487, reward 1318.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5488, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 5489, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 5490, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5491, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5492, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 5493, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5494, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5495, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 5496, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5497, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 5498, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 5499, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 5500, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 112\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 5501, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 5502, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 5503, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 5504, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 5505, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 23, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5506, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 5507, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5508, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 5509, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 5510, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 144\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5511, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 5512, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 5513, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 5514, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5515, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 5516, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5517, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 5518, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 5519, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 5520, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 5521, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 5522, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 5523, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5524, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 5525, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 5526, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 5527, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 5528, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 5529, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 5530, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5531, reward 650.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 5532, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 5533, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 5534, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 5535, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5536, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 5537, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 5538, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 5539, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5540, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 5541, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5542, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 114\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 5543, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 5544, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 5545, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 5546, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 5547, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 5548, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5549, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5550, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 5551, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 5552, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5553, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 5554, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 5555, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 5556, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 5557, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5558, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 5559, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 115\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5560, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 5561, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 5562, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5563, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 5564, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 5565, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 5566, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 5567, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 5568, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5569, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 5570, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 6, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5571, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5572, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5573, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 5574, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 5575, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 5576, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 5577, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 5578, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5579, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 5580, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 5581, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 5582, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 5583, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5584, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 5585, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 5586, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 5587, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 5588, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 5589, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 5590, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5591, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 5592, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5593, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 5594, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 5595, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 5596, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5597, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 5598, reward 1324.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 5599, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 5600, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 5601, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 5602, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5603, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 5604, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 5605, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 5606, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 5607, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 5608, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 5609, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5610, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 5611, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 5612, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 5613, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 5614, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5615, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 5616, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5617, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5618, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 5619, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 5620, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5621, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 5622, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 5623, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 5624, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 152\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 5625, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5626, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 136\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 5627, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 5628, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 5629, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 5630, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 5631, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 5632, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 5633, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5634, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 5635, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 3, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5636, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 5637, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 5638, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 5639, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 5640, reward 578.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 5641, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 5642, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 5643, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 5644, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 5645, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 5646, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 5647, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 5648, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 5649, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 5650, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5651, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 5652, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5653, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 5654, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5655, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 5656, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 108\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 5657, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 5658, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 5659, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 5660, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 5661, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 5662, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5663, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 5664, reward 572.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 5665, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 5666, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5667, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 5668, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 5669, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5670, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 5671, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 5672, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 5673, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 5674, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 116\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 5675, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 5676, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5677, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 5678, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 5679, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 5680, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 5681, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5682, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 5683, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 5684, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 5685, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 5686, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5687, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5688, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 5689, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 5690, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 5691, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 5692, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 5693, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5694, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 5695, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 5696, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 157\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5697, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 124\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5698, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 5699, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5700, reward 568.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 2, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5701, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 5702, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 5703, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5704, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 5705, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5706, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 5707, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 5708, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 5709, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 5710, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 5711, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5712, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 5713, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5714, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 5715, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 5716, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 5717, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 5718, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 5719, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 5720, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 5721, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5722, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 5723, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 5724, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 5725, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5726, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 5727, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 5728, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 5729, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 5730, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5731, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 5732, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 5733, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 5734, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 5735, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 5736, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5737, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 5738, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5739, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5740, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 118\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 5741, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 5742, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 5743, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 5744, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5745, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 5746, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 5747, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 5748, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5749, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 5750, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 5751, reward 567.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 5752, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 5753, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 5754, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 5755, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 5756, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 5757, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 5758, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 5759, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 5760, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 5761, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 5762, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 5763, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 5764, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 5765, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5766, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5767, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 5768, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 5769, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5770, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 5771, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 5772, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 5773, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 5774, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5775, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 5776, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5777, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5778, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 5779, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 5780, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 5781, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 5782, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 5783, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 5784, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 5785, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 5786, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5787, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 5788, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 5789, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 5790, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 5791, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 5792, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 5793, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 5794, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5795, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 5796, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 5797, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 5798, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 5799, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 5800, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5801, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 5802, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 5803, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5804, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 5805, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 5806, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5807, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 5808, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 5809, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 5810, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 5811, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5812, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5813, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 5814, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 5815, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 5816, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5817, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 5818, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 5819, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 5820, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5821, reward 1345.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5822, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 5823, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 5824, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 143\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 5825, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 5826, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 5827, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 5828, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5829, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 5830, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 12, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5831, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 5832, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 5833, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 5834, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 5835, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 5836, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5837, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5838, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5839, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5840, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 5841, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 5842, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 5843, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 5844, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5845, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 5846, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 5847, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 5848, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 5849, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 5850, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 116\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5851, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 5852, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 5853, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 5854, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5855, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 5856, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 5857, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 5858, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 5859, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 5860, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 5861, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 5862, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5863, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 5864, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 5865, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 5866, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 131\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 5867, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 5868, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 5869, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 5870, reward 1305.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5871, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 5872, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 5873, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 5874, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 5875, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 5876, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 5877, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 5878, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5879, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 5880, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 5881, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 5882, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 5883, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5884, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5885, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 5886, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5887, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 5888, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 5889, reward 540.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 5890, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 5891, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 5892, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 5893, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 5894, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 5895, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 9, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5896, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5897, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 5898, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 5899, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 5900, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 5901, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 5902, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5903, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 5904, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 5905, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 5906, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 5907, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 5908, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 5909, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 5910, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5911, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 5912, reward 1364.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 5913, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5914, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 119\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 5915, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5916, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5917, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 5918, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5919, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 5920, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 5921, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 5922, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 5923, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 5924, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 5925, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 120\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5926, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 5927, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 5928, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5929, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 5930, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 5931, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 5932, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 5933, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 5934, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 5935, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 5936, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5937, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 5938, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 5939, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 5940, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 5941, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 5942, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 5943, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 5944, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 5945, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 5946, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 5947, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5948, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 5949, reward 1298.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5950, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 5951, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 5952, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 5953, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 5954, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 5955, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5956, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 5957, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 5958, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 5959, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 17, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5960, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 5961, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 5962, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 5963, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5964, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 5965, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 5966, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 5967, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 5968, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 5969, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5970, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 5971, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 5972, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 5973, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5974, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 5975, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 5976, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 5977, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 115\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 5978, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 5979, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 5980, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 114\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 5981, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 5982, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 5983, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 5984, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5985, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5986, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 115\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 5987, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 5988, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 5989, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 5990, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 5991, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 5992, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 5993, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5994, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 5995, reward 1353.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 5996, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 5997, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 5998, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 5999, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 6000, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 6001, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 6002, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6003, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 142\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 6004, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 6005, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6006, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 152\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 6007, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 6008, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 6009, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 6010, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 147\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 6011, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 6012, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 6013, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 6014, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6015, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6016, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 6017, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6018, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6019, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 6020, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 139\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 6021, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 140\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 6022, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6023, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [0, 22, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6024, reward 1341.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 6025, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 6026, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 6027, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 6028, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 6029, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 6030, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 6031, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 6032, reward 1336.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6033, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 6034, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 6035, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 6036, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 6037, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 6038, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 6039, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 6040, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 6041, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 6042, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 6043, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6044, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 6045, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 6046, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6047, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 136\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 6048, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6049, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 6050, reward 497.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6051, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 6052, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 6053, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6054, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6055, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6056, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 6057, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6058, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6059, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 6060, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6061, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 6062, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6063, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 6064, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 6065, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 145\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 6066, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6067, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6068, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 6069, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 6070, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 6071, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 6072, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6073, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 6074, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 6075, reward 559.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 6076, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6077, reward 1355.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6078, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 6079, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 6080, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 6081, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 6082, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 6083, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 6084, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6085, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 6086, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 6087, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 6, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6088, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 6089, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 6090, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6091, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6092, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 6093, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 6094, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 119\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 6095, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 6096, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 6097, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 6098, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6099, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 6100, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 6101, reward 1361.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 6102, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 6103, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 6104, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 6105, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 6106, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 6107, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 6108, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 6109, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 6110, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6111, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 6112, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 6113, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 6114, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 6115, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 6116, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 6117, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 6118, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 6119, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 135\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 6120, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 6121, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6122, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 6123, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 6124, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 6125, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6126, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 6127, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 6128, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 6129, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6130, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 6131, reward 1241.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6132, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 6133, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 6134, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 6135, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 6136, reward 1474.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6137, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 6138, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6139, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 6140, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 6141, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 6142, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 6143, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 6144, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6145, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 6146, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 156\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 6147, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 6148, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 6149, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6150, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6151, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 6152, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [4, 8, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6153, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 6154, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6155, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6156, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 6157, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 6158, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 6159, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 6160, reward 427.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 6161, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 6162, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 6163, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 6164, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 6165, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 6166, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6167, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 6168, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 6169, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 6170, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6171, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 6172, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 6173, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6174, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 6175, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 6176, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 6177, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 6178, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6179, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 6180, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6181, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 6182, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 6183, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6184, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6185, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 154\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 6186, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 6187, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 6188, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6189, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 6190, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 6191, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 6192, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 6193, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 6194, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6195, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 6196, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 6197, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 6198, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6199, reward 523.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 6200, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 6201, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6202, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 6203, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 116\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 6204, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 6205, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 131\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 6206, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6207, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 6208, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 118\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 6209, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 6210, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 6211, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 6212, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 6213, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 6214, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 6215, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6216, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6217, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [0, 19, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6218, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6219, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6220, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 6221, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6222, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 6223, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 6224, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 6225, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6226, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 6227, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 6228, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 6229, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 6230, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 6231, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 6232, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 6233, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6234, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 6235, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6236, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 6237, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 6238, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 6239, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 6240, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6241, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 6242, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 6243, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6244, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 6245, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 118\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 6246, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 6247, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 117\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 6248, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 6249, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6250, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 118\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 6251, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 6252, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 6253, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 6254, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 6255, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6256, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 6257, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 6258, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 6259, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6260, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 6261, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6262, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6263, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 6264, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 6265, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 6266, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6267, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6268, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 124\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 6269, reward 1324.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 6270, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6271, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 6272, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 6273, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6274, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 6275, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 6276, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6277, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 6278, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 6279, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6280, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 6281, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 6282, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6283, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 6284, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 6285, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 6286, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 6287, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 6288, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 6289, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 6290, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 6291, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 123\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6292, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 6293, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 6294, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 6295, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 6296, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6297, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 6298, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6299, reward 641.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 6300, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 6301, reward 1241.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6302, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 6303, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 6304, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 6305, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6306, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 6307, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 120\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 6308, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 6309, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 6310, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 6311, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 6312, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 135\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6313, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6314, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 6315, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 6316, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 6317, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6318, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 6319, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 6320, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 6321, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 6322, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6323, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 6324, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 6325, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 6326, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6327, reward 1359.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 6328, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 6329, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 117\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 6330, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 6331, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 6332, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 6333, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 6334, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 6335, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6336, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 6337, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 6338, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 6339, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 6340, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6341, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6342, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 6343, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6344, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6345, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 6346, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 6347, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6348, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 6349, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6350, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 6351, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 6352, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 6353, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 154\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 6354, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6355, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 6356, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 6357, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 6358, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 6359, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 6360, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 6361, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 6362, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6363, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6364, reward 1357.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6365, reward 582.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6366, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 6367, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6368, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 117\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6369, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6370, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 6371, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 6372, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6373, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 6374, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6375, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 6376, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6377, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 6378, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 6379, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6380, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 6381, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 6382, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 6383, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6384, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6385, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 6386, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6387, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 6388, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 6389, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 6390, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6391, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 6392, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 6393, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 6394, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 6395, reward 1250.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 6396, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 6397, reward 489.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 6398, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6399, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 6400, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 6401, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 6402, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 6403, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6404, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 6405, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 6406, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 6407, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6408, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 6409, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6410, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6411, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 6412, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 9, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6413, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 6414, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 6415, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 6416, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6417, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 6418, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 6419, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 6420, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 6421, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 155\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 6422, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 6423, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6424, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 6425, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 6426, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 6427, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 6428, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 6429, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 6430, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6431, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 6432, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 6433, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6434, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6435, reward 495.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 6436, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 6437, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 6438, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6439, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6440, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 6441, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 6442, reward 1353.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 6443, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 6444, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 6445, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 6446, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6447, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 6448, reward 1291.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6449, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 151\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 6450, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 6451, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6452, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6453, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 6454, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6455, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6456, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 6457, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 6458, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 6459, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 6460, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6461, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 6462, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6463, reward 608.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6464, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 6465, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 6466, reward 1415.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6467, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 6468, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6469, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 6470, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 6471, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 6472, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 6473, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 123\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6474, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 6475, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 6476, reward 1374.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 6477, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 7, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6478, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 6479, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 115\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 6480, reward 536.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 6481, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6482, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 6483, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 6484, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 6485, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 6486, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6487, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6488, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 6489, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 6490, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 6491, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6492, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 6493, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 6494, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 6495, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6496, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 6497, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 118\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6498, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 6499, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 6500, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 6501, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 6502, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 6503, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 6504, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6505, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6506, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 6507, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6508, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6509, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 6510, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 6511, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 6512, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 6513, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 6514, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 6515, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 6516, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 6517, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 6518, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 6519, reward 1372.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6520, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 6521, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 6522, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6523, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6524, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6525, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 6526, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 6527, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 6528, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 6529, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6530, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 6531, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6532, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 6533, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 139\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 6534, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6535, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 6536, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 6537, reward 1291.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6538, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6539, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 6540, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 6541, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 6542, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 2, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6543, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6544, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 6545, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6546, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 6547, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 6548, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 6549, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 6550, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 6551, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 6552, reward 575.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 6553, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 6554, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 6555, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6556, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 6557, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6558, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6559, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6560, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6561, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 6562, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 6563, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6564, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 6565, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 6566, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 6567, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 6568, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6569, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 6570, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6571, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6572, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 6573, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6574, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 6575, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6576, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6577, reward 612.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 6578, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 6579, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 6580, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6581, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 139\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6582, reward 1333.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 155\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 6583, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6584, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 6585, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6586, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 6587, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6588, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 6589, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 158\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 6590, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 6591, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 6592, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 6593, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6594, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 6595, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6596, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 6597, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 6598, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 6599, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6600, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 6601, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 6602, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 6603, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6604, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 6605, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 6606, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 14, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6607, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 6608, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6609, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6610, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 6611, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 6612, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 6613, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 6614, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 6615, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6616, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 6617, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 6618, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 6619, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 6620, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6621, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 6622, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6623, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6624, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 6625, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 6626, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6627, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6628, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 6629, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 6630, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6631, reward 1250.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6632, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6633, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6634, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6635, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 6636, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 6637, reward 533.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6638, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 6639, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 6640, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6641, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6642, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 6643, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6644, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 6645, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 165\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6646, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6647, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6648, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 6649, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 117\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6650, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 6651, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 6652, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6653, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 6654, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 6655, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 6656, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6657, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6658, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6659, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6660, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6661, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 6662, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6663, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 6664, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 6665, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6666, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 6667, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 6668, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 6669, reward 499.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 6670, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 123\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6671, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 21, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6672, reward 1295.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 6673, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6674, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 6675, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6676, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6677, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 6678, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 6679, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 6680, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 6681, reward 1327.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 6682, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 116\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6683, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 6684, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 6685, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 6686, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 6687, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 6688, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 6689, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 6690, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 6691, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 6692, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 6693, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 6694, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 6695, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 6696, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 6697, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 6698, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6699, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 6700, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 6701, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 6702, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 6703, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 6704, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 6705, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6706, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6707, reward 1304.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6708, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 6709, reward 571.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 112\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6710, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 6711, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6712, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 6713, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 6714, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 6715, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 6716, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 6717, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6718, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6719, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6720, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6721, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6722, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 6723, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 6724, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6725, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6726, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 6727, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 6728, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6729, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 6730, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6731, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 6732, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 6733, reward 1430.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 6734, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6735, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6736, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 6737, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6738, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 6739, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 6740, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 6741, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 6742, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 148\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 6743, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 6744, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 6745, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6746, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 6747, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 6748, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 6749, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 6750, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 6751, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 6752, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 6753, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6754, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 6755, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 6756, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 6757, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 6758, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6759, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 6760, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 6761, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 6762, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 6763, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6764, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 6765, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 6766, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6767, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 6768, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 6769, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 6770, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 6771, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 6772, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 6773, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 6774, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 6775, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 6776, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 6777, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 6778, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 6779, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 6780, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6781, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 6782, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 6783, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 6784, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 6785, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 6786, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 6787, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 6788, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 6789, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6790, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 6791, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 6792, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6793, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 152\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 6794, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6795, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 6796, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 6797, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6798, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 6799, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6800, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6801, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 6802, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 6803, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6804, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 6805, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 6806, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6807, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6808, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6809, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 6810, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 6811, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6812, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 6813, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 6814, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 6815, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 6816, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 6817, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6818, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 6819, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 6820, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6821, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 6822, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 6823, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 6824, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 6825, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 6826, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6827, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 6828, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 6829, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 6830, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 6831, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 6832, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 6833, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6834, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 6835, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 6836, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 6837, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6838, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 6839, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 6840, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6841, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 6842, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 6843, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 6844, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 6845, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 6846, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 6847, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6848, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 6849, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 135\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6850, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 6851, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6852, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6853, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 6854, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6855, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6856, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 6857, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 6858, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6859, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6860, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 6861, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 6862, reward 590.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 6863, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 6864, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6865, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 7, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6866, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 6867, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 6868, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 6869, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 6870, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 6871, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 6872, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 6873, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 6874, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6875, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 6876, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 6877, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 6878, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6879, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 6880, reward 1506.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 6881, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6882, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6883, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 151\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 6884, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 6885, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 6886, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 6887, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 6888, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 6889, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6890, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 145\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6891, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 6892, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 6893, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 6894, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 6895, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 6896, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 6897, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6898, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 6899, reward 1313.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 6900, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 6901, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 157\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 6902, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 6903, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6904, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 6905, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6906, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 6907, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 6908, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 6909, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 6910, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6911, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 6912, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 6913, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 119\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 6914, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 6915, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6916, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6917, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 6918, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 6919, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 6920, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6921, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6922, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 6923, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6924, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6925, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6926, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6927, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 6928, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 6929, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 6930, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 23, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6931, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 6932, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 6933, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 6934, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 6935, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 6936, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 6937, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6938, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6939, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6940, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6941, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 6942, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6943, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 6944, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 6945, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 113\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6946, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 6947, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 6948, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6949, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 6950, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 6951, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 6952, reward 1348.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6953, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 6954, reward 1298.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 6955, reward 1302.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 6956, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 6957, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 6958, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6959, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 6960, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 6961, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6962, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 6963, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 6964, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6965, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6966, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 6967, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 6968, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 6969, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 6970, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 6971, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 6972, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 6973, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6974, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 6975, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 6976, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6977, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 6978, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 6979, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 6980, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 6981, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 6982, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6983, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 6984, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 6985, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 6986, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 6987, reward 1537.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 6988, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 6989, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 6990, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 6991, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6992, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 6993, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6994, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 6995, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 13, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6996, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6997, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 6998, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 6999, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 7000, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 7001, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 7002, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 7003, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 7004, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7005, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7006, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7007, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 7008, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 7009, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 7010, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7011, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 7012, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7013, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 7014, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7015, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 7016, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 124\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7017, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7018, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 7019, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 7020, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 125\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 7021, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 7022, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 7023, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 7024, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 7025, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 7026, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 7027, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7028, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 7029, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 7030, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 7031, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 7032, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 7033, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7034, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7035, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 7036, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 7037, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 7038, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 122\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 7039, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 7040, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 7041, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 7042, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 7043, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7044, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 7045, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 133\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 7046, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 7047, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 7048, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 7049, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 7050, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7051, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7052, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 7053, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 7054, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 7055, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 7056, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 7057, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 7058, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 7059, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 5, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7060, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 7061, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 7062, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 7063, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 7064, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 7065, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 7066, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 7067, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 7068, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 7069, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7070, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7071, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 7072, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 128\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 7073, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7074, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 7075, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 154\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7076, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7077, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 7078, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 7079, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 7080, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 7081, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 7082, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 7083, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7084, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 7085, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7086, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 7087, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7088, reward 1364.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7089, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 7090, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7091, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 7092, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 7093, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7094, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 7095, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 7096, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 7097, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7098, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7099, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7100, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 7101, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 7102, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 7103, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 7104, reward 521.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 122\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 7105, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7106, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7107, reward 1375.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 7108, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 7109, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 7110, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7111, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 7112, reward 1270.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 7113, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 7114, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 7115, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 7116, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 7117, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 7118, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 7119, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 7120, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 7121, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7122, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 7123, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7124, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [1, 17, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7125, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 7126, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 7127, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 7128, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 7129, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7130, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 7131, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7132, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7133, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 7134, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7135, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 7136, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 7137, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 7138, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 7139, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7140, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 7141, reward 638.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 7142, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 7143, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 155\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7144, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 7145, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 7146, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 7147, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 7148, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7149, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 7150, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7151, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7152, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7153, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7154, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 7155, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 7156, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 7157, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 7158, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 7159, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7160, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7161, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 7162, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 7163, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7164, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7165, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 7166, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 7167, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7168, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 7169, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7170, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 7171, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 7172, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7173, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 7174, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 7175, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 7176, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 7177, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 7178, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 7179, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 122\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 7180, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 7181, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7182, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 7183, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 7184, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 7185, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 7186, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7187, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7188, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 7, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7189, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 7190, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 7191, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 7192, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 7193, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 7194, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 121\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 7195, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 7196, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 7197, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 7198, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 7199, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 7200, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 7201, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 7202, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 7203, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 7204, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 7205, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 7206, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 7207, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 7208, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 7209, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 7210, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 7211, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 7212, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7213, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 7214, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 7215, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 7216, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 7217, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7218, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 7219, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7220, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 7221, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 7222, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 7223, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 129\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7224, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 7225, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 7226, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 7227, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7228, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7229, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 7230, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 140\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 7231, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7232, reward 1325.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 155\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 7233, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 7234, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 7235, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 7236, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 7237, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7238, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 7239, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 7240, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 7241, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 7242, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 7243, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 7244, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7245, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 7246, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 7247, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7248, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 7249, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 7250, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 7251, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 7252, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 7253, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 1, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7254, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 7255, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 7256, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 127\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 7257, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 7258, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 7259, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 7260, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 7261, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 7262, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7263, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 7264, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 7265, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7266, reward 1299.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7267, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 7268, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 155\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7269, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 7270, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 7271, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 7272, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 7273, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7274, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 7275, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7276, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 7277, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 7278, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7279, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 117\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 7280, reward 1470.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 7281, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 7282, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 7283, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 7284, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 7285, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 7286, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 7287, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 7288, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 7289, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 153\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 7290, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 7291, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 7292, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 7293, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 7294, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 7295, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7296, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7297, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 7298, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 7299, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 7300, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 7301, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7302, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7303, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 7304, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 7305, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7306, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7307, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 7308, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7309, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 7310, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 7311, reward 559.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 7312, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 7313, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7314, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7315, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 7316, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 7317, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 7318, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 4, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7319, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 7320, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7321, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7322, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 7323, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 7324, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 7325, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 7326, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7327, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 7328, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 7329, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7330, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 7331, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7332, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 7333, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 7334, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 7335, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 7336, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7337, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 124\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7338, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7339, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 7340, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 7341, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 7342, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 7343, reward 526.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 7344, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7345, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 7346, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 7347, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 7348, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 7349, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 7350, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 7351, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 7352, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 7353, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 7354, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 7355, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 7356, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7357, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7358, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 118\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 7359, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 7360, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7361, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 7362, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 7363, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 7364, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 119\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 7365, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 7366, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 7367, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 7368, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 7369, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 7370, reward 421.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 7371, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 7372, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 7373, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 7374, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7375, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 7376, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 7377, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7378, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 7379, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 7380, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7381, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7382, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7383, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [1, 8, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7384, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 7385, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 7386, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7387, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7388, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 7389, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7390, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7391, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 7392, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7393, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 7394, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 7395, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7396, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 7397, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 7398, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 7399, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 7400, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 7401, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 7402, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7403, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 7404, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 7405, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 7406, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 7407, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 7408, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 7409, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 7410, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 7411, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7412, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 7413, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 7414, reward 563.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7415, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 7416, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 7417, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 124\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7418, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 7419, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 7420, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 131\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 7421, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 7422, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 7423, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 7424, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 7425, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 7426, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 7427, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 7428, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 7429, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 7430, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 7431, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 7432, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 7433, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 7434, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 7435, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 7436, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 7437, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 7438, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 7439, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 7440, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 7441, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 7442, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7443, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7444, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 7445, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 7446, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 159\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 7447, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7448, reward 566.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7449, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7450, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 137\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7451, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 7452, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7453, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7454, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 7455, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 7456, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 7457, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7458, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 7459, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7460, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 7461, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7462, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 7463, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 7464, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 7465, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 7466, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 7467, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 7468, reward 613.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7469, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 7470, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 7471, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 7472, reward 1294.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 7473, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 7474, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7475, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 7476, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 7477, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 7478, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 7479, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 7480, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 7481, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 7482, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 7483, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7484, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 7485, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 7486, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 7487, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 7488, reward 1345.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 7489, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 7490, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 7491, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 7492, reward 656.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 7493, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 7494, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 7495, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 7496, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 7497, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 7498, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7499, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 7500, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 7501, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 7502, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 7503, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 7504, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 7505, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 7506, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 7507, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 7508, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 7509, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7510, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 7511, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 7512, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 7513, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 8, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7514, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 7515, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7516, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 7517, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 7518, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 7519, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 7520, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7521, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7522, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 7523, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 7524, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 7525, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7526, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 7527, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7528, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 7529, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 124\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 7530, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 125\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7531, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 7532, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 7533, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 7534, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7535, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 7536, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 116\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7537, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 7538, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 7539, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 7540, reward 1389.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 7541, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7542, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 7543, reward 1334.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 7544, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 7545, reward 602.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 7546, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 7547, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 7548, reward 1482.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 7549, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7550, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 7551, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 7552, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 7553, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 7554, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7555, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7556, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 7557, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 7558, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 7559, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 7560, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7561, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7562, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 7563, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 7564, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 7565, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 7566, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 7567, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 7568, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7569, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 7570, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7571, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7572, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 7573, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 7574, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7575, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 7576, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 7577, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 154\n",
      "Initial State is  [4, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7578, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 7579, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 118\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 7580, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 7581, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 7582, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7583, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 7584, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 7585, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 7586, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 7587, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7588, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 7589, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 7590, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 7591, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 7592, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 7593, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 7594, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 7595, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 7596, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 7597, reward 601.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 7598, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 7599, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7600, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 7601, reward 508.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7602, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 7603, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 7604, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 7605, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 7606, reward 1322.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7607, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 7608, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 7609, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 7610, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 7611, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7612, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 7613, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 7614, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 7615, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 7616, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 7617, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 7618, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7619, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7620, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7621, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 7622, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 7623, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7624, reward 586.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 7625, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 7626, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 7627, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 7628, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 7629, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7630, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 7631, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 7632, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 7633, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 7634, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7635, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7636, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7637, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 7638, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 7639, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 7640, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7641, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 7642, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 23, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7643, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7644, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 7645, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 7646, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 7647, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7648, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7649, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7650, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 7651, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 7652, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 7653, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 7654, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 7655, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 7656, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 7657, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 7658, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7659, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 7660, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7661, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 7662, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7663, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 7664, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 7665, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 7666, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 7667, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 7668, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 7669, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7670, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 7671, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 7672, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7673, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7674, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 7675, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 7676, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 7677, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7678, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 7679, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7680, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7681, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7682, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 7683, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 7684, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 7685, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 7686, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7687, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 7688, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7689, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 7690, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 7691, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 7692, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7693, reward 1270.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 7694, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 7695, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 7696, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 7697, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7698, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7699, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 7700, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 7701, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 7702, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 7703, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 7704, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 7705, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 7706, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 7707, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 18, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7708, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 7709, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 7710, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 7711, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 162\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7712, reward 446.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 7713, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 124\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 7714, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 7715, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 7716, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 7717, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 7718, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 7719, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 7720, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7721, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7722, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7723, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7724, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7725, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 7726, reward 1261.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7727, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 7728, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 7729, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7730, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 7731, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 7732, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 7733, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7734, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7735, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 7736, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 7737, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 7738, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 7739, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7740, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7741, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7742, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 7743, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 746.0, rides 142\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 7744, reward 1325.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7745, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 7746, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 133\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 7747, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 7748, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 7749, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 7750, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 7751, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 7752, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 7753, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 7754, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 7755, reward 522.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 7756, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 7757, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 7758, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 133\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 7759, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 7760, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 119\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 7761, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7762, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 7763, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 7764, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 7765, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 7766, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7767, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 7768, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7769, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7770, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 7771, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 10, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7772, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7773, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 7774, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7775, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 7776, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7777, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 7778, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 7779, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7780, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 7781, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 7782, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 7783, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7784, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 7785, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 7786, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 7787, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7788, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 7789, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 7790, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7791, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 7792, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 7793, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 7794, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 7795, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 7796, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 7797, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 7798, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 147\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7799, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 7800, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7801, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 7802, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 7803, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 7804, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 7805, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7806, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 7807, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 7808, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7809, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7810, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 7811, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 7812, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 7813, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 7814, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 117\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 7815, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 7816, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 7817, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7818, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 7819, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7820, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7821, reward 641.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7822, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 7823, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 7824, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7825, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 7826, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7827, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 7828, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 7829, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 122\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 7830, reward 1323.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 7831, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 7832, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 7833, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 7834, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7835, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 9, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7836, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7837, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 7838, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7839, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7840, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 7841, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 118\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 7842, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 7843, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 7844, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 7845, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 7846, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 7847, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 7848, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 7849, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 7850, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7851, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7852, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 7853, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 7854, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 7855, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 7856, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 7857, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7858, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 7859, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7860, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 7861, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7862, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7863, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 7864, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 7865, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7866, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7867, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7868, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7869, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 7870, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7871, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 7872, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 7873, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 7874, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 7875, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 7876, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 7877, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7878, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7879, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 7880, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 7881, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 7882, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 7883, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7884, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 7885, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 135\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 7886, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 7887, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7888, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 7889, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 7890, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 7891, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7892, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 7893, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7894, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7895, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7896, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7897, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 7898, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 7899, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 7900, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 6, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7901, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 7902, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7903, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7904, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7905, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 7906, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 7907, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7908, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 7909, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 7910, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 7911, reward 455.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7912, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 120\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 7913, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 7914, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 7915, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 7916, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 7917, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7918, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 7919, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 7920, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 7921, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 7922, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7923, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 7924, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7925, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 7926, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7927, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7928, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 7929, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 7930, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 7931, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7932, reward 612.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 7933, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 7934, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7935, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7936, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 7937, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 7938, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 135\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 7939, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 7940, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 7941, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 160\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 7942, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7943, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 7944, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7945, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 7946, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7947, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 7948, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 7949, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7950, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 7951, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7952, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 7953, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7954, reward 1486.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 7955, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7956, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 7957, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 7958, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 7959, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 7960, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 7961, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7962, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 7963, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 7964, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 4, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7965, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7966, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 7967, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7968, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 7969, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7970, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 7971, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 7972, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 7973, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 7974, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 7975, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 7976, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 7977, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 7978, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7979, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 7980, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 7981, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 7982, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 7983, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 7984, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 7985, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7986, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 7987, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 7988, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 7989, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 7990, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 7991, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 7992, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 7993, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 7994, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 7995, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7996, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7997, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 7998, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 119\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 7999, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 161\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 8000, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 8001, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 8002, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 8003, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8004, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 8005, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 8006, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 8007, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 8008, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 8009, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 8010, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 8011, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 8012, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 8013, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 8014, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 8015, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 8016, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 8017, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 8018, reward 613.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 8019, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 8020, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 8021, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 8022, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 8023, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 8024, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 8025, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 8026, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 8027, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 8028, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 8029, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 10, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8030, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 8031, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 8032, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 8033, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 8034, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 8035, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 149\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 8036, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 8037, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 127\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 8038, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 8039, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 8040, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 8041, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 8042, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 8043, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 8044, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 8045, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 121\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 8046, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 8047, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 8048, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 8049, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 8050, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 8051, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 8052, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 8053, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 8054, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 8055, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 8056, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 8057, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 8058, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 8059, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 8060, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 8061, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 8062, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 8063, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 8064, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 8065, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 8066, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 8067, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 8068, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 8069, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 8070, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 117\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 8071, reward 1419.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 8072, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 8073, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 8074, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 8075, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 8076, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 8077, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 8078, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 8079, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 8080, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 8081, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 8082, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 118\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 8083, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 8084, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 8085, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 8086, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 8087, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 8088, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 8089, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 8090, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 8091, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 8092, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 8093, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 18, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8094, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 8095, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 8096, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 8097, reward 593.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 115\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 8098, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 8099, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 8100, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 8101, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 132\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 8102, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 8103, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 8104, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 8105, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 8106, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 8107, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 8108, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 8109, reward 570.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 8110, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 8111, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 8112, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 8113, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 8114, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 8115, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 8116, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 8117, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 8118, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 8119, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 8120, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 8121, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 8122, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 8123, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 8124, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 8125, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 8126, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 8127, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 8128, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 8129, reward 570.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 8130, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 8131, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 8132, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 8133, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 8134, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 151\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 8135, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 8136, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 8137, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 8138, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 8139, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 8140, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 8141, reward 1341.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 8142, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 8143, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 8144, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 116\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 8145, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 8146, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 8147, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 8148, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 8149, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 8150, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 8151, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 120\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 8152, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 8153, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 8154, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 8155, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 8156, reward 1382.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 8157, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 117\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 8158, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 20, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8159, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 8160, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 8161, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 8162, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 8163, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 8164, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 8165, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 155\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 8166, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 8167, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 8168, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 8169, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 8170, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 8171, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 8172, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 120\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 8173, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 8174, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 8175, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 8176, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 8177, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 8178, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 8179, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 8180, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 8181, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 8182, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 8183, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 8184, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 8185, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 8186, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 8187, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 8188, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 8189, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 8190, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 8191, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 8192, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 8193, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 8194, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 8195, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 8196, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 8197, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 8198, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 8199, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 8200, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 8201, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 8202, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 155\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 8203, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 8204, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 8205, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 8206, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 8207, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 8208, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 8209, reward 1325.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 8210, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 8211, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 8212, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 156\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 8213, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 117\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 8214, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 8215, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 8216, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8217, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 8218, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 8219, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 8220, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 133\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 8221, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 8222, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [3, 2, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8223, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 8224, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 8225, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 8226, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 8227, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 8228, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 8229, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 8230, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 8231, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 8232, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 8233, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 8234, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 8235, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 8236, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 8237, reward 1333.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 8238, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 8239, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 8240, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 8241, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 8242, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 8243, reward 1250.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 8244, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 8245, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 8246, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 8247, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 8248, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 8249, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 8250, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 8251, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 8252, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 8253, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 8254, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 8255, reward 1481.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 8256, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 8257, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 146\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 8258, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 8259, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 8260, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 8261, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 8262, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 8263, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 8264, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 8265, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 8266, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 8267, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 8268, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 8269, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 8270, reward 593.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 8271, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 8272, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 8273, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 8274, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 8275, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 8276, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 8277, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 8278, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 8279, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 8280, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 8281, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 8282, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 8283, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 8284, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 8285, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 8286, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 9, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8287, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 8288, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 8289, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 8290, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 8291, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 8292, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 8293, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 8294, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 8295, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 8296, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 8297, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 8298, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 8299, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 8300, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 8301, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 8302, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 8303, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 8304, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 8305, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 8306, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 8307, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 8308, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 8309, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 8310, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 8311, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 8312, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 8313, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 8314, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 8315, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 8316, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 8317, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 8318, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 8319, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 8320, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 8321, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 8322, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 8323, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 8324, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 8325, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 8326, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 8327, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 8328, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 8329, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 8330, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 8331, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 8332, reward 590.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 8333, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 8334, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 8335, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 134\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 8336, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 8337, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 8338, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 8339, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 8340, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 8341, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 8342, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 8343, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 8344, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 8345, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 8346, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 8347, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 8348, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 8349, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 8350, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 17, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8351, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 8352, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 8353, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 8354, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 8355, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 8356, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 8357, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 8358, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 8359, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 8360, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 8361, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 8362, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 8363, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 8364, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 8365, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 8366, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 8367, reward 1300.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 8368, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 8369, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 8370, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 8371, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 8372, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 8373, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 8374, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 8375, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 8376, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 8377, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 8378, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 115\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 8379, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 8380, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 8381, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 8382, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 117\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 8383, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 8384, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 8385, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 8386, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 8387, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 8388, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 8389, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 8390, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 8391, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 8392, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 8393, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 8394, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 8395, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 8396, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 8397, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 8398, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 8399, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 8400, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 8401, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 8402, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 8403, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 8404, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 8405, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 8406, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 8407, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 8408, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 8409, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 8410, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 8411, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 8412, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 8413, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 8414, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8415, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 8416, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 8417, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 8418, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 8419, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 8420, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 8421, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 8422, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 8423, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 8424, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 8425, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 8426, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 8427, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 119\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 8428, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 8429, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 8430, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 8431, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 8432, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 8433, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 8434, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 8435, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 8436, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 8437, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 8438, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 8439, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 8440, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 8441, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 8442, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 8443, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 8444, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 8445, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 8446, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 8447, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 8448, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 8449, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 8450, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 8451, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 8452, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 8453, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 8454, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 8455, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 8456, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 8457, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 108\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 8458, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 8459, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 8460, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 8461, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 8462, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 8463, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 8464, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 8465, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 8466, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 8467, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 8468, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 145\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 8469, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 8470, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 8471, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 8472, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 8473, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 8474, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 8475, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 8476, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 8477, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 8478, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 22, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8479, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 8480, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 8481, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 8482, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 8483, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 8484, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 8485, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 8486, reward 1380.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 8487, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 8488, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 8489, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 8490, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 8491, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 8492, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 8493, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 8494, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 8495, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 8496, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 8497, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 8498, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 8499, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 8500, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 8501, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 8502, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 8503, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 8504, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 8505, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 8506, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 8507, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 8508, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 8509, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 8510, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 8511, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 157\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 8512, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 8513, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 8514, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 8515, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 8516, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 8517, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 152\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 8518, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 136\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 8519, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 8520, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 8521, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 8522, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 8523, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8524, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 126\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 8525, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 8526, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 8527, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 8528, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 8529, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 8530, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 8531, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 8532, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 8533, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 8534, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 8535, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 8536, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 8537, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 8538, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 8539, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 8540, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 8541, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 8542, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 8543, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [1, 22, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8544, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 8545, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 8546, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 8547, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 8548, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 8549, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 8550, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 8551, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 8552, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 8553, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 8554, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 8555, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 8556, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 8557, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 8558, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 8559, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 8560, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 8561, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 8562, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 8563, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 8564, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 8565, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 8566, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 8567, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 8568, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 8569, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 8570, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 8571, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 8572, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 8573, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 8574, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 8575, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 8576, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 8577, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 8578, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 8579, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 8580, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 8581, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 8582, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 8583, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 8584, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 8585, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 8586, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 8587, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 8588, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 8589, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 8590, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 8591, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 8592, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 8593, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 8594, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 8595, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 8596, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 8597, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 8598, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 8599, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 8600, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 8601, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 8602, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 116\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 8603, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 8604, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 8605, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 115\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 8606, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 8607, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 8608, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [2, 17, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8609, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 119\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 8610, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 8611, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 8612, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 8613, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 8614, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 8615, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 8616, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 8617, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 8618, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 8619, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 8620, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 8621, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 115\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 8622, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 8623, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 8624, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 8625, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 8626, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 8627, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 8628, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 8629, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 8630, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 8631, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 8632, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 8633, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 8634, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 8635, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 8636, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 8637, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 8638, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 8639, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 8640, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 8641, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 8642, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 8643, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 8644, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 8645, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 8646, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 8647, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 8648, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 8649, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 8650, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 8651, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 8652, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 8653, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 8654, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 8655, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 8656, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 8657, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 8658, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 8659, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 129\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 8660, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 8661, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 8662, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 8663, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 8664, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 8665, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 8666, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 8667, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 8668, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 8669, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 8670, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 157\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 8671, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 8672, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 8673, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [1, 1, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8674, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 8675, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 8676, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 8677, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 8678, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 113\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 8679, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 8680, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 8681, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 8682, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 8683, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 8684, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 8685, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 8686, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 8687, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 8688, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 8689, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 8690, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 8691, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 8692, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 8693, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 8694, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 8695, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 8696, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 8697, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 8698, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 8699, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 8700, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 8701, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 8702, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 8703, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 8704, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 8705, reward 598.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 8706, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 8707, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 8708, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 8709, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 8710, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 8711, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 8712, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 8713, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 8714, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 8715, reward 1327.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 8716, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 8717, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 8718, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 8719, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 8720, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 8721, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 8722, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 8723, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 8724, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 8725, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 8726, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 8727, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 8728, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 8729, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 8730, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 8731, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 8732, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8733, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 8734, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 8735, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 8736, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 8737, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 13, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8738, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 8739, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 8740, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 8741, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 8742, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 8743, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 8744, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 8745, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 8746, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 8747, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 8748, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 8749, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 8750, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 8751, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 8752, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 8753, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 8754, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 8755, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 8756, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 8757, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 8758, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 8759, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 8760, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 8761, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 8762, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 8763, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 8764, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 8765, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 8766, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 8767, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 8768, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 8769, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 8770, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 8771, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 8772, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 8773, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 8774, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 8775, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 8776, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 8777, reward 567.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 8778, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 8779, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 8780, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 8781, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 8782, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 8783, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 8784, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 8785, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 8786, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 8787, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 8788, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 8789, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 8790, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 8791, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 8792, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 8793, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 8794, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 8795, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 8796, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 8797, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 8798, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 8799, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 8800, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 8801, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [4, 10, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8802, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 8803, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 8804, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 8805, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 8806, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 139\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 8807, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 8808, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 8809, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 8810, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 8811, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 8812, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 156\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 8813, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 8814, reward 1416.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 8815, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 8816, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 8817, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 8818, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 8819, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 8820, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 8821, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 8822, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 8823, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 8824, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 8825, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 8826, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 8827, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 8828, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 8829, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 8830, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 8831, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 8832, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 8833, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 8834, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 8835, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 8836, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 8837, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 8838, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 8839, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 8840, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 8841, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 8842, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 8843, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 8844, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 8845, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 8846, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 8847, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 8848, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 8849, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 8850, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 8851, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 8852, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 8853, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 8854, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 8855, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 8856, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8857, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 8858, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 8859, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 8860, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 8861, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 8862, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 8863, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 8864, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 8865, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8866, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 8867, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 8868, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 8869, reward 1326.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 8870, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 8871, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 8872, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 155\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 8873, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 8874, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 8875, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 8876, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 8877, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 8878, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 8879, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 8880, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 8881, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 8882, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 8883, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 8884, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 8885, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 8886, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 8887, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 8888, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 8889, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 8890, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 8891, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 8892, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 8893, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 8894, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 8895, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 8896, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 8897, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 8898, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 118\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 8899, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 8900, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 8901, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 8902, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 8903, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 8904, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 149\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 8905, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 8906, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 8907, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 8908, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 8909, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 8910, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 132\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 8911, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 8912, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 8913, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 8914, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 8915, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 8916, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 8917, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 8918, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 8919, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 8920, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 8921, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 8922, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 8923, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 8924, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 8925, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 8926, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 8927, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 8928, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 8929, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 156\n",
      "Initial State is  [2, 6, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8930, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 8931, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 8932, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 8933, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 8934, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 8935, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 8936, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 8937, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 8938, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 8939, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 8940, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 8941, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 8942, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 8943, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 8944, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 8945, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 8946, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 8947, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 8948, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 8949, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 8950, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 8951, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 8952, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 8953, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 8954, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 8955, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 8956, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 8957, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 8958, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 8959, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 8960, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 8961, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 8962, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 8963, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 8964, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 8965, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 149\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 8966, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 8967, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 8968, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 8969, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 8970, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 161\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 8971, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 8972, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 8973, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 8974, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 8975, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 8976, reward 438.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 8977, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 8978, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 8979, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 8980, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 8981, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 8982, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 116\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 8983, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 8984, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 8985, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 8986, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 8987, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 8988, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 8989, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 8990, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 8991, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 8992, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 121\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 8993, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 8994, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 8995, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 8996, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 8997, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 8998, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 8999, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 155\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 9000, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 9001, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 9002, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 9003, reward 1307.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 9004, reward 1342.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 9005, reward 1366.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 9006, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 9007, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 9008, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 9009, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 9010, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 9011, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 9012, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 9013, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 9014, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 9015, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 9016, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 9017, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 9018, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 9019, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 9020, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 9021, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 9022, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 9023, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 9024, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 9025, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 9026, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 9027, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 9028, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 9029, reward 1425.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 9030, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 9031, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 9032, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 9033, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 9034, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 9035, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 9036, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 9037, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 9038, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 9039, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 9040, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 9041, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 9042, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 9043, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 9044, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 9045, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 9046, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 9047, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 9048, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 9049, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 9050, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 9051, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 9052, reward 1450.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 9053, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 9054, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 9055, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 9056, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 9057, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 9058, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9059, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 155\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 9060, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 9061, reward 567.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 9062, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 9063, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 9064, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 9065, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 146\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 9066, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 9067, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 9068, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 9069, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 9070, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 9071, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 9072, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 9073, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 9074, reward 1474.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 9075, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 9076, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 9077, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 9078, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 9079, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 9080, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 9081, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 9082, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 9083, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 9084, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 9085, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 9086, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 9087, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 9088, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 9089, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 9090, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 9091, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 9092, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 9093, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 9094, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 9095, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 9096, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 9097, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 9098, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 9099, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 9100, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 9101, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 9102, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 9103, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 9104, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 9105, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 9106, reward 1381.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 9107, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 9108, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 9109, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 9110, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 9111, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 9112, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 9113, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 9114, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 9115, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 9116, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 9117, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 9118, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 9119, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 9120, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 9121, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 9122, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 1, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9123, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 144\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 9124, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 9125, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 9126, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 9127, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 9128, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 9129, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 145\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 9130, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 9131, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 9132, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 9133, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 9134, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 9135, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 9136, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 155\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 9137, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 9138, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9139, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 9140, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 9141, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 9142, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 9143, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 9144, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 9145, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 9146, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 9147, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 9148, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 9149, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 9150, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 9151, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 9152, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 9153, reward 1487.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 9154, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 154\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 9155, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 155\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 9156, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 9157, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 9158, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 9159, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 9160, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 9161, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 116\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 9162, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 9163, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 9164, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 9165, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 9166, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 9167, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 9168, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 9169, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 9170, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 9171, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 9172, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 9173, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 9174, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 9175, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 9176, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 9177, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 9178, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 9179, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 9180, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 9181, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 9182, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 9183, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 9184, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 9185, reward 582.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 9186, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 118\n",
      "Initial State is  [3, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9187, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 9188, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 9189, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 9190, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 9191, reward 1306.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 9192, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 9193, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 9194, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 9195, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 9196, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 9197, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 9198, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 9199, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 9200, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 9201, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 9202, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 9203, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 9204, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 9205, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 9206, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 9207, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 154\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 9208, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 9209, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 9210, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 9211, reward 1319.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 9212, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 9213, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 9214, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 9215, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 9216, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 9217, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 9218, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 9219, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9220, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 9221, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 9222, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 9223, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 9224, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 9225, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 9226, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 9227, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 135\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 9228, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 9229, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 9230, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 9231, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 9232, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 9233, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 9234, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 9235, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 9236, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 9237, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 9238, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 9239, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 9240, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 9241, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 9242, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 9243, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 9244, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 9245, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 9246, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 9247, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 9248, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 9249, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 9250, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 9251, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 18, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9252, reward 1378.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 9253, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 9254, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9255, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 9256, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 9257, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 9258, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 9259, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 9260, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 9261, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 9262, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 9263, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 9264, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 9265, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 9266, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 9267, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 9268, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 9269, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 9270, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 9271, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 155\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 9272, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 9273, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 9274, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 9275, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 9276, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 9277, reward 1288.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 9278, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 9279, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 9280, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 9281, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 9282, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 9283, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 9284, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 9285, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 9286, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 9287, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 9288, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 9289, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 9290, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 9291, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 9292, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 9293, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 9294, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 9295, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 9296, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 9297, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 9298, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 9299, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 156\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 9300, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 9301, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 9302, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 9303, reward 1368.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 9304, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 9305, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 9306, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 9307, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 9308, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 9309, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 9310, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 9311, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 9312, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 9313, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 9314, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 9315, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 10, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9316, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 9317, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 9318, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 9319, reward 1270.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 9320, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 9321, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 9322, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 9323, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 9324, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 9325, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 149\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 9326, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 9327, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 9328, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 9329, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 9330, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 9331, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 9332, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 9333, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 9334, reward 1547.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 9335, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 9336, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 9337, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 9338, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 9339, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 9340, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 9341, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 9342, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 9343, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 9344, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 145\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 9345, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 9346, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 9347, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 9348, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 9349, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 9350, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 9351, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 9352, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 9353, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 9354, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 9355, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 9356, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 9357, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 9358, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 9359, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 9360, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 9361, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 9362, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 9363, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 9364, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 9365, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 9366, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 9367, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 9368, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 9369, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 9370, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 9371, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 9372, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 9373, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 9374, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 9375, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 9376, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 9377, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 9378, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 9379, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 9380, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 2, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9381, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 9382, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 9383, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 9384, reward 1423.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 9385, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 9386, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 9387, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 9388, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 9389, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 9390, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 9391, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 9392, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 9393, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 9394, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 9395, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 9396, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 9397, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 9398, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 9399, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 9400, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 9401, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 9402, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 9403, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 9404, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 9405, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 9406, reward 600.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 9407, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 9408, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 9409, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 9410, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 9411, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 9412, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 9413, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 9414, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 9415, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 9416, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 9417, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 9418, reward 602.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 9419, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 9420, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 9421, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 9422, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 9423, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 9424, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 9425, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 152\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 9426, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 166\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 9427, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 9428, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 9429, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 9430, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 9431, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 9432, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 9433, reward 1420.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 9434, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 9435, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 9436, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 9437, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 9438, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 9439, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 9440, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 9441, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 9442, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 9443, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 9444, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 9445, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9446, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 9447, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 9448, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 9449, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 9450, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 9451, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 9452, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 9453, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 9454, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 9455, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 9456, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 9457, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 9458, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 9459, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 9460, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 9461, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 9462, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 9463, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 9464, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 9465, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 9466, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 9467, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 9468, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 9469, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 9470, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 9471, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 9472, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 9473, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 9474, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 9475, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 9476, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 9477, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 9478, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 9479, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 9480, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 9481, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 9482, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 9483, reward 1408.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 9484, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 9485, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 9486, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 9487, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 9488, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 9489, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 9490, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 9491, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 9492, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 149\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 9493, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 9494, reward 537.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 116\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 9495, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 9496, reward 516.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 9497, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 9498, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 9499, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 9500, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 9501, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 9502, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 9503, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 9504, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 9505, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 9506, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 9507, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 9508, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 9509, reward 393.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 9510, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [3, 11, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9511, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 9512, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 9513, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 9514, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 9515, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 9516, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 9517, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 9518, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 9519, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 9520, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 9521, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 9522, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 9523, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 9524, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 9525, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 9526, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 9527, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 9528, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 9529, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 9530, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 9531, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 9532, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 9533, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 9534, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 9535, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 125\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 9536, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 9537, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 9538, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 145\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 9539, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 9540, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 9541, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 9542, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 9543, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 9544, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 9545, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 142\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 9546, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 9547, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 9548, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 9549, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 9550, reward 580.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 122\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 9551, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 9552, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 9553, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 9554, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 9555, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 9556, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 9557, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 9558, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 9559, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 9560, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 9561, reward 433.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 9562, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 9563, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 9564, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 9565, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 9566, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 9567, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 9568, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 9569, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 9570, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 9571, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 9572, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 9573, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 9574, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 9575, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 4, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9576, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 9577, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 9578, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 9579, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 9580, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 9581, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 9582, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 9583, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 9584, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 9585, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 9586, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 9587, reward 1463.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 9588, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 9589, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 9590, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 9591, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 9592, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 137\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 9593, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 9594, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 9595, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 9596, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 9597, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 151\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 9598, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 155\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 9599, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 9600, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 9601, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 9602, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 9603, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 9604, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 9605, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 9606, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 9607, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 9608, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 9609, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 9610, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 9611, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 9612, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 9613, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 9614, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 9615, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 9616, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 9617, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 9618, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 9619, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 9620, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 9621, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 9622, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 9623, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 126\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 9624, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 9625, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 9626, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 9627, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 9628, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 9629, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 9630, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9631, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 9632, reward 1316.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 9633, reward 1345.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 9634, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 9635, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 9636, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 9637, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 9638, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 746.0, rides 127\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 9639, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9640, reward 1292.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 9641, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 9642, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 9643, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 9644, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 9645, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 9646, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 9647, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 9648, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 9649, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 9650, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 9651, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 9652, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 9653, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 9654, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 9655, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 9656, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 9657, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 9658, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 9659, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 9660, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 9661, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 9662, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 9663, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 9664, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 9665, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 9666, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 9667, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 9668, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 143\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 9669, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 9670, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 9671, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 9672, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 9673, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 9674, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 9675, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 9676, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 9677, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 9678, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 9679, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 9680, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 9681, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 9682, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 9683, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 9684, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 9685, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 9686, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 9687, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 9688, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 9689, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 9690, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 150\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 9691, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 153\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 9692, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 9693, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 9694, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 126\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 9695, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 9696, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 9697, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 9698, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 9699, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 9700, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 9701, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 9702, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 9703, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 7, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9704, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 9705, reward 585.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 9706, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 9707, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 9708, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 9709, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 9710, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 9711, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 9712, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 160\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 9713, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 9714, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 9715, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 9716, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 9717, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 9718, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 9719, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 9720, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 9721, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 9722, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 9723, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 9724, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 9725, reward 1332.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 9726, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 9727, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 9728, reward 1267.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 9729, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 9730, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 9731, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 9732, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 9733, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 9734, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 9735, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 9736, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 9737, reward 1397.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 9738, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 9739, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 9740, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 9741, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 9742, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 9743, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 9744, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 9745, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 9746, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 9747, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 9748, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 9749, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 122\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 9750, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 9751, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 9752, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 9753, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 9754, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 9755, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 9756, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 9757, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 9758, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 9759, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 9760, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 9761, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 9762, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 9763, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 9764, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 9765, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 9766, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 9767, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 9768, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 17, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9769, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 9770, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 9771, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 9772, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 9773, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 9774, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 9775, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 9776, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 9777, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 9778, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 9779, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 9780, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 9781, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 9782, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 9783, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 9784, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 9785, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 9786, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 9787, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 9788, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 141\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 9789, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 9790, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 9791, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 9792, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 9793, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 9794, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 9795, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 9796, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 9797, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 9798, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 9799, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 9800, reward 1337.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 9801, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 9802, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 9803, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 9804, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 9805, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 9806, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 155\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 9807, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 9808, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 9809, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 9810, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 9811, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 9812, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 9813, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 9814, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 9815, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 9816, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 9817, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 9818, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 9819, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 9820, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 9821, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 9822, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 9823, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 134\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 9824, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 9825, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 9826, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 9827, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 9828, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 9829, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 9830, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 9831, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 9832, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 9833, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9834, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 9835, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 9836, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 9837, reward 1397.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 9838, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 9839, reward 1375.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 9840, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 9841, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 9842, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 9843, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 9844, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 9845, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 9846, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 9847, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 9848, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 9849, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 9850, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 9851, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 9852, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 9853, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 9854, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 9855, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 9856, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 9857, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 9858, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 9859, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 9860, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 9861, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 9862, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 9863, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 9864, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 9865, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9866, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 9867, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 9868, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 9869, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 9870, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 9871, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 9872, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 9873, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 9874, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 9875, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 9876, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 9877, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 9878, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 9879, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 9880, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 9881, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 9882, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 9883, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 9884, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 9885, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 9886, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 9887, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 9888, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 9889, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 9890, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 9891, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 9892, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 9893, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 9894, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 9895, reward 1318.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 9896, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 9897, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 19, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9898, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 9899, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 9900, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 9901, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 9902, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 9903, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 9904, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 9905, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 9906, reward 1322.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 9907, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 9908, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 9909, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 155\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 9910, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 9911, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 9912, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 9913, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 9914, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 9915, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 9916, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 9917, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 9918, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 9919, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 9920, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 9921, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 9922, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 9923, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 9924, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 9925, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 9926, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 9927, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 9928, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 9929, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 9930, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 9931, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 9932, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 9933, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 9934, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 9935, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 9936, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 9937, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 9938, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 154\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 9939, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 9940, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 9941, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 9942, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 9943, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 9944, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 9945, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 9946, reward 1284.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 9947, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 9948, reward 1334.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 9949, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 9950, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 9951, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 9952, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 9953, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 9954, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 9955, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 9956, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 9957, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 9958, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 9959, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 9960, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 9961, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 8, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 9962, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 9963, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 9964, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 9965, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 9966, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 9967, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 9968, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 9969, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 9970, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 9971, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 9972, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 9973, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 9974, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 9975, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 9976, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 9977, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 9978, reward 1367.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 9979, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 9980, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 9981, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 9982, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 9983, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 9984, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 9985, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 9986, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 9987, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 9988, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 117\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 9989, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 9990, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 9991, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 9992, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 9993, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 9994, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 9995, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 9996, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 9997, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 9998, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 9999, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 10000, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 10001, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 10002, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 10003, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 10004, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 10005, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 10006, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 10007, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 10008, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 10009, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 10010, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 156\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 10011, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 10012, reward 1417.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 152\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 10013, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 10014, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 10015, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 10016, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 10017, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 10018, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 10019, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 10020, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 10021, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 10022, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 10023, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 10024, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 10025, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 2, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10026, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 10027, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 10028, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 141\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 10029, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 10030, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 10031, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 10032, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 10033, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 10034, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 10035, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 10036, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 10037, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 10038, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 10039, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 10040, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 10041, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 10042, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 10043, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 10044, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 10045, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 10046, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 10047, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 10048, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 124\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 10049, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 10050, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 10051, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 10052, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 10053, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 10054, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 10055, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 10056, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 10057, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 10058, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 10059, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 10060, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 10061, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 10062, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 10063, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 10064, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 10065, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 10066, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 10067, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 10068, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 10069, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 10070, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 10071, reward 604.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 10072, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 10073, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 10074, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 10075, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 10076, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 10077, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 10078, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 10079, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 10080, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 10081, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 10082, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 10083, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 151\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 10084, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 10085, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 10086, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 10087, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 10088, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 10089, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 10, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10090, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 10091, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 10092, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 10093, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 10094, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 10095, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 147\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 10096, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10097, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 10098, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 10099, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 10100, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 10101, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 10102, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 10103, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 10104, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 10105, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 10106, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10107, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 10108, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 10109, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 10110, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 10111, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 123\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 10112, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 10113, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 10114, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 10115, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 10116, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 10117, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 10118, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 10119, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 122\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 10120, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 10121, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 10122, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 10123, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 10124, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 10125, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 140\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 10126, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 10127, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 10128, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 10129, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 10130, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 10131, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 10132, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 10133, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 10134, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 10135, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 10136, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 10137, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 10138, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 155\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 10139, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 10140, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 10141, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 10142, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 10143, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 10144, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 10145, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 122\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 10146, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 10147, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 10148, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 10149, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 10150, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 10151, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 10152, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 10153, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 0, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10154, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 10155, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 10156, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 10157, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 10158, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 10159, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 10160, reward 1306.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 10161, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 10162, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 10163, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 10164, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 10165, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 10166, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 10167, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 145\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 10168, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 10169, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 10170, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 10171, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 10172, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 10173, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 10174, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 10175, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 10176, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 10177, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 10178, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 10179, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 10180, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 10181, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 10182, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 10183, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 10184, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 10185, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 10186, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 10187, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 10188, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 10189, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 10190, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 10191, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 10192, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 10193, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 10194, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 10195, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 10196, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 10197, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 10198, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 10199, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 10200, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 10201, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 10202, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 10203, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 10204, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 10205, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 10206, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 10207, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 10208, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 10209, reward 1369.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 10210, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 10211, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 10212, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 10213, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 10214, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 10215, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 10216, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 10217, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 15, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10218, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 10219, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 10220, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 10221, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10222, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 10223, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 10224, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 10225, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 10226, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 114\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 10227, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 10228, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 10229, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 10230, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 10231, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 10232, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 10233, reward 1372.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 10234, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 10235, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 10236, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 118\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 10237, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 10238, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 10239, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 10240, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 10241, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 10242, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 10243, reward 1307.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 10244, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 10245, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 10246, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 10247, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 10248, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 10249, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 10250, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 10251, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 10252, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 10253, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 10254, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 10255, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 10256, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 10257, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 10258, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 10259, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 10260, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 10261, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 10262, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 10263, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 10264, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 10265, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 10266, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 10267, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 10268, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 10269, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 10270, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 10271, reward 1414.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 10272, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 10273, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 10274, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 10275, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 10276, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 10277, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 10278, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 10279, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 120\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 10280, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 10281, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 4, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10282, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 10283, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 10284, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 10285, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 10286, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 10287, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 10288, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 10289, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 10290, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 10291, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 10292, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 10293, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 10294, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 10295, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 10296, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10297, reward 541.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 10298, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 10299, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 10300, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 10301, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 150\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 10302, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 127\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 10303, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 10304, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 10305, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 10306, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 10307, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 10308, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 154\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 10309, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 10310, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 10311, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 10312, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 10313, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 10314, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 10315, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 10316, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 10317, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 10318, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 10319, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 10320, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 10321, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 10322, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 10323, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 10324, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 10325, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 10326, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 150\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 10327, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 10328, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 10329, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 10330, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 10331, reward 1359.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 10332, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 10333, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 10334, reward 1369.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 10335, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 10336, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 10337, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 10338, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 10339, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 10340, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 10341, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 10342, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 10343, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 10344, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 10345, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 6, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10346, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 10347, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 10348, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 10349, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 10350, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 10351, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 10352, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 10353, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 10354, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 10355, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 10356, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 10357, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 10358, reward 582.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 10359, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 10360, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 10361, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 10362, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 10363, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 10364, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 10365, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 10366, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 10367, reward 602.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 10368, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 10369, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 10370, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 10371, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 10372, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 10373, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 10374, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 121\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 10375, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 10376, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 10377, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 10378, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 10379, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 10380, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 10381, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 10382, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 10383, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 10384, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 10385, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 10386, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 10387, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 10388, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 10389, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 10390, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 10391, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 10392, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 10393, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 10394, reward 558.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 10395, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 10396, reward 538.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 10397, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 10398, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 10399, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 10400, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 10401, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 110\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 10402, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 10403, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 10404, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10405, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 10406, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 10407, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 10408, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 10409, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [4, 6, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10410, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 10411, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 10412, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 10413, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 10414, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 10415, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 10416, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 10417, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 10418, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 10419, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 10420, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 10421, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 10422, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 10423, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 10424, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 10425, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 10426, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 10427, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 10428, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 10429, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 10430, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 10431, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 10432, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 10433, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 159\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 10434, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 10435, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 10436, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 10437, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 10438, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 10439, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 10440, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 10441, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 10442, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 10443, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 10444, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 154\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 10445, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 10446, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 126\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 10447, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 10448, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 10449, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 10450, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 140\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 10451, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 10452, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 10453, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 10454, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 10455, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 10456, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 10457, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 10458, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 10459, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 10460, reward 582.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 10461, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 10462, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 10463, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 10464, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 10465, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 10466, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 10467, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 10468, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 10469, reward 270.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 10470, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 10471, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 126\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 10472, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 10473, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 15, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10474, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 10475, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 10476, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 10477, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 10478, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 10479, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 10480, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 10481, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 10482, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 10483, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 10484, reward 448.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 10485, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 10486, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 10487, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 10488, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 10489, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 10490, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 10491, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 10492, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 10493, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 10494, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 141\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 10495, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 10496, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 156\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 10497, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 10498, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 10499, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 10500, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 10501, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 10502, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 10503, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 10504, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 10505, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 10506, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 10507, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 10508, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 10509, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 10510, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 10511, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 10512, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 10513, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 118\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 10514, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 10515, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 10516, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 10517, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 157\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 10518, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 10519, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 10520, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 10521, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 10522, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 10523, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 10524, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 10525, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 10526, reward 536.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 10527, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 10528, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 10529, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 10530, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 10531, reward 1335.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 10532, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 10533, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 10534, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 10535, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 10536, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 10537, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 22, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10538, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 10539, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 10540, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 10541, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 10542, reward 1450.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 10543, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 10544, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 10545, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 10546, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 10547, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 10548, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 10549, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 10550, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 10551, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 10552, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 10553, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 10554, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 10555, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 10556, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 10557, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 10558, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 10559, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 10560, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 10561, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 10562, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 10563, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 10564, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 10565, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 10566, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 10567, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 163\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 10568, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 10569, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 134\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 10570, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 10571, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 10572, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 10573, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 10574, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 10575, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 10576, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 10577, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 10578, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 10579, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 10580, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 10581, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 10582, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 10583, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 10584, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 10585, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 10586, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 10587, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 10588, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 10589, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 10590, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 10591, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 10592, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 149\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 10593, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 10594, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 10595, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 10596, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 10597, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 10598, reward 513.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 10599, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 10600, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 10601, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 12, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10602, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 10603, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 10604, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 10605, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 10606, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 10607, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 10608, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 10609, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 10610, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 10611, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 10612, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 10613, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 10614, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 10615, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 10616, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 10617, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 10618, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 10619, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 10620, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 10621, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 10622, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 10623, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 10624, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 10625, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 120\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 10626, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 10627, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 10628, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 10629, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 157\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 10630, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 10631, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 10632, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 148\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 10633, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 10634, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 10635, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 10636, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 10637, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 10638, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 10639, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 10640, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 10641, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 10642, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 10643, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 10644, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 10645, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 147\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 10646, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 10647, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 10648, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 10649, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 10650, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 10651, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 10652, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 10653, reward 608.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 10654, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 10655, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 10656, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 10657, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 10658, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 10659, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 10660, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 10661, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 10662, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 10663, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 10664, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 10665, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 5, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10666, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 10667, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 10668, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 10669, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 10670, reward 1283.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 10671, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 10672, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 10673, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 10674, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 10675, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 10676, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 10677, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 10678, reward 616.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 10679, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 10680, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 10681, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 10682, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 10683, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 10684, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 125\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 10685, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 10686, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 10687, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 10688, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 10689, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 10690, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 10691, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 10692, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 10693, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 10694, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 10695, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 10696, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 10697, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 10698, reward 569.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 10699, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 10700, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 10701, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 10702, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 10703, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 10704, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 10705, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 10706, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 10707, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 10708, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 10709, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 10710, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 10711, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 10712, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 10713, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 10714, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 10715, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 10716, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 10717, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 10718, reward 1314.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 139\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 10719, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 10720, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 10721, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 158\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 10722, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 10723, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 10724, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 10725, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 10726, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 10727, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 10728, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 10729, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 15, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10730, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 10731, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 10732, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 10733, reward 1299.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 10734, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 10735, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 10736, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 10737, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 10738, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 10739, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 10740, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 10741, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 140\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 10742, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 10743, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 10744, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 10745, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 10746, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 10747, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 10748, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 10749, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 10750, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 10751, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 10752, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 10753, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 10754, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 10755, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 10756, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 10757, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 10758, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 10759, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 10760, reward 481.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 10761, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 10762, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 10763, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 10764, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 10765, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 10766, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 10767, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 10768, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 10769, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 10770, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 10771, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 10772, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 10773, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 10774, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 10775, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 10776, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 10777, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 10778, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 10779, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 10780, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 10781, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 10782, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 10783, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 10784, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 10785, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 10786, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 10787, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 10788, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 10789, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 10790, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 10791, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 10792, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 10793, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 13, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10794, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 10795, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 10796, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 10797, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 10798, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 10799, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 10800, reward 1390.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 10801, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 10802, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 160\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 10803, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 10804, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 10805, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 10806, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 10807, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 10808, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 10809, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 153\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 10810, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 10811, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 10812, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 149\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 10813, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 10814, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 10815, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 10816, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 10817, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 10818, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 10819, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 10820, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 10821, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 10822, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 10823, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 10824, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 132\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 10825, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 10826, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 10827, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 10828, reward 1486.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 10829, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 10830, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 10831, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 10832, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 10833, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 10834, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 163\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 10835, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 10836, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 10837, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 10838, reward 1425.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 10839, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 10840, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 10841, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 10842, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 10843, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 157\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 10844, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 10845, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 10846, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 10847, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 10848, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 10849, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 10850, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 158\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 10851, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 10852, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 10853, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 10854, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 10855, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 10856, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 10857, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [4, 18, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10858, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 10859, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 10860, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 10861, reward 580.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 10862, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 10863, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 10864, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 10865, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 10866, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 153\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 10867, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 10868, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 10869, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 10870, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 10871, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 10872, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 10873, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 10874, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 10875, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 10876, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 10877, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 10878, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 10879, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 10880, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 10881, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 10882, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 10883, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 10884, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 10885, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 10886, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 10887, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 10888, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 10889, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 10890, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 10891, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 10892, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 10893, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 10894, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 10895, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 10896, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 10897, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 138\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 10898, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 10899, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 10900, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 10901, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 10902, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 10903, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 10904, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 10905, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 136\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 10906, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 10907, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 10908, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 10909, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 10910, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 10911, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 10912, reward 587.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 10913, reward 1315.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 10914, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 10915, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 10916, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 10917, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 10918, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 10919, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 10920, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 10921, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 9, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10922, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 10923, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 10924, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 10925, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 10926, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 10927, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 10928, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 10929, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 10930, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 10931, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 10932, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 10933, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 10934, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 10935, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 10936, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 10937, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 10938, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 10939, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 10940, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 10941, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 127\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 10942, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 10943, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 10944, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 10945, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 10946, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 10947, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 10948, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 10949, reward 572.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 10950, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 151\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 10951, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 10952, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 10953, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 10954, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 10955, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 10956, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 140\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 10957, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 10958, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 10959, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 10960, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 10961, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 10962, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 10963, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 10964, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 10965, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 10966, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 10967, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 10968, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 10969, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 10970, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 10971, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 10972, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 10973, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 10974, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 10975, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 10976, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 150\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 10977, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 10978, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 10979, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 10980, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 10981, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 10982, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 10983, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 10984, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 10985, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 2, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 10986, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 10987, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 10988, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 10989, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 10990, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 10991, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 10992, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 10993, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 10994, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 10995, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 164\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 10996, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 127\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 10997, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 10998, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 10999, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 11000, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 11001, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 11002, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 11003, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 11004, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 11005, reward 603.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 11006, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 11007, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 11008, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 11009, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 11010, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 11011, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 11012, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 11013, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 11014, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 11015, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 11016, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 11017, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 11018, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 11019, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 11020, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 11021, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 11022, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 11023, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 11024, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 11025, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 11026, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 11027, reward 581.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 116\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 11028, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 11029, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 11030, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 11031, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 11032, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 11033, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 11034, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 11035, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 11036, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 11037, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 11038, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 11039, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 11040, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 11041, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 11042, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 149\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 11043, reward 638.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 11044, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 11045, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 11046, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 11047, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 11048, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 150\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 11049, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 23, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11050, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 11051, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 11052, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 11053, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 11054, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 11055, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 11056, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 11057, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 11058, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 11059, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 11060, reward 550.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 11061, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 11062, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 11063, reward 1311.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 11064, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 151\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 11065, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 11066, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 11067, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 11068, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 11069, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 11070, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 11071, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 154\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 11072, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 11073, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 11074, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 11075, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 11076, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 11077, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 11078, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 11079, reward 1404.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 11080, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 11081, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 11082, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 11083, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 11084, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 11085, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 11086, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 11087, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 149\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 11088, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 11089, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 11090, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 11091, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 11092, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 11093, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 11094, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 11095, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 11096, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 11097, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 11098, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 11099, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 11100, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 11101, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 11102, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 11103, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 11104, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 11105, reward 478.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 11106, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 11107, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 11108, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 11109, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 11110, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 11111, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 11112, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 11113, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 8, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11114, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 11115, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 11116, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 11117, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 11118, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 11119, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 11120, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 11121, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 11122, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 11123, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 11124, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 11125, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 11126, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 11127, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 11128, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 11129, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 11130, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 11131, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 11132, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 11133, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 11134, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 11135, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 11136, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 11137, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 11138, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 11139, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 11140, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 11141, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 11142, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 11143, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 11144, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 11145, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 11146, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 152\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 11147, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 11148, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 11149, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 11150, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 11151, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 11152, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 11153, reward 650.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 11154, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 11155, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 11156, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 11157, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 11158, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 11159, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 11160, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 11161, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 11162, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 11163, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 11164, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 11165, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 11166, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 11167, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 11168, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 11169, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 11170, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 11171, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 11172, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 11173, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 11174, reward 503.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 11175, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 11176, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 11177, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 4, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11178, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 11179, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 11180, reward 1335.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 11181, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 11182, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 11183, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 11184, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 11185, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 11186, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 11187, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 11188, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 11189, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 11190, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 11191, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 11192, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 11193, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 11194, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 11195, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 11196, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 11197, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 11198, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 11199, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 159\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 11200, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 11201, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 11202, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 11203, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 11204, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 11205, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 11206, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 158\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 11207, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 11208, reward 580.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 11209, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 151\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 11210, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 11211, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 11212, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 11213, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 11214, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 11215, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 11216, reward 580.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 11217, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 11218, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 11219, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 11220, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 11221, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 11222, reward 420.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 11223, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 11224, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 11225, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 11226, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 11227, reward 1289.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 11228, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 11229, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 11230, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 11231, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 11232, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 11233, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 11234, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 11235, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 11236, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 11237, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 11238, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 11239, reward 598.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 115\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 11240, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 11241, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11242, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 11243, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 11244, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 11245, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 11246, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 11247, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 11248, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 11249, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 11250, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 11251, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 11252, reward 1289.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 11253, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 11254, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 11255, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 11256, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 11257, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 11258, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 11259, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 11260, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 11261, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 153\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 11262, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 11263, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 11264, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 11265, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 11266, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 11267, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 11268, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 11269, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 11270, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 11271, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 11272, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 11273, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 11274, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 11275, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 11276, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 11277, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 11278, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 11279, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 11280, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 11281, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 11282, reward 612.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 11283, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 11284, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 11285, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 11286, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 11287, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 11288, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 11289, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 11290, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 11291, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 11292, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 11293, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 11294, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 150\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 11295, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 11296, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 11297, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 11298, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 11299, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 11300, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 11301, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 11302, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 11303, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 11304, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 11305, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 0, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11306, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 11307, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 11308, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 11309, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 11310, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 11311, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 11312, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 11313, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 11314, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 149\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 11315, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 11316, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 11317, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 11318, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 11319, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 11320, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 11321, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 11322, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 11323, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 11324, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 11325, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 11326, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 11327, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 11328, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 11329, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 11330, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 11331, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 11332, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 11333, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 11334, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 11335, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 11336, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 11337, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 11338, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 11339, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 11340, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 11341, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 11342, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 11343, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 11344, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 11345, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 11346, reward 1286.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 11347, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 11348, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 11349, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 11350, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 11351, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 11352, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 11353, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 11354, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 11355, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 11356, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 11357, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 11358, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 11359, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 11360, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 11361, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 11362, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 11363, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 11364, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 11365, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 11366, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 11367, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 11368, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 11369, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 15, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11370, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 11371, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 154\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 11372, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 11373, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 11374, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 11375, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 11376, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 11377, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 11378, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 11379, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 11380, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 11381, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 11382, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 11383, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 11384, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 11385, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 160\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 11386, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 11387, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 11388, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 11389, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 11390, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 11391, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 11392, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 11393, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 11394, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 11395, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 11396, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 11397, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 11398, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 11399, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 11400, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 11401, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 11402, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 11403, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 11404, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 11405, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 11406, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 11407, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 11408, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 11409, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 11410, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 11411, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 118\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 11412, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 11413, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 11414, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 11415, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 11416, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 11417, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 11418, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 11419, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 141\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 11420, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 11421, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 11422, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 11423, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 11424, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 11425, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 11426, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 11427, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 11428, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 11429, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 11430, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 11431, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 11432, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 11433, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11434, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 11435, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 11436, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 11437, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 11438, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 11439, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 11440, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 11441, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 11442, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 11443, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 11444, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 11445, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 11446, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 11447, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 11448, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 11449, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 11450, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 11451, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 148\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 11452, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 11453, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 11454, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 11455, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 11456, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 11457, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 11458, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 11459, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 11460, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 11461, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 11462, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 11463, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 11464, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 11465, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 11466, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 11467, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 11468, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 11469, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 11470, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 11471, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 154\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 11472, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 11473, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 11474, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 11475, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 11476, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 11477, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 11478, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 11479, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 11480, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 11481, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 11482, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 11483, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 11484, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 125\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 11485, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 11486, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 155\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 11487, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 11488, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 11489, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 11490, reward 1466.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 11491, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 11492, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 11493, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 11494, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 11495, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 11496, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 11497, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 155\n",
      "Initial State is  [0, 4, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11498, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 11499, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 11500, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 11501, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 11502, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 11503, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 11504, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 11505, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 11506, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 11507, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 11508, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 11509, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 11510, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 11511, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 116\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 11512, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 11513, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 11514, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 11515, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 11516, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 11517, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 11518, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 11519, reward 656.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 11520, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 11521, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 11522, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 11523, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 11524, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 11525, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 11526, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 11527, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 11528, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 11529, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 11530, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 11531, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 11532, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 11533, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 11534, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 11535, reward 509.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 11536, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 149\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 11537, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 11538, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 11539, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 11540, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 11541, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 128\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 11542, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 11543, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 11544, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 11545, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 11546, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 11547, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 11548, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 11549, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 11550, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 11551, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 11552, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 11553, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 11554, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 11555, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 11556, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 11557, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 11558, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 11559, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 11560, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 148\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 11561, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 1, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11562, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 11563, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 11564, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 11565, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 111\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 11566, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 11567, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 11568, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 11569, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 11570, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 11571, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 11572, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 11573, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 11574, reward 520.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 11575, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 11576, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 11577, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 11578, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 11579, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 11580, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 11581, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 11582, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 11583, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 11584, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 11585, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 11586, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 11587, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 11588, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 11589, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 11590, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 11591, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 11592, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 11593, reward 319.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 116\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 11594, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 11595, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 11596, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 11597, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 11598, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 11599, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 11600, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 11601, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 11602, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 11603, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 11604, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 11605, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 145\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 11606, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 11607, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 11608, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 11609, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 11610, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 11611, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 11612, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 11613, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 11614, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 11615, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 11616, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 155\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 11617, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 153\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 11618, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 11619, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 11620, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 11621, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 11622, reward 558.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 11623, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 11624, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 11625, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 141\n",
      "Initial State is  [4, 9, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11626, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 11627, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 11628, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 11629, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 11630, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 11631, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 11632, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 11633, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 11634, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 11635, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 153\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 11636, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 11637, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 11638, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 161\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 11639, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 11640, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 11641, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 11642, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 11643, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 11644, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 11645, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 11646, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 11647, reward 1410.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 11648, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 11649, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 11650, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 11651, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 11652, reward 549.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 143\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 11653, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 161\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 11654, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 11655, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 11656, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 11657, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 11658, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 11659, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 11660, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 11661, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 11662, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 11663, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 11664, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 156\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 11665, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 11666, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 11667, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 11668, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 11669, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 11670, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 11671, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 11672, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 11673, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 11674, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 11675, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 11676, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 11677, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 11678, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 11679, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 11680, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 11681, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 11682, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 11683, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 11684, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 11685, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 11686, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 11687, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 11688, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 11689, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 16, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11690, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 11691, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 11692, reward 547.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 11693, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 11694, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 11695, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 11696, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 11697, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 11698, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 11699, reward 562.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 11700, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 11701, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 116\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 11702, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 11703, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 11704, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 11705, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 11706, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 11707, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 11708, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 11709, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 11710, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 11711, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 11712, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 11713, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 11714, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 11715, reward 1420.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 11716, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 11717, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 11718, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 11719, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 11720, reward 1380.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 11721, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 11722, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 11723, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 11724, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 11725, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 11726, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 11727, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 11728, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 11729, reward 569.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 11730, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 11731, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 11732, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 11733, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 11734, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 11735, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 11736, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 11737, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 11738, reward 1433.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 11739, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 11740, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 11741, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 11742, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 11743, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 11744, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 11745, reward 1424.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 11746, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 152\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 11747, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 11748, reward 1379.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 11749, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 11750, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 11751, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 11752, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 11753, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 17, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11754, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 11755, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 11756, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 11757, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 11758, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 11759, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 11760, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 11761, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 11762, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 156\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 11763, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 11764, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 11765, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 11766, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 11767, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 11768, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 11769, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 11770, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 11771, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 11772, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 11773, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 11774, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 11775, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 11776, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 11777, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 11778, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 11779, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 11780, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 11781, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 11782, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 11783, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 11784, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 11785, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 11786, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 11787, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 11788, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 11789, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 11790, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 11791, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 11792, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 11793, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 11794, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 11795, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 11796, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 11797, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 11798, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 11799, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 11800, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 11801, reward 1323.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 149\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 11802, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 11803, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 11804, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 11805, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 11806, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 11807, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 159\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 11808, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 11809, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 11810, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 11811, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 11812, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 11813, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 11814, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 11815, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 11816, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 11817, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [3, 15, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11818, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 11819, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 11820, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 11821, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 11822, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 11823, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 11824, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 11825, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 11826, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 11827, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 11828, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 11829, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 11830, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 11831, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 11832, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 11833, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 11834, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 11835, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 11836, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 11837, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 11838, reward 305.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 11839, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 11840, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 11841, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 11842, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 11843, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 11844, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 11845, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 11846, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 11847, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 11848, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 11849, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 11850, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 11851, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 11852, reward 1374.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 11853, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 11854, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 11855, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 158\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 11856, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 11857, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 11858, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 11859, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 11860, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 11861, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 11862, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 11863, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 11864, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 11865, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 11866, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 11867, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 11868, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 11869, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 11870, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 11871, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 11872, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 11873, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 11874, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 11875, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 11876, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 162\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 11877, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 11878, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 11879, reward 1493.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 154\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 11880, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 11881, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 2, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11882, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 11883, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 11884, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 11885, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 11886, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 11887, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 11888, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 11889, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 11890, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 11891, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 11892, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 11893, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 11894, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 11895, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 11896, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 11897, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 11898, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 11899, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 11900, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 11901, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 150\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 11902, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 11903, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 11904, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 11905, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 11906, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 11907, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 11908, reward 1409.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 11909, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 11910, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 11911, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 11912, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 11913, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 11914, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 11915, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 11916, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 11917, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 11918, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 11919, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 11920, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 11921, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 11922, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 11923, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 11924, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 11925, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 11926, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 11927, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 11928, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 11929, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 11930, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 11931, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 11932, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 11933, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 144\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 11934, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 11935, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 11936, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 11937, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 11938, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 11939, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 11940, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 11941, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 11942, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 11943, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 11944, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 11945, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 11946, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 11947, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 11948, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 11949, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 11950, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 11951, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 11952, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 11953, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 11954, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 11955, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 11956, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 11957, reward 1283.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 11958, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 11959, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 11960, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 11961, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 11962, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 11963, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 11964, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 11965, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 11966, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 11967, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 11968, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 11969, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 11970, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 11971, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 11972, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 11973, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 11974, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 11975, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 11976, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 11977, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 11978, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 11979, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 11980, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 11981, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 11982, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 11983, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 11984, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 11985, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 11986, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 11987, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 151\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 11988, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 11989, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 11990, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 11991, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 11992, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 11993, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 155\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 11994, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 11995, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 11996, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 11997, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 11998, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 11999, reward 570.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 12000, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 12001, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 12002, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 12003, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 12004, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 12005, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 12006, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 12007, reward 578.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 12008, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 12009, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 16, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12010, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 12011, reward 568.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 12012, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 12013, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 12014, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 12015, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 12016, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 12017, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 12018, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 12019, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 12020, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 141\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 12021, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 12022, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 12023, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 12024, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 12025, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 12026, reward 635.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 125\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 12027, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 12028, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 12029, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 12030, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 12031, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 12032, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 12033, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 12034, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 12035, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 12036, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 12037, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 12038, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 12039, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 12040, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 12041, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 12042, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 12043, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 12044, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 12045, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 12046, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 12047, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 12048, reward 1267.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 12049, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 12050, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 12051, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 12052, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 12053, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 12054, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 12055, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 12056, reward 1337.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 12057, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 12058, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 12059, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 12060, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 12061, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 12062, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 12063, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 12064, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 12065, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 12066, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 12067, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 12068, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 12069, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 12070, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 12071, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 12072, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 12073, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12074, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 12075, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 12076, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 12077, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 12078, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 12079, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 12080, reward 612.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 12081, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 12082, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 12083, reward 1399.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 12084, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 12085, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 155\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 12086, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 12087, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 12088, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 12089, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 12090, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 12091, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 12092, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 12093, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12094, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 12095, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 12096, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 12097, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 139\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 12098, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 12099, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 144\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 12100, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 12101, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 12102, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 12103, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 12104, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 12105, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 12106, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 12107, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 12108, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 12109, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 12110, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 12111, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 12112, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 149\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 12113, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 12114, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 12115, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 12116, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 12117, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 12118, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 12119, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 12120, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 12121, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 12122, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 12123, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 12124, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 12125, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 12126, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 12127, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 12128, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 12129, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 12130, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 12131, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 12132, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 12133, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 12134, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 12135, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 12136, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 12137, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 12, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12138, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 12139, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 12140, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 12141, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 12142, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 156\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 12143, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 12144, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 12145, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 12146, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 12147, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 12148, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 12149, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12150, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 12151, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 12152, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 12153, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 12154, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 12155, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 12156, reward 1313.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 12157, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 12158, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 12159, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 12160, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 12161, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 12162, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 12163, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 12164, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 12165, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 12166, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 12167, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 12168, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 12169, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 12170, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 12171, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 12172, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 12173, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 12174, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 12175, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 12176, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 12177, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 12178, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 12179, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 12180, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 157\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 12181, reward 1308.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 160\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 12182, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 12183, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 12184, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 12185, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 12186, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 12187, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 12188, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 12189, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 12190, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 12191, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 12192, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 12193, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 12194, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 12195, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 12196, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 12197, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 12198, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 12199, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 12200, reward 1327.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 12201, reward 1313.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [1, 17, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12202, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 12203, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 12204, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 12205, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 12206, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 12207, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 12208, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 12209, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 12210, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 12211, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 12212, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 12213, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 12214, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 12215, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 12216, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 12217, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 12218, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 12219, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 12220, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 148\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 12221, reward 614.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 12222, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 12223, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 12224, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 12225, reward 641.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 12226, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 12227, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 12228, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 12229, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 12230, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 12231, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 12232, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 12233, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 12234, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 12235, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 12236, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 12237, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 12238, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 12239, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 12240, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 12241, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 12242, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 12243, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 12244, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 12245, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 12246, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 12247, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 12248, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 12249, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 12250, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 12251, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 12252, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 12253, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 12254, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 12255, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 12256, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 12257, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 12258, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 12259, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 12260, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 12261, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 12262, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 12263, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 12264, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 12265, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 18, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12266, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 12267, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 12268, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 12269, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 12270, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 12271, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 12272, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 12273, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 12274, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 12275, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 12276, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 12277, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 12278, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 12279, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 12280, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 12281, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 12282, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 12283, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 12284, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 12285, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 12286, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 12287, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 12288, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 12289, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 12290, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 12291, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 12292, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 12293, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 12294, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 12295, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 12296, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 12297, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 12298, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 140\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 12299, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 12300, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 12301, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 12302, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 12303, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 12304, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 12305, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 12306, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 12307, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 12308, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 12309, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 12310, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 12311, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 12312, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 12313, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 12314, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 12315, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 144\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 12316, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 12317, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 12318, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 12319, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 12320, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 12321, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 12322, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 12323, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 12324, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 12325, reward 608.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 12326, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 12327, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 12328, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 12329, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 21, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12330, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 12331, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 12332, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 12333, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 12334, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 12335, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 12336, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 12337, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 12338, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 12339, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 12340, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 12341, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 12342, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 12343, reward 1297.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 12344, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 12345, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 12346, reward 1250.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 12347, reward 1396.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 12348, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 12349, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 12350, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 12351, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 12352, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 12353, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 12354, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 12355, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 12356, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 12357, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 12358, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 12359, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 12360, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 12361, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 12362, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 12363, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 12364, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12365, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 12366, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 12367, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 12368, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 12369, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 12370, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 12371, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 12372, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 12373, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 12374, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 12375, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 12376, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 12377, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 12378, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 12379, reward 535.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 12380, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 12381, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 12382, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 12383, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 12384, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 12385, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 12386, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 12387, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 12388, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 12389, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 12390, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 12391, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 12392, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 12393, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 16, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12394, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 12395, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12396, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 12397, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 12398, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 12399, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 12400, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 12401, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 12402, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 12403, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 12404, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 12405, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 12406, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 12407, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 12408, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 12409, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 12410, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 12411, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 12412, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 12413, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 12414, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 12415, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 12416, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 12417, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 12418, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 12419, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 12420, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 12421, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 12422, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 12423, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 12424, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 12425, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 12426, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 12427, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 12428, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 12429, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 12430, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 12431, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 12432, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 12433, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 12434, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 12435, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 12436, reward 1392.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 12437, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 12438, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 12439, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 12440, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 12441, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 12442, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 12443, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 12444, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 12445, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 12446, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 12447, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 12448, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 12449, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12450, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 12451, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 12452, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 12453, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 12454, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 12455, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 12456, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 12457, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 2, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12458, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 12459, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 12460, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 12461, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 12462, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 12463, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 12464, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 12465, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 12466, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 12467, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 12468, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 156\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 12469, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 12470, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 12471, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 12472, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 12473, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 12474, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 12475, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 12476, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 12477, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 12478, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 12479, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 12480, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 12481, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 12482, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 12483, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 12484, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 12485, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 12486, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 12487, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 152\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 12488, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 12489, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 12490, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 12491, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 12492, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 12493, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 12494, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 12495, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 12496, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 12497, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 155\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 12498, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 12499, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 12500, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 12501, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 12502, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 12503, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 12504, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 12505, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 12506, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 12507, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 12508, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 12509, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 12510, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 12511, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 12512, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 12513, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 12514, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 12515, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 12516, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 12517, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 12518, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 12519, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 12520, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 12521, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [4, 10, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12522, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 12523, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 12524, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 12525, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 12526, reward 456.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 12527, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 12528, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 154\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 12529, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 12530, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 12531, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 12532, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 12533, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 158\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 12534, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 12535, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 12536, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 12537, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 12538, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 12539, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 12540, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 12541, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 12542, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 12543, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 12544, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 12545, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 12546, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 12547, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 12548, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 12549, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 12550, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 12551, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 12552, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 12553, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 12554, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 12555, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 12556, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 12557, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 12558, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 12559, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 12560, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 114\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 12561, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 12562, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 12563, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 12564, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 12565, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 12566, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 12567, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 12568, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 12569, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 12570, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 12571, reward 521.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 12572, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 12573, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 12574, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 12575, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 12576, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 12577, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 12578, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 12579, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 12580, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 12581, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 12582, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 12583, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 12584, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 12585, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12586, reward 608.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 12587, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 12588, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 12589, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 12590, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 12591, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 12592, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 12593, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 12594, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 12595, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 12596, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 149\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 12597, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 12598, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 12599, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 12600, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 12601, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 12602, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 12603, reward 621.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 12604, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 12605, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 12606, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 12607, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 12608, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 145\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 12609, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 12610, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 12611, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 12612, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 12613, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 12614, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 12615, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 12616, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 12617, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 12618, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 117\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 12619, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 12620, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 12621, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 12622, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 12623, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 12624, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 12625, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 12626, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 12627, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 12628, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 12629, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 12630, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 12631, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 12632, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 12633, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 12634, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 12635, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 149\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 12636, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 12637, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 12638, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 12639, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 12640, reward 510.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 12641, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 12642, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 12643, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 12644, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 12645, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 12646, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 12647, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 12648, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 12649, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12650, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 12651, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 12652, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 12653, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 136\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 12654, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 12655, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 12656, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 12657, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 12658, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 12659, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 12660, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 12661, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 12662, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 12663, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 12664, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 150\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 12665, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 12666, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 12667, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 12668, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 12669, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 139\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 12670, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 12671, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 12672, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 12673, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 12674, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 12675, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 147\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 12676, reward 645.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 12677, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 12678, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 12679, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 12680, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 12681, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 12682, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 12683, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 12684, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 12685, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 12686, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 12687, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 12688, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 12689, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 12690, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 12691, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 12692, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 12693, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 12694, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 12695, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 12696, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 12697, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 12698, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 12699, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 12700, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 12701, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 12702, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 12703, reward 1241.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 12704, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 12705, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 120\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 12706, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 12707, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 12708, reward 603.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 12709, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 12710, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 12711, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 12712, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 12713, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [1, 8, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12714, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 12715, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 157\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 12716, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 157\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 12717, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 12718, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 154\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 12719, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 12720, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 12721, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 12722, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 12723, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 12724, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 12725, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 12726, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 12727, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 12728, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 12729, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 12730, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 12731, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 12732, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 12733, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 12734, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 12735, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 12736, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 12737, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 12738, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 12739, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 12740, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 153\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 12741, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 12742, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 12743, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 12744, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 12745, reward 507.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 12746, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 12747, reward 542.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 12748, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 12749, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 158\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 12750, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 12751, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 12752, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 12753, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 12754, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 12755, reward 577.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 12756, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 12757, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 12758, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 12759, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 12760, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 12761, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 12762, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 12763, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 12764, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 155\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 12765, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 12766, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 12767, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 12768, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 12769, reward 544.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 12770, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 12771, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 12772, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 12773, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 133\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 12774, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 12775, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 12776, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 12777, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 21, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12778, reward 1280.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 12779, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 12780, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 163\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 12781, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 12782, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 12783, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 12784, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 12785, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 12786, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 12787, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 12788, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 12789, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 12790, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 12791, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 12792, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 12793, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 12794, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 12795, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 12796, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 12797, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 12798, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 12799, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 12800, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 12801, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 12802, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 12803, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 12804, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 12805, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 12806, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 12807, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 12808, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 12809, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 12810, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 12811, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 12812, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 12813, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 12814, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 12815, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 12816, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 12817, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 12818, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 12819, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 12820, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 141\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 12821, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 12822, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 12823, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 12824, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 12825, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 12826, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 12827, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 12828, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 12829, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 12830, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 12831, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 12832, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 12833, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 12834, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 12835, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 12836, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 12837, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 12838, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 12839, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 12840, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 12841, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12842, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 12843, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 12844, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 12845, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 12846, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 12847, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 12848, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 12849, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 12850, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 12851, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 12852, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 12853, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 12854, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 12855, reward 614.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 12856, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 12857, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 12858, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 12859, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 12860, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 12861, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 12862, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 12863, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 12864, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 12865, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 12866, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 12867, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 12868, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 12869, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 12870, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 12871, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 12872, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 12873, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 12874, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 12875, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 12876, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 12877, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 12878, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 12879, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 12880, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 12881, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 12882, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 12883, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 12884, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 12885, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 12886, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 12887, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 12888, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 12889, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 12890, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 12891, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 12892, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 12893, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 12894, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 12895, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 12896, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 12897, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 12898, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 12899, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 12900, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 12901, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 12902, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 12903, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 12904, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 157\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 12905, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 15, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12906, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 12907, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 12908, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 123\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 12909, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 12910, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 12911, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 12912, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 12913, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 12914, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 12915, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 12916, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 12917, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 12918, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 12919, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 12920, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 12921, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 12922, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 12923, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 12924, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 12925, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 12926, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 12927, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 12928, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 12929, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 12930, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 12931, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 12932, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 12933, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 12934, reward 1491.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 12935, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 12936, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 12937, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 12938, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 12939, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 12940, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 12941, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 12942, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 122\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 12943, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 12944, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 12945, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 12946, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 12947, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 12948, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 12949, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 151\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 12950, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 12951, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 12952, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 12953, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 12954, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 12955, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 12956, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 12957, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 159\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 12958, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 12959, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 12960, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 12961, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 12962, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 12963, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 12964, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 12965, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 12966, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 12967, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 12968, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 12969, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [3, 16, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 12970, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 12971, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 12972, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 12973, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 12974, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 12975, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 12976, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 12977, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 12978, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 12979, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 12980, reward 669.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 12981, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 12982, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 12983, reward 503.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 12984, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 12985, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 157\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 12986, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 12987, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 12988, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 12989, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 12990, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 12991, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 12992, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 12993, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 12994, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 12995, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 12996, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 12997, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 155\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 12998, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 12999, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 13000, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 13001, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 13002, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 13003, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 13004, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 13005, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 13006, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 13007, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 13008, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 13009, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 13010, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 13011, reward 423.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 13012, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 13013, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 132\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 13014, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 13015, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 13016, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 149\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 13017, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 13018, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 13019, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 13020, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 13021, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 13022, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 13023, reward 528.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 13024, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 13025, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 13026, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 13027, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 13028, reward 559.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 13029, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 13030, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 13031, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 13032, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 13033, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [2, 13, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13034, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 140\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 13035, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 13036, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 13037, reward 1261.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 13038, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 13039, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 13040, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 13041, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 13042, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 13043, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 132\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 13044, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 13045, reward 638.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 13046, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 13047, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 13048, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 13049, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 13050, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 13051, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 13052, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 13053, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 13054, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 13055, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 13056, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 149\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 13057, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 13058, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 13059, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 13060, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 13061, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 13062, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 13063, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 13064, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 13065, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 13066, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 143\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 13067, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 13068, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 13069, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 13070, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 13071, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 13072, reward 673.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 13073, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 13074, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 13075, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 13076, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 13077, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 13078, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 13079, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 13080, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 13081, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 13082, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 13083, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 13084, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 13085, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 13086, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 13087, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 13088, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 13089, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 13090, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 13091, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 13092, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 13093, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 13094, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 13095, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 13096, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 13097, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 14, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13098, reward 552.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 13099, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 13100, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 13101, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 13102, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 13103, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 13104, reward 641.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 13105, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 13106, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 13107, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 13108, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 13109, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 138\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 13110, reward 1363.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 13111, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 13112, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 152\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 13113, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 13114, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 13115, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 13116, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 13117, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 13118, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 13119, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 13120, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 13121, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 13122, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 13123, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 13124, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 13125, reward 528.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 13126, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 13127, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 13128, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 13129, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 13130, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 13131, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 13132, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 13133, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 13134, reward 465.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 13135, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 13136, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 13137, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 13138, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 13139, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 13140, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 13141, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 13142, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 13143, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 13144, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 13145, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 13146, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 130\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 13147, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 13148, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 13149, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 13150, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 13151, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 13152, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 13153, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 13154, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 13155, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 13156, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 13157, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 13158, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 13159, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 13160, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 13161, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13162, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 13163, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 13164, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 13165, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 13166, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 13167, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 13168, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 13169, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 13170, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 13171, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 13172, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 13173, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 13174, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 13175, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 13176, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 13177, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 13178, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 13179, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 13180, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 13181, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 13182, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 13183, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 13184, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 122\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 13185, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 13186, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 13187, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 13188, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 13189, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 13190, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 155\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 13191, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 13192, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 13193, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 13194, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 13195, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 13196, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 13197, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 13198, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 13199, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 13200, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 125\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 13201, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 13202, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 13203, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 13204, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 13205, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 13206, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 13207, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 13208, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 13209, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 13210, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 13211, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 13212, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 13213, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 13214, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 13215, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 13216, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 13217, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 13218, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 13219, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 13220, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 13221, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 13222, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 13223, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 13224, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 13225, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 1, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13226, reward 381.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 13227, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 13228, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 13229, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 13230, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 13231, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 13232, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 13233, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 13234, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 13235, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 13236, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 13237, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 13238, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 13239, reward 519.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 13240, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 151\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 13241, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 13242, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 13243, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 13244, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 13245, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 13246, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 13247, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 13248, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 13249, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 13250, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 13251, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 160\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 13252, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 13253, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 13254, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 13255, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 13256, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 13257, reward 575.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 154\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 13258, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 13259, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 13260, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 13261, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 13262, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 13263, reward 528.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 13264, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 13265, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 13266, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 13267, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 13268, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 13269, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 13270, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 13271, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 13272, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 13273, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 13274, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 13275, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 13276, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 13277, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 13278, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 13279, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 13280, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 13281, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 13282, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 13283, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 13284, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 13285, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 13286, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 13287, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 13288, reward 1421.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 13289, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [0, 18, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13290, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 13291, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 13292, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 13293, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 13294, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 13295, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 13296, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 13297, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 13298, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 13299, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 13300, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 13301, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 13302, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 13303, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 13304, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 13305, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 13306, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 13307, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 13308, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 13309, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 13310, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 13311, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 13312, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 13313, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 13314, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 13315, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 13316, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 13317, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 13318, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 13319, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 13320, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 13321, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 13322, reward 602.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 13323, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 13324, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 13325, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 13326, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 13327, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 13328, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 149\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 13329, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 13330, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 13331, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 13332, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 13333, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 13334, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 144\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 13335, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 13336, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 13337, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 13338, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 13339, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 13340, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 13341, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 13342, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 13343, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 13344, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 13345, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 13346, reward 1286.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 13347, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 13348, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 13349, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 13350, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 13351, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 13352, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 13353, reward 1302.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [2, 23, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13354, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 13355, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 13356, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 13357, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 13358, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 13359, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 13360, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 13361, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 13362, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 152\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 13363, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 13364, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 13365, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 13366, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 13367, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 13368, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 13369, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 13370, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 13371, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 13372, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 13373, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 13374, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 13375, reward 1363.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 13376, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 13377, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 13378, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 13379, reward 1389.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 13380, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 13381, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 13382, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 13383, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 13384, reward 1298.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 13385, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 153\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 13386, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 13387, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 13388, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 13389, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 13390, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 13391, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 13392, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 13393, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 13394, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 13395, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 13396, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 13397, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 13398, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 13399, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 13400, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 13401, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 13402, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 13403, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 13404, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 13405, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 13406, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 13407, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 13408, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 13409, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 13410, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 13411, reward 1307.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 13412, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 13413, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 13414, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 13415, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 13416, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 13417, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 16, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13418, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 13419, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 13420, reward 635.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 13421, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 13422, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 13423, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 13424, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 13425, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 13426, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 13427, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 13428, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 13429, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 13430, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 13431, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 13432, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 13433, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 13434, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 13435, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 13436, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 13437, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 13438, reward 1346.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 13439, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 13440, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 13441, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 13442, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 13443, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 13444, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 13445, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 13446, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 13447, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 154\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 13448, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 13449, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 13450, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 156\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 13451, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 13452, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 13453, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 13454, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 13455, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 13456, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 13457, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 13458, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 13459, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 13460, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 13461, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 13462, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 13463, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 13464, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 13465, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 13466, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 13467, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 13468, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 13469, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 13470, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 13471, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 13472, reward 1391.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 13473, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 13474, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 13475, reward 1317.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 13476, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 13477, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 13478, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 152\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 13479, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 13480, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 13481, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13482, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 13483, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 13484, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 13485, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 13486, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 13487, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 13488, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 13489, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 13490, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 13491, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 13492, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 13493, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 13494, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 13495, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 13496, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 13497, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 163\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 13498, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 13499, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 13500, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 13501, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 13502, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 13503, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 13504, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 13505, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 13506, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 13507, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 13508, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 13509, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 13510, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 13511, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 13512, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 13513, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 13514, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 13515, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 13516, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 13517, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 13518, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 13519, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 13520, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 13521, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 13522, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 13523, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 13524, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 13525, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 13526, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 13527, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 13528, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 13529, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 13530, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 13531, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 143\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 13532, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 13533, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 13534, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 13535, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 114\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 13536, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 13537, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 13538, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 13539, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 13540, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 13541, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 13542, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 13543, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 13544, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 13545, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 15, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13546, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 13547, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 13548, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 13549, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 142\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 13550, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 13551, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 13552, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 13553, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 13554, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 13555, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 13556, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 13557, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 13558, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 13559, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 152\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 13560, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 13561, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 13562, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 13563, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 13564, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 13565, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 13566, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 13567, reward 1328.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 151\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 13568, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 158\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 13569, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 13570, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 13571, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 13572, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 13573, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 13574, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 13575, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 13576, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 13577, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 13578, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 13579, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 13580, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 13581, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 13582, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 13583, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 13584, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 13585, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 13586, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 13587, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 13588, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 13589, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 13590, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 13591, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 13592, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 13593, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 13594, reward 1324.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 13595, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 13596, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 13597, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 13598, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 13599, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 13600, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 13601, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 13602, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 13603, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 13604, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 158\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 13605, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 13606, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 13607, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 13608, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 13609, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 12, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13610, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 13611, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 13612, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 13613, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 13614, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 13615, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 13616, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 13617, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 13618, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 13619, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 13620, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 13621, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 13622, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 13623, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 13624, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 13625, reward 1308.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 13626, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 13627, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 13628, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 13629, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 13630, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 13631, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 13632, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 13633, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 13634, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 153\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 13635, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 13636, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 13637, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 13638, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 13639, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 13640, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 13641, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 13642, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 13643, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 13644, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 13645, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 13646, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 13647, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 13648, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 13649, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 13650, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 13651, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 13652, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 13653, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 13654, reward 1311.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 13655, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 13656, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 13657, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 13658, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 13659, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 13660, reward 1412.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 13661, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 13662, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 13663, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 13664, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 13665, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 13666, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 13667, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 13668, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 13669, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 13670, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 13671, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 13672, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 151\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 13673, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 2, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13674, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 13675, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 160\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 13676, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 13677, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 13678, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 13679, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 13680, reward 1317.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 13681, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 13682, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 13683, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 120\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 13684, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 13685, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 13686, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 13687, reward 543.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 13688, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 13689, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 13690, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 13691, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 13692, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 13693, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 13694, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 13695, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 13696, reward 1289.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 13697, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 13698, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 13699, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 13700, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 13701, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 13702, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 13703, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 13704, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 13705, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 13706, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 13707, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 13708, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 13709, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 13710, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 13711, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 13712, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 13713, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 13714, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 13715, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 13716, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 13717, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 13718, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 13719, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 13720, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 13721, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 13722, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 13723, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 13724, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 13725, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 13726, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 13727, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 13728, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 13729, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 155\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 13730, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 13731, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 13732, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 13733, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 13734, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 13735, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 13736, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 13737, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 12, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13738, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 13739, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 13740, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 13741, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 13742, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 13743, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 13744, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 13745, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 13746, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 13747, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 13748, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 13749, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 13750, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 157\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 13751, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 13752, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 155\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 13753, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 13754, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 13755, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 13756, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 13757, reward 431.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 13758, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 13759, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 13760, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 148\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 13761, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 13762, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 13763, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 13764, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 13765, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 13766, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 13767, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 13768, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 13769, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 13770, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 13771, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 13772, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 13773, reward 1239.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 13774, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 13775, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 13776, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 13777, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 13778, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 13779, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 13780, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 157\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 13781, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 13782, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 13783, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 154\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 13784, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 13785, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 13786, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 13787, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 13788, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 13789, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 13790, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 13791, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 13792, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 13793, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 159\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 13794, reward 1411.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 165\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 13795, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 13796, reward 631.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 13797, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 13798, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 13799, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 13800, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 13801, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 0, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13802, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 13803, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 13804, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 13805, reward 544.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 13806, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 13807, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 13808, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 13809, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 13810, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 157\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 13811, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 13812, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 13813, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 13814, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 13815, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 13816, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 13817, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 13818, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 13819, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 13820, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 13821, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 13822, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 13823, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 749.0, rides 144\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 13824, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 13825, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 13826, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 13827, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 13828, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 13829, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 13830, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 13831, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 13832, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 13833, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 13834, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 13835, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 13836, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 13837, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 13838, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 13839, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 13840, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 13841, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 13842, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 13843, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 13844, reward 555.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 13845, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 13846, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 13847, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 13848, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 13849, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 13850, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 13851, reward 1359.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 13852, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 138\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 13853, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 13854, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 13855, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 13856, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 13857, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 13858, reward 1387.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 13859, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 13860, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 13861, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 13862, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 13863, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 13864, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 13865, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 6, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13866, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 13867, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 162\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 13868, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 13869, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 13870, reward 1279.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 13871, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 13872, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 13873, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 13874, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 13875, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 13876, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 13877, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 13878, reward 1336.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 13879, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 13880, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 13881, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 13882, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 13883, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 13884, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 13885, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 118\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 13886, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 13887, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 13888, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 13889, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 13890, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 13891, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 13892, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 13893, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 121\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 13894, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 13895, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 13896, reward 1498.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 13897, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 13898, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 13899, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 13900, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 122\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 13901, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 13902, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 13903, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 13904, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 13905, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 13906, reward 551.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 13907, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 13908, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 13909, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 13910, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 13911, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 13912, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 13913, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 13914, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 13915, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 13916, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 13917, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 13918, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 13919, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 13920, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 13921, reward 1345.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 13922, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 13923, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 13924, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 13925, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 13926, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 13927, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 13928, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 13929, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13930, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 13931, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 13932, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 13933, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 13934, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 13935, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 13936, reward 604.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 13937, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 13938, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 13939, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 13940, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 13941, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 13942, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 13943, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 13944, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 13945, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 13946, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 13947, reward 1303.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 13948, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 13949, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 13950, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 13951, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 149\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 13952, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 13953, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 13954, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 13955, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 13956, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 13957, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 13958, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 152\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 13959, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 13960, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 13961, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 13962, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 13963, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 13964, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 13965, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 13966, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 13967, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 13968, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 13969, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 13970, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 13971, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 13972, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 13973, reward 656.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 13974, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 13975, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 13976, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 13977, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 13978, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 13979, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 13980, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 13981, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 13982, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 13983, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 13984, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 13985, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 13986, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 13987, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 118\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 13988, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 13989, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 115\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 13990, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 13991, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 13992, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 13993, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [4, 15, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 13994, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 13995, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 13996, reward 1241.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 13997, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 13998, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 13999, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 14000, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 14001, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 14002, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 14003, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 14004, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 14005, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 14006, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 14007, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 14008, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 14009, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 14010, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 14011, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 119\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 14012, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 14013, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 14014, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 14015, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 14016, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 14017, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 14018, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 14019, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 14020, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 14021, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 14022, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 14023, reward 1280.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 14024, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 14025, reward 1381.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 14026, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 14027, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 14028, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 14029, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 14030, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 14031, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 14032, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 14033, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 14034, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 14035, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 14036, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 14037, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 14038, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 14039, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 14040, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 14041, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 14042, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 14043, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 14044, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 14045, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 14046, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 14047, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 14048, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 14049, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 14050, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 14051, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 14052, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 112\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 14053, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 14054, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 14055, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 14056, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 14057, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [0, 14, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14058, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 14059, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 14060, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 158\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 14061, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 14062, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 14063, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 14064, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 14065, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 14066, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 14067, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 14068, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 14069, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 14070, reward 1400.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 14071, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 14072, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 14073, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 14074, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 14075, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 14076, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 153\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 14077, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 14078, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 154\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 14079, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 14080, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 14081, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 14082, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 14083, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 157\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 14084, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 14085, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 14086, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 14087, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 14088, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 14089, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 14090, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 14091, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 14092, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 14093, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 14094, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 14095, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 14096, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 14097, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 14098, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 14099, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 156\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 14100, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 14101, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 14102, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 14103, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 14104, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 14105, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 14106, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 14107, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 14108, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 14109, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 14110, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 14111, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 14112, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 14113, reward 490.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 14114, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 14115, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 14116, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 14117, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 14118, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 14119, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 14120, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 14121, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 7, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14122, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 14123, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 14124, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 14125, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 14126, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 14127, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 141\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 14128, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 14129, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 14130, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 14131, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 14132, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 14133, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 14134, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 14135, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 14136, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 14137, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 162\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 14138, reward 1362.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 14139, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 14140, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 14141, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 14142, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 157\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 14143, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 14144, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 14145, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 14146, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 14147, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 14148, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 14149, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 14150, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 14151, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 14152, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 14153, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 14154, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 14155, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 14156, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 14157, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 14158, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 14159, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 14160, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 14161, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 148\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 14162, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 14163, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 14164, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 14165, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 14166, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 14167, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 14168, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 14169, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 14170, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 14171, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 156\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 14172, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 14173, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 14174, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 14175, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 14176, reward 562.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 14177, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 14178, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 14179, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 14180, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 14181, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 14182, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 14183, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 14184, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 14185, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 11, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14186, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 14187, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 14188, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 14189, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 14190, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 14191, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 14192, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 14193, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 14194, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 14195, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 14196, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 14197, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 14198, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 14199, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 14200, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 14201, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 14202, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 14203, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 14204, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 14205, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 14206, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 14207, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 14208, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 14209, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 14210, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 129\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 14211, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 14212, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 14213, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 14214, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 14215, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 151\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 14216, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 14217, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 14218, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 14219, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 14220, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 14221, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 14222, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 14223, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 14224, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 14225, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 158\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 14226, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 14227, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 158\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 14228, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 14229, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 14230, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 14231, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 14232, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 14233, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 14234, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 14235, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 14236, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 14237, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 14238, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 14239, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 14240, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 14241, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 14242, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 14243, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 14244, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 14245, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 14246, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 14247, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 14248, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 14249, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [1, 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14250, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 14251, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 14252, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 14253, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 14254, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 14255, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 14256, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 14257, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 14258, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 14259, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 14260, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 148\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 14261, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 14262, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 14263, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 14264, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 14265, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 14266, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 14267, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 14268, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 158\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 14269, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 155\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 14270, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 14271, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 14272, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 14273, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 14274, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 14275, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 14276, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 14277, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 14278, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 14279, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 14280, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 144\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 14281, reward 1519.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 14282, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 14283, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 14284, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 14285, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 14286, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 14287, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 14288, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 14289, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 141\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 14290, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 14291, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 14292, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 14293, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 14294, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 14295, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 14296, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 14297, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 14298, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 14299, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 14300, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 14301, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 14302, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 154\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 14303, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 14304, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 158\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 14305, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 14306, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 14307, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 14308, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 14309, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 14310, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 14311, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 14312, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 14313, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 9, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14314, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 14315, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 14316, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 14317, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 14318, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 14319, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 14320, reward 1294.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 14321, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 14322, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 14323, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 14324, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 14325, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 14326, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 14327, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 14328, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 14329, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 14330, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 14331, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 14332, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 14333, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 14334, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 14335, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 14336, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 14337, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 14338, reward 578.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 14339, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 14340, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 14341, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 14342, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 14343, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 14344, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 14345, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 150\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 14346, reward 1304.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 14347, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 14348, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 14349, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 14350, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 14351, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 14352, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 14353, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 14354, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 14355, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 14356, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 14357, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 14358, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 14359, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 14360, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 14361, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 14362, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 14363, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 14364, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 14365, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 14366, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 14367, reward 559.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 14368, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 14369, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 14370, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 14371, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 14372, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 14373, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 14374, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 14375, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 14376, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 14377, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 116\n",
      "Initial State is  [2, 0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14378, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 14379, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 14380, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 14381, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 14382, reward 1300.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 14383, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 14384, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 14385, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 14386, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 14387, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 119\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 14388, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 14389, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 14390, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 14391, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 14392, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 14393, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 14394, reward 1334.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 14395, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 14396, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 14397, reward 550.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 14398, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 14399, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 14400, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 14401, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 14402, reward 1382.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 14403, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 14404, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 14405, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 14406, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 14407, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 14408, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 14409, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 14410, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 14411, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 14412, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 14413, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 14414, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 165\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 14415, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 14416, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 14417, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 14418, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 150\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 14419, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 14420, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 14421, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 14422, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 14423, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 14424, reward 550.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 14425, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 14426, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 14427, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 14428, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 14429, reward 1438.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 14430, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 14431, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 14432, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 14433, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 14434, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 14435, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 14436, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 14437, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 14438, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 14439, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 14440, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 14441, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 3, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14442, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 14443, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 14444, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 14445, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 14446, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 14447, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 14448, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 14449, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 14450, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 14451, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 14452, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 14453, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 14454, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 14455, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 14456, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 14457, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 14458, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 14459, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 14460, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 14461, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 14462, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 14463, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 14464, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 14465, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 14466, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 14467, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 14468, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 14469, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 14470, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 14471, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 115\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 14472, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 14473, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 14474, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 14475, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 14476, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 14477, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 14478, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 14479, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 14480, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 14481, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 14482, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 14483, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 14484, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 14485, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 14486, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 14487, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 14488, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 14489, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 14490, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 14491, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 14492, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 14493, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 14494, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 14495, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 14496, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 14497, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 14498, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 14499, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 14500, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 14501, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 14502, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 14503, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 14504, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 14505, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 12, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14506, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 14507, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 14508, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 14509, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 14510, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 14511, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 14512, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 14513, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 14514, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 14515, reward 1280.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 14516, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 14517, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 14518, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 14519, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 14520, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 14521, reward 1374.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 14522, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 14523, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 14524, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 151\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 14525, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 14526, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 14527, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 14528, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 14529, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 14530, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 14531, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 14532, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 14533, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 14534, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 14535, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 14536, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 14537, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 14538, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 14539, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 14540, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 14541, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 14542, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 14543, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 14544, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 14545, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 14546, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 14547, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 14548, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 14549, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 14550, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 14551, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 14552, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 14553, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 14554, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 14555, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 14556, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 746.0, rides 127\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 14557, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 14558, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 14559, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 14560, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 14561, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 14562, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 14563, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 14564, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 14565, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 14566, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 14567, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 14568, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 14569, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 15, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14570, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 14571, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 14572, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 151\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 14573, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 14574, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 14575, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 14576, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 14577, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 14578, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 14579, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 14580, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 14581, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 14582, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 14583, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 14584, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 14585, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 14586, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 14587, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 14588, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 14589, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 14590, reward 1471.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 14591, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 14592, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 14593, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 14594, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 14595, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 14596, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 14597, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 14598, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 14599, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 14600, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 14601, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 14602, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 14603, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 14604, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 14605, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 14606, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 14607, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 14608, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 14609, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 14610, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 158\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 14611, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 14612, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 14613, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 14614, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 14615, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 150\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 14616, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 14617, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 14618, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 14619, reward 1299.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 141\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 14620, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 14621, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 14622, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 14623, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 14624, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 14625, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 127\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 14626, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 128\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 14627, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 14628, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 14629, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 14630, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 14631, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 156\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 14632, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 14633, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14634, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 14635, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 14636, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 14637, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 14638, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 14639, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 14640, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 14641, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 114\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 14642, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 14643, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 14644, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 14645, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 116\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 14646, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 14647, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 14648, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 14649, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 14650, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 14651, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 14652, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 14653, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 14654, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 14655, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 14656, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 14657, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 14658, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 14659, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 14660, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 14661, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 14662, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 14663, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 14664, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 14665, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 14666, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 14667, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 14668, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 14669, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 14670, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 14671, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 14672, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 14673, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 14674, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 14675, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 14676, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 14677, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 14678, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 14679, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 14680, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 14681, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 14682, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 14683, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 14684, reward 601.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 14685, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 14686, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 14687, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 14688, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 14689, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 14690, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 14691, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 14692, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 14693, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 14694, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 14695, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 14696, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 14697, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [1, 8, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14698, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 14699, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 14700, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 14701, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 14702, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 14703, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 14704, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 14705, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 14706, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 14707, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 14708, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 14709, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 14710, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 14711, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 14712, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 14713, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 14714, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 14715, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 14716, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 14717, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 114\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 14718, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 14719, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 14720, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 14721, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 14722, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 14723, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 14724, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 14725, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 14726, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 14727, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 14728, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 14729, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 14730, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 116\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 14731, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 14732, reward 1256.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 14733, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 14734, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 14735, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 14736, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 14737, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 14738, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 14739, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 14740, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 14741, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 14742, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 14743, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 14744, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 14745, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 14746, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 14747, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 14748, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 14749, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 153\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 14750, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 14751, reward 593.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 14752, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 14753, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 14754, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 14755, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 154\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 14756, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 14757, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 14758, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 14759, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 14760, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 14761, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 6, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14762, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 14763, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 14764, reward 586.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 14765, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 14766, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 14767, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 14768, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 14769, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 14770, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 14771, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 112\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 14772, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 14773, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 14774, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 14775, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 14776, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 14777, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 14778, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 14779, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 14780, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 14781, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 14782, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 14783, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 14784, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 14785, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 14786, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 14787, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 14788, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 14789, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 14790, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 14791, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 14792, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 14793, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 14794, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 14795, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 14796, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 14797, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 14798, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 14799, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 14800, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 14801, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 14802, reward 1332.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 14803, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 14804, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 14805, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 14806, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 14807, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 14808, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 14809, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 134\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 14810, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 14811, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 14812, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 14813, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 14814, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 14815, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 14816, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 14817, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 14818, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 14819, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 14820, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 14821, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 14822, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 112\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 14823, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 14824, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 14825, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 19, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14826, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 14827, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 14828, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 14829, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 14830, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 14831, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 14832, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 14833, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 14834, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 14835, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 14836, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 14837, reward 1288.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 14838, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 14839, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 14840, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 14841, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 14842, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 14843, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 14844, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 14845, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 14846, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 14847, reward 1388.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 14848, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 14849, reward 1455.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 14850, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 153\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 14851, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 14852, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 14853, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 14854, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 14855, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 14856, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 14857, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 14858, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 157\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 14859, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 14860, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 14861, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 14862, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 14863, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 14864, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 14865, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 14866, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 14867, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 14868, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 14869, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 14870, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 14871, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 14872, reward 1384.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 14873, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 14874, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 14875, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 14876, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 14877, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 14878, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 14879, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 14880, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 14881, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 14882, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 14883, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 14884, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 14885, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 14886, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 14887, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 14888, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 14889, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [1, 0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14890, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 14891, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 14892, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 14893, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 14894, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 14895, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 14896, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 14897, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 14898, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 14899, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 14900, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 151\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 14901, reward 1342.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 14902, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 14903, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 14904, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 14905, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 14906, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 14907, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 14908, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 14909, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 14910, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 14911, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 14912, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 14913, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 14914, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 14915, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 14916, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 14917, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 14918, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 14919, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 14920, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 14921, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 14922, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 14923, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 14924, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 14925, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 14926, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 14927, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 14928, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 14929, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 14930, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 14931, reward 571.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 14932, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 14933, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 14934, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 14935, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 14936, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 14937, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 14938, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 14939, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 14940, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 14941, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 14942, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 14943, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 14944, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 14945, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 14946, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 14947, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 14948, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 14949, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 14950, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 144\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 14951, reward 1283.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 14952, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 14953, reward 1291.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 21, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 14954, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 14955, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 14956, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 14957, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 14958, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 14959, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 14960, reward 1355.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 14961, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 14962, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 14963, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 14964, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 14965, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 14966, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 14967, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 14968, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 14969, reward 1326.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 14970, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 14971, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 14972, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 14973, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 14974, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 14975, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 14976, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 14977, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 14978, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 14979, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 14980, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 14981, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 14982, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 14983, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 157\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 14984, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 14985, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 14986, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 14987, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 14988, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 14989, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 14990, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 14991, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 14992, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 14993, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 14994, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 14995, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 14996, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 14997, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 14998, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 14999, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 15000, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 15001, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 15002, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 15003, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 15004, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 15005, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 15006, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 15007, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 15008, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 15009, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 15010, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 15011, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 15012, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 15013, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 15014, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 15015, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 15016, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 15017, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [3, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15018, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 15019, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 15020, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 15021, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 15022, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 158\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 15023, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 15024, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 15025, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 15026, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 15027, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 15028, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 15029, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 15030, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 15031, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 15032, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 15033, reward 1317.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 15034, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 15035, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 15036, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 15037, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 15038, reward 1320.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 15039, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 160\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15040, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 15041, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 15042, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 15043, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 15044, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 15045, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 15046, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 15047, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 15048, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 15049, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 15050, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 15051, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 15052, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 15053, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 15054, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 15055, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 15056, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 15057, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 15058, reward 669.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 15059, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 15060, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 15061, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 15062, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 15063, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 15064, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 15065, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 15066, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 15067, reward 1482.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 15068, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 15069, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 15070, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 15071, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 15072, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 15073, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 15074, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 15075, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 15076, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 15077, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 15078, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 15079, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 15080, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 15081, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 6, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15082, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 15083, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 15084, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 15085, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 15086, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 15087, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 15088, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 15089, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 15090, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 15091, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 15092, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 15093, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 15094, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 15095, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 155\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 15096, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 15097, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 15098, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 15099, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 15100, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 15101, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 15102, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 15103, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 15104, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 15105, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 15106, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 15107, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 15108, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 15109, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 15110, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 149\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 15111, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 15112, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 15113, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 15114, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 15115, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 15116, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 15117, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 15118, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 15119, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 15120, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 15121, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 15122, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 15123, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 15124, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 15125, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 15126, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 15127, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 15128, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 15129, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 15130, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 15131, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 15132, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 151\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 15133, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 15134, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 15135, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 15136, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 15137, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 15138, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 15139, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 15140, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 15141, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 15142, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 15143, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 15144, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 15145, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15146, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 15147, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 15148, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 15149, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 15150, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 152\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 15151, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 15152, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 15153, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 15154, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 15155, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 15156, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 15157, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 15158, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 15159, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 15160, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 15161, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 15162, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 15163, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 15164, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 15165, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 15166, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 15167, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 15168, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 15169, reward 1353.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 15170, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 15171, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 15172, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 15173, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 15174, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 15175, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 15176, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 153\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 15177, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 15178, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 15179, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 15180, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 15181, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 15182, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 15183, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 15184, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 15185, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 15186, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 15187, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 15188, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 15189, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 15190, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 15191, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 15192, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 15193, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 15194, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 15195, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 15196, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 15197, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 15198, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 15199, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 15200, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 153\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 15201, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 15202, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 15203, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 15204, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 15205, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 15206, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 15207, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15208, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 15209, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [1, 20, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15210, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 154\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 15211, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 15212, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 15213, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 15214, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 15215, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 15216, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 149\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 15217, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 15218, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 15219, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 15220, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 15221, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 15222, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 144\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 15223, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 15224, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 15225, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 15226, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 15227, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 15228, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 15229, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 15230, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 15231, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 15232, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 15233, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 15234, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 15235, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 15236, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 15237, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 15238, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 15239, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 15240, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 15241, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 15242, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 15243, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 15244, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 15245, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 15246, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 15247, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 15248, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 15249, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 15250, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 15251, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 15252, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 15253, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 15254, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 15255, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 15256, reward 1282.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 15257, reward 1289.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 15258, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 15259, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 15260, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 15261, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 15262, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 15263, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 15264, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 15265, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 15266, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 15267, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 15268, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 15269, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 15270, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 15271, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 15272, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 15273, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [0, 23, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15274, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 15275, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 15276, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 15277, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 15278, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 15279, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 15280, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 15281, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 15282, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 15283, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 15284, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 15285, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 15286, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 15287, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 15288, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 15289, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 15290, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 15291, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 15292, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 15293, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 15294, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 15295, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 15296, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 15297, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 15298, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 15299, reward 655.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 15300, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 15301, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 15302, reward 1324.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 15303, reward 597.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 15304, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 15305, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 15306, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 15307, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 15308, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 15309, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 15310, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 15311, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 15312, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 15313, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 15314, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 15315, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 15316, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 15317, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 15318, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 15319, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 15320, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 15321, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 15322, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 15323, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 15324, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 15325, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 15326, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 15327, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 15328, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 15329, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 15330, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 15331, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 15332, reward 1360.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 15333, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 15334, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 15335, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 15336, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 15337, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 19, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15338, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 15339, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 15340, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 15341, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 15342, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 15343, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 15344, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 15345, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 15346, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 15347, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 15348, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 15349, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 15350, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 15351, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 15352, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 15353, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 117\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 15354, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 162\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 15355, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 15356, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 15357, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 15358, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 158\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 15359, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 15360, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 15361, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 15362, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 15363, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 15364, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 15365, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 15366, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 15367, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 15368, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 15369, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 15370, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 15371, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 15372, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 15373, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 15374, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 15375, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 161\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 15376, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 15377, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 15378, reward 613.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 15379, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 15380, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 15381, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 15382, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 15383, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 15384, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 15385, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 15386, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 15387, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 15388, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 15389, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 15390, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 15391, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 15392, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 156\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 15393, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 15394, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 15395, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 15396, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 15397, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 15398, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 15399, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 15400, reward 1394.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 15401, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [1, 16, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15402, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 15403, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 15404, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 143\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 15405, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 15406, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 15407, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 15408, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 15409, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 15410, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 15411, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 15412, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 15413, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 15414, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 15415, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 15416, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 15417, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 15418, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 15419, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 15420, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 15421, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 15422, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 15423, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 15424, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 15425, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 15426, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 15427, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 15428, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 15429, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 15430, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 15431, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 15432, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 15433, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 15434, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 15435, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 15436, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 15437, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 15438, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 15439, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 15440, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 15441, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 150\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 15442, reward 641.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 15443, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 15444, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 15445, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 15446, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 15447, reward 433.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 15448, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 15449, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 15450, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 144\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 15451, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 15452, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 15453, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 15454, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 15455, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 15456, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 15457, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 15458, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 15459, reward 1290.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 15460, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 15461, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 15462, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 15463, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 15464, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 15465, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [4, 13, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15466, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 15467, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 15468, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 15469, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 15470, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 15471, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 15472, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 15473, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 15474, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 15475, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 15476, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 15477, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 15478, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 15479, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 15480, reward 539.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 15481, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 143\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 15482, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 15483, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 15484, reward 621.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 15485, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 15486, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 15487, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 15488, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 15489, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 15490, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 15491, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 15492, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 15493, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 15494, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 15495, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 15496, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 15497, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 15498, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 15499, reward 531.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 15500, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 15501, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 15502, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 15503, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 15504, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 15505, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 15506, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 15507, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 15508, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 15509, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 15510, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 15511, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 15512, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 15513, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 15514, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 15515, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 15516, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 15517, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 15518, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 15519, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 15520, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 15521, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 15522, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 15523, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 15524, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 127\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 15525, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 15526, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 15527, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 15528, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 15529, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 10, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15530, reward 1410.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 157\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 15531, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 15532, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 15533, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 15534, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 15535, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 15536, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 15537, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 15538, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 15539, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 15540, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 15541, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 15542, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 15543, reward 528.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 15544, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 115\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 15545, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 153\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 15546, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 15547, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 138\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 15548, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 15549, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 15550, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 15551, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 15552, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 15553, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 15554, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 15555, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 15556, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 15557, reward 601.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 15558, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 15559, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 15560, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 15561, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 15562, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 155\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 15563, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 15564, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 15565, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 15566, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 15567, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 15568, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 15569, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 15570, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 15571, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 15572, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 15573, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 15574, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 15575, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 15576, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 15577, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 15578, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 15579, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 15580, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 15581, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 15582, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 15583, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 15584, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 15585, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 128\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 15586, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15587, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 15588, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 15589, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 15590, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 15591, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 15592, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 15593, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15594, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 15595, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 15596, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 15597, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 15598, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 15599, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 15600, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 15601, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 15602, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 15603, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 15604, reward 558.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 15605, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 15606, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 15607, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 15608, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 15609, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 15610, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 15611, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 15612, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 15613, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 15614, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 15615, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 15616, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 15617, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 15618, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 15619, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 15620, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 15621, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 15622, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 15623, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 15624, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15625, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 15626, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 15627, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 15628, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 15629, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 15630, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 15631, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 15632, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 15633, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 15634, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 15635, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 15636, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 15637, reward 1282.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 15638, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 15639, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 15640, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 15641, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 15642, reward 583.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 15643, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 15644, reward 602.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 15645, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 15646, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 15647, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 15648, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 15649, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 15650, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 15651, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 15652, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 15653, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 15654, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 15655, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15656, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 15657, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15658, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 15659, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 154\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 15660, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 15661, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 15662, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 15663, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 15664, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 15665, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 15666, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 15667, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 15668, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 15669, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 15670, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 15671, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 15672, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 15673, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 15674, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 15675, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 15676, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 15677, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 15678, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 15679, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 124\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 15680, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 15681, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 15682, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 15683, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 15684, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 15685, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 15686, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 15687, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 15688, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 15689, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 15690, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 15691, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 15692, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 15693, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 15694, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 15695, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 15696, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 15697, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 15698, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 15699, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 152\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 15700, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 15701, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 15702, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 15703, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 15704, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 15705, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 149\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 15706, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 15707, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 15708, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 15709, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 158\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 15710, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 15711, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 15712, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 15713, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 15714, reward 1394.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 15715, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 15716, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 15717, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 141\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 15718, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 15719, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 15720, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 15721, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 19, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15722, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 15723, reward 1385.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 15724, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 145\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 15725, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 15726, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 15727, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 15728, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 155\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 15729, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 15730, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 15731, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 15732, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 15733, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 15734, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 15735, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 15736, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 15737, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 15738, reward 1428.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 15739, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 15740, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 15741, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 15742, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 15743, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 15744, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 15745, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 15746, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 15747, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 15748, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 15749, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 15750, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 15751, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 15752, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 15753, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 15754, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 15755, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 15756, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 15757, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 15758, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 15759, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 15760, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 15761, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 15762, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 15763, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 114\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 15764, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 15765, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 15766, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 15767, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 15768, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 15769, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 15770, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 15771, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 15772, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 15773, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 15774, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 15775, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 15776, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 15777, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 15778, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 15779, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 15780, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 15781, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 15782, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 15783, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 15784, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 15785, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 18, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15786, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 15787, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 15788, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 15789, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 15790, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 15791, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 15792, reward 579.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 15793, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 15794, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 15795, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 15796, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 15797, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 15798, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 15799, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 15800, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 15801, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 15802, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 15803, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 15804, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 15805, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 15806, reward 1340.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 15807, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 15808, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 15809, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 127\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 15810, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 15811, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 15812, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 15813, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 15814, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 15815, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 155\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 15816, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 15817, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 15818, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 15819, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 15820, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 124\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 15821, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 15822, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 15823, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 15824, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 15825, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 15826, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 15827, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 15828, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 15829, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 15830, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 15831, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 15832, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 15833, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 15834, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 15835, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 15836, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 15837, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 15838, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 15839, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 15840, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 15841, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 15842, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 15843, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 15844, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 15845, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 15846, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 15847, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 15848, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 15849, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 23, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15850, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 15851, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 15852, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 15853, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 15854, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 15855, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 15856, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 15857, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 15858, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 15859, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 15860, reward 594.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 15861, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 15862, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 15863, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 15864, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 15865, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 15866, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 15867, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 15868, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 15869, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 15870, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 15871, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 15872, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 15873, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 15874, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 15875, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 15876, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 15877, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 15878, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 15879, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 15880, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 15881, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 15882, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 15883, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 15884, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 15885, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 15886, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 15887, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 15888, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 15889, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 15890, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 15891, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 15892, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 15893, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 15894, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 15895, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 133\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 15896, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 15897, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 15898, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 15899, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 15900, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 15901, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 15902, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 15903, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 15904, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 15905, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 15906, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 15907, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 15908, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 15909, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 15910, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 15911, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 15912, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 15913, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15914, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 15915, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 15916, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 15917, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 15918, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 15919, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 15920, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 15921, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 15922, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 15923, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 15924, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 15925, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 15926, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 15927, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 159\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 15928, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 15929, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 15930, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 15931, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 15932, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 15933, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 15934, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 15935, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 15936, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 15937, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 15938, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 15939, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 15940, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 15941, reward 567.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 15942, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 15943, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 15944, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 15945, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 15946, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 15947, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 15948, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 15949, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 15950, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 15951, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 15952, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 15953, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 15954, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 15955, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 15956, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 15957, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 15958, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 154\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 15959, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 15960, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 15961, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 15962, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 15963, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 15964, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 15965, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 15966, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 15967, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 15968, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 15969, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 15970, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 15971, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 15972, reward 1326.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 15973, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 15974, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 15975, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 15976, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 15977, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 7, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 15978, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 15979, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 15980, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 15981, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 15982, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 15983, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 15984, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 137\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 15985, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 15986, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 15987, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 15988, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 15989, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 15990, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 15991, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 15992, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 15993, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 15994, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 15995, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 15996, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 15997, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 15998, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 15999, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 143\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 16000, reward 1432.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 16001, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 16002, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 16003, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 16004, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 16005, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 16006, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 16007, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 16008, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 16009, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 118\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 16010, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 16011, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 16012, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 16013, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 16014, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 16015, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 16016, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 16017, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 16018, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 16019, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 16020, reward 587.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 16021, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 16022, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 16023, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 16024, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 16025, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 16026, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 16027, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 16028, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 16029, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 16030, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 16031, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 16032, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 16033, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 16034, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 16035, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 16036, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 16037, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 144\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 16038, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 16039, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 16040, reward 626.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 16041, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [1, 1, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16042, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 142\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 16043, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 16044, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 16045, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 16046, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 16047, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 16048, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 16049, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 16050, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 16051, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 16052, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 16053, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 16054, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 16055, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 16056, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 16057, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 152\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 16058, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 16059, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 16060, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 16061, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 16062, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 16063, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 16064, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 16065, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 16066, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 16067, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 16068, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 16069, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 16070, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 16071, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 16072, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 16073, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 16074, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 16075, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 16076, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 16077, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 16078, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 16079, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 16080, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 16081, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 16082, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 16083, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 16084, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 16085, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 16086, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 16087, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 16088, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 16089, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 16090, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 16091, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 16092, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 16093, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 16094, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 16095, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 16096, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 16097, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 16098, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 16099, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 16100, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 16101, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 16102, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 16103, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 16104, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 16105, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [2, 20, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16106, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 16107, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 16108, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 16109, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 16110, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 16111, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 16112, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 16113, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 16114, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 16115, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 16116, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 16117, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 154\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 16118, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 16119, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 16120, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 16121, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 16122, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 16123, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 16124, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 16125, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 16126, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 16127, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 16128, reward 600.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 16129, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 16130, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 16131, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 16132, reward 568.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 16133, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 16134, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 16135, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 16136, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 16137, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 16138, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 16139, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 16140, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 16141, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 16142, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 16143, reward 1332.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 16144, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 16145, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 16146, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 16147, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 16148, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 16149, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 16150, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 16151, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 16152, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 16153, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 16154, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 16155, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 16156, reward 512.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 16157, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 16158, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 16159, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 16160, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 16161, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 16162, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 16163, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 16164, reward 498.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 16165, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 16166, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 16167, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 16168, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 16169, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [4, 8, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16170, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 16171, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 16172, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 16173, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 16174, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 16175, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 16176, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 16177, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 16178, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 16179, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 16180, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 158\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 16181, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 16182, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 16183, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 16184, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 16185, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 158\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 16186, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 16187, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 16188, reward 1418.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 16189, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 153\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 16190, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 16191, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 16192, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 16193, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 16194, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 16195, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 16196, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 16197, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 16198, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 16199, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 16200, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 16201, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 16202, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 16203, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 16204, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 16205, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 16206, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 16207, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 16208, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 133\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 16209, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 16210, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 16211, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 16212, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 16213, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 16214, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 16215, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 16216, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 16217, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 16218, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 16219, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 16220, reward 620.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 16221, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 16222, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 16223, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 16224, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 16225, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 16226, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 16227, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 16228, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 16229, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 16230, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 16231, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 16232, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 16233, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 2, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16234, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 16235, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 16236, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 16237, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 16238, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 16239, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 16240, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 16241, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 16242, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 16243, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 16244, reward 1376.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 16245, reward 1353.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 16246, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 16247, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 16248, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 16249, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 16250, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 166\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 16251, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 16252, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 16253, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 16254, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 16255, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 154\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 16256, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 153\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 16257, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 16258, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 16259, reward 1551.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 16260, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 16261, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 16262, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 16263, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 16264, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 16265, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 16266, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 16267, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 16268, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 16269, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 16270, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 16271, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 16272, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 16273, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 16274, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 159\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 16275, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 16276, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 16277, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 16278, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 16279, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 16280, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 16281, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 16282, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 16283, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 16284, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 16285, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 16286, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 16287, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 16288, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 16289, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 154\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 16290, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 16291, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 16292, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 16293, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 16294, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 16295, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 16296, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 16297, reward 534.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [2, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16298, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 16299, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 16300, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 16301, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 16302, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 16303, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 16304, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 16305, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 16306, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 16307, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 16308, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 16309, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 16310, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 16311, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 16312, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 16313, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 16314, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 16315, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 16316, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 16317, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 16318, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 16319, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 16320, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 16321, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 16322, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 16323, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 16324, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 16325, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 16326, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 16327, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 16328, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 16329, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 130\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 16330, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 16331, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 16332, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 16333, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 16334, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 16335, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 16336, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 151\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 16337, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 16338, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 16339, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 16340, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 16341, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 16342, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 16343, reward 1389.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 16344, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 16345, reward 1368.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 16346, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 16347, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 16348, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 16349, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 16350, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 16351, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 16352, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 16353, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 16354, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 140\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 16355, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 16356, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 16357, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 16358, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 16359, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 16360, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 16361, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 5, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16362, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 16363, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 16364, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 16365, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 16366, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 16367, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 16368, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 16369, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 16370, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 16371, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 16372, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 16373, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 16374, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 16375, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 16376, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 16377, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 16378, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 16379, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 168\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 16380, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 16381, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 16382, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 16383, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 16384, reward 1288.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 16385, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 16386, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 16387, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 16388, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 16389, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 16390, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 16391, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 16392, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 16393, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 16394, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 16395, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 16396, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 16397, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 16398, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 16399, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 16400, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 16401, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 155\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 16402, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 16403, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 16404, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 16405, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 16406, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 16407, reward 1358.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 16408, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 16409, reward 581.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 16410, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 16411, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 16412, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 16413, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 16414, reward 1426.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 16415, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 16416, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 16417, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 16418, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 16419, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 16420, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 16421, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 16422, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 16423, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 16424, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 16425, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16426, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 16427, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 16428, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 16429, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 16430, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 159\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 16431, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 16432, reward 1228.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 16433, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 16434, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 16435, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 16436, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 16437, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 16438, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 16439, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 16440, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 16441, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 16442, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 16443, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 16444, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 16445, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 16446, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 16447, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 16448, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 16449, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 16450, reward 1250.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 16451, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 16452, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 16453, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 16454, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 16455, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 16456, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 16457, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 16458, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 16459, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 16460, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 16461, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 16462, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 16463, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 16464, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 16465, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 16466, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 16467, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 16468, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 16469, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 16470, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 16471, reward 587.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 16472, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 16473, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 16474, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 16475, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 16476, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 16477, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 137\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 16478, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 16479, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 135\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 16480, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 16481, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 16482, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 16483, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 16484, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 16485, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 16486, reward 1284.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 16487, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 16488, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 16489, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 11, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16490, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 16491, reward 522.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 16492, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 16493, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 16494, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 16495, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 16496, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 16497, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 16498, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 16499, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 16500, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 16501, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 16502, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 16503, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 132\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 16504, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 152\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 16505, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 16506, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 129\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 16507, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 16508, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 156\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 16509, reward 1471.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 155\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 16510, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 16511, reward 487.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 16512, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 16513, reward 1327.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 16514, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 16515, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 16516, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 16517, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 16518, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 16519, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 16520, reward 1519.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 16521, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 16522, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 16523, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 16524, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 16525, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 16526, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 16527, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 16528, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 16529, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 16530, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 16531, reward 1320.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 16532, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 16533, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 16534, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 16535, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 16536, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 16537, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 16538, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 16539, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 16540, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 16541, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 16542, reward 489.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 113\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 16543, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 16544, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 16545, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 16546, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 16547, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 16548, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 16549, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 16550, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 16551, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 16552, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 16553, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [0, 19, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16554, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 16555, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 16556, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 16557, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 16558, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 16559, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 16560, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 16561, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 16562, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 16563, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 16564, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 16565, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 16566, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 16567, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 16568, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 16569, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 16570, reward 1364.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 16571, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 16572, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 16573, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 16574, reward 585.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 16575, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 16576, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 16577, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 16578, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 16579, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 16580, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 137\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 16581, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 16582, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 16583, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 16584, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 16585, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 16586, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 16587, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 16588, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 16589, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 16590, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 16591, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 16592, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 16593, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 16594, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 16595, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 16596, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 16597, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 16598, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 16599, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 16600, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 16601, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 16602, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 153\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 16603, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 16604, reward 1301.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 16605, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 16606, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 16607, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 16608, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 16609, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 16610, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 16611, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 16612, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 16613, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 16614, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 16615, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 16616, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 16617, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 23, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16618, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 16619, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 16620, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 16621, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 16622, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 118\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 16623, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 16624, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 16625, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 16626, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 16627, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 16628, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 16629, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 16630, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 16631, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 16632, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 16633, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 16634, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 16635, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 16636, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 16637, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 16638, reward 556.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 16639, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 145\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 16640, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 16641, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 16642, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 16643, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 16644, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 16645, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 16646, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 16647, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 16648, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 16649, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 16650, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 16651, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 16652, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 16653, reward 1385.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 16654, reward 1352.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 16655, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 16656, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 16657, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 16658, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 16659, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 16660, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 16661, reward 1229.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 16662, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 16663, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 16664, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 153\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 16665, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 16666, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 16667, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 16668, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 16669, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 16670, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 16671, reward 1363.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 16672, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 16673, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 16674, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 16675, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 16676, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 16677, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 16678, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 16679, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 16680, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 16681, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16682, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 16683, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 16684, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 16685, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 16686, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 16687, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 16688, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 16689, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 16690, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 16691, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 16692, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 16693, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 16694, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 16695, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 16696, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 16697, reward 534.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 16698, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 16699, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 16700, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 16701, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 16702, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 16703, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 16704, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 16705, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 141\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 16706, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 16707, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 16708, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 16709, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 16710, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 16711, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 152\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 16712, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 16713, reward 581.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 16714, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 16715, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 16716, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 16717, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 16718, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 16719, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 16720, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 16721, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 16722, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 16723, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 16724, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 16725, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 156\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 16726, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 16727, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 16728, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 16729, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 16730, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 16731, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 16732, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 16733, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 16734, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 16735, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 16736, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 16737, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 16738, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 139\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 16739, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 16740, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 16741, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 16742, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 16743, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 16744, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 16745, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 23, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16746, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 16747, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 16748, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 16749, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 16750, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 16751, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 16752, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 16753, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 16754, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 16755, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 16756, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 16757, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 144\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 16758, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 16759, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 16760, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 16761, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 16762, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 16763, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 16764, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 16765, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 16766, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 16767, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 16768, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 16769, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 16770, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 16771, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 16772, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 16773, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 16774, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 16775, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 155\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 16776, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 16777, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 16778, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 16779, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 16780, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 16781, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 16782, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 16783, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 16784, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 16785, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 16786, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 16787, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 16788, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 16789, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 16790, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 16791, reward 1313.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 16792, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 16793, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 146\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 16794, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 16795, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 16796, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 16797, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 16798, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 16799, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 16800, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 16801, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 16802, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 16803, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 16804, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 16805, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 16806, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 16807, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 16808, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 16809, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 21, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16810, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 16811, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 16812, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 16813, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 16814, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 16815, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 16816, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 16817, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 16818, reward 1199.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 16819, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 16820, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 16821, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 16822, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 16823, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 16824, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 16825, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 16826, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 16827, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 16828, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 16829, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 16830, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 16831, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 16832, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 16833, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 16834, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 16835, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 16836, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 16837, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 16838, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 16839, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 16840, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 16841, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 16842, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 16843, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 16844, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 16845, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 16846, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 16847, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 16848, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 16849, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 16850, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 16851, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 16852, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 16853, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 16854, reward 616.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 16855, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 141\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 16856, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 16857, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 16858, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 16859, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 114\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 16860, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 16861, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 16862, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 164\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 16863, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 16864, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 16865, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 16866, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 16867, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 16868, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 16869, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 16870, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 16871, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 16872, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 16873, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 3, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16874, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 16875, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 156\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 16876, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 154\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 16877, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 16878, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 16879, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 16880, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 16881, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 16882, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 16883, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 16884, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 16885, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 16886, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 16887, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 16888, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 16889, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 16890, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 16891, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 16892, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 16893, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 16894, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 16895, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 16896, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 158\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 16897, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 16898, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 16899, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 16900, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 16901, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 16902, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 16903, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 16904, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 16905, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 16906, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 16907, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 16908, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 16909, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 16910, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 16911, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 16912, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 16913, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 16914, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 16915, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 16916, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 16917, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 16918, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 16919, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 16920, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 16921, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 16922, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 16923, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 16924, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 16925, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 16926, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 16927, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 16928, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 16929, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 16930, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 16931, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 16932, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 16933, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 16934, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 16935, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 161\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 16936, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 147\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 16937, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 15, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 16938, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 16939, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 16940, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 16941, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 16942, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 16943, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 16944, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 16945, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 16946, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 16947, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 16948, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 16949, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 16950, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 16951, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 16952, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 16953, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 16954, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 16955, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 16956, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 16957, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 16958, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 16959, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 16960, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 16961, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 16962, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 16963, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 16964, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 16965, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 16966, reward 1379.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 16967, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 16968, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 16969, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 16970, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 16971, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 16972, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 16973, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 16974, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 16975, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 16976, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 16977, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 16978, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 16979, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 16980, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 16981, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 16982, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 16983, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 16984, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 153\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 16985, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 16986, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 16987, reward 705.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 16988, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 16989, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 16990, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 16991, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 16992, reward 1337.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 16993, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 16994, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 16995, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 16996, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 16997, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 16998, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 16999, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 17000, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 17001, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 19, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17002, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 17003, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 17004, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 17005, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 17006, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 151\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 17007, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 17008, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 17009, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 17010, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 17011, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 17012, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 17013, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 17014, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 17015, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 17016, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 17017, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 17018, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 17019, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 17020, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 17021, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 17022, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 17023, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 17024, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 17025, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 17026, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 17027, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 17028, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 17029, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 17030, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 17031, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 17032, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 17033, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 17034, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 17035, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 17036, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 17037, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 17038, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 17039, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 17040, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 17041, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 17042, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 17043, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 17044, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 17045, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 154\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 17046, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 17047, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 17048, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 17049, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 17050, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 17051, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 17052, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 17053, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 17054, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 157\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 17055, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 17056, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 17057, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 17058, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 17059, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 17060, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 17061, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 152\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 17062, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 17063, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 17064, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 17065, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17066, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 17067, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 17068, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 17069, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 17070, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 17071, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 17072, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 17073, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 17074, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 17075, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 17076, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 17077, reward 1388.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 17078, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 17079, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 17080, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 17081, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 17082, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 17083, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 17084, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 17085, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 17086, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 127\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 17087, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 17088, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 17089, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 17090, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 17091, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 17092, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 17093, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 17094, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 17095, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 17096, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 17097, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 17098, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 17099, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 17100, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 17101, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 17102, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 162\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 17103, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 17104, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 17105, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 17106, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 17107, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 17108, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 17109, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 17110, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 17111, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 17112, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 17113, reward 593.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 17114, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 17115, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 17116, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 17117, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 17118, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 17119, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 17120, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 17121, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 17122, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 17123, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 17124, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 17125, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 17126, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 17127, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 17128, reward 616.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 17129, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 6, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17130, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 17131, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 17132, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 17133, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 17134, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 17135, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 17136, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 17137, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 17138, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 17139, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 17140, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 17141, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 17142, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 17143, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 117\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 17144, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 17145, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 119\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 17146, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 17147, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 17148, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 17149, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 17150, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 17151, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 17152, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 17153, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 17154, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 17155, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 17156, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 17157, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 17158, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 17159, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 17160, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 17161, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 17162, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 17163, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 748.0, rides 135\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 17164, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 17165, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 17166, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 17167, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 17168, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 17169, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 17170, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 17171, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 17172, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 17173, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 17174, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 17175, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 17176, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 17177, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 17178, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 17179, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 17180, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 17181, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 17182, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 17183, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 17184, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 17185, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 17186, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 17187, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 17188, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 17189, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 17190, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 17191, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 17192, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 17193, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 14, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17194, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 17195, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 17196, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 17197, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 17198, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 17199, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 17200, reward 601.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 17201, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 17202, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 17203, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 17204, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 17205, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 17206, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 17207, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 17208, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 17209, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 17210, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 17211, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 17212, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 17213, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 17214, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 17215, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 17216, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 17217, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 17218, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 17219, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 17220, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 17221, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 17222, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 17223, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 17224, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 17225, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 17226, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 17227, reward 635.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 17228, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 17229, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 17230, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 17231, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 17232, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 17233, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 17234, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 17235, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 17236, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 17237, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 154\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 17238, reward 656.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 17239, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 17240, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 17241, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 17242, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 17243, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 17244, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 17245, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 17246, reward 563.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 17247, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 17248, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 17249, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 17250, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 17251, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 17252, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 17253, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 17254, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 17255, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 17256, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 17257, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17258, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 17259, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 17260, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 17261, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 17262, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 17263, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 17264, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 17265, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 17266, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 17267, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 17268, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 17269, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 17270, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 17271, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 17272, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 17273, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 17274, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 17275, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 17276, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 17277, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 17278, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 17279, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 17280, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 17281, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 17282, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 17283, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 17284, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 17285, reward 487.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 17286, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 17287, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 17288, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 17289, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 17290, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 17291, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 116\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 17292, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 17293, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 17294, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 17295, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 17296, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 17297, reward 1320.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 17298, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 17299, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 17300, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 17301, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 17302, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 17303, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 17304, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 17305, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 17306, reward 534.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 153\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 17307, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 17308, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 17309, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 17310, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 153\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 17311, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 17312, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 115\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 17313, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 17314, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 17315, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 17316, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 17317, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 17318, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 17319, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 17320, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 17321, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [4, 16, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17322, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 17323, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 17324, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 17325, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 17326, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 17327, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 17328, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 17329, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 17330, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 17331, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 119\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 17332, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 17333, reward 592.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 17334, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 17335, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 17336, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 17337, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 17338, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 17339, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 17340, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 17341, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 17342, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 17343, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 17344, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 17345, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 17346, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 17347, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 17348, reward 438.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 17349, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 17350, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 17351, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 17352, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 17353, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 17354, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 17355, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 17356, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 17357, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 17358, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 17359, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 17360, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 17361, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 17362, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 17363, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 17364, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 17365, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 17366, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 17367, reward 425.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 17368, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 17369, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 17370, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 17371, reward 1241.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 17372, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 17373, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 17374, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 17375, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 17376, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 17377, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 17378, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 137\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 17379, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 17380, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 17381, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 17382, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 17383, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 17384, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 17385, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 13, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17386, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 17387, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 17388, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 17389, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 17390, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 17391, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 17392, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 17393, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 17394, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 17395, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 17396, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 17397, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 17398, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 17399, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 17400, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 17401, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 17402, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 17403, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 134\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 17404, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 17405, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 17406, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 17407, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 17408, reward 629.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 17409, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 17410, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 17411, reward 535.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 17412, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 17413, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 129\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 17414, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 17415, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 17416, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 17417, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 17418, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 17419, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 17420, reward 581.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 17421, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 17422, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 17423, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 17424, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 17425, reward 592.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 17426, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 17427, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 17428, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 17429, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 17430, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 17431, reward 570.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 17432, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 17433, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 17434, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 17435, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 17436, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 17437, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 17438, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 17439, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 17440, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 17441, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 17442, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 17443, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 17444, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 17445, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 17446, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 17447, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 17448, reward 395.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 17449, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 7, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17450, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 17451, reward 525.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 17452, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 17453, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 17454, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 17455, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 17456, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 17457, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 17458, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 132\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 17459, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 17460, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 17461, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 17462, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 17463, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 17464, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 17465, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 17466, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 17467, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 17468, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 17469, reward 591.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 17470, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17471, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 17472, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 17473, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 17474, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 17475, reward 509.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 17476, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 17477, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 17478, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 17479, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 17480, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 17481, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 17482, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 17483, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 17484, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 17485, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 130\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 17486, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 17487, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 17488, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 144\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 17489, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 17490, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 17491, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 17492, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 119\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 17493, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17494, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 17495, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 17496, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 17497, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 17498, reward 650.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 17499, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 138\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 17500, reward 543.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 17501, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 17502, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 17503, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 17504, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 17505, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 17506, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 17507, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 17508, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 17509, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 17510, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 17511, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 17512, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 17513, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 113\n",
      "Initial State is  [3, 18, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17514, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 17515, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 17516, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 17517, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 17518, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 17519, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 17520, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 17521, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 17522, reward 642.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 17523, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 17524, reward 598.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 17525, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 17526, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 17527, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 17528, reward 547.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 17529, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 17530, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 17531, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 17532, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 17533, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 17534, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 17535, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 17536, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 17537, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 17538, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 17539, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 17540, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 17541, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 126\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 17542, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 17543, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 17544, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 17545, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 17546, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 155\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 17547, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 17548, reward 515.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 17549, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 17550, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 17551, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 17552, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 17553, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 17554, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 17555, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 17556, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 17557, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 17558, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 17559, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 17560, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 17561, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 17562, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 17563, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 17564, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 17565, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 17566, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 17567, reward 377.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 17568, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 17569, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 17570, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 17571, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 17572, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 17573, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 17574, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 17575, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 17576, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 17577, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [4, 23, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17578, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 17579, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 17580, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 17581, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 138\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 17582, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 17583, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17584, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 17585, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 17586, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 17587, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 17588, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 17589, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 17590, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 17591, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 17592, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 17593, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 17594, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 17595, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 17596, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 17597, reward 464.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 17598, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 17599, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 17600, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 17601, reward 573.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 17602, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 17603, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 17604, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 17605, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 118\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 17606, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 17607, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 17608, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 17609, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 17610, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 17611, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 17612, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 17613, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 17614, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 17615, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 17616, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 116\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 17617, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 17618, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 17619, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 17620, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 17621, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 17622, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 17623, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 17624, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 17625, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 17626, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 17627, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 17628, reward 499.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 17629, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 17630, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 17631, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 17632, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 17633, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 17634, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 138\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 17635, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 17636, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 17637, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 17638, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 125\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 17639, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 17640, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 17641, reward 524.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 12, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17642, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 17643, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 17644, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 17645, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 17646, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 17647, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 17648, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 110\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 17649, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 17650, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 17651, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 17652, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 17653, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 17654, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 17655, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 17656, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 17657, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 17658, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 17659, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 17660, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 17661, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 17662, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 17663, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 17664, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 17665, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 17666, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 131\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 17667, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 17668, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 17669, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 17670, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 17671, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 17672, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 17673, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 17674, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 17675, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 17676, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 17677, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 17678, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 17679, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 17680, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 17681, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 17682, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 17683, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 17684, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 136\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 17685, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 17686, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 17687, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 17688, reward 599.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 17689, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 17690, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 120\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 17691, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 116\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 17692, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 17693, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 17694, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 17695, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 17696, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 17697, reward 1308.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 17698, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 17699, reward 570.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 17700, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 17701, reward 487.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 17702, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 17703, reward 1379.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 17704, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 17705, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 1, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17706, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 17707, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 17708, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 17709, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 17710, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 17711, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 17712, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 17713, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 17714, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 17715, reward 555.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 17716, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 131\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 17717, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 17718, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 17719, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 17720, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 17721, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 17722, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 17723, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 17724, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 17725, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 17726, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 17727, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 17728, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 17729, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 17730, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 17731, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 17732, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 17733, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 17734, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 17735, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 17736, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 17737, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 17738, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 17739, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 17740, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 17741, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 17742, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 17743, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 17744, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 151\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 17745, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 17746, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 17747, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 17748, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 17749, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 17750, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 17751, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 17752, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 17753, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 17754, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 17755, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 17756, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 17757, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 17758, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 17759, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 17760, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 17761, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 17762, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 17763, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 17764, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 17765, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 17766, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 17767, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 17768, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 17769, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 19, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17770, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 17771, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 17772, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 17773, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 17774, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 17775, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 17776, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 17777, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 17778, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 17779, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 17780, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 17781, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 17782, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 17783, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 17784, reward 477.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 17785, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 17786, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 17787, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 17788, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 119\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 17789, reward 552.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 118\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 17790, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 17791, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 17792, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 17793, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 17794, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 17795, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 17796, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 17797, reward 473.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 17798, reward 574.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 17799, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 17800, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 17801, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 17802, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 17803, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 17804, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 17805, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 17806, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 17807, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 17808, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 17809, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 17810, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 17811, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 17812, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 17813, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 17814, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 17815, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 17816, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 17817, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 17818, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 17819, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 17820, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 17821, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 17822, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 17823, reward 1261.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17824, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 17825, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 17826, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 17827, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 17828, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 17829, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 17830, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 17831, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 17832, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 131\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 17833, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 8, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17834, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 123\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 17835, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 17836, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 17837, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 17838, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 17839, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 17840, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 17841, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 17842, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 17843, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 17844, reward 526.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 17845, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 17846, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 17847, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 17848, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 17849, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 17850, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 17851, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 17852, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 17853, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 17854, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 17855, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 17856, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 17857, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 17858, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 17859, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 17860, reward 623.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 17861, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 17862, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 17863, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 17864, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 17865, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 17866, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 17867, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 17868, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 17869, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 17870, reward 511.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 17871, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 17872, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 17873, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 17874, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 17875, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 17876, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 17877, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 17878, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 17879, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 17880, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 17881, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 17882, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 17883, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 17884, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 122\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 17885, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 17886, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 17887, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 17888, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 17889, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 17890, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 17891, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 17892, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 17893, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 17894, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 17895, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 17896, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 17897, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 11, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17898, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 123\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 17899, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 17900, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 17901, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 17902, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 17903, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 17904, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 17905, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 17906, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 17907, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 17908, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 17909, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17910, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 17911, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 17912, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 17913, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 17914, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 151\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 17915, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 17916, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 17917, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 17918, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 17919, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 17920, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 17921, reward 564.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 17922, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 17923, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 17924, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 17925, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 17926, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 17927, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 17928, reward 382.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 17929, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 17930, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 17931, reward 569.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 17932, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 17933, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 17934, reward 437.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 17935, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 17936, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 17937, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 140\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 17938, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 17939, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 17940, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 17941, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 17942, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 17943, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 17944, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 17945, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 17946, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 17947, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 17948, reward 566.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 17949, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 17950, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 17951, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 17952, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 17953, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 17954, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 17955, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 17956, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 17957, reward 1194.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 144\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 17958, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 17959, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 17960, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 17961, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 5, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 17962, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 17963, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 17964, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 17965, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 17966, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 17967, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 17968, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 17969, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 17970, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 17971, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 17972, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 17973, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 17974, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 17975, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 17976, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 17977, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 17978, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 17979, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 17980, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 17981, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 17982, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 17983, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 17984, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 17985, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 17986, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 17987, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 17988, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 17989, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 17990, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 17991, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 17992, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 149\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 17993, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 17994, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 17995, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 17996, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 17997, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 17998, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 17999, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 18000, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 142\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 18001, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 18002, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 18003, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 18004, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 18005, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 139\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 18006, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18007, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 18008, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 18009, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 18010, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 18011, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 18012, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 18013, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 18014, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 18015, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 152\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 18016, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 18017, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 18018, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 18019, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 18020, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 18021, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 18022, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 18023, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 18024, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 18025, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 5, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18026, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 18027, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18028, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 18029, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 18030, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 18031, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 18032, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 18033, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 18034, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 18035, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 18036, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 18037, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 18038, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 18039, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 18040, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 18041, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 18042, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 18043, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 18044, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18045, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 18046, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 18047, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 18048, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18049, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 158\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 18050, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 18051, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 18052, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 18053, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 18054, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 18055, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 18056, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 18057, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 18058, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 18059, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 18060, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 18061, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 18062, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 18063, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 18064, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 18065, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 18066, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 18067, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 18068, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 18069, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 18070, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 18071, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 18072, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 18073, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 18074, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 18075, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 18076, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 18077, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 151\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 18078, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 18079, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 18080, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 18081, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 18082, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 18083, reward 597.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 18084, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 18085, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 18086, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 18087, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 18088, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 159\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 18089, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 11, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18090, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 18091, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 18092, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 18093, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 18094, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 18095, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 18096, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 18097, reward 1299.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 18098, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 18099, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 141\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 18100, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 18101, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 18102, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 18103, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 18104, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 18105, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 18106, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 18107, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 18108, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 18109, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 18110, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 18111, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 18112, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 18113, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 18114, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 18115, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 18116, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 18117, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 18118, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 18119, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 18120, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 18121, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 18122, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 18123, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 18124, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 18125, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 18126, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 18127, reward 600.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 18128, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 18129, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 18130, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 18131, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 18132, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 157\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 18133, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 18134, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 18135, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 18136, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 18137, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 152\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 18138, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 18139, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 18140, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 18141, reward 682.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 18142, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 18143, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 18144, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 18145, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 153\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 18146, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 18147, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 18148, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 18149, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 18150, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 18151, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 18152, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 18153, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 5, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18154, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 18155, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 18156, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 18157, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 18158, reward 560.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 18159, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 18160, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 18161, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 18162, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 18163, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 18164, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18165, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 18166, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 18167, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 18168, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 18169, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 18170, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 18171, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 18172, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 18173, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 18174, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 18175, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 18176, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 18177, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 18178, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 18179, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 18180, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 115\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 18181, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 18182, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 18183, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 118\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 18184, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 18185, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 18186, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 134\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 18187, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 18188, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 18189, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 126\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 18190, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 18191, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 18192, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 18193, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 18194, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 18195, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 18196, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 18197, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 18198, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 18199, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 18200, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 18201, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 18202, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 18203, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 18204, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 157\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 18205, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 18206, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 18207, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 18208, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 18209, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 18210, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 18211, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 18212, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 18213, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 18214, reward 544.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 18215, reward 541.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 18216, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 157\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 18217, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 162\n",
      "Initial State is  [3, 5, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18218, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 18219, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 154\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 18220, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18221, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 18222, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 18223, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 18224, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 18225, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 18226, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 18227, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 150\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 18228, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 18229, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 18230, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 18231, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 18232, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 18233, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 18234, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 18235, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 18236, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 18237, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 18238, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 18239, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 18240, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 18241, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 18242, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 18243, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 143\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 18244, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 148\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 18245, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 18246, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 18247, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 18248, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 18249, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 18250, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 18251, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 18252, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 18253, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 18254, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 18255, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 18256, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 18257, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 18258, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 18259, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 18260, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 18261, reward 569.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 18262, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 18263, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 18264, reward 459.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 18265, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 18266, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 18267, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 18268, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 18269, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 18270, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 18271, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 18272, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 18273, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 18274, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 18275, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 18276, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 18277, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 18278, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 18279, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 18280, reward 590.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 18281, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18282, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 18283, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 18284, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 18285, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 18286, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 18287, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 18288, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 18289, reward 1288.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 18290, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 18291, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 18292, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 154\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 18293, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 18294, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 18295, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 18296, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 18297, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 18298, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 18299, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 18300, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 154\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 18301, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 18302, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 18303, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 159\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 18304, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 18305, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 18306, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 18307, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 18308, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 18309, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 18310, reward 1321.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 18311, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18312, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 18313, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18314, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 141\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 18315, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 18316, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 18317, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 18318, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18319, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 18320, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 18321, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 18322, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 18323, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 18324, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 158\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 18325, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 18326, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 18327, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 18328, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 18329, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 18330, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 18331, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 18332, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 18333, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 18334, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 18335, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 18336, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 18337, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 18338, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 18339, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 18340, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 18341, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 18342, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 18343, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 18344, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 18345, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [2, 13, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18346, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 18347, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 18348, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 18349, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 18350, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 18351, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 18352, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 18353, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 18354, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 129\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 18355, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 18356, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 18357, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 18358, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 18359, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 18360, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 18361, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 18362, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 18363, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 18364, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 18365, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 18366, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 18367, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 18368, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 18369, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 18370, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 18371, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 18372, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 18373, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 18374, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 125\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 18375, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 18376, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 18377, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 129\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 18378, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 18379, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 18380, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 18381, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 18382, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 18383, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 18384, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 18385, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 18386, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 18387, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 18388, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 18389, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 18390, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 18391, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 125\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 18392, reward 1289.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 18393, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 18394, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 18395, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 18396, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 18397, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 18398, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 18399, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 18400, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 18401, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 18402, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 18403, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 18404, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 124\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 18405, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 18406, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 18407, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 18408, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 18409, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 12, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18410, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 18411, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 18412, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 18413, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 119\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 18414, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 18415, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 18416, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 18417, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 129\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 18418, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 18419, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18420, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 18421, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 18422, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 18423, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 18424, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 18425, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 18426, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 18427, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 18428, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 138\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 18429, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 18430, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 746.0, rides 128\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 18431, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 18432, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 18433, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 18434, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 18435, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 18436, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 18437, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 18438, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 18439, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 18440, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 18441, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18442, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 18443, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 18444, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 18445, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 18446, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 18447, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 18448, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 18449, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 18450, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 18451, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 18452, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 18453, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 18454, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 18455, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 18456, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 18457, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 18458, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 18459, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 18460, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 18461, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 18462, reward 1299.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 18463, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 150\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 18464, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 18465, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 18466, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 18467, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 18468, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 18469, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 18470, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 18471, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 119\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 18472, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 18473, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [1, 0, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18474, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 18475, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 18476, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 18477, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 18478, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 18479, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 18480, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 18481, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 18482, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 18483, reward 660.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 18484, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 18485, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 18486, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 18487, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 18488, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 18489, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 18490, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 18491, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 18492, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 18493, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 18494, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 18495, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 18496, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 18497, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 18498, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 18499, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 18500, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 18501, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 18502, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 18503, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 18504, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 132\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 18505, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 126\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 18506, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 18507, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 18508, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 18509, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 18510, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 18511, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 18512, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 18513, reward 598.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 18514, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 18515, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 18516, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 18517, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 18518, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 18519, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 18520, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 18521, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 18522, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 18523, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 18524, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 18525, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 18526, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 18527, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18528, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 18529, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 18530, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 18531, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 18532, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 18533, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 18534, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 18535, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 18536, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 18537, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [4, 10, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18538, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 157\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 18539, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 18540, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18541, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 18542, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 18543, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 18544, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 18545, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 18546, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 18547, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 18548, reward 543.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 18549, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 18550, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 18551, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 143\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 18552, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 18553, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 18554, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 18555, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 18556, reward 604.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 18557, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 18558, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 18559, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 18560, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 18561, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 18562, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 18563, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 18564, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 18565, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 18566, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 18567, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 18568, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 18569, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 18570, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 18571, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 18572, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 18573, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 140\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 18574, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 18575, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 18576, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 18577, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 18578, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 18579, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 18580, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 18581, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 18582, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 18583, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 18584, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 18585, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 18586, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 18587, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 18588, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 18589, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 18590, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 18591, reward 695.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 18592, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 18593, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 18594, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 18595, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 18596, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 18597, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 18598, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 18599, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 18600, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 18601, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 18, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18602, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 18603, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 18604, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 18605, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 120\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 18606, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 18607, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 18608, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 18609, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 18610, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 18611, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 18612, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 18613, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 18614, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 18615, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 18616, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 18617, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 18618, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 18619, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 18620, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 18621, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 18622, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 18623, reward 1350.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 18624, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 124\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 18625, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 18626, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 18627, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 18628, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 18629, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 18630, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 18631, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 18632, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 18633, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 18634, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 18635, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 18636, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 18637, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 18638, reward 583.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 18639, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 18640, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 18641, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 18642, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 18643, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 18644, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 18645, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 18646, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 18647, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 18648, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 18649, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 18650, reward 1218.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 18651, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 18652, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 18653, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 18654, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 18655, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 18656, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 18657, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 18658, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 18659, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 18660, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 18661, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 18662, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 18663, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 18664, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 18665, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 10, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18666, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 18667, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 18668, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 156\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 18669, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 156\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 18670, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 18671, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 18672, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 18673, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 18674, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 18675, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 18676, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 18677, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 18678, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 18679, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 18680, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 156\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 18681, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 18682, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 18683, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 18684, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 18685, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 18686, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 137\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 18687, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 18688, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 18689, reward 711.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 18690, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18691, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 18692, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 18693, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 18694, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 18695, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 18696, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 18697, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 18698, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 18699, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 18700, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 18701, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 18702, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 18703, reward 613.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 18704, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 18705, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 18706, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 18707, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 18708, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 18709, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 18710, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 18711, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 18712, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 18713, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 18714, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 18715, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 18716, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 18717, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 18718, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 139\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 18719, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 18720, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 18721, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 18722, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 18723, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 18724, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 18725, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 18726, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 18727, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 18728, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 18729, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 2, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18730, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 18731, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 18732, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 18733, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 18734, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 18735, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 18736, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 18737, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 18738, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 18739, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 18740, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 18741, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 18742, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 18743, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 18744, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 18745, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 18746, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 18747, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 18748, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 18749, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 146\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 18750, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 18751, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 18752, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 18753, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 18754, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 18755, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 18756, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 18757, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 18758, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 18759, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 18760, reward 1279.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 18761, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 18762, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 18763, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18764, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 140\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 18765, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 18766, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 18767, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 18768, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 18769, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 18770, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 18771, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 18772, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 128\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 18773, reward 1391.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 18774, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 18775, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 18776, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 18777, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 18778, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 18779, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 18780, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 18781, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 18782, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 18783, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 18784, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 18785, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 18786, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 18787, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 18788, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 18789, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 18790, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 18791, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 18792, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 18793, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [0, 17, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18794, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 18795, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 18796, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 18797, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 18798, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 18799, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 18800, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 18801, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 18802, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 18803, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 18804, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 18805, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 18806, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 18807, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 18808, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 18809, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 18810, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 18811, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 18812, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 18813, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 18814, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 18815, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 18816, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 18817, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 141\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 18818, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 18819, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 18820, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 18821, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 18822, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 18823, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 18824, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 18825, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 18826, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 18827, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 18828, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 144\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 18829, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 18830, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 18831, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 137\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 18832, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 18833, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 18834, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 18835, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 18836, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 18837, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 18838, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 18839, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 18840, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 18841, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 18842, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 18843, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 18844, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 18845, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 18846, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 18847, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 18848, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 18849, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 18850, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 18851, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 18852, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 18853, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 18854, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 147\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 18855, reward 1263.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 18856, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 18857, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 20, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18858, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 18859, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 18860, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 18861, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 18862, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 18863, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 18864, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 18865, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 18866, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 18867, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 18868, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 18869, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 18870, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 18871, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 18872, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 18873, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 18874, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 18875, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 18876, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 18877, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 18878, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 18879, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 18880, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 18881, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 18882, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 18883, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 18884, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 18885, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 18886, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 18887, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 18888, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 18889, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 18890, reward 1352.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 18891, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 18892, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 18893, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 18894, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 18895, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 18896, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 18897, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 18898, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 18899, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 18900, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 18901, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 116\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 18902, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 18903, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 18904, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 18905, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 18906, reward 369.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 18907, reward 543.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 18908, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 18909, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 18910, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 18911, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 18912, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 18913, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 18914, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 18915, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 18916, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 18917, reward 1303.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 18918, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 124\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 18919, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 18920, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 18921, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 22, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18922, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 18923, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 18924, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 18925, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 18926, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 18927, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 18928, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 18929, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 18930, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 18931, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 18932, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 18933, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 18934, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 18935, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 18936, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 18937, reward 492.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 18938, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 18939, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 18940, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 18941, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 18942, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 18943, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 18944, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 18945, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 18946, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 18947, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 18948, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 18949, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 18950, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 18951, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 18952, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 18953, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 18954, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 18955, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 18956, reward 559.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 18957, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 18958, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 18959, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 18960, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 18961, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 18962, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 18963, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 159\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 18964, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 18965, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 18966, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 18967, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 18968, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 18969, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 18970, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 18971, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 18972, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 18973, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 18974, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 18975, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 153\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 18976, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 18977, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 18978, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 18979, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 18980, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 18981, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 18982, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 18983, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 18984, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 18985, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 17, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 18986, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 18987, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 162\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 18988, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 18989, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 18990, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 18991, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 18992, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 18993, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 18994, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 18995, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 18996, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 18997, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 18998, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 18999, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 19000, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 19001, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 19002, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 19003, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 19004, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 19005, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 19006, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 19007, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 19008, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 19009, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 19010, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 19011, reward 662.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 19012, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 19013, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 19014, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 19015, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 19016, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 19017, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 19018, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 19019, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 19020, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 19021, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 19022, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 19023, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 19024, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 19025, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 19026, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 152\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 19027, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 19028, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 19029, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 19030, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 19031, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 19032, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 19033, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 19034, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 19035, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 19036, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 19037, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 19038, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 19039, reward 1339.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 156\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 19040, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 19041, reward 621.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 19042, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 19043, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 19044, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 19045, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 19046, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 19047, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 19048, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 19049, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 12, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19050, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 19051, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 19052, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 19053, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 19054, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 19055, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 19056, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 19057, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 19058, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 19059, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 19060, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 19061, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 19062, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 112\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 19063, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 19064, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 19065, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 134\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 19066, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 131\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 19067, reward 1306.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 19068, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 19069, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 148\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 19070, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 19071, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 19072, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 19073, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 19074, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 19075, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 19076, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 19077, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 114\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 19078, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 19079, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 19080, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 19081, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 128\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 19082, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 19083, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 19084, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 19085, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 19086, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 19087, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 19088, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 19089, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 19090, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 19091, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 19092, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 19093, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 19094, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 19095, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 19096, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 19097, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 19098, reward 541.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 19099, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 19100, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 19101, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 19102, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 19103, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 19104, reward 1453.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 19105, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 19106, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 19107, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 151\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 19108, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 19109, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 19110, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 19111, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 19112, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 157\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 19113, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 20, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19114, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 19115, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 19116, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 19117, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 19118, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 19119, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 19120, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 19121, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 19122, reward 587.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 19123, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 19124, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 19125, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 19126, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 19127, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 19128, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 19129, reward 1310.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 19130, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 19131, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 19132, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 19133, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 19134, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 19135, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 19136, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 19137, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 19138, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 19139, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 19140, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 19141, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 19142, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 19143, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 19144, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 19145, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 19146, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 19147, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 19148, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 19149, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 19150, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 19151, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 19152, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 19153, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 19154, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 122\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 19155, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 19156, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 19157, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 19158, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 19159, reward 503.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 145\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 19160, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 19161, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 19162, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 19163, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 19164, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 19165, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 152\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 19166, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 19167, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 144\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 19168, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 142\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 19169, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 19170, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 138\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 19171, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 19172, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 19173, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 19174, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 19175, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 19176, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 19177, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19178, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 19179, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 19180, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 19181, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 19182, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 19183, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 19184, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 19185, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 19186, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 19187, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 19188, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 19189, reward 517.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 19190, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 19191, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 19192, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 19193, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 19194, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 19195, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 19196, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 19197, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 19198, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 19199, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 19200, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 19201, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 19202, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 19203, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 19204, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 19205, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 19206, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 19207, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 19208, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 19209, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 19210, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 19211, reward 681.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 19212, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 19213, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 19214, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 19215, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 19216, reward 1340.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 19217, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 19218, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 19219, reward 609.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 19220, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 19221, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 19222, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 19223, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 19224, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 19225, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 19226, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 19227, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 19228, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 19229, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 19230, reward 528.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 19231, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 19232, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 19233, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 19234, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 19235, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 19236, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 19237, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 19238, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 19239, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 19240, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 19241, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 12, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19242, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 19243, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 19244, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 19245, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 19246, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 19247, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 19248, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 19249, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 19250, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 19251, reward 547.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 19252, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 19253, reward 1344.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 19254, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 19255, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 19256, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 122\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 19257, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 19258, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 19259, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 19260, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 19261, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 19262, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 19263, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 19264, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 19265, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 148\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 19266, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 19267, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 19268, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 19269, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 19270, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 19271, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 19272, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 19273, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 19274, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 19275, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 145\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 19276, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 153\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 19277, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 19278, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 142\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 19279, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 19280, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 19281, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 19282, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 19283, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 19284, reward 647.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 19285, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 19286, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 19287, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 118\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 19288, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 19289, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 19290, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 19291, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 19292, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 156\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 19293, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 19294, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 19295, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 19296, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 19297, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 19298, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 19299, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 19300, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 19301, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 19302, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 19303, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 19304, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 19305, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [3, 22, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19306, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 19307, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 19308, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 19309, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 19310, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 19311, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 19312, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 19313, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 19314, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 145\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 19315, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 19316, reward 605.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 19317, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 19318, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 19319, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 19320, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 19321, reward 567.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 116\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 19322, reward 450.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 19323, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 151\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 19324, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 19325, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 19326, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 19327, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 19328, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 19329, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 19330, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 19331, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 19332, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 19333, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 19334, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 19335, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 19336, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 19337, reward 501.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 19338, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 19339, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 19340, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 19341, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 19342, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 19343, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 19344, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 19345, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 19346, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 19347, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 19348, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 19349, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 19350, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 19351, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 19352, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 19353, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 19354, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 19355, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 19356, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 19357, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 19358, reward 508.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 19359, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 19360, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 144\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 19361, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 128\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 19362, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 19363, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 19364, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 19365, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 19366, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 19367, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 19368, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 19369, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 11, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19370, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 19371, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 19372, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 19373, reward 1361.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 19374, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 19375, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 19376, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 19377, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 19378, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 19379, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 19380, reward 1357.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 149\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 19381, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 129\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 19382, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 19383, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 19384, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 19385, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 19386, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 19387, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 19388, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 19389, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 19390, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19391, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 19392, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 19393, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 19394, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 19395, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 19396, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 19397, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 19398, reward 546.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 19399, reward 581.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 19400, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 19401, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 19402, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 19403, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 19404, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 19405, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 19406, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 19407, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 19408, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 19409, reward 579.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 118\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 19410, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 19411, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 19412, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 19413, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 19414, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 19415, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 19416, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 19417, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 19418, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 19419, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 19420, reward 511.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 19421, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 19422, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 19423, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 19424, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 19425, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 19426, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 115\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 19427, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 19428, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 19429, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 19430, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 19431, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 150\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 19432, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 19433, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 22, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19434, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 19435, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 19436, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 19437, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 19438, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 19439, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 19440, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 19441, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 19442, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 19443, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 19444, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 19445, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 127\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 19446, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 19447, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 19448, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 19449, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 19450, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 19451, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 19452, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 19453, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 19454, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 19455, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 19456, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 19457, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 19458, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 19459, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 19460, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 19461, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 19462, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 19463, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 19464, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 19465, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 19466, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 19467, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 131\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 19468, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 19469, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 19470, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 19471, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 19472, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 19473, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 134\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 19474, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 19475, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 19476, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 19477, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 19478, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 19479, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 19480, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 19481, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 19482, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 152\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 19483, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 19484, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 19485, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 19486, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 19487, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 19488, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 19489, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 19490, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 19491, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 161\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 19492, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 19493, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 19494, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 19495, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 19496, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 19497, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 2, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19498, reward 744.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 19499, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 19500, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 19501, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 19502, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 19503, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 19504, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 19505, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 149\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 19506, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 19507, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 19508, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 19509, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 19510, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 19511, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 19512, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 19513, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 19514, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 19515, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 142\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 19516, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 19517, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 19518, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 154\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 19519, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 19520, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 19521, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 19522, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 125\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 19523, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 19524, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 19525, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 132\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 19526, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 19527, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 19528, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 19529, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 19530, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 19531, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 19532, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 19533, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 19534, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 19535, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 19536, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 19537, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 19538, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 19539, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 19540, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 19541, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 19542, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 19543, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 19544, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 19545, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 19546, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 19547, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 19548, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 19549, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 19550, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 19551, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 19552, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 19553, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 19554, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 19555, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 19556, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 19557, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 19558, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 19559, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 19560, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 19561, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19562, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 19563, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 19564, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 19565, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 19566, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 19567, reward 1268.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 19568, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 19569, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 19570, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 19571, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 19572, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 19573, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 19574, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 19575, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 19576, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 19577, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 19578, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 19579, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 19580, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 19581, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 19582, reward 548.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 19583, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 19584, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 19585, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 19586, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 19587, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 19588, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 19589, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 19590, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 19591, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19592, reward 1185.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 19593, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 19594, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 19595, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 151\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 19596, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 19597, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 19598, reward 1278.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 19599, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 157\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 19600, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 19601, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 19602, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 19603, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 19604, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 19605, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 19606, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 19607, reward 584.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 19608, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 19609, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 19610, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 19611, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 19612, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 19613, reward 1344.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 19614, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 19615, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 19616, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 19617, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 19618, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 19619, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 19620, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 19621, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 19622, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 19623, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 19624, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 19625, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 19, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19626, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 19627, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 19628, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 19629, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 19630, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 19631, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 19632, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 19633, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 19634, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 19635, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 19636, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 123\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 19637, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 19638, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 19639, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 117\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 19640, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 19641, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 116\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 19642, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 19643, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 19644, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 19645, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 118\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 19646, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 19647, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 19648, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 19649, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 19650, reward 1041.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 19651, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 19652, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 19653, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 19654, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 19655, reward 686.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 19656, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 19657, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 19658, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 19659, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 19660, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 148\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 19661, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 19662, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 19663, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 19664, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 19665, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 19666, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 19667, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 19668, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 19669, reward 649.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 19670, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 19671, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 19672, reward 1457.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 19673, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 19674, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 19675, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 19676, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 19677, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 19678, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19679, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 19680, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 19681, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 19682, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 19683, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 19684, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 19685, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 19686, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 19687, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 19688, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 19689, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 155\n",
      "Initial State is  [0, 8, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19690, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 19691, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 19692, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 19693, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 19694, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19695, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 146\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 19696, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 19697, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 19698, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 19699, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 19700, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 19701, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 19702, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 19703, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 19704, reward 1209.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 19705, reward 1309.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 19706, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 19707, reward 1175.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 19708, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 19709, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 19710, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 19711, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 19712, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 19713, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 19714, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 19715, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 19716, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 19717, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 19718, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 19719, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 19720, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 19721, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 138\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 19722, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 19723, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 19724, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 123\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 19725, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 19726, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 19727, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 19728, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 19729, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 19730, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 19731, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 19732, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 131\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 19733, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 19734, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 123\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 19735, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 119\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 19736, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 19737, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 19738, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 19739, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 19740, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 19741, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 19742, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 19743, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 19744, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19745, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 19746, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 19747, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 19748, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 19749, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 19750, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 19751, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 19752, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 113\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 19753, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 5, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19754, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 19755, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 19756, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 19757, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 19758, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 19759, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 19760, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 19761, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 19762, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 19763, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 142\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 19764, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 19765, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 19766, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 19767, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 19768, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 19769, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 19770, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 19771, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 19772, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 19773, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 19774, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 19775, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 19776, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 19777, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 19778, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 19779, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 19780, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 19781, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 19782, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 19783, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 19784, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 19785, reward 611.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 19786, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 19787, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 144\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 19788, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 19789, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 19790, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 19791, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 19792, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 19793, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 19794, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 19795, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 19796, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 19797, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 19798, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 19799, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 19800, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 19801, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 121\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 19802, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 19803, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 19804, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 19805, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 19806, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 19807, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 19808, reward 578.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 19809, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 19810, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 148\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 19811, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 19812, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 19813, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 19814, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 19815, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 19816, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 19817, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [2, 21, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19818, reward 543.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 19819, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 19820, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 19821, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 19822, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 19823, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 19824, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 139\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 19825, reward 572.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 19826, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 19827, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 19828, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 19829, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 19830, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 19831, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 19832, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 19833, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 19834, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 19835, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 19836, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 19837, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 19838, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 19839, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 155\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 19840, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 19841, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 19842, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 121\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 19843, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 19844, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 19845, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 19846, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 19847, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 19848, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 19849, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 19850, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 19851, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 19852, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 19853, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 19854, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 19855, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 19856, reward 671.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 19857, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 19858, reward 606.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 19859, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 19860, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 19861, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 19862, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 19863, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 19864, reward 1292.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 19865, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 141\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 19866, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 19867, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 19868, reward 745.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 19869, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 19870, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 19871, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 19872, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 147\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 19873, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 19874, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 19875, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 19876, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 154\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 19877, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 19878, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 115\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 19879, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 19880, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 19881, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 22, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19882, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 19883, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 19884, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 19885, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 122\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 19886, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 19887, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 19888, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 19889, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 19890, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 121\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 19891, reward 837.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 19892, reward 588.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 19893, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 19894, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 19895, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 19896, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 19897, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 19898, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 19899, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 136\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 19900, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 19901, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 19902, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 19903, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 19904, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 19905, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 19906, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 19907, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 19908, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 19909, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 19910, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 151\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 19911, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 19912, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 19913, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 19914, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 19915, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 19916, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 19917, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 19918, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 19919, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 19920, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 19921, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 19922, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 141\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 19923, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 19924, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 19925, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 19926, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 19927, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 19928, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 19929, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 19930, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 19931, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 19932, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 19933, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 19934, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 19935, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 121\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 19936, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 19937, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 19938, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 19939, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 19940, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 19941, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 151\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 19942, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 135\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 19943, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 19944, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 19945, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 11, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 19946, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 19947, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 19948, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 19949, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 19950, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 19951, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 19952, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 19953, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 19954, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 19955, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 19956, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 19957, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 19958, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 19959, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 19960, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 19961, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 19962, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 19963, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 19964, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 19965, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 19966, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 19967, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 19968, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 19969, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 19970, reward 668.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 19971, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 19972, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 19973, reward 499.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 19974, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 19975, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 19976, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 19977, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 19978, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 19979, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 19980, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 19981, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 19982, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 19983, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 19984, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 19985, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 19986, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 19987, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 19988, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 19989, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 19990, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 19991, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 19992, reward 1362.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 19993, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 19994, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 19995, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 19996, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 19997, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 19998, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 19999, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(36,21)\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    # Call all the initialised variables of the environment\n",
    "    state_space = env.state_space\n",
    "    action_space = env.action_space\n",
    "    state = env.state_init\n",
    "    print(\"Initial State is \",state)\n",
    "    time = 0\n",
    "    #Call the DQN agent\n",
    "    terminal_state = False\n",
    "    score = 0\n",
    "    action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "    score += env.reward_func(state,action_space[action],Time_matrix)\n",
    "    next_state,ride_time = env.next_state_func(state,action_space[action],Time_matrix)\n",
    "    time += ride_time\n",
    "    if time >= 24*30:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),True)\n",
    "    else:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),False)\n",
    "    loop = 0\n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        \n",
    "        if time >= 24*30:\n",
    "            terminal_state = True\n",
    "            pass\n",
    "        state = next_state\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        reward_curr_ride = env.reward_func(state,action_space[action],Time_matrix)\n",
    "        score+= reward_curr_ride\n",
    "        next_state,ride_time = env.next_state_func(next_state,action_space[action],Time_matrix)\n",
    "        time += ride_time\n",
    "        # 3. Append the experience to the memory\n",
    "        if time >= 24*30:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),True)\n",
    "        else:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),False)\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model(env)\n",
    "        #print('Time elapsed {} and current loop {}'.format(time,loop))\n",
    "        loop+= 1\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "    \n",
    "    rewards_per_episode.append(score)   \n",
    "    episodes.append(episode)\n",
    "    \n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}, time {4}, rides {5}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon,time,loop))\n",
    "    # every few episodes:\n",
    "    if episode % 1000 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "\n",
    "        # save model weights\n",
    "        agent.save(name=\"model_weights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -22.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        23.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        -7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -26.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        17.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -22.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        23.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        -27.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -25.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -2.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -25.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -10.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        27.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -1.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        -12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        17.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        44.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        2.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        11.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -18.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        1.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        -8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -1.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        -2.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        -7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        15.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        27.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        26.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        -12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        14,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        -3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -5.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        13.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        10.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -10.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        14.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        10.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        -40.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        22.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        30.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        -28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        27.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -30.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        11.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        36.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        19.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        -23.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        7,\n",
       "        -20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        40.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        15.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -6.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -15.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        1.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        -1.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        -7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        14,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -15.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        35.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        14,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        -35.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        28.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        -26.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        17.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        -12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -1.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        -22.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -27.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        14.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -36.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        -29.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        14,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        10.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -5.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        13.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        40.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -2.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -23.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        -2.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        -2.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        1.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -26.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        14,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        -8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        31.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        -16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        15.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       ...])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d30124dc48>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes,rewards_per_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon2=[]\n",
    "for i in range(0,10000):\n",
    "    if i==0:\n",
    "        epsilon2.append(1)\n",
    "    else:\n",
    "        epsilon2.append(0.9991 * epsilon2[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
